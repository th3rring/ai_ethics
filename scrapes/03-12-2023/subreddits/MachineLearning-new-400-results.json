{
    "scrape_settings": {
        "subreddit": "MachineLearning",
        "category": "new",
        "n_results_or_keywords": "400",
        "time_filter": null
    },
    "data": [
        {
            "author": "u/jplhughes",
            "created_utc": "03-12-2023 18:27:02",
            "distinguished": null,
            "edited": false,
            "id": "11prxd9",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_11prxd9",
            "nsfw": false,
            "num_comments": 7,
            "permalink": "/r/MachineLearning/comments/11prxd9/r_introducing_ursa_from_speechmatics_25/",
            "score": 26,
            "selftext": "Ursa is the world\u2019s most accurate speech-to-text system and delivers a relative accuracy gain of 22% and 25%\u00a0versus Microsoft and OpenAI's Whisper respectively. \n\nFind out more and try it for free with just one click: [www.speechmatics.com/ursa](http://www.speechmatics.com/ursa) \n\nSpeechmatics achieved this by building on the scaling laws from DeepMind\u2019s Chinchilla paper and applying them to large self-supervised learning models for speech. By scaling to 2 billion parameters, the models can learn richer acoustic features from over 1 million hours of unlabeled multi-lingual data, allowing Ursa to understand a larger spectrum of voices.\n\nhttps://preview.redd.it/y54g784nudna1.png?width=1024&format=png&auto=webp&v=enabled&s=1ed83c647697e2dfb95ed2277377fadc52e4b8f4",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Introducing Ursa from Speechmatics | 25% improvement over Whisper",
            "upvote_ratio": 0.81,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11prxd9/r_introducing_ursa_from_speechmatics_25/"
        },
        {
            "author": "u/fullgoopy_alchemist",
            "created_utc": "03-12-2023 16:00:41",
            "distinguished": null,
            "edited": false,
            "id": "11po6qw",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11po6qw",
            "nsfw": false,
            "num_comments": 8,
            "permalink": "/r/MachineLearning/comments/11po6qw/d_whats_the_mathematical_notation_for_top_k_argmax/",
            "score": 1,
            "selftext": "I'm trying to express something in mathematical notation - let's say I want to get the top k indices for which a function obtains highest values. So, something like argmax, but for a general k number of indices instead of just the top index. Is there a standard notation for this?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] What's the mathematical notation for \"top k argmax\"?",
            "upvote_ratio": 1.0,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11po6qw/d_whats_the_mathematical_notation_for_top_k_argmax/"
        },
        {
            "author": "u/actmademewannakms",
            "created_utc": "03-12-2023 15:42:02",
            "distinguished": null,
            "edited": false,
            "id": "11pnppv",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_11pnppv",
            "nsfw": false,
            "num_comments": 5,
            "permalink": "/r/MachineLearning/comments/11pnppv/p_promptlab_playground_to_test_chains_of_prompts/",
            "score": 14,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[P] PromptLab: playground to test chains of prompts faster",
            "upvote_ratio": 0.77,
            "url": "https://v.redd.it/auvuh5sm2dna1"
        },
        {
            "author": "u/Amazing_Painter_7692",
            "created_utc": "03-12-2023 15:13:24",
            "distinguished": null,
            "edited": false,
            "id": "11pmz69",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_11pmz69",
            "nsfw": false,
            "num_comments": 27,
            "permalink": "/r/MachineLearning/comments/11pmz69/p_discord_chatbot_for_llama_4bit_quantized_that/",
            "score": 156,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Discord Chatbot for LLaMA 4-bit quantized that runs 13b in <9 GiB VRAM",
            "upvote_ratio": 0.97,
            "url": "https://github.com/AmericanPresidentJimmyCarter/yal-discord-bot"
        },
        {
            "author": "u/UnknownInsanity",
            "created_utc": "03-12-2023 13:15:41",
            "distinguished": null,
            "edited": false,
            "id": "11pjxd6",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11pjxd6",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/11pjxd6/dlooking_to_build_an_enthusiastic_community_for/",
            "score": 0,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[D]Looking to build an enthusiastic community for exploring AI",
            "upvote_ratio": 0.21,
            "url": "/r/StableDiffusion/comments/11pj96r/looking_to_build_an_enthusiastic_community_for/"
        },
        {
            "author": "u/AutoModerator",
            "created_utc": "03-12-2023 11:00:25",
            "distinguished": null,
            "edited": false,
            "id": "11pgj86",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11pgj86",
            "nsfw": false,
            "num_comments": 6,
            "permalink": "/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/",
            "score": 13,
            "selftext": "Please post your questions here instead of creating a new thread. Encourage others who create new posts for questions to post here instead!\n\nThread will stay alive until next one so keep posting after the date in the title.\n\nThanks to everyone for answering questions in the previous thread!",
            "spoiler": false,
            "stickied": true,
            "title": "[D] Simple Questions Thread",
            "upvote_ratio": 0.85,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11pgj86/d_simple_questions_thread/"
        },
        {
            "author": "u/Own-Junket-3057",
            "created_utc": "03-12-2023 04:48:20",
            "distinguished": null,
            "edited": false,
            "id": "11p9p67",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11p9p67",
            "nsfw": false,
            "num_comments": 2,
            "permalink": "/r/MachineLearning/comments/11p9p67/d_tracking_dancing_people/",
            "score": 1,
            "selftext": " \n\nHi everyone!\n\nOne interesting problem has been posed to me!\n\nGiven people dancing in a video, tracking a single one. The reference video I have been given is: [https://www.youtube.com/watch?v=g0BvpzR\\_2MQ](https://www.youtube.com/watch?v=g0BvpzR_2MQ).   As you will see in the video, occlusions happen an incredible amount,  and they are all wearing roughly similar clothing. Further, sometimes  the people get off screen, then come back on.\n\nI  have tried many different things, but I am unable to find a good way to  track a single person, as the re-identification is iffy.\n\nAny help would be appreciated!",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Tracking Dancing People",
            "upvote_ratio": 0.66,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11p9p67/d_tracking_dancing_people/"
        },
        {
            "author": "u/fchung",
            "created_utc": "03-12-2023 00:36:15",
            "distinguished": null,
            "edited": false,
            "id": "11p6hjl",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "News",
            "locked": false,
            "name": "t3_11p6hjl",
            "nsfw": false,
            "num_comments": 26,
            "permalink": "/r/MachineLearning/comments/11p6hjl/n_man_beats_machine_at_go_in_human_victory_over/",
            "score": 0,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[N] Man beats machine at Go in human victory over AI : \u00ab It shows once again we\u2019ve been far too hasty to ascribe superhuman levels of intelligence to machines. \u00bb",
            "upvote_ratio": 0.45,
            "url": "https://arstechnica.com/information-technology/2023/02/man-beats-machine-at-go-in-human-victory-over-ai/"
        },
        {
            "author": "u/TeamDman",
            "created_utc": "03-11-2023 21:54:47",
            "distinguished": null,
            "edited": false,
            "id": "11p3a0j",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11p3a0j",
            "nsfw": false,
            "num_comments": 23,
            "permalink": "/r/MachineLearning/comments/11p3a0j/d_finetuning_20b_llms_with_rlhf_on_a_24gb/",
            "score": 138,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Fine-tuning 20B LLMs with RLHF on a 24GB consumer GPU",
            "upvote_ratio": 0.97,
            "url": "https://huggingface.co/blog/trl-peft"
        },
        {
            "author": "u/MRMohebian",
            "created_utc": "03-11-2023 20:40:35",
            "distinguished": null,
            "edited": false,
            "id": "11p1oqq",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_11p1oqq",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/11p1oqq/text2image_controlnet_and_stable_diffusion_r/",
            "score": 1,
            "selftext": "In this tutorial, we will show you how to create beautiful and high-quality images from text using the powerful combination of diffusion model and ControlNet. \n\nText2Image generation is a fascinating field of AI that enables machines to understand and visualize human language in a more creative way.\n\n we will walk you through the step-by-step process of how to use the diffusion model and ControlNet to generate images from text. By the end of this tutorial, you will have a thorough understanding of text2image generation and how to use diffusion model and ControlNet to create stunning images from text. You will also have the knowledge and skills to apply these techniques to your own projects and experiments.\n\n So, get ready to dive into the exciting world of text2image generation and start creating your own beautiful images from text today!\n\nhttps://youtu.be/0D5Nlo2REb0",
            "spoiler": false,
            "stickied": false,
            "title": "Text2Image ControlNet and Stable Diffusion [R]",
            "upvote_ratio": 0.56,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11p1oqq/text2image_controlnet_and_stable_diffusion_r/"
        },
        {
            "author": "u/poppear",
            "created_utc": "03-11-2023 19:07:08",
            "distinguished": null,
            "edited": false,
            "id": "11ozl85",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_11ozl85",
            "nsfw": false,
            "num_comments": 7,
            "permalink": "/r/MachineLearning/comments/11ozl85/p_vanillallama_an_hackable_plainpytorch/",
            "score": 77,
            "selftext": "I put together this plain pytorch implementation of LLaMA (i just substituted the fairscale layers with the native ones and converted the weights accordingly) that can be more easily run in different environments. \n\nThe big problem with the official implementation is that in order to run the 65B version you need 8 GPUs no matter what, and to run the 30B version you need 4 and so on. In reality you can easily fit the 65B version in 2 A100 with 100G of VRAM.\n\nvanilla-llama solves this problem. You just need to have enough memory and the model will be load in all the available GPUs.\n\n&#x200B;\n\n[https://github.com/galatolofederico/vanilla-llama](https://github.com/galatolofederico/vanilla-llama)",
            "spoiler": false,
            "stickied": false,
            "title": "[P] vanilla-llama an hackable plain-pytorch implementation of LLaMA that can be run on any system (if you have enough resources)",
            "upvote_ratio": 0.95,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11ozl85/p_vanillallama_an_hackable_plainpytorch/"
        },
        {
            "author": "u/XiaolongWang",
            "created_utc": "03-11-2023 18:25:53",
            "distinguished": null,
            "edited": false,
            "id": "11oykrc",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_11oykrc",
            "nsfw": false,
            "num_comments": 12,
            "permalink": "/r/MachineLearning/comments/11oykrc/r_odise_stable_diffusion_but_for_openvocabulary/",
            "score": 286,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] ODISE: Stable Diffusion but for Open-Vocabulary Segmentation and Detection",
            "upvote_ratio": 0.98,
            "url": "https://v.redd.it/80li1jvt17na1"
        },
        {
            "author": "u/CeFurkan",
            "created_utc": "03-11-2023 14:10:07",
            "distinguished": null,
            "edited": false,
            "id": "11os9wy",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11os9wy",
            "nsfw": false,
            "num_comments": 7,
            "permalink": "/r/MachineLearning/comments/11os9wy/d_what_model_methodology_is_state_of_the_art_to/",
            "score": 1,
            "selftext": "I am trying to calculate similarity of given 2 images.\n\nI want to utilize this for calculating similarity of different clothes.\n\nSo what is the state of the art methodology / AI model to calculate?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] What model, methodology is state of the art to calculate similarity of given 2 images?",
            "upvote_ratio": 0.57,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11os9wy/d_what_model_methodology_is_state_of_the_art_to/"
        },
        {
            "author": "u/jacobgil",
            "created_utc": "03-11-2023 13:36:07",
            "distinguished": null,
            "edited": "03-11-2023 14:12:10",
            "id": "11orezx",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_11orezx",
            "nsfw": false,
            "num_comments": 8,
            "permalink": "/r/MachineLearning/comments/11orezx/p_introducing_confidenceinterval_the_long_missing/",
            "score": 104,
            "selftext": "[https://github.com/jacobgil/confidenceinterval](https://github.com/jacobgil/confidenceinterval)\n\npip install confidenceinterval\n\ntldr: You don't have an excuse anymore to not use confidence intervals !\n\n&#x200B;\n\nIn statistics, confidence intervals are commonly reported along accuracy metrics to help interpret them.\n\nFor example, an AUC metric might be 0.9 but if the 95% confidence interval is in the range \\[0.7, 0.96\\], we can't confidently say we didn't just get lucky - we should be really careful making decisions around that result.\n\nMore formally, a confidence interval gives us a range on where the true unknown accuracy metric could be, and a 95% confidence interval means that if we would repeat the experiment many times, 95% of the confidence-intervals we reported would have the actual true metric (which is unknown) inside them - coverage.\n\nConfidence intervals are usually computed analytically, by making some assumptions about the metric distribution and using the central limit theorem,or by using bootstrapping - resampling the results again and again, computing the metric, and checking the resulting distribution.\n\nHowever, in the python data science world, I rarely saw these being used. I guess part of the reason is the culture, where many data science practitioners don't come from the statistics world. But I think the main reason is that there aren't easy to use libraries that do this. While in the R language there is fantastic support for confidence intervals, for python there are mostly scattered pieces of code and blog posts.\n\n&#x200B;\n\nThe confidenceinterval package keeps the clean and popular scikit-learn metric API,\n\ne.g roc\\_auc\\_score(y\\_true, y\\_pred), but also returns confidence intervals.\n\nIt supports analytical computations for many methods (including AUC with the delong method, or F1 with macro, micro averaging, following the recent results from [https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8936911/#APP2](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8936911/#APP2), or binary proportions like the TPR using binomial CI methods like the wilson interval).\n\nIt can be easily switched to using bootstrapping (with several supported bootstrapping methods),\n\nand also gives you a way to easily compute the confidence interval for any metric with bootstrapping.",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Introducing confidenceinterval, the long missing python library for computing confidence intervals",
            "upvote_ratio": 0.99,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11orezx/p_introducing_confidenceinterval_the_long_missing/"
        },
        {
            "author": "u/ng_guardian",
            "created_utc": "03-11-2023 13:24:27",
            "distinguished": null,
            "edited": false,
            "id": "11or4qb",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11or4qb",
            "nsfw": false,
            "num_comments": 8,
            "permalink": "/r/MachineLearning/comments/11or4qb/d_statsmodels_arima_model_predict_function_not/",
            "score": 0,
            "selftext": "I trained my ARIMA model by doing the following\n\n`from statsmodels.tsa.arima.model import ARIMA`\n\n`model_ar = ARIMA(data.Num_Passengers, order=(1,0, 0))`\n\n`results_ar = model_ar.fit()results_ar.summary()`\n\n&#x200B;\n\nThe code worked with the resulting output\n\n&#x200B;\n\nhttps://preview.redd.it/zi8f1lhak5na1.png?width=746&format=png&auto=webp&v=enabled&s=3f5ef9fe1504892e4ce48b5287d8b834f1dfdb27\n\nBut then I tried predicting on the testing dataset, and I got the following error.\n\n&#x200B;\n\nhttps://preview.redd.it/uni7ws1ck5na1.png?width=1675&format=png&auto=webp&v=enabled&s=ce520334f3b1e420a101adda9f43868714617272\n\nAm I just messing something up, is anyone else dealing with this error?\n\nIs there another way to use the predict function, or is it really unimplemented.\n\nCould you please help me out with this?\n\nHow would I overwrite the method?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Statsmodels ARIMA model predict function not working",
            "upvote_ratio": 0.4,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11or4qb/d_statsmodels_arima_model_predict_function_not/"
        },
        {
            "author": "u/aliwissam",
            "created_utc": "03-11-2023 12:58:33",
            "distinguished": null,
            "edited": false,
            "id": "11oqhhj",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11oqhhj",
            "nsfw": false,
            "num_comments": 5,
            "permalink": "/r/MachineLearning/comments/11oqhhj/d_looking_for_eye_gaze_detection_dataset/",
            "score": 0,
            "selftext": " I have a project in my university where i have to make a CNN able to predict where the person is looking on a laptop screen using the webcam of the laptop, does anyone know where i can find data sets that can help me train the network",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Looking for eye gaze detection dataset",
            "upvote_ratio": 0.5,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11oqhhj/d_looking_for_eye_gaze_detection_dataset/"
        },
        {
            "author": "u/jazzjamplatform",
            "created_utc": "03-11-2023 12:13:54",
            "distinguished": null,
            "edited": false,
            "id": "11opf45",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_11opf45",
            "nsfw": false,
            "num_comments": 3,
            "permalink": "/r/MachineLearning/comments/11opf45/p_i_built_a_chatgpt_podcast_studio_to_produce/",
            "score": 0,
            "selftext": "&#x200B;\n\nhttps://reddit.com/link/11opf45/video/xwn9kurp75na1/player",
            "spoiler": false,
            "stickied": false,
            "title": "[p] I built a ChatGPT podcast studio to produce random audio podcasts for me lol. https://aipodcastmania.web.app/",
            "upvote_ratio": 0.41,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11opf45/p_i_built_a_chatgpt_podcast_studio_to_produce/"
        },
        {
            "author": "u/onebigcat",
            "created_utc": "03-11-2023 11:01:01",
            "distinguished": null,
            "edited": false,
            "id": "11onol2",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11onol2",
            "nsfw": false,
            "num_comments": 8,
            "permalink": "/r/MachineLearning/comments/11onol2/d_unsupervised_learning_have_there_been_any_big/",
            "score": 7,
            "selftext": "I feel like unsupervised learning models have always been the less-sexy part of machine learning. There's been some interesting solutions like scBERT and others in the space of single-cell RNAseq, but other than that it seems like clustering, dimensionality reduction, etc, has been mostly the same for years now.\n\nWhat big stuff has come out, and what's on the radar?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Unsupervised Learning \u2014 have there been any big advances recently?",
            "upvote_ratio": 0.71,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11onol2/d_unsupervised_learning_have_there_been_any_big/"
        },
        {
            "author": "u/SpatialComputing",
            "created_utc": "03-11-2023 08:54:26",
            "distinguished": null,
            "edited": false,
            "id": "11okrp0",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_11okrp0",
            "nsfw": false,
            "num_comments": 3,
            "permalink": "/r/MachineLearning/comments/11okrp0/r_neural_radiance_fields_for_street_views/",
            "score": 49,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] neural radiance fields for street views",
            "upvote_ratio": 0.97,
            "url": "https://v.redd.it/9ixkppr7iwma1"
        },
        {
            "author": "u/Simusid",
            "created_utc": "03-11-2023 08:54:22",
            "distinguished": null,
            "edited": false,
            "id": "11okrni",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11okrni",
            "nsfw": false,
            "num_comments": 48,
            "permalink": "/r/MachineLearning/comments/11okrni/discussion_compare_openai_and_sentencetransformer/",
            "score": 478,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[Discussion] Compare OpenAI and SentenceTransformer Sentence Embeddings",
            "upvote_ratio": 0.94,
            "url": "https://i.redd.it/7muze2s684na1.png"
        },
        {
            "author": "u/Soft-Material3294",
            "created_utc": "03-11-2023 08:24:02",
            "distinguished": null,
            "edited": false,
            "id": "11ok44i",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_11ok44i",
            "nsfw": false,
            "num_comments": 3,
            "permalink": "/r/MachineLearning/comments/11ok44i/p_detailed_explanation_of_how_alphafold_works/",
            "score": 24,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Detailed Explanation of how AlphaFold Works, Protein Folding and Design",
            "upvote_ratio": 1.0,
            "url": "https://medium.com/@universvm/how-to-solve-the-protein-folding-problem-alphafold2-6c81faba670d"
        },
        {
            "author": "u/madredditscientist",
            "created_utc": "03-11-2023 07:42:26",
            "distinguished": null,
            "edited": false,
            "id": "11oj9pm",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_11oj9pm",
            "nsfw": false,
            "num_comments": 24,
            "permalink": "/r/MachineLearning/comments/11oj9pm/p_ask_a_subreddit_the_collective_gptembodied/",
            "score": 180,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Ask a subreddit - The collective GPT-embodied wisdom of Reddit communities",
            "upvote_ratio": 0.94,
            "url": "https://v.redd.it/90yvvpkou3na1"
        },
        {
            "author": "u/takeafuckinsipp",
            "created_utc": "03-11-2023 05:50:43",
            "distinguished": null,
            "edited": false,
            "id": "11oh727",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11oh727",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/11oh727/d_input_size_equal_to_seasonality_for_timeseries/",
            "score": 3,
            "selftext": "When doing timeseries forecasting with models like NHits or NBEATS, does it make sense to set the model's input size according to the seasonality of the timeseries? Does it improve performance empirically?\n\nFor example NBEATS uses a \"seasonality block\" for interpretable forecasting and one would expect that this is where the seasonality is learnt. Then does it make sense to have a variable input size to the model where we find the seasonality length and use that as the size of the input window that the model sees?\n\nWould this scheme actually improve performance or is it just the increase in input size that might lead to better results?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Input size equal to seasonality for timeseries forecasting",
            "upvote_ratio": 0.8,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11oh727/d_input_size_equal_to_seasonality_for_timeseries/"
        },
        {
            "author": "u/gokulPRO",
            "created_utc": "03-11-2023 05:45:44",
            "distinguished": null,
            "edited": false,
            "id": "11oh450",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11oh450",
            "nsfw": false,
            "num_comments": 7,
            "permalink": "/r/MachineLearning/comments/11oh450/d_is_pytorch_lightning_wandb_a_good_combination/",
            "score": 0,
            "selftext": "I am planning on moving from Pytorch to Lightning for more structured research. Is lightning + Wandb a good combination in the long run for research experimentations? Which tech stack do you use for research? And for code version control, what do you use? Also, for Kaggle, is it a good choice to use lightning and Wandb? Thank you",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Is Pytorch Lightning + Wandb a good combination for research?",
            "upvote_ratio": 0.5,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11oh450/d_is_pytorch_lightning_wandb_a_good_combination/"
        },
        {
            "author": "u/science-raven",
            "created_utc": "03-10-2023 23:14:33",
            "distinguished": null,
            "edited": false,
            "id": "11oaek2",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11oaek2",
            "nsfw": false,
            "num_comments": 10,
            "permalink": "/r/MachineLearning/comments/11oaek2/d_development_challenges_of_an_autonomous/",
            "score": 17,
            "selftext": "Why do some folk think that this futuristic type of robot can't logically achieve a broad array of stated ML tasks?\n\n[https://youtu.be/EYTiTh7\\_zO4](https://youtu.be/EYTiTh7_zO4)\n\nI see the dev cost of this robot as being 100 times less than a self-driving car: single error fatality risk, unlimited chaotic cities, 90mph compute time limits, make self-driving cars unfeasible compared to multitask garden robots. \n\nFruit-picking is very difficult using AI, but weeding, digging, sowing seeds, irrigation, are fairly easy tasks, and an experienced developer knows that anything is possible with logic.\n\nMillions of acres of farmland are chemically and brutally treated for food that is wrapped in plastic, shipped hundreds of miles, to supermarkets, so as an environmental chemist, rural processes analyst and EE dabbler, I have created an emulator prototype for a garden robot :)",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Development challenges of an autonomous gardening robot using object detection and mapping.",
            "upvote_ratio": 0.95,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11oaek2/d_development_challenges_of_an_autonomous/"
        },
        {
            "author": "u/NovelspaceOnly",
            "created_utc": "03-10-2023 22:12:17",
            "distinguished": null,
            "edited": false,
            "id": "11o97on",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_11o97on",
            "nsfw": false,
            "num_comments": 25,
            "permalink": "/r/MachineLearning/comments/11o97on/p_gitmodel_dynamically_generate_highquality/",
            "score": 108,
            "selftext": "Decompose Python libraries and generate Coherent hierarchical topic models of the repository.  \n[https://github.com/danielpatrickhug/GitModel](https://github.com/danielpatrickhug/GitModel)\n\nThe ability to bootstrap its own codebase is a powerful feature as it allows for efficient self-improvement and expansion. It means that the codebase is designed in such a way that it can use its own output as an input to improve itself. In the context of GitModel, this feature allows for the efficient improvement and expansion of its own codebase. By using its own output to generate hierarchical topic trees of GitHub repositories, it can analyze and extract insights from its own codebase and other codebases to improve its functionality. This can lead to more efficient and effective code generation, better semantic graph generation, and improved text generation capabilities.\n\n  \nI spent around 10 hours today on a major refactor creating a simple pipeline abstraction and allowing dynamic instantiation from yaml configs. It now also supports multiple GNN heads.\n\nPlease try it out and let me know what you think!\n\nExample:  \n[https://github.com/deepmind/clrs](https://github.com/deepmind/clrs)\n\nhttps://preview.redd.it/ut4fc6c401na1.png?width=1506&format=png&auto=webp&v=enabled&s=b039242432c1f0526d1d81eadbfe8abc1168d2fd",
            "spoiler": false,
            "stickied": false,
            "title": "[P] GITModel: Dynamically generate high-quality hierarchical topic tree representations of GitHub repositories using customizable GNN message passing layers, chatgpt, and topic modeling.",
            "upvote_ratio": 0.93,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11o97on/p_gitmodel_dynamically_generate_highquality/"
        },
        {
            "author": "u/Character-Capital-70",
            "created_utc": "03-10-2023 21:52:36",
            "distinguished": null,
            "edited": "03-10-2023 22:42:22",
            "id": "11o8tgd",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11o8tgd",
            "nsfw": false,
            "num_comments": 2,
            "permalink": "/r/MachineLearning/comments/11o8tgd/d_one_shot_learning_tasks/",
            "score": 2,
            "selftext": "From my understanding, a one shot learning task requires us that given a query example, we must classify it correctly out of N different classes (typically N = 5 way or 20 way). The goal however is that we are provided with only one example per class.\n\nSuppose we take an MNIST type dataset. I can map every pixel that makes up the digit onto a cartesian plane where the xy coordinates values is every \"pixel\". Using this cartesian representation, can I just find the simple distance metric between the pairs? For example on a 20 way task, My question is: At each iteration, we are provided with some query example, along with 20 other candidates...if we compute some sort of simple similarity score (that doesnt require neural nets) like (intersection over union) between each candidate to query pair, does this still count as a one shot learning task?\n\nSo leaving aside a neural network approach, if we were to just use a simple distance metric on the coordinates to compute the pairwise similarity between the query and every \"candidate\", does this count as one shot learning?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] One Shot Learning Tasks",
            "upvote_ratio": 1.0,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11o8tgd/d_one_shot_learning_tasks/"
        },
        {
            "author": "u/glassAlloy",
            "created_utc": "03-10-2023 16:47:05",
            "distinguished": null,
            "edited": false,
            "id": "11o1vjw",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11o1vjw",
            "nsfw": false,
            "num_comments": 5,
            "permalink": "/r/MachineLearning/comments/11o1vjw/d_what_improvements_accelerate_the_ai_field/",
            "score": 0,
            "selftext": "These are just my perspectives, I am curious to hear how other people see it in the comments.\n\n  \nFrom my perspective there are the following improvements that accelerate AI reserch with multiple orders of magnitude every year:\n\n1.) Low barrier to entrance for researchers as hugging face, kaggle, google colab gives you free resources (CPU,RAM,GPU,TPU) to study\n\n2.) More efficient models: with smaller models reproducing similar results as larger counterpart a good example is Open AI DALL-E vs stable diffusion.\n\n3.) More efficient techniques: Ex changing computation from FP32 -> FP 16 in Nvidia GPUs\n\n4.) Cleaner better labeled data by the community\n\n4.) More efficient underlying programing language optimizations\n\n5.) Rewritten more efficient code\n\n6.) New hardware\n\n7.) Special purpose hardware (while for gaming and other general purpose benchmarks there are 20-30% improvements every year or every 2 years) for AI reserch TENSOR cores (Nvidia GPUs, Google Cloud TPUs) or apple's Neural engines are orders of magnitude of speed improvement for AI models. Or many supercomputers are ARM based (that is not fully related to here but overall great architectural changes).\n\n8.) New hardware types: analog processors might make a comeback soon that helps calculate floating point operations faster for neural nets. (others: Intelligence Processing Unit, Hogel processing unit (HPU) )\n\n9.) Just the number of new professionals/researchers entering different fields of the AI game. University Majors, online courses, jobs ...\n\n10.) Money/funding.\n\n11.) Becoming culturally mainstream, non professionals realizing that they use it every day.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] What Improvements Accelerate the AI field Multiple orders of magnitude every year?",
            "upvote_ratio": 0.5,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11o1vjw/d_what_improvements_accelerate_the_ai_field/"
        },
        {
            "author": "u/FlamingUnicorns",
            "created_utc": "03-10-2023 14:30:17",
            "distinguished": null,
            "edited": false,
            "id": "11nyeem",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11nyeem",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/11nyeem/d_what_are_the_inputs_to_a_model_that_plays/",
            "score": 6,
            "selftext": "I am familiar with writing networks to play games that have very defined inputs such as Snake or tic tac toe. But what are the inputs for games where units and buildings are constantly being spawned/destroyed? I assume the amount of parameters in the input layer cant be dynamically changing so how do the models handle this? Whats the input difference from a game state with 5 enemies revealed vs. a game state with 100 units revealed?\n\nI assume there is a lot of \"hand waiving\" going on in the input layer and its not getting the position of every unit in the game but Im not sure. Any insight would be great!",
            "spoiler": false,
            "stickied": false,
            "title": "[D] What are the Inputs to a Model That Plays Dynamic RTS Games Like StarCraft?",
            "upvote_ratio": 0.75,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11nyeem/d_what_are_the_inputs_to_a_model_that_plays/"
        },
        {
            "author": "u/Ill_Relationship_547",
            "created_utc": "03-10-2023 13:43:07",
            "distinguished": null,
            "edited": "03-10-2023 14:00:20",
            "id": "11nx6ak",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_11nx6ak",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/11nx6ak/p_frouros_a_python_library_for_drift_detection_in/",
            "score": 11,
            "selftext": "Hey everyone!\n\nI want to share with you an open-source library that we've been building for a while. Frouros: A Python library for drift detection in machine learning problems.\n\n[https://github.com/IFCA/frouros](https://github.com/IFCA/frouros)\n\nFrouros implements multiple methods capable of detecting both concept and data drift with a simple, flexible and extendable API. It is intended to be used in conjunction with any machine learning library/framework, therefore is framework-agnostic, although it could also be used for non machine learning problems.\n\nMoreover, Frouros offers the well-known concept of callbacks that is included in libraries like Keras or PyTorch Lightning. This makes it simple to run custom user code at certain points (e.g., on\\_drift\\_detected, on\\_update\\_start, on\\_update\\_end).\n\nWe are currently working on including more examples in the documentation to show what can be done with Frouros.\n\nI would appreciate any feedback you could provide us!",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Frouros: A Python library for drift detection in Machine Learning problems",
            "upvote_ratio": 0.93,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11nx6ak/p_frouros_a_python_library_for_drift_detection_in/"
        },
        {
            "author": "u/ustainbolt",
            "created_utc": "03-10-2023 10:14:36",
            "distinguished": null,
            "edited": false,
            "id": "11nrrx6",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_11nrrx6",
            "nsfw": false,
            "num_comments": 3,
            "permalink": "/r/MachineLearning/comments/11nrrx6/p_counterpoint_a_generative_model_for_fugues_and/",
            "score": 6,
            "selftext": "Samples can be found [here](https://soundcloud.com/loua19/sets/bach-ai-chorales) and [here](https://soundcloud.com/loua19/sets/bach-ai-fugues). See how they compare to the original [chorales](https://www.youtube.com/watch?v=rXZBxlVQkjE) and [fugues](https://www.youtube.com/watch?v=w76Bsxs6qvc).\n\nThe model uses a Transformer encoder architecture to complete partially corrupted sequences representations of music. A version of Gibbs sampling is then used to construct new music from scratch. The entire model was trained in under 30 minutes on a single Tesla V100 - really showcasing the efficiency of Transformers in general.\n\nNote that the fugue samples are seeded by the first three bars of an actual Bach fugue. The chorales are generated completely from scratch!\n\nFor more information on how it works - see the [GitHub repo](https://github.com/loua19/counterpoint) or follow me on [Twitter](https://twitter.com/loua42).",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Counterpoint - a generative model for Fugues and Chorales in the style of J.S. Bach (with samples)",
            "upvote_ratio": 0.99,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11nrrx6/p_counterpoint_a_generative_model_for_fugues_and/"
        },
        {
            "author": "u/bo_peng",
            "created_utc": "03-10-2023 09:59:31",
            "distinguished": null,
            "edited": "03-11-2023 03:19:53",
            "id": "11nre6t",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_11nre6t",
            "nsfw": false,
            "num_comments": 29,
            "permalink": "/r/MachineLearning/comments/11nre6t/p_rwkv_14b_is_a_strong_chatbot_despite_only/",
            "score": 221,
            "selftext": "The latest CharRWKV v2 has a new chat prompt (works for any topic), and here are some raw user chats with RWKV-4-Pile-14B-20230228-ctx4096-test663 model (topp=0.85, temp=1.0, presence penalty 0.2, frequency penalty 0.5). You are welcome to try ChatRWKV v2:  [https://github.com/BlinkDL/ChatRWKV](https://github.com/BlinkDL/ChatRWKV)\n\nAnd please keep in mind that RWKV is 100% RNN :) Pile v1 date cutoff is year 2020.\n\n[Chat #1](https://preview.redd.it/ripvptomexma1.png?width=438&format=png&auto=webp&v=enabled&s=29ed1cd499dc4d693dee32ad7550a7910402d033)\n\n[Chat #2](https://preview.redd.it/8t75njnnexma1.png?width=438&format=png&auto=webp&v=enabled&s=d20186f2e423d321817b79e6e559dc74a42bf0b8)\n\nThese are surprisingly good because RWKV is only trained on the Pile (and 100% RNN). No finetuning. No instruct tuning. No RLHF. You are welcome to try it.\n\n1. Update ChatRWKV v2 \\[and rwkv pip package\\] to latest version.\n2. Use  [https://huggingface.co/BlinkDL/rwkv-4-pile-14b/blob/main/RWKV-4-Pile-14B-20230228-ctx4096-test663.pth](https://huggingface.co/BlinkDL/rwkv-4-pile-14b/blob/main/RWKV-4-Pile-14B-20230228-ctx4096-test663.pth)\n3. Run v2/chat.py and enjoy.\n\nChatRWKV v2 supports INT8 now (with my crappy slow quantization, **works for windows, supports any GPU**, 16G VRAM for 14B if you offload final layer to CPU). And you can offload more layers to CPU to run it with 3G VRAM though that will be very slow :) More optimizations are coming.\n\nOr you can try the 7B model (less coherency) and 3B model (not very coherent, but still fun).",
            "spoiler": false,
            "stickied": false,
            "title": "[P] RWKV 14B is a strong chatbot despite only trained on Pile (16G VRAM for 14B ctx4096 INT8, more optimizations incoming)",
            "upvote_ratio": 0.96,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11nre6t/p_rwkv_14b_is_a_strong_chatbot_despite_only/"
        },
        {
            "author": "u/OpenDR_H2020_Project",
            "created_utc": "03-10-2023 09:55:10",
            "distinguished": null,
            "edited": false,
            "id": "11nrako",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11nrako",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/11nrako/d_version_21_of_the_open_deep_learning_toolkit/",
            "score": 18,
            "selftext": "The latest version of the  Open Deep Learning Toolkit for Robotics, **Version 2.1 is already available !**\n\n This new version includes the following updates:\n\n**New Features:**\n\n* Added Efficient LiDAR Panoptic Segmentation\n* Added Nanodet 2D Object Detection tool\u00a0\n* Added C API implementations of NanoDet 2D Object Detection tool\n* Added C API implementations of forward pass of DETR 2D Object Detection tool\n* Added C API implementations of forward pass of DeepSORT 2D Object Tracking tool\u00a0\n* Added C API implementations of forward pass of Lightweight OpenPose, Pose Estimator tool\n* Added C API implementations of forward pass of X3D 2D Activity Recognition tool\u00a0\n* Added C API implementations of forward pass of Progressive Spatiotemporal GCN Skeleton-based Action Recognition tool\n* Added Binary High Resolution Analysis tool\n* Added Multi-Object-Search tool\u00a0\n\n***Enhancements***\n\n* Added support in C API for detection target structure and vector of detections\u00a0\n* Added support in C API for tensor structure and vector of tensors\n* Added support in C API for json parser\u00a0 \n\n You can download the toolkit here:  \n\\- GitHub: [https://github.com/opendr-eu/opendr](https://github.com/opendr-eu/opendr)  \n\\- pip: [https://pypi.org/project/opendr-toolkit/](https://pypi.org/project/opendr-toolkit/)  \n\\- Docker Hub: [https://hub.docker.com/r/opendr/opendr-toolkit/tags](https://hub.docker.com/r/opendr/opendr-toolkit/tags) \n\nLooking forward for your comments and suggestions!",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Version 2.1 of the Open Deep Learning Toolkit for Robotics is already available!",
            "upvote_ratio": 0.89,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11nrako/d_version_21_of_the_open_deep_learning_toolkit/"
        },
        {
            "author": "u/blabboy",
            "created_utc": "03-10-2023 06:30:39",
            "distinguished": null,
            "edited": false,
            "id": "11nmmjw",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_11nmmjw",
            "nsfw": false,
            "num_comments": 9,
            "permalink": "/r/MachineLearning/comments/11nmmjw/r_gigagan_scaling_up_gans_for_texttoimage/",
            "score": 120,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] GigaGAN: Scaling up GANs for Text-to-Image Synthesis",
            "upvote_ratio": 0.97,
            "url": "https://arxiv.org/abs/2303.05511"
        },
        {
            "author": "u/1azytux",
            "created_utc": "03-10-2023 05:14:01",
            "distinguished": null,
            "edited": false,
            "id": "11nl766",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11nl766",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/11nl766/recent_advances_in_multimodal_models_what_are/",
            "score": 14,
            "selftext": "Hi everyone,\n\nI'm interested in learning more about recent advances in multimodal models, particularly chain of thoughts models. I'm curious to know what people working in this field are most excited about and what ideas and papers have inspired them.\n\nSpecifically, I'm interested in learning about:\n\n- The latest research on multimodal models, especially chain of thoughts models\n- The challenges that researchers are currently facing when developing these models\n- How researchers are addressing these challenges\n- What researchers are most excited about when it comes to the potential applications of these models\n\nIf you work on multimodal models, I'd love to hear your thoughts and insights. What papers have been particularly inspiring or influential? What challenges are you currently facing, and how are you addressing them? What are you most excited about when it comes to the future of multimodal models?\n\nThank you in advance for your responses :)",
            "spoiler": false,
            "stickied": false,
            "title": "Recent advances in multimodal models: What are your thoughts on chain of thoughts models? [D]",
            "upvote_ratio": 0.82,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11nl766/recent_advances_in_multimodal_models_what_are/"
        },
        {
            "author": "u/TheStartIs2019",
            "created_utc": "03-10-2023 03:50:32",
            "distinguished": null,
            "edited": false,
            "id": "11njpb9",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11njpb9",
            "nsfw": false,
            "num_comments": 143,
            "permalink": "/r/MachineLearning/comments/11njpb9/d_is_ml_a_big_boys_game_now/",
            "score": 158,
            "selftext": "As much as I enjoy ML as a whole, I am a bit skeptical of the future for individuals. With OpenAI trying to monopolize the market along with Microsoft, which part remains for the small time researchers/developers?\n\nIt seems everything now is just a ChatGPT wrapper, and with GPT-4 around the corner I assume itll be even more prominent.\n\nWhat are your thoughts?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Is ML a big boys game now?",
            "upvote_ratio": 0.82,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11njpb9/d_is_ml_a_big_boys_game_now/"
        },
        {
            "author": "u/zhangboknight",
            "created_utc": "03-10-2023 03:38:05",
            "distinguished": null,
            "edited": "03-10-2023 04:05:39",
            "id": "11njhnz",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_11njhnz",
            "nsfw": false,
            "num_comments": 4,
            "permalink": "/r/MachineLearning/comments/11njhnz/r_rodin_a_generative_model_for_sculpting_3d/",
            "score": 33,
            "selftext": "We, the team from Microsoft Research, propose a diffusion-based generative model to automatically produces highly detailed 3D digital avatars. The generated avatars can be freely viewed in 360 degrees with unprecedented quality. The model significantly accelerates the traditionally sophisticated 3D modeling process and opens new opportunities for 3D artists. The work has been accepted to CVPR 2022.\n\nProject page: [https://3d-avatar-diffusion.microsoft.com/](https://3d-avatar-diffusion.microsoft.com/)\n\nArxiv paper link: [https://arxiv.org/abs/2212.06135](https://arxiv.org/abs/2212.06135)\n\n[360-degree renderable avatar](https://reddit.com/link/11njhnz/video/3bhbf5x7evma1/player)\n\nOne can use a user-given image or natural language prompt to produce a personalized avatar.\n\n[Text-conditioned avatar generation.](https://preview.redd.it/yp32l7u6fvma1.png?width=2778&format=png&auto=webp&v=enabled&s=e8699c81e0750084209c2d2f6b94a7df117fcf78)\n\nWhile this work is validated on 3D avatar generation, as a broader impact, we hope this work paves the way toward building a 3D generative foundation model for general 3D objects.",
            "spoiler": false,
            "stickied": false,
            "title": "[R] RODIN: A Generative Model for Sculpting 3D Digital Avatars Using Diffusion",
            "upvote_ratio": 0.86,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11njhnz/r_rodin_a_generative_model_for_sculpting_3d/"
        },
        {
            "author": "u/Tin_Ng",
            "created_utc": "03-10-2023 03:17:44",
            "distinguished": null,
            "edited": false,
            "id": "11nj58o",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_11nj58o",
            "nsfw": false,
            "num_comments": 4,
            "permalink": "/r/MachineLearning/comments/11nj58o/p_implementing_vision_transformer_vit_from/",
            "score": 72,
            "selftext": "I recently delved into the world of transformers and their application to vision tasks.\n\nAs part of my learning process, I implemented the Vision Transformer (ViT) from scratch using PyTorch. I am sharing my implementation and a step-by-step guide to implementing the model in this post.\n\nI hope you find it helpful.\n\nGithub: [https://github.com/tintn/vision-transformer-from-scratch](https://github.com/tintn/vision-transformer-from-scratch)\n\nPost: [https://medium.com/towards-data-science/implementing-vision-transformer-vit-from-scratch-3e192c6155f0](https://medium.com/towards-data-science/implementing-vision-transformer-vit-from-scratch-3e192c6155f0)",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Implementing Vision Transformer (ViT) from Scratch using PyTorch",
            "upvote_ratio": 0.87,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11nj58o/p_implementing_vision_transformer_vit_from/"
        },
        {
            "author": "u/New_Yak1645",
            "created_utc": "03-10-2023 01:53:27",
            "distinguished": null,
            "edited": false,
            "id": "11nhl03",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11nhl03",
            "nsfw": false,
            "num_comments": 8,
            "permalink": "/r/MachineLearning/comments/11nhl03/d_is_it_possible_to_train_llama/",
            "score": 0,
            "selftext": "Most AI is impossible to train(like chat GPT)\n\nDose LLaMa can be trained? \n\nAlthough the dataset is very hard to get, It would be nice if LLaMa can be trained.\n\nWhen searching for reddit, this topic cannot be searched, so I hope it becomes a discuss about HW or availability.  \nThank you.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Is it possible to train LLaMa?",
            "upvote_ratio": 0.36,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11nhl03/d_is_it_possible_to_train_llama/"
        },
        {
            "author": "u/noelgaIIagher",
            "created_utc": "03-09-2023 23:15:10",
            "distinguished": null,
            "edited": false,
            "id": "11ned6g",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11ned6g",
            "nsfw": false,
            "num_comments": 10,
            "permalink": "/r/MachineLearning/comments/11ned6g/d_neuron_modeling/",
            "score": 12,
            "selftext": "Disclaimer : I am just a SWE who only knows some basic concepts of NN and ML, so I might be talking total garbage here.\n\nRecently, I read the news that the organoid made from brain cells can now play a simple game. Since it was made from the real neurons, it was way more efficient in learning.\n\nIf we think about it, our brain is very small and consumes comparably lower power, but still we are pretty smarter than the most of ai models powered by 1000s of gpus.\n\nI was wondering if there are any interesting research papers that actually try to model a human neuron. Btw I am not talking about a neural network itself. I feel like we are over simplifying a neuron as just a number while it can be an object that contains interesting features of our real neurons.\n\nI would really appreciate it if anyone could recommend any related research papers to read!",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Neuron Modeling",
            "upvote_ratio": 0.71,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11ned6g/d_neuron_modeling/"
        },
        {
            "author": "u/Singularian2501",
            "created_utc": "03-09-2023 13:30:58",
            "distinguished": null,
            "edited": false,
            "id": "11mzqxu",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "News",
            "locked": false,
            "name": "t3_11mzqxu",
            "nsfw": false,
            "num_comments": 81,
            "permalink": "/r/MachineLearning/comments/11mzqxu/n_gpt4_is_coming_next_week_and_it_will_be/",
            "score": 641,
            "selftext": "[https://www.heise.de/news/GPT-4-is-coming-next-week-and-it-will-be-multimodal-says-Microsoft-Germany-7540972.html](https://www.heise.de/news/GPT-4-is-coming-next-week-and-it-will-be-multimodal-says-Microsoft-Germany-7540972.html)\n\n>**GPT-4 is coming next week**: at an approximately one-hour hybrid information event entitled \"**AI in Focus - Digital Kickoff\" on 9 March 2023**, four Microsoft Germany employees presented Large Language Models (LLM) like GPT series as a disruptive force for companies and their Azure-OpenAI offering in detail. The kickoff event took place in the German language, news outlet Heise was present. **Rather casually, Andreas Braun, CTO Microsoft Germany** and Lead Data & AI STU, **mentioned** what he said was **the imminent release of GPT-4.** The fact that **Microsoft is fine-tuning multimodality with OpenAI should no longer have been a secret since the release of Kosmos-1 at the beginning of March.**\n\n[ Dr. Andreas Braun, CTO Microsoft Germany and Lead Data  & AI STU at the Microsoft Digital Kickoff: \\\\\"KI im Fokus\\\\\" \\(AI in  Focus, Screenshot\\) \\(Bild:\u00a0Microsoft\\) ](https://preview.redd.it/rnst03avarma1.jpg?width=1920&format=pjpg&auto=webp&v=enabled&s=c398017ac69b7dda4c95f0d0ee28aa3a37893b90)",
            "spoiler": false,
            "stickied": false,
            "title": "[N] GPT-4 is coming next week \u2013 and it will be multimodal, says Microsoft Germany - heise online",
            "upvote_ratio": 0.98,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11mzqxu/n_gpt4_is_coming_next_week_and_it_will_be/"
        },
        {
            "author": "u/LaRosaBiagio",
            "created_utc": "03-09-2023 13:10:31",
            "distinguished": null,
            "edited": false,
            "id": "11mz7mj",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_11mz7mj",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/11mz7mj/r_survey_on_visual_analytics_for_explainable_deep/",
            "score": 4,
            "selftext": "Hi, we are happy to share our recently published survey, \"State of the Art of Visual Analytics for Explainable Deep Learning\". Any feedback is welcome!\n\nThe survey provides a ptaxonomical analysis of visual analytics (VA) solutions that employ explanation methods to aid the user in understanding deep learning models. The paper analyzes them by their explanation methods, the visualization techniques used, the degree of analytics support toward human-based analysis, the types of evaluation activities applied, and how this field is evolving, among others.\n\n&#x200B;\n\nhttps://preview.redd.it/whhhkt4l7rma1.png?width=803&format=png&auto=webp&v=enabled&s=7c20c1045289bc58fcc8a5830994f042438a3749\n\nWe wrote the paper intending to make it readable by researchers working in visual analytics, AI, or XAI. It aims at bridging their communities and providing a common reasoning ground for them to foster new joint research contributions.\n\nIn the last part of the paper, we argue for more research on[ ](https://mobile.twitter.com/hashtag/VisualAnalytics?src=hashtag_click)VA systems supporting the end-users in confirmatory and what-if analysis, in addition to exploratory analysis at the model and input levels. We invite researchers of the three communities to tighter collaboration to fix issues and challenges identified in the literature, such as using a limited set of explanation methods, the trustworthiness of the systems, and the lack of standard interfaces for cross-contamination.\n\nPaper: [https://onlinelibrary.wiley.com/doi/10.1111/cgf.14733](https://onlinelibrary.wiley.com/doi/10.1111/cgf.14733)\n\nInteractive explorable survey: [https://aware-diag-sapienza.github.io/VA4XDL/survis/](https://aware-diag-sapienza.github.io/VA4XDL/survis/)\n\nTweet: [https://mobile.twitter.com/Lynos79/status/1623995496804089860](https://mobile.twitter.com/Lynos79/status/1623995496804089860)\n\nAbstract:\n\n>The use and creation of machine-learning-based solutions to solve problems or reduce their computational costs are becoming increasingly widespread in many domains. Deep Learning plays a large part in this growth. However, it has drawbacks such as a lack of explainability and behaving as a black-box model. During the last few years, Visual Analytics has provided several proposals to cope with these drawbacks, supporting the emerging eXplainable Deep Learning field. This survey aims to (i) systematically report the contributions of Visual Analytics for eXplainable Deep Learning; (ii) spot gaps and challenges; (iii) serve as an anthology of visual analytical solutions ready to be exploited and put into operation by the Deep Learning community (architects, trainers and end users) and (iv) prove the degree of maturity, ease of integration and results for specific domains. The survey concludes by identifying future research challenges and bridging activities that are helpful to strengthen the role of Visual Analytics as effective support for eXplainable Deep Learning and to foster the adoption of Visual Analytics solutions in the eXplainable Deep Learning community. An interactive explorable version of this survey is available online at [https://aware-diag-sapienza.github.io/VA4XDL](https://aware-diag-sapienza.github.io/VA4XDL).",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Survey on Visual Analytics for Explainable Deep Learning",
            "upvote_ratio": 0.67,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11mz7mj/r_survey_on_visual_analytics_for_explainable_deep/"
        },
        {
            "author": "u/pagggga",
            "created_utc": "03-09-2023 12:50:54",
            "distinguished": null,
            "edited": false,
            "id": "11myoug",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11myoug",
            "nsfw": false,
            "num_comments": 38,
            "permalink": "/r/MachineLearning/comments/11myoug/d_jax_vs_pytorch_in_2023/",
            "score": 59,
            "selftext": "I've recently started my Ph.D. in Multi-Agent RL, and want to learn JAX/Flax and use that for my research, the reason being that DeepMind/Google use it, and I want to land an internship/job there at some point.\n\nI have been using PyTorch for 2.5 years, and in the past few days, I've been struggling to make the switch to JAX/Flax. Although the ideas behind JAX are cool, I feel like they make it unnecessarily complicated, and I would just be better off if I simply kept using PyTorch since I'm very familiar with it.\n\nI had tried to learn JAX 1-2 years ago already, and I came to the same conclusion back then, which makes me think that the usability of JAX hasn't improved much.\n\nDo you think it's worth it to make a serious effort this time to learn JAX, so that I will be able to use it for the rest of my Ph.D., or is there just no point in doing so and I should keep using PyTorch?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] JAX vs PyTorch in 2023",
            "upvote_ratio": 0.95,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11myoug/d_jax_vs_pytorch_in_2023/"
        },
        {
            "author": "u/pgalgali",
            "created_utc": "03-09-2023 11:08:28",
            "distinguished": null,
            "edited": false,
            "id": "11mw2xy",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11mw2xy",
            "nsfw": false,
            "num_comments": 3,
            "permalink": "/r/MachineLearning/comments/11mw2xy/d_what_is_the_best_way_to_fine_tune_a_llm_with/",
            "score": 2,
            "selftext": " I am new to LLM. What is the best way to build a custom text classifier leveraging your own data? The data is not labeled. Also what is the best starting LLM for this purpose- smaller model like Roberta or larger ones like GPT?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] What is the best way to fine tune a LLM with your own data and build a custom text classifier?",
            "upvote_ratio": 0.63,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11mw2xy/d_what_is_the_best_way_to_fine_tune_a_llm_with/"
        },
        {
            "author": "u/IAMATARDISAMA",
            "created_utc": "03-09-2023 10:47:54",
            "distinguished": null,
            "edited": false,
            "id": "11mvjtu",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11mvjtu",
            "nsfw": false,
            "num_comments": 3,
            "permalink": "/r/MachineLearning/comments/11mvjtu/d_is_a_diverse_dataset_necessary_for_accuracy_if/",
            "score": 3,
            "selftext": "Let's say hypothetically that I want to train an object detection model to recognize dogs in the video output of my home security camera. I know for a fact that I will only use my model on this one camera and that the position and rotation of my camera will never change. Normally when building a dataset, especially for computer vision models, you want to include diverse data to ensure that objects can be detected regardless of their surroundings. However in this case one can make the assumption that the surroundings will largely be static other than some minor variations. For this example does it make more sense to train a model on images collected from the perspective of the camera itself, or should a variety of dog pictures in various environments still be used? My thought process is that if we know enough about the conditions the model will be deployed in it would make more sense to provide training data that reflects this real world usage, but pretty much all the sources I've found online always say your dataset should be diverse. I'm curious to hear what reddit's thoughts on this approach are, or if there's any research that's been done into this topic that I've missed.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Is a diverse dataset necessary for accuracy if the conditions in which inference will be used are narrow?",
            "upvote_ratio": 1.0,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11mvjtu/d_is_a_diverse_dataset_necessary_for_accuracy_if/"
        },
        {
            "author": "u/Bughyman3000",
            "created_utc": "03-09-2023 09:18:01",
            "distinguished": null,
            "edited": false,
            "id": "11mtctv",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_11mtctv",
            "nsfw": false,
            "num_comments": 9,
            "permalink": "/r/MachineLearning/comments/11mtctv/research_feature_extraction_for_geospatial_vector/",
            "score": 5,
            "selftext": "I am exploring a binary classification problem about classifying road intersections into\u00a0roundabouts\u00a0or\u00a0not roundabouts. The available input data consists of the GPS latitude / longitude points contained inside the intersection polygons. So each sample contains a list of GPS points that we know that are contained in the intersection.\n\nAs such, I am interested in Machine Learning / Deep Learning techniques for\u00a0classifying geospatial vector data\u00a0specifically (as opposed to raster data). I've searched the web quite a bit and it seems to me that most of the ML research on geospatial data focuses on raster data, but rasterization is not an option for me. The only paper researching learning techniques applied on geospatial vector data I found is this:\u00a0https://arxiv.org/abs/1806.03857, which refers to Polygon data, not Points. I was considering taking the (projected and scaled) point coordinates as features, but since each intersection contains a different number of points, the feature vectors will have variable-length.\n\nI suspect that simply taking the point coordinates and zero-padding until the feature vectors have a fixed length, isn't going to work, due to the dimensionality curse, especially given that I only have ~800 intersection samples.\nOther data I could derive from the points include speed, curvature and curvature change. How do I go about feature engineering / extraction in this case?",
            "spoiler": false,
            "stickied": false,
            "title": "[Research] Feature Extraction for Geospatial Vector Data",
            "upvote_ratio": 1.0,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11mtctv/research_feature_extraction_for_geospatial_vector/"
        },
        {
            "author": "u/doerlbh",
            "created_utc": "03-09-2023 08:52:38",
            "distinguished": null,
            "edited": false,
            "id": "11msqu6",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "News",
            "locked": false,
            "name": "t3_11msqu6",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/11msqu6/n_cfp_ijcai_2023_workshop_on_knowledgebased/",
            "score": 2,
            "selftext": "\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\* KBCG @ IJCAI 2023 Call for papers \\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\n\nThe 1st International Workshop on Knowledge-Based Compositional Generalization (KBCG)\n\nHeld  in conjunction with the 32nd International Joint Conference on  Artificial Intelligence (IJCAI 2023), August 19th 2023, Cape Town, South  Africa\n\n* Website: [https://KnowledgeAI.github.io/](https://knowledgeai.github.io/)\n* Submission deadline: April 26th, 2023 (11:59 pm AOE)\n* Submission link: [https://openreview.net/group?id=ijcai.org/IJCAI/2023/Workshop/KBCG](https://openreview.net/group?id=ijcai.org/IJCAI/2023/Workshop/KBCG)\n* IJCAI format, 7-page paper (+2-page references) for proceeding articles\n* IJCAI format, 2-page abstract for posters/demonstrations\n\n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\n\nDear Colleagues,\n\nWe  are excited to announce the First International Workshop on  Knowledge-Based Compositional Generalization (KBCG), which will be held  in conjunction with IJCAI 2023 this August in Cape Town, South Africa.  Our workshop aims to bring together researchers from academia and  industry to discuss the latest advances and challenges in the area of  knowledge representation and compositional generalization in AI.\n\nWebsite: [https://knowledgeai.github.io/](https://knowledgeai.github.io/)\n\nWe  invite researchers in AI, machine learning, statistics, cognitive  sciences, psychology and neuroscience to submit their latest work on  knowledge-based compositional generalization. The goal of this workshop  is to provide a platform for researchers to present their latest work  and to foster discussions on the challenges and opportunities in this  area.  \nThe submission deadline is April 26th, 2023 (11:59 pm AOE), and  the acceptance notification will be on June 1st, 2022. Accepted papers  will be presented at the workshop and included in a workshop proceeding.\n\nWe  invite researchers in AI, machine learning, statistics, cognitive  sciences and neuroscience to submit their papers, posters, and  demonstrations on any topic related to knowledge representation and  compositional generalization, including but not limited to:\n\n* Representation learning for compositional generalization\n* Meta-learning for compositional generalization\n* Transfer learning for compositional generalization\n* Reasoning for compositional generalization\n* Applications of knowledge-based compositional generalization\n* Learning compositional representations\n* Combining knowledge from multiple sources\n* Transfer learning and domain adaptation\n* Compositional generalization in natural language understanding\n* Compositional generalization in reinforcement learning\n* Compositional generalization in knowledge representation and reasoning\n* Relational machine Learning\n* Using external knowledge for efficient machine learning\n* Symbol grounding and Abstractions\n* Benchmarks for compositional generalization\n\nSubmissions  should be in the form of a 7-page paper (+2-page references) for  proceeding articles or a 2-page abstract for posters/demonstrations,  formatted according to the conference's guidelines ([https://www.ijcai.org/authors\\_kit](https://www.ijcai.org/authors_kit)). The submission website is on OpenReview: [https://openreview.net/group?id=ijcai.org/IJCAI/2023/Workshop/KBCG](https://openreview.net/group?id=ijcai.org/IJCAI/2023/Workshop/KBCG)\n\nKey Dates:\n\n* Submission deadline: April 26th, 2023 (11:59 pm AOE)\n* Acceptance notification: June 1st, 2022\n* Camera ready for accepted submissions: June 15th, 2022\n\nOrganizing Committee:\n\n* Baihan Lin, Columbia University\n* Djallel Bouneffouf, IBM Research\n* Asim Munawar, IBM Research\n* Irina Rish, Mila - Quebec AI Institute\n\nWe  look forward to your submissions and to seeing you at the workshop. If  you have any questions, please feel free to contact the organizing  committee at [kbcg.workshop@gmail.com](mailto:kbcg.workshop@gmail.com).",
            "spoiler": false,
            "stickied": false,
            "title": "[N] CFP: IJCAI 2023 Workshop on Knowledge-Based Compositional Generalization (KBCG)",
            "upvote_ratio": 1.0,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11msqu6/n_cfp_ijcai_2023_workshop_on_knowledgebased/"
        },
        {
            "author": "u/blacklemon67",
            "created_utc": "03-08-2023 23:35:42",
            "distinguished": null,
            "edited": false,
            "id": "11misax",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": null,
            "locked": false,
            "name": "t3_11misax",
            "nsfw": false,
            "num_comments": 17,
            "permalink": "/r/MachineLearning/comments/11misax/d_why_are_so_many_tokens_needed_to_train_large/",
            "score": 11,
            "selftext": "Hey everyone!\n\nA quick fermi estimate shows that if a person were to encounter 50,000 tokens a day (extremely high estimate, this is a novel per day assuming 1 token = 1 word) then by the time they are 20 they would have encountered 365 million tokens.\n\nObviously this person would be VERY well read. However, if we feed a transformer language model with the same number of tokens then according to scaling laws it would be worse than gpt-2 (which was trained with a dataset about an order of magnitude larger).\n\nSo the question is, why do language models need so many tokens? Does anyone know of any review papers/blog posts discussing this observation?\n\nMy theory is that we haven't yet found the most efficient architecture for language yet, and that transformers' ability to excell at many different tasks means that you need to give it a lot of data to force it to come up with the right neural circuits for the job.\n\nTLDR: Humans need substantially fewer tokens than transformer language models. What's the current understanding for why this is?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Why are so many tokens needed to train large language models?",
            "upvote_ratio": 0.82,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11misax/d_why_are_so_many_tokens_needed_to_train_large/"
        },
        {
            "author": "u/Singularian2501",
            "created_utc": "03-08-2023 12:09:00",
            "distinguished": null,
            "edited": false,
            "id": "11m1ux4",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": null,
            "locked": false,
            "name": "t3_11m1ux4",
            "nsfw": false,
            "num_comments": 3,
            "permalink": "/r/MachineLearning/comments/11m1ux4/r_internet_explorer_targeted_representation/",
            "score": 19,
            "selftext": "Paper: [https://arxiv.org/abs/2302.14051](https://arxiv.org/abs/2302.14051) \n\nYoutube: [https://youtu.be/1hYtGZ0CUSA](https://youtu.be/1hYtGZ0CUSA) \n\nBlog: [https://internet-explorer-ssl.github.io/](https://internet-explorer-ssl.github.io/) \n\nCode coming soon! : [https://github.com/internet-explorer-ssl/internet-explorer](https://github.com/internet-explorer-ssl/internet-explorer) \n\nAbstract:\n\n>Modern vision models typically rely on fine-tuning general-purpose models pre-trained on large, static datasets. These general-purpose models only capture the knowledge within their pre-training datasets, which are tiny, out-of-date snapshots of the Internet -- where billions of images are uploaded each day. We suggest an alternate approach: rather than hoping our static datasets transfer to our desired tasks after large-scale pre-training, we propose dynamically utilizing the Internet to quickly train a small-scale model that does extremely well on the task at hand. Our approach, called **Internet Explorer,** **explores the web in a self-supervised manner to progressively find relevant examples that improve performance on a desired target dataset.** It cycles between searching for images on the Internet with text queries, self-supervised training on downloaded images, determining which images were useful, and prioritizing what to search for next. We evaluate Internet Explorer across several datasets and show that it **outperforms or matches CLIP oracle performance by using just a single GPU desktop to actively query the Internet for 30--40 hours.** \n\nhttps://preview.redd.it/zjcqpn4qrjma1.jpg?width=804&format=pjpg&auto=webp&v=enabled&s=d2d53c37527aee160847551371d7159432869212\n\nhttps://preview.redd.it/7v97tp4qrjma1.jpg?width=580&format=pjpg&auto=webp&v=enabled&s=3c9a765589f9710de46e0bb4e40c858c3fc35433\n\nhttps://preview.redd.it/j4bp7s4qrjma1.jpg?width=1646&format=pjpg&auto=webp&v=enabled&s=e63626dce48a8504ddf5c0bec294b9202c8eece0\n\nhttps://preview.redd.it/q2uibu4qrjma1.jpg?width=1466&format=pjpg&auto=webp&v=enabled&s=a256020a48f39af67786a19e4528b12ba6f1a28b\n\nhttps://preview.redd.it/j4z0gr4qrjma1.jpg?width=1457&format=pjpg&auto=webp&v=enabled&s=6729bdb52838304710e6962a9f7102fcd8ecfbb9",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Internet Explorer: Targeted Representation Learning on the Open Web - Carnegie Mellon University Alexander C. Li et al 2023 - Trained on a single GPU for 40 hours and outperforms CLIP ResNet-50 that was trained on 4000 GPU hours!",
            "upvote_ratio": 0.95,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11m1ux4/r_internet_explorer_targeted_representation/"
        },
        {
            "author": "u/MysteryInc152",
            "created_utc": "03-09-2023 02:24:35",
            "distinguished": null,
            "edited": false,
            "id": "11mlwty",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_11mlwty",
            "nsfw": false,
            "num_comments": 29,
            "permalink": "/r/MachineLearning/comments/11mlwty/r_visual_chatgpt_talking_drawing_and_editing_with/",
            "score": 841,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation Models",
            "upvote_ratio": 0.97,
            "url": "https://www.reddit.com/gallery/11mlwty"
        },
        {
            "author": "u/JayMBurris",
            "created_utc": "03-08-2023 18:14:38",
            "distinguished": null,
            "edited": false,
            "id": "11mbikv",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11mbikv",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/11mbikv/d_machinedeep_learning_jupyter_notebooks_for/",
            "score": 12,
            "selftext": "Hi, I work at Intel as an academic outreach coordinator.  I'm sharing about Intel's open source OpenVINO toolkit for optimizing and deploy AI inference on CPUs, discrete and integrated GPUs, and other accelerators like Movidius VPUs and Intel FPGA.  The [github](https://github.com/openvinotoolkit/openvino_notebooks) has over 60 jupyter notebooks that can work on Intel PCs/laptop using Windows & Linux, or on Macs on MacOS including M1 processors.\n\nTry out the stable diffusion Jupyter Notebook [\\#225](https://github.com/openvinotoolkit/openvino_notebooks/tree/main/notebooks/225-stable-diffusion-text-to-image),  or try out the vehicle recognition and detection Jupyter Notebook [\\#218](https://github.com/openvinotoolkit/openvino_notebooks/tree/main/notebooks/218-vehicle-detection-and-recognition)\n\nIts easy to install in 9 simple steps on Windows with pip install, 8 steps on MacOS, and 7 steps on Linux.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Machine/Deep learning jupyter notebooks for computer vision, NLP, and recommender systems",
            "upvote_ratio": 0.77,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11mbikv/d_machinedeep_learning_jupyter_notebooks_for/"
        },
        {
            "author": "u/keisukegoda3804",
            "created_utc": "03-08-2023 16:48:32",
            "distinguished": null,
            "edited": false,
            "id": "11m99js",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11m99js",
            "nsfw": false,
            "num_comments": 10,
            "permalink": "/r/MachineLearning/comments/11m99js/d_text_embedding_model_for_financial_documents/",
            "score": 8,
            "selftext": "I'm currently working on a project where I'm analyzing financial documents such as 10Ks and 10Qs. I'm looking for a pretrained text embedding model that has been fine-tuned on such documents to generate accurate embeddings. While there are models like FinBERT that are tuned for sentiment analysis, I'm interested in a model that can generate more accurate embeddings in general, without focusing solely on sentiment.\n\n&#x200B;\n\nThanks!",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Text embedding model for financial documents",
            "upvote_ratio": 0.83,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11m99js/d_text_embedding_model_for_financial_documents/"
        },
        {
            "author": "u/perone",
            "created_utc": "03-08-2023 13:52:24",
            "distinguished": null,
            "edited": false,
            "id": "11m4l8y",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_11m4l8y",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/11m4l8y/p_feste_an_opensource_framework_to_optimize_and/",
            "score": 6,
            "selftext": "Hi, just sharing a new open-source framework called Feste.\n\nDocumentation: https://feste.readthedocs.io\n\nGithub: https://github.com/perone/feste\n\nFeste is a tool for LLMs task composition that does automatic parallelization of backend API calls, tools, and *automatic batching* using graph optimization. Contributions are welcome!",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Feste, an open-source framework to optimize and parallelize NLP tasks",
            "upvote_ratio": 0.75,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11m4l8y/p_feste_an_opensource_framework_to_optimize_and/"
        },
        {
            "author": "u/Informal-Swordfish27",
            "created_utc": "03-08-2023 09:44:20",
            "distinguished": null,
            "edited": false,
            "id": "11ly4d9",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_11ly4d9",
            "nsfw": false,
            "num_comments": 33,
            "permalink": "/r/MachineLearning/comments/11ly4d9/p_introducing_the_github_profile_summarizer/",
            "score": 200,
            "selftext": "Hi guys, I built a website that summarizes a GitHub user using GPT.\n\nWhat is it?You type a GitHub profile URL, then it gives you a summary of the user.\n\nHow does it work?It finds the most important work by heuristics, then summarizes it using GPT.\n\nGive it a try and let me know what you think. :)\n\n[sample summary](https://preview.redd.it/c5o8tccc2jma1.png?width=1238&format=png&auto=webp&v=enabled&s=9a5c6bc7ba5661020f75b22e3d76aa4441483ff4)\n\n[http://devmarizer.firebaseapp.com/](http://devmarizer.firebaseapp.com/)",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Introducing the GitHub profile summarizer",
            "upvote_ratio": 0.89,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11ly4d9/p_introducing_the_github_profile_summarizer/"
        },
        {
            "author": "u/ThePerson654321",
            "created_utc": "03-08-2023 02:52:16",
            "distinguished": null,
            "edited": "03-09-2023 11:30:32",
            "id": "11lq5j4",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11lq5j4",
            "nsfw": false,
            "num_comments": 20,
            "permalink": "/r/MachineLearning/comments/11lq5j4/d_why_isnt_everyone_using_rwkv_if_its_so_much/",
            "score": 13,
            "selftext": "The machine learning (ML) community is progressing at a remarkable pace and is embracing new techniques very quickly. Based on my comprehension of this model, it appears to offer a distinct set of advantages relative to transformers, while lacking any real drawbacks. Despite these benefits, it remains unclear why adopting this approach is not more widespread among individuals and organizations in the field.\n\nWhy is this the case? I really can't wrap my head around it. The [RWKV](https://github.com/BlinkDL/RWKV-LM) principle has existed for more than a year now and has more than 2k stars on GitHub! I feel like we should have seen wider adoption.\n\nAny thoughts?\n\n------------------\n\nJust to sum things up:\n\n/u/LetterRip explains this by saying that the larger organizations basically just haven't noticed/understood it's potential yet.\n\nMy explaination is that it's actually something problematic with the RWKV architecture. Still wondering what it is though.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Why isn't everyone using RWKV if it's so much better than transformers?",
            "upvote_ratio": 0.94,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11lq5j4/d_why_isnt_everyone_using_rwkv_if_its_so_much/"
        },
        {
            "author": "u/MysteryInc152",
            "created_utc": "03-07-2023 16:59:30",
            "distinguished": null,
            "edited": false,
            "id": "11lcspc",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_11lcspc",
            "nsfw": false,
            "num_comments": 5,
            "permalink": "/r/MachineLearning/comments/11lcspc/r_prismer_an_open_source_visionlanguage_model/",
            "score": 26,
            "selftext": "Paper here -  [https://arxiv.org/abs/2303.02506](https://arxiv.org/abs/2303.02506)\n\nCode and Models -  [https://github.com/NVlabs/prismer](https://github.com/NVlabs/prismer)",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Prismer: An Open Source Vision-Language Model with An Ensemble of Experts.",
            "upvote_ratio": 0.91,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11lcspc/r_prismer_an_open_source_visionlanguage_model/"
        },
        {
            "author": "u/029187",
            "created_utc": "03-07-2023 12:55:53",
            "distinguished": null,
            "edited": false,
            "id": "11l66uj",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11l66uj",
            "nsfw": false,
            "num_comments": 14,
            "permalink": "/r/MachineLearning/comments/11l66uj/d_have_neural_networks_that_modulate_their_own/",
            "score": 30,
            "selftext": " Is it possible to train a neural network that modulates its own loss function, as well as the hyperparameters of its training like momentum?\n\nWould backpropagation still be possible on such a model?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] - Have neural networks that modulate their own loss functions been attempted? Is there any active research into this area?",
            "upvote_ratio": 0.92,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11l66uj/d_have_neural_networks_that_modulate_their_own/"
        },
        {
            "author": "u/pgao_aquarium",
            "created_utc": "03-07-2023 12:07:54",
            "distinguished": null,
            "edited": false,
            "id": "11l4xo0",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11l4xo0",
            "nsfw": false,
            "num_comments": 6,
            "permalink": "/r/MachineLearning/comments/11l4xo0/d_to_make_your_model_better_first_figure_out/",
            "score": 0,
            "selftext": "I have a relatively contrarian take that most deep learning applications are not super different from each other.\n\nIt feels like in traditional software engineering, there is at least a set of well-known best practices that have been accumulated over time as people figured out what works and doesn't work. For example, most teams have some sort of CI/CD flow and a hosted version control system. People can ignore this, but they do so at their own risk.\n\nIn applied deep learning (typical supervised tasks on text / imagery / etc), I've seen a lot of industry ML teams spin their wheels when they get to the stage of improving their model performance instead of following a more disciplined workflow that, in my opinion, more reliably produce results. I think we're all trying to figure out what the best practices around ML development should look like, but here's my opinionated contribution on that front. Feedback welcome!\n\n[https://www.aquariumlearning.com/blog-posts/to-make-your-model-better-first-figure-out-whats-wrong](https://www.aquariumlearning.com/blog-posts/to-make-your-model-better-first-figure-out-whats-wrong)",
            "spoiler": false,
            "stickied": false,
            "title": "[D] To Make Your Model Better, First Figure Out What's Wrong",
            "upvote_ratio": 0.45,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11l4xo0/d_to_make_your_model_better_first_figure_out/"
        },
        {
            "author": "u/SleekEagle",
            "created_utc": "03-07-2023 11:43:38",
            "distinguished": null,
            "edited": false,
            "id": "11l49y5",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11l49y5",
            "nsfw": false,
            "num_comments": 20,
            "permalink": "/r/MachineLearning/comments/11l49y5/d_the_emergent_abilities_of_large_language_models/",
            "score": 96,
            "selftext": "Hey everyone!  \n\n\nLarge Language Models have been shown to gain new abilities (like translation and arithmetic) as they are scaled. Some of these abilities have been recently observed to be **emergent**, meaning that there is an apparent discontinuity in their appearance with scale.  \n\n\nThis article on [**the emergent abilities of large language models**](https://www.assemblyai.com/blog/emergent-abilities-of-large-language-models/) examines this phenomenon, providing necessary background and information on the concept of emergence as a whole.  \n\n\nI'm interested to hear what folks here think about this phenomenon and observation, especially regarding potential explanations as well as real-world implications. Let me know what you think!\n\n&#x200B;\n\nhttps://preview.redd.it/hrh3zuztgcma1.png?width=1316&format=png&auto=webp&v=enabled&s=ad511d6d8875cf2765d5f80672d32e49abe28f55",
            "spoiler": false,
            "stickied": false,
            "title": "[D] The Emergent Abilities of Large Language Models",
            "upvote_ratio": 0.92,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11l49y5/d_the_emergent_abilities_of_large_language_models/"
        },
        {
            "author": "u/__Maximum__",
            "created_utc": "03-07-2023 11:06:33",
            "distinguished": null,
            "edited": false,
            "id": "11l3as6",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11l3as6",
            "nsfw": false,
            "num_comments": 18,
            "permalink": "/r/MachineLearning/comments/11l3as6/d_can_someone_explain_the_discrepancy_between_the/",
            "score": 9,
            "selftext": "Chinchilla states that the model size/dataset ratio should be 1 to 20 and they show it experimentally. LLaMA states their 7B model continued to improve even after 1T tokens. That's 1 to 142. Has anyone figured it out?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Can someone explain the discrepancy between the findings of LLaMA and Chinchilla?",
            "upvote_ratio": 0.85,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11l3as6/d_can_someone_explain_the_discrepancy_between_the/"
        },
        {
            "author": "u/hcarlens",
            "created_utc": "03-07-2023 08:37:52",
            "distinguished": null,
            "edited": "03-10-2023 05:53:15",
            "id": "11kzkla",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_11kzkla",
            "nsfw": false,
            "num_comments": 30,
            "permalink": "/r/MachineLearning/comments/11kzkla/r_analysis_of_200_ml_competitions_in_2022/",
            "score": 475,
            "selftext": "I run mlcontests.com, a website that aggregates ML competitions across Kaggle and other platforms.\n\nI've just finished a detailed analysis of **200+ competitions** in 2022, and what winners did (we found winning solutions for 67 competitions).\n\nSome highlights:\n\n* **Kaggle still dominant** with the most prize money, most competitions, and most entries per competition...\n* ... but there are **10+ other platforms** with interesting competitions and decent prize money, and dozens of single-competition sites\n* **Almost all competition winners used Python**, 1 used C++, 1 used R, 1 used Java\n* **96% (!) of Deep Learning solutions used PyTorch** (up from 77% last year)\n* **All winning NLP solutions we found used Transformers**\n* **Most computer vision solutions used CNNs**, though some used Transformer-based models\n* **Tabular data competitions were mostly won by GBDTs** (gradient-boosted decision trees; mostly LightGBM), though ensembles with PyTorch are common\n* **Some winners spent hundreds of dollars on cloud compute** for a single training run, **others managed to win just using Colab**'s free tier\n* Winners have largely converged on a common toolkit - PyData stack for the basics, PyTorch for deep learning, LightGBM/XGBoost/CatBoost for GBDTs, Optuna for hyperparam optimisation.\n* Half of competition winners are first-time winners; a third have won multiple comps before; half are solo winners. Some *serial winners* won 2-3 competitions just in 2022!\n\nWay more details as well as methodology here in the full report: [https://mlcontests.com/state-of-competitive-machine-learning-2022?ref=mlc\\_reddit](https://mlcontests.com/state-of-competitive-machine-learning-2022?ref=mlc_reddit)\n\n[Most common Python Packages used by winners](https://preview.redd.it/kwqmozh9lbma1.png?width=1600&format=png&auto=webp&v=enabled&s=1096de087592eb4cc2fbe85c8068617cb4f73d8f)\n\nWhen I published something similar here [last year](https://www.reddit.com/r/MachineLearning/comments/tdd889/news_analysis_of_83_ml_competitions_in_2021/), I got a lot of questions about tabular data, so I did a [deep dive](https://mlcontests.com/state-of-competitive-machine-learning-2022/#tabular-data?ref=mlc_reddit) into that this year.People also asked about [leaderboard shakeups](https://mlcontests.com/state-of-competitive-machine-learning-2022/#cross-validation?ref=mlc_reddit) and [compute cost trends](https://mlcontests.com/state-of-competitive-machine-learning-2022/#compute-and-hardware?ref=mlc_reddit), so those are included too. I'd love to hear your suggestions for next year.\n\nI managed to spend way more time on this analysis than last year thanks to the report sponsors (**G-Research**, a top quant firm, and **Genesis Cloud**, a renewable-energy cloud compute firm) - if you want to support this research, please check them out. I won't spam you with links here, there's more detail on them at the bottom of the report.",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Analysis of 200+ ML competitions in 2022",
            "upvote_ratio": 0.99,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11kzkla/r_analysis_of_200_ml_competitions_in_2022/"
        },
        {
            "author": "u/Both-Ad3462",
            "created_utc": "03-07-2023 06:45:06",
            "distinguished": null,
            "edited": false,
            "id": "11kx4ba",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11kx4ba",
            "nsfw": false,
            "num_comments": 2,
            "permalink": "/r/MachineLearning/comments/11kx4ba/rd_measuring_the_gender_gap_in_animated_films/",
            "score": 0,
            "selftext": "Hi fellow ML enthusiasts!  \nI published my [Masters Research on Medium](https://medium.com/better-programming/measuring-the-gender-gap-in-animation-using-ai-fac738be4b19) and got more attention than I thought! I Hope some in this community also find it interesting. AMA!",
            "spoiler": false,
            "stickied": false,
            "title": "[R][D] Measuring the Gender Gap in Animated Films using Computer Vision",
            "upvote_ratio": 0.26,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11kx4ba/rd_measuring_the_gender_gap_in_animated_films/"
        },
        {
            "author": "u/_underlines_",
            "created_utc": "03-07-2023 06:08:42",
            "distinguished": null,
            "edited": "03-12-2023 03:07:18",
            "id": "11kwdu9",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11kwdu9",
            "nsfw": false,
            "num_comments": 27,
            "permalink": "/r/MachineLearning/comments/11kwdu9/d_tutorial_run_llama_on_8gb_vram_on_windows/",
            "score": 87,
            "selftext": "~~facebookresearch/LLaMA-7b-8bit using less than 10GB vram, or LLaMA-13b on less than 24GB~~.\n\nfacebookresearch/LLaMA-7b-4bit using less than 6GB vram, or LLaMA-13b-4bit on less than 10GB.\n\n\n**Udpate:**\n\nDevelopments are fast, the guide below is already outdated. You can now get LLaMA 4bit models, which are smaller than original model weights, and better than 8bit models and need even less vram. Follow the new guide for Windows and Linux: \n\nhttps://github.com/underlines/awesome-marketing-datascience/blob/master/llama.md\n\n---\n\nEfforts are being made to  get the larger LLaMA 30b onto <24GB vram with 4bit quantization by implementing the technique from the paper [GPTQ quantization](https://github.com/oobabooga/text-generation-webui/issues/177) \n\nSince bitsandbytes doesn't officially have windows binaries, the following trick using an older unofficially compiled cuda compatible bitsandbytes binary works for windows.\n\n1. install miniconda, start the miniconda console\n1. create a new dir, for example *C:\\textgen\\* and cd into it\n1. git clone *github.com/oobabooga/text-generation-webui*\n1. follow the installation instructions of text-generation-webui for conda, create the env with the name textgen\n1. Download not the original LLaMA weights, but the [HuggingFace converted](https://rentry.org/llama-tard-v2) weights. The torrent link is on top of this linked article.\n1. copy the llama-7b or -13b folder (or whatever size you want to run) into *C:\\textgen\\text-generation-webui\\models*. The folder should contain the config.json, generation_config.json, pytorch_model.bin, index.json, special_tokens_map.json, tokenizer.model, tokenizer_config.json as well as all the 33 pytorch_model-000xx-of-00033.bin files\n1. put [libbitsandbytes_cuda116.dll](https://github.com/DeXtmL/bitsandbytes-win-prebuilt) in *C:\\Users\\xxx\\miniconda3\\envs\\textgen\\lib\\site-packages\\bitsandbytes\\*\n1. edit *\\bitsandbytes\\cuda_setup\\main.py*:\n  \n  search for:\n  \n  *if not torch.cuda.is_available(): return 'libsbitsandbytes_cpu.so', None, None, None, None*\n  \n  replace with:\n  \n  *if torch.cuda.is_available(): return 'libbitsandbytes_cuda116.dll', None, None, None, None*\n\n  search for this twice:\n  \n  *self.lib = ct.cdll.LoadLibrary(binary_path)*\n  \n  replace with:\n  \n  *self.lib = ct.cdll.LoadLibrary(str(binary_path))*\n\n1. Start text-generation-webui by typing: *python server.py --model LLaMA-7B --load-in-8bit*",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Tutorial: Run LLaMA on 8gb vram on windows (thanks to bitsandbytes 8bit quantization)",
            "upvote_ratio": 0.96,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11kwdu9/d_tutorial_run_llama_on_8gb_vram_on_windows/"
        },
        {
            "author": "u/Quirky-Indication670",
            "created_utc": "03-07-2023 05:59:52",
            "distinguished": null,
            "edited": false,
            "id": "11kw74g",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11kw74g",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/11kw74g/d_kaggle_or_upwork_while_working_in_a_company/",
            "score": 2,
            "selftext": "While working in an AI company not doing the same kind of product, what are the things to check before joining a kaggle competition? (except not using the same code etc)",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Kaggle or Upwork while working in a company",
            "upvote_ratio": 0.75,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11kw74g/d_kaggle_or_upwork_while_working_in_a_company/"
        },
        {
            "author": "u/mrx-ai",
            "created_utc": "03-07-2023 05:57:45",
            "distinguished": null,
            "edited": false,
            "id": "11kw5oh",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_11kw5oh",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/11kw5oh/r_an_overview_of_imitation_learning_by_d_garg/",
            "score": 9,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] An overview of Imitation Learning (by D. Garg)",
            "upvote_ratio": 0.74,
            "url": "https://ai.stanford.edu/blog/learning-to-imitate/"
        },
        {
            "author": "u/lifesthateasy",
            "created_utc": "03-07-2023 03:49:20",
            "distinguished": null,
            "edited": "03-07-2023 05:38:26",
            "id": "11ktxjl",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11ktxjl",
            "nsfw": false,
            "num_comments": 6,
            "permalink": "/r/MachineLearning/comments/11ktxjl/d_neat_project_that_would_fit_onto_a_4090/",
            "score": 7,
            "selftext": "I've finally pulled the plug on a 4090 that'll arrive by the end of this week after ages with a 1050, and besides throwing everything ray traced at it, I also want to use it to train some deep learning models.\n\nI do know the talk of the town, LLMs, are waaay too big to be done on such a card (iirc ChatGPT was train on 1024 industrial cards), but I was wondering if there's some neat DIY projects I could set up and train in a human amount of time (something that's not neural style transfer, that already ran on the 1050 too).\n\nFYI I'm not specifically looking for language modeling, Chat was just an example about a model that'd def be too big.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Neat project that would \"fit\" onto a 4090?",
            "upvote_ratio": 0.71,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11ktxjl/d_neat_project_that_would_fit_onto_a_4090/"
        },
        {
            "author": "u/WatercressTraining",
            "created_utc": "03-07-2023 03:45:52",
            "distinguished": null,
            "edited": "03-07-2023 03:49:29",
            "id": "11ktvkk",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_11ktvkk",
            "nsfw": false,
            "num_comments": 21,
            "permalink": "/r/MachineLearning/comments/11ktvkk/r_deduping_laion_60m_duplicates_and_imagenet_12m/",
            "score": 29,
            "selftext": "The authors fastdup ran an analysis on LAION 400M and Imagenet21K. Here's what they found.\n\n[Analysing LAION](https://reddit.com/link/11ktvkk/video/peit4pya5ama1/player)\n\nLAION 400M - TLDR [video](https://www.youtube.com/watch?v=s6qamoFzyis&ab_channel=visual-layer).\n\n* 60M duplicates.\n* 962K broken images.\n* Various label discrepancies.\n\nImageNet21K - [Link](https://medium.com/@amiralush/large-image-datasets-today-are-a-mess-e3ea4c9e8d22) to blog post.\n\n* 1.2M duplicate images.\n* 104K train/val leak.\n\nGitHub repo - [https://github.com/visual-layer/fastdup](https://github.com/visual-layer/fastdup)",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Dedup-ing LAION (60M duplicates) and ImageNet (1.2M duplicates) with fastdup",
            "upvote_ratio": 0.88,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11ktvkk/r_deduping_laion_60m_duplicates_and_imagenet_12m/"
        },
        {
            "author": "u/NalNezumi",
            "created_utc": "03-07-2023 02:17:13",
            "distinguished": null,
            "edited": false,
            "id": "11ksf39",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11ksf39",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/11ksf39/d_3d_image_data_augmentation_techniques_for/",
            "score": 2,
            "selftext": "Hello!  The question is slightly more research oriented, but I'm wondering if  anyone have good sources (Papers, talks, literature studies, libraries)  about useful data augmentation for 3D data (RGBD -> Point Cloud /  Voxel).\n\nI want to decrease the  data-requirement for my perception pipeline in a robotics manipulation  task, and also make it more robust. I'm not trying to learn some  traditional Computer Vision task (Segmentation/detection) but learn  affordance directly. This makes some methods (Self-supervised learning  methods) slightly more tricky to apply, but I think some data  augmentation methods for 3D data could still be used (I'm already using  Translation/Rotation augmentation).\n\nI  recently noticed drastic performance drop due to brightness bias in the  dataset, and I can ofc just collect more data with different brightness  condition in the real world, or add augmentation that takes that in to  consideration. That's where the question stems from; might as well take a  look at more augmentation method that could boost this.\n\nGoogling  this question didn't give me relevant result, adding \"reddit\" to the  query gave me slightly better pointers, but slightly outdated sources,  (papers from 2016-2018 that is a bit hard to apply on my problem) so I  tried to ask it here again. Any source would be greatly helpful!",
            "spoiler": false,
            "stickied": false,
            "title": "[D] (3D) Image data augmentation techniques for increasing learning robustness in DL models?",
            "upvote_ratio": 0.75,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11ksf39/d_3d_image_data_augmentation_techniques_for/"
        },
        {
            "author": "u/FoolishBluntman",
            "created_utc": "03-07-2023 02:09:41",
            "distinguished": null,
            "edited": false,
            "id": "11ksajc",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11ksajc",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/11ksajc/dcustom_trained_networks_for_easyocr/",
            "score": 2,
            "selftext": " \n\nHas anyone here trained or retrained(transfer trained) any of the networks for EasyOCR?\n\nI am able to do the training itself fairly easily, the validation is showing 95%+ for accuracy but when placed into EasyOCR, I'm getting garbage output.",
            "spoiler": false,
            "stickied": false,
            "title": "[D]Custom Trained Networks for EasyOCR",
            "upvote_ratio": 0.75,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11ksajc/dcustom_trained_networks_for_easyocr/"
        },
        {
            "author": "u/Balance-",
            "created_utc": "03-07-2023 02:08:52",
            "distinguished": null,
            "edited": false,
            "id": "11ksa12",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "News",
            "locked": false,
            "name": "t3_11ksa12",
            "nsfw": false,
            "num_comments": 6,
            "permalink": "/r/MachineLearning/comments/11ksa12/n_tinygrad_050_released/",
            "score": 3,
            "selftext": "tinygrad, a deep learning Frameworks that aims to have a complexity between a pytorch and a karpathy/micrograd, just tagged their [0.5.0 release](https://github.com/geohot/tinygrad/releases/tag/v0.5.0).\n\n*Release notes*\n\nAn upsetting 2223 lines of code, but so much great stuff!\n\n- 7 backends : CLANG, CPU, CUDA, GPU, LLVM, METAL, and TORCH\n- A TinyJit for speed (decorate your GPU function today)\n- Support for a lot of onnx, including all the models in the backend tests\n- No more MLOP convs, all HLOP (autodiff for convs)\n- Improvements to shapetracker and symbolic engine\n- 15% faster at running the openpilot model",
            "spoiler": false,
            "stickied": false,
            "title": "[N] tinygrad 0.5.0 released",
            "upvote_ratio": 0.64,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11ksa12/n_tinygrad_050_released/"
        },
        {
            "author": "u/Singularian2501",
            "created_utc": "03-07-2023 01:24:29",
            "distinguished": null,
            "edited": false,
            "id": "11krgp4",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_11krgp4",
            "nsfw": false,
            "num_comments": 138,
            "permalink": "/r/MachineLearning/comments/11krgp4/r_palme_an_embodied_multimodal_language_model/",
            "score": 425,
            "selftext": "Paper: [https://arxiv.org/abs/2303.03378](https://arxiv.org/abs/2303.03378)\n\nBlog: [https://palm-e.github.io/](https://palm-e.github.io/)\n\nTwitter: [https://twitter.com/DannyDriess/status/1632904675124035585](https://twitter.com/DannyDriess/status/1632904675124035585)\n\nAbstract:\n\n>Large language models excel at a wide range of complex tasks. However, enabling general inference in the real world, e.g., for robotics problems, raises the challenge of grounding. We propose embodied language models to directly incorporate real-world continuous sensor modalities into language models and thereby establish the link between words and percepts. Input to our embodied language model are multi-modal sentences that interleave visual, continuous state estimation, and textual input encodings. We train these encodings end-to-end, in conjunction with a pre-trained large language model, for multiple embodied tasks including sequential robotic manipulation planning, visual question answering, and captioning. Our evaluations show that PaLM-E, a single large embodied multimodal model, can address a variety of embodied reasoning tasks, from a variety of observation modalities, on multiple embodiments, and further, **exhibits positive transfer**: the model benefits from diverse joint training across internet-scale language, vision, and visual-language domains. **Our largest model, PaLM-E-562B with 562B parameters, in addition to being trained on robotics tasks, is a visual-language generalist with state-of-the-art performance on OK-VQA, and retains generalist language capabilities with increasing scale.**       \n\nhttps://preview.redd.it/1z3zc3kte9ma1.jpg?width=1321&format=pjpg&auto=webp&v=enabled&s=7ee212c74d468ba5a911e8f3bcfcad520cdd8733\n\nhttps://preview.redd.it/2qapt8kte9ma1.jpg?width=1180&format=pjpg&auto=webp&v=enabled&s=30edaa9b99d8c1481b90721e14dae54764999e68\n\nhttps://preview.redd.it/thtfg6kte9ma1.jpg?width=725&format=pjpg&auto=webp&v=enabled&s=c430e48e068eab0870e215b743d4a293d97177d2\n\nhttps://preview.redd.it/nffus6kte9ma1.jpg?width=712&format=pjpg&auto=webp&v=enabled&s=8234af6ab133385ff96425312ef2d86b95e14d9e\n\nhttps://preview.redd.it/henjo3kte9ma1.jpg?width=710&format=pjpg&auto=webp&v=enabled&s=1a36d074839a85a64ee9fc21c10c40234c75cadc",
            "spoiler": false,
            "stickied": false,
            "title": "[R] PaLM-E: An Embodied Multimodal Language Model - Google 2023 - Exhibits positve transfer learning!",
            "upvote_ratio": 0.98,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11krgp4/r_palme_an_embodied_multimodal_language_model/"
        },
        {
            "author": "u/ortegaalfredo",
            "created_utc": "03-07-2023 01:03:29",
            "distinguished": null,
            "edited": "03-07-2023 01:08:22",
            "id": "11kr20f",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_11kr20f",
            "nsfw": false,
            "num_comments": 20,
            "permalink": "/r/MachineLearning/comments/11kr20f/r_created_a_discord_server_with_llama_13b/",
            "score": 74,
            "selftext": "Installed LLaMA 13B (legitimate download) on a Dual RTX 3090 server and created a discord bot to interact with it.\n\nAs it's quite fast I'm opening it to the public, here is the discord invite. No registration/payments, etc. completely free.\n\nInstructions in comments as I cannot post an invite directly here.",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Created a Discord server with LLaMA 13B",
            "upvote_ratio": 0.9,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11kr20f/r_created_a_discord_server_with_llama_13b/"
        },
        {
            "author": "u/omniron",
            "created_utc": "03-06-2023 23:50:21",
            "distinguished": null,
            "edited": false,
            "id": "11kpjas",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11kpjas",
            "nsfw": false,
            "num_comments": 2,
            "permalink": "/r/MachineLearning/comments/11kpjas/d_lora_vs_ptuning_for_llms/",
            "score": 3,
            "selftext": "Has anyone seen a comparison anywhere of how these two techniques compare when used with LLMs? I can\u2019t seem to find a comparison of these anywhere\n\nLora: https://arxiv.org/abs/2106.09685\n\nPtuning: https://arxiv.org/abs/2110.07602",
            "spoiler": false,
            "stickied": false,
            "title": "[D] LoRA vs P-Tuning for LLMS?",
            "upvote_ratio": 0.8,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11kpjas/d_lora_vs_ptuning_for_llms/"
        },
        {
            "author": "u/Kanahei",
            "created_utc": "03-06-2023 23:00:44",
            "distinguished": null,
            "edited": false,
            "id": "11kogmq",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_11kogmq",
            "nsfw": false,
            "num_comments": 3,
            "permalink": "/r/MachineLearning/comments/11kogmq/rp_navigating_a_deep_reinforcement_learning_agent/",
            "score": 22,
            "selftext": "Hi MachineLearning,\n\nI would like to introduce this idea to you, using virtual guidance to instruct a deep reinforcement learning (DRL) agent to navigate toward its destination. \n\nThe advantage of this approach is that, \n\n>virtual guidance based approach differs from prior relative direction-based guidance in its ability to provide dense and informative navigation instructions to guide the agent in a straightforward manner. And this helps prevent the agent from learning correlations and relationships between visual observations and navigation instructions. \n\nIn the below video, we demonstrate that we are able to navigate a DRL agent (i.e., the AE86) to follow the virtual guidance represented by navigation paths or waypoints, like what Google Map shows the guide with augmented reality.\n\n[Screenshot of the demo video.](https://preview.redd.it/klxr2b2xp8ma1.png?width=1902&format=png&auto=webp&v=enabled&s=32bcd6266a44244abdf9f2b28dc28ddad26ec185)\n\nHope you like the idea and enjoy the video!\n\nDemo video: [https://youtu.be/XtZ7Az7Hxko](https://youtu.be/XtZ7Az7Hxko)  \nMore details here: [https://arxiv.org/abs/2303.02731](https://arxiv.org/abs/2303.02731)",
            "spoiler": false,
            "stickied": false,
            "title": "[R][P] Navigating a deep reinforcement learning agent with virtual guidance",
            "upvote_ratio": 0.9,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11kogmq/rp_navigating_a_deep_reinforcement_learning_agent/"
        },
        {
            "author": "u/michaelaalcorn",
            "created_utc": "03-06-2023 20:56:43",
            "distinguished": null,
            "edited": false,
            "id": "11klm5o",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_11klm5o",
            "nsfw": false,
            "num_comments": 4,
            "permalink": "/r/MachineLearning/comments/11klm5o/r_understanding_the_diffusion_objective_as_a/",
            "score": 24,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Understanding the Diffusion Objective as a Weighted Integral of ELBOs",
            "upvote_ratio": 0.94,
            "url": "https://arxiv.org/abs/2303.00848"
        },
        {
            "author": "u/Neurosymbolic",
            "created_utc": "03-06-2023 19:54:07",
            "distinguished": null,
            "edited": "03-06-2023 22:58:39",
            "id": "11kk3iq",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_11kk3iq",
            "nsfw": false,
            "num_comments": 15,
            "permalink": "/r/MachineLearning/comments/11kk3iq/r_pyreason_logic_for_use_with_ml/",
            "score": 90,
            "selftext": "Last week,  we released a paper on [PyReason on Arxiv](https://arxiv.org/pdf/2302.13482.pdf). PyReason is a Python package for logical inference and designed for use with machine learning ([https://github.com/lab-v2/pyreason](https://github.com/lab-v2/pyreason)).\n\nYou may think that\u2019s all fine and good, but are wondering why would we need a logic for machine learning? In this post, I\u2019ll discuss why we did it.\n\nFirst, a lot of the criticism of machine learning, especially deep learning is that while it obtains excellent result son may tasks, it is merely mimicking historical data and not learning actual relationships. This has resulted in a lot of the major shortcomings in ML such as the [hallucinations](https://www.nytimes.com/2023/02/17/podcasts/hard-fork-bing-ai-elon.html?action=click&module=audio-series-bar&region=header&pgtype=Article) of large language models, the requirements of vast amounts of training data to learn games, and brittleness in certain applications (e.g., the recent defeat of AlphaGo, difficulty in [solving math problems](https://www.reddit.com/r/MachineLearning/comments/11f29f9/r_chatgpt_failure_increase_linearly_with_addition/)). In a video lecture, we review some of these shortcomings, much of which constitutes active areas of research ([part 1](https://www.youtube.com/watch?v=9cooDzgd8NA), [part 2](https://www.youtube.com/watch?v=d2xfgwovwso)).\n\nThen enter \u201c[neuro symbolic](https://neurosymoblic.asu.edu/)\u201d artificial intelligence. Actually an old idea where neural architectures can work hand-in-hand with logic, often even having an equivalence between the two. The idea is symbolic AI has many shortcomings (brittleness to noise, difficulty in learning) that can be address with deep learning while its strengths (modularity, ability to add constraints, symbolic manipulation) can address some of deep learning\u2019s limitations.\n\nNeuro symbolic AI is a highly active area of research, and much of the advancements have identified special logical languages to use in their approach. Our goal with PyReason was to unify many of these logics and provide logic capabilities in a robust and modern Python implementation. We are working on a few joint projects with industry partners applying this to various use-cases, and now we have made the code base and library available as an open source package. In a [video](https://www.youtube.com/watch?v=E1PSl3KQCmo&t=8s), we outline six major capabilities that we felt were important:\n\n1. Open world reasoning \u2013 ability to reason in uncertain situations (important for interfacing with ML models)\n2. Multi-step inference\n3. Explainability\n4. Temporal reasoning\n5. Graph-based reasoning\n6. Designed to support neuro symbolic frameworks\n\nThe release of PyReason will kick off not only new research by our group and our collaborators, but also associated software. We\u2019re pretty excited about this new direction!",
            "spoiler": false,
            "stickied": false,
            "title": "[R] PyReason: logic for use with ML",
            "upvote_ratio": 0.97,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11kk3iq/r_pyreason_logic_for_use_with_ml/"
        },
        {
            "author": "u/neur0g33k",
            "created_utc": "03-06-2023 18:56:04",
            "distinguished": null,
            "edited": false,
            "id": "11kimff",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_11kimff",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/11kimff/research_universal_speech_model_by_google_research/",
            "score": 27,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[Research] Universal Speech Model by Google Research",
            "upvote_ratio": 0.84,
            "url": "https://arxiv.org/abs/2303.01037"
        },
        {
            "author": "u/SnooHabits2524",
            "created_utc": "03-06-2023 16:06:21",
            "distinguished": null,
            "edited": false,
            "id": "11ke0an",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11ke0an",
            "nsfw": false,
            "num_comments": 2,
            "permalink": "/r/MachineLearning/comments/11ke0an/d_resources_for_instruction_fine_tuning_t5llama/",
            "score": 2,
            "selftext": "Are there any good resources for instruction fine tuning T5 or llama for question answering at the moment?\n\nas in like, datasets that help with instruction fine tuning for more, human like conversations, that can be used to make the models more conversational?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Resources for instruction fine tuning T5/llama or similar models?",
            "upvote_ratio": 0.75,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11ke0an/d_resources_for_instruction_fine_tuning_t5llama/"
        },
        {
            "author": "u/NaturalGradient",
            "created_utc": "03-06-2023 16:01:00",
            "distinguished": null,
            "edited": false,
            "id": "11kdumf",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_11kdumf",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/11kdumf/r_tiny_classifier_circuits_evolving_accelerators/",
            "score": 14,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Tiny Classifier Circuits: Evolving Accelerators for Tabular Data",
            "upvote_ratio": 0.86,
            "url": "https://arxiv.org/abs/2303.00031"
        },
        {
            "author": "u/doctorjuice",
            "created_utc": "03-06-2023 15:21:29",
            "distinguished": null,
            "edited": false,
            "id": "11kcpye",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11kcpye",
            "nsfw": false,
            "num_comments": 30,
            "permalink": "/r/MachineLearning/comments/11kcpye/d_im_a_machine_learning_engineer_for_faang/",
            "score": 44,
            "selftext": "I have around 6 YoE doing MLE full time work for various companies. I've recently started doing Machine Learning contract work for clients.\n\nRecently, I submitted a post here asking for advice on how to get started. Because of that helpful post, I have started getting clients for ML contract work, set up some basics, and I'm now asking directly: Is anyone here looking for ML contract work to be done or know of any resources to find such leads?\n\nMy main ideas for outreach is to post on forums such as this one, but also through LinkedIn networks, through servers such as Slack and Discord, and other places.\n\nIf anyone has other ideas on good ways to do outreach, please let me know. Thanks for your help!",
            "spoiler": false,
            "stickied": false,
            "title": "[D] I\u2019m a Machine Learning Engineer for FAANG companies. What are some places looking for freelance / contract work for ML?",
            "upvote_ratio": 0.72,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11kcpye/d_im_a_machine_learning_engineer_for_faang/"
        },
        {
            "author": "u/florinandrei",
            "created_utc": "03-06-2023 14:51:18",
            "distinguished": null,
            "edited": false,
            "id": "11kbuzq",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11kbuzq",
            "nsfw": false,
            "num_comments": 6,
            "permalink": "/r/MachineLearning/comments/11kbuzq/d_the_mmsegmentation_library_from_openmmlab/",
            "score": 26,
            "selftext": "In December last year, I've completed my MS in Data Science. My capstone project had to do with semantic segmentation of medical ultrasound images (TLDR: cancer detection). I used a transformer model based on SegFormer. After the project was completed, I tried to improve the model performance a bit more.\n\nI was surprised by the IoU performance, which seemed a little too good to be true. I ended up writing my own metrics which calculated IoU, Dice, precision, and recall, among other things. My IoU results, computed with my own code, were consistently less than the IoU results I got from the library I was using at the time - the Evaluate library from Hugging Face. But their IoU was equal to what my code computed as recall (sensitivity). I've opened a ticket with Hugging Face:\n\nhttps://github.com/huggingface/evaluate/issues/421\n\nThey basically said they had copied that whole code from OpenMMLab and I should take it up with them. So I did:\n\nhttps://github.com/open-mmlab/mmsegmentation/issues/2655\n\nThat was more than a week ago and there's still no reply. Meanwhile I've seen other bug reports which appear to point at the same problem:\n\nhttps://github.com/open-mmlab/mmsegmentation/issues/2594\n\nI'm pretty sure I am right. The definition of IoU is quite simple, and there isn't much room there for interpretation. Their code fails simple test cases.\n\nMy concern is - since they effectively calculate recall instead of IoU, and recall is larger than, or equal to IoU, and since the MMSegmentation library is widely used in image segmentation research, it's possible there are quite a few results floating out there in the literature that are a few percentage points larger than what they should be - e.g. 90% IoU instead of 85%.\n\nThoughts?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] The MMSegmentation library from OpenMMLab appears to return the wrong results when computing basic image segmentation metrics such as the Jaccard index (IoU - intersection-over-union). It appears to compute recall (sensitivity) instead of IoU, which artificially inflates the performance metrics.",
            "upvote_ratio": 0.94,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11kbuzq/d_the_mmsegmentation_library_from_openmmlab/"
        },
        {
            "author": "u/No_Canary_5299",
            "created_utc": "03-06-2023 13:42:18",
            "distinguished": null,
            "edited": false,
            "id": "11k9oxr",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11k9oxr",
            "nsfw": false,
            "num_comments": 2,
            "permalink": "/r/MachineLearning/comments/11k9oxr/d_does_best_subset_selection_in_linear_regression/",
            "score": 7,
            "selftext": "Hi all, I am reading the ISLR2 and I am confused about selecting the linear models. Is there any guarantee that the performance of the forward stepwise and backward stepwise regression? When should we use each of them? Thanks!",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Does best subset selection in Linear Regression always perform better than Forward and Backward Stepwise selection?",
            "upvote_ratio": 0.9,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11k9oxr/d_does_best_subset_selection_in_linear_regression/"
        },
        {
            "author": "u/NaturalGradient",
            "created_utc": "03-06-2023 13:36:00",
            "distinguished": null,
            "edited": false,
            "id": "11k9es7",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_11k9es7",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/11k9es7/r_evotorch_scalable_evolutionary_computation_in/",
            "score": 2,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] EvoTorch: Scalable Evolutionary Computation in Python (technical report describing the EvoTorch library)",
            "upvote_ratio": 0.67,
            "url": "https://arxiv.org/abs/2302.12600"
        },
        {
            "author": "u/Mikyacer",
            "created_utc": "03-06-2023 12:45:09",
            "distinguished": null,
            "edited": false,
            "id": "11k6qp5",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_11k6qp5",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/11k6qp5/p_sir_model_for_covid_data_gradio_demo/",
            "score": 2,
            "selftext": " Hi everyone!\n\nIt's my first post showcasing one of my projects so please be kind, I am well aware that I did not achieve much but I just want to ask for feedback/suggestions.\n\nIn this project I model the COVID spread in a country with a SIR (susceptible-infected-recovered) model and use Bayesian inference to estimate the value of the parameters. The results obtained are pretty satisfying on Germany data (the model is able to catch quite well the changes in human interactions enforced by the government).\n\nMoreover, I developed a live demo so that you can try to estimate the parameters for any country (based on COVID/population data for 2020).\n\nRepo: [SnoopKilla/covidSIR: SIR model for COVID-19 data (github.com)](https://github.com/SnoopKilla/covidSIR)\n\nLive demo on HuggingFace spaces: [CovidSIR - a Hugging Face Space by SnoopKilla](https://huggingface.co/spaces/SnoopKilla/covidSIR)\n\nModel description: [covidSIR/SIR\\_model.pdf at main \u00b7 SnoopKilla/covidSIR (github.com)](https://github.com/SnoopKilla/covidSIR/blob/main/SIR_model.pdf)",
            "spoiler": false,
            "stickied": false,
            "title": "[P] SIR model for COVID data + gradio demo",
            "upvote_ratio": 1.0,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11k6qp5/p_sir_model_for_covid_data_gradio_demo/"
        },
        {
            "author": "u/adityyya13",
            "created_utc": "03-06-2023 12:06:45",
            "distinguished": null,
            "edited": false,
            "id": "11k4qzs",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11k4qzs",
            "nsfw": false,
            "num_comments": 9,
            "permalink": "/r/MachineLearning/comments/11k4qzs/what_is_the_future_of_ai_in_medicine_d/",
            "score": 10,
            "selftext": "With increasing research and technological innovation in the Machine Learning and Deep Learning Domain, how will healthcare be impacted.\n\n1) If adequate and competent datasets are available for symptoms, signs and management of common and well studied diseases like Tuberculosis and Diabetes along with their complications, whats stopping AI from replacing or atleast relieving physicians at Primary Healthcare Setups.\nStatistics about these diseases in context to social and vertical(age) demography could be fed and treatment would be on the basis of guidelines.\n\n2) How hard is to process non radiological data like heart murmurs, visible body anomalies like ulcers, grading of pain, dyspnea, fatigue into well set parameters to be fed into a machine.\n\n3) Since the software can be centralized, shouldn't deployment of various AI modalities be widespread since only input devices will be required for investigations and the output will be generated after cloud processing. \n\n4) How far are we from solving data aggregation problems like noise reduction, input heterogenity and labeling bias?\n\n5) If regulatory and \"human touch\" aspects of medicine are to be hypothetically ignored, Is it possible to replace physicians with AI systems and midlevels in next few decades.",
            "spoiler": false,
            "stickied": false,
            "title": "What is the future of AI in medicine? [D]",
            "upvote_ratio": 0.73,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11k4qzs/what_is_the_future_of_ai_in_medicine_d/"
        },
        {
            "author": "u/GyaanYogi",
            "created_utc": "03-06-2023 10:37:25",
            "distinguished": null,
            "edited": false,
            "id": "11k23xl",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11k23xl",
            "nsfw": false,
            "num_comments": 37,
            "permalink": "/r/MachineLearning/comments/11k23xl/d_are_there_any_standard_methods_for_finding/",
            "score": 8,
            "selftext": "I have a dataset where each user is assigned to a unique set of features. Given a subset of users, I want to identify the nearest neighbours of the subset.\n\nI can do this in an ad hoc way, by clustering or applying k-nn, followed by an algorithm that collects the nearest neighbours for each point and aggregates that in some way (e.g. find the nearest 10 users not in the subset for each user in the subset, then rank them by the number of times they appear in total).\n\nHowever, I imagine this is a common enough problem that it must have been addressed already. Are there any methods / libraries that solve this problem?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Are there any standard methods for finding nearest-neighbours for a subset (rather than a single point)?",
            "upvote_ratio": 0.9,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11k23xl/d_are_there_any_standard_methods_for_finding/"
        },
        {
            "author": "u/von-hust",
            "created_utc": "03-06-2023 08:20:00",
            "distinguished": null,
            "edited": false,
            "id": "11jyrfj",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_11jyrfj",
            "nsfw": false,
            "num_comments": 34,
            "permalink": "/r/MachineLearning/comments/11jyrfj/r_we_found_nearly_half_a_billion_duplicated/",
            "score": 376,
            "selftext": "Using our new method, we found that at least 25% of the LAION-2B-en dataset are near duplicates (wrt to image data). You may find the de duplicated set and code to verify result here:\n\nhttps://github.com/ryanwebster90/snip-dedup\n\nIn addition, we used the duplicate histograms, and found a handful of \u201cverbatim copied\u201d generated images by stable diffusion, with much less resources than deepmind (our process runs on a standard computer), like the following\n\n[stable diffusion verbatim copy](https://github.com/ryanwebster90/snip-dedup/blob/main/sylvester_overfit.jpeg)\n\n**disclaimer** \nThis is a fairly new result, we\u2019ll publish once we\u2019ve done more verification. Take it with a grain of salt. You are welcome to explore and verify the deduplicated set we\u2019ve released.",
            "spoiler": false,
            "stickied": false,
            "title": "[R] We found nearly half a billion duplicated images on LAION-2B-en.",
            "upvote_ratio": 0.96,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11jyrfj/r_we_found_nearly_half_a_billion_duplicated/"
        },
        {
            "author": "u/Pretend_Ad3180",
            "created_utc": "03-05-2023 20:20:08",
            "distinguished": null,
            "edited": false,
            "id": "11jk5ky",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11jk5ky",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/11jk5ky/optimized_implementation_of_trainingfinetuning_of/",
            "score": 6,
            "selftext": "Have anyone tried to optimize the forward and backward using custom Cuda code or fused kernel to speed up the training time of current LLMs? I only have seen FasterTransformer ( [NVIDIA/FasterTransformer](https://github.com/NVIDIA/FasterTransformer/)) and other similar tools but they're only focusing on inference.",
            "spoiler": false,
            "stickied": false,
            "title": "Optimized implementation of training/fine-tuning of LLMs [D]",
            "upvote_ratio": 0.88,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11jk5ky/optimized_implementation_of_trainingfinetuning_of/"
        },
        {
            "author": "u/QTQRQD",
            "created_utc": "03-05-2023 19:45:30",
            "distinguished": null,
            "edited": false,
            "id": "11jjd18",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11jjd18",
            "nsfw": false,
            "num_comments": 15,
            "permalink": "/r/MachineLearning/comments/11jjd18/d_best_way_to_run_llms_in_the_cloud/",
            "score": 25,
            "selftext": "I'm looking to run some of the bigger models (LLaMA 30B, 65B, namely) on a cloud instance so that I can have some useable performance for completions. I was thinking of an EC2 instance with a single A100 attached, but is this the best setup, or does anyone have any other suggestions?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Best way to run LLMs in the cloud?",
            "upvote_ratio": 0.94,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11jjd18/d_best_way_to_run_llms_in_the_cloud/"
        },
        {
            "author": "u/jsonathan",
            "created_utc": "03-05-2023 17:48:56",
            "distinguished": null,
            "edited": false,
            "id": "11jgig0",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_11jgig0",
            "nsfw": false,
            "num_comments": 65,
            "permalink": "/r/MachineLearning/comments/11jgig0/p_i_built_a_chatbot_that_helps_you_debug_your_code/",
            "score": 789,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[P] I built a chatbot that helps you debug your code",
            "upvote_ratio": 0.95,
            "url": "https://v.redd.it/x8pdi2n610ma1"
        },
        {
            "author": "u/Singularian2501",
            "created_utc": "03-05-2023 13:33:43",
            "distinguished": null,
            "edited": false,
            "id": "11j6y82",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_11j6y82",
            "nsfw": false,
            "num_comments": 2,
            "permalink": "/r/MachineLearning/comments/11j6y82/r_grounded_decoding_guiding_text_generation_with/",
            "score": 6,
            "selftext": "Paper: [https://arxiv.org/abs/2303.00855](https://arxiv.org/abs/2303.00855) \n\nBlog: [https://grounded-decoding.github.io/](https://grounded-decoding.github.io/) \n\nYoutube: [https://youtu.be/KHhAlBIQftQ](https://youtu.be/KHhAlBIQftQ) \n\nAbstract:\n\n>Recent progress in large language models (LLMs) has demonstrated the ability to learn and leverage Internet-scale knowledge through pre-training with autoregressive models. Unfortunately, applying such models to settings with embodied agents, such as robots, is challenging due to their lack of experience with the physical world, inability to parse non-language observations, and ignorance of rewards or safety constraints that robots may require. On the other hand, language-conditioned robotic policies that learn from interaction data can provide the necessary grounding that allows the agent to be correctly situated in the real world, but such policies are limited by the lack of high-level semantic understanding due to the limited breadth of the interaction data available for training them. Thus, if we want to make use of the semantic knowledge in a language model while still situating it in an embodied setting, we must construct an action sequence that is both likely according to the language model and also realizable according to grounded models of the environment. We frame this as a problem similar to probabilistic filtering: decode a sequence that both has high probability under the language model and high probability under a set of grounded model objectives. We demonstrate this guided decoding strategy is able to solve complex, long-horizon embodiment tasks in a robotic setting by leveraging the knowledge of both models. \n\nhttps://preview.redd.it/3rhkqupgsyla1.jpg?width=1401&format=pjpg&auto=webp&v=enabled&s=1b9bc7f2def8a9f0bbab4af50c36e43a999a3d1a\n\nhttps://preview.redd.it/hwm1aypgsyla1.jpg?width=1149&format=pjpg&auto=webp&v=enabled&s=eb2f31acfbc9b695ae3605c26bc2b1ecf1a192b2\n\nhttps://preview.redd.it/fxz7u0qgsyla1.jpg?width=1156&format=pjpg&auto=webp&v=enabled&s=c7b1e6beba2106739a741261584d874353032e06\n\nhttps://preview.redd.it/5u6c6wpgsyla1.jpg?width=516&format=pjpg&auto=webp&v=enabled&s=502e66a93281a677c0961d52655f1f929301e2f3",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Grounded Decoding: Guiding Text Generation with Grounded Models for Robot Control - Google 2023",
            "upvote_ratio": 1.0,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11j6y82/r_grounded_decoding_guiding_text_generation_with/"
        },
        {
            "author": "u/BoltzmannBrain1",
            "created_utc": "03-05-2023 13:01:59",
            "distinguished": null,
            "edited": false,
            "id": "11j5go4",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11j5go4",
            "nsfw": false,
            "num_comments": 4,
            "permalink": "/r/MachineLearning/comments/11j5go4/great_quantization_libraries_d/",
            "score": 12,
            "selftext": "I want to quantize my models down to very low precision (8 bit, 4 bit). And I want them to run on GPU, of course. Anybody have good recommendations for quantization libraries? PyTorch seems to be capped at 16 bit, and LLM.int8 seems to be not quite what I\u2019m looking for.",
            "spoiler": false,
            "stickied": false,
            "title": "Great Quantization Libraries? [D]",
            "upvote_ratio": 0.94,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11j5go4/great_quantization_libraries_d/"
        },
        {
            "author": "u/waterstrider123",
            "created_utc": "03-05-2023 11:44:15",
            "distinguished": null,
            "edited": false,
            "id": "11j1nhk",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11j1nhk",
            "nsfw": false,
            "num_comments": 4,
            "permalink": "/r/MachineLearning/comments/11j1nhk/d_mixup_data_augmentation_for_image_segmentation/",
            "score": 3,
            "selftext": "I have been studying the mixup algorithm to increase the number of datapoints for training and this is done with mixup using the following below equations:\n\nhttps://preview.redd.it/1k1dg7319yla1.png?width=762&format=png&auto=webp&v=enabled&s=c71095545feb5230a6772d6990c3ed20df68a12b\n\nHowever, since the y are one hot label encodings, I don't think I can use the above equations to augment annotated image segmentation datasets. I have been trying to find out if there have been any updates in this field for enhancing segmentation datasets, but I was not able to find any papers. Is there a better approach for augmenting the data for image segmentation tasks?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Mixup Data Augmentation for Image Segmentation",
            "upvote_ratio": 1.0,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11j1nhk/d_mixup_data_augmentation_for_image_segmentation/"
        },
        {
            "author": "u/Jakaboy",
            "created_utc": "03-05-2023 11:12:00",
            "distinguished": null,
            "edited": false,
            "id": "11j0shw",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11j0shw",
            "nsfw": false,
            "num_comments": 3,
            "permalink": "/r/MachineLearning/comments/11j0shw/d_p_llms_for_text_classification_7b_parameters/",
            "score": 2,
            "selftext": "Hi!\n\nI'm doing my Master's thesis on text classification of long documents in the legal domain (>100 labels). \n\nI'm mainly doing fine-tuning of Bert/Roberta and using GNN models. The results are not great, micro-f1 \\~55%.\n\nBut I wonder if it's possible to leverage chatgpt/llama/flan. LLMs that are designed to do generative AI/chat.\n\nIs it possible to fine-tunning them in a consumer gpu? (3090)? Can I \"train\" them by using only prompts?\n\nI have the feeling that text classification is a \"done\" subject, if a well-fine-tunned Bert can't get the result you want, 99% is because your data is awful. Is that a correct assumption?\n\n&#x200B;\n\nThanks everyone!",
            "spoiler": false,
            "stickied": false,
            "title": "[D] [P] LLMs for Text Classification (7B parameters)",
            "upvote_ratio": 0.75,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11j0shw/d_p_llms_for_text_classification_7b_parameters/"
        },
        {
            "author": "u/radi-cho",
            "created_utc": "03-05-2023 10:20:00",
            "distinguished": null,
            "edited": false,
            "id": "11izjc1",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "News",
            "locked": false,
            "name": "t3_11izjc1",
            "nsfw": false,
            "num_comments": 45,
            "permalink": "/r/MachineLearning/comments/11izjc1/r_n_dropout_reduces_underfitting_liu_et_al/",
            "score": 758,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] [N] Dropout Reduces Underfitting - Liu et al.",
            "upvote_ratio": 0.98,
            "url": "https://i.redd.it/pr6uonpztxla1.png"
        },
        {
            "author": "u/JindraMachka",
            "created_utc": "03-05-2023 09:49:30",
            "distinguished": null,
            "edited": false,
            "id": "11iyv5s",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11iyv5s",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/11iyv5s/discussion_the_official_website_for_gtsrb_is_down/",
            "score": 3,
            "selftext": "I'm currently writing documentation for a school project containing image classification of the German Traffic Recognition Benchmark. The official website for GTSRB ([http://benchmark.ini.rub.de/](http://benchmark.ini.rub.de/)) currently seems to be down and right now it'd be useful for me to have access to it. Does anyone know if a new one is being developed or if the old one will come back up?",
            "spoiler": false,
            "stickied": false,
            "title": "[Discussion] The official website for GTSRB is down",
            "upvote_ratio": 1.0,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11iyv5s/discussion_the_official_website_for_gtsrb_is_down/"
        },
        {
            "author": "u/zx2zx",
            "created_utc": "03-05-2023 09:32:54",
            "distinguished": null,
            "edited": false,
            "id": "11iyim9",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11iyim9",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/11iyim9/d_discretization_equalwidth_vs_equalfrequency/",
            "score": 4,
            "selftext": "As a rule of thumb, should equal-width be the first choice?\n\nThis 2022 paper documents an instance where equal-width is better:\n\n[Performance Comparison of Equal Width and Equal Frequency Discretization Methods for Author\u2019s Handwriting Recognition](https://link.springer.com/chapter/10.1007/978-981-16-8515-6_41)\n\nA similar conclusion results after evaluating four popular scikit-learn datasets:\n\n[equal_width_vs_equal_frequency](https://github.com/c4pub/misc/blob/main/notebooks/equal_width_vs_equal_frequency.ipynb)\n\nObviously, there are cases where equal-frequency performs better. But there seems to be a general tendency in favor of equal-width.\nWhat are your experiences on this topic?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Discretization: equal-width vs equal-frequency",
            "upvote_ratio": 1.0,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11iyim9/d_discretization_equalwidth_vs_equalfrequency/"
        },
        {
            "author": "u/bo_peng",
            "created_utc": "03-05-2023 08:11:02",
            "distinguished": null,
            "edited": "03-05-2023 14:39:55",
            "id": "11iwt1b",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_11iwt1b",
            "nsfw": false,
            "num_comments": 24,
            "permalink": "/r/MachineLearning/comments/11iwt1b/r_rwkv_100_rnn_can_genuinely_model_ctx4k/",
            "score": 61,
            "selftext": "Hi everyone.  I have tested RWKV \\[loss vs token position\\] for 10000 ctx4k+ documents in Pile:\n\nhttps://preview.redd.it/3ld2629h6xla1.png?width=941&format=png&auto=webp&v=enabled&s=e5afbb8d9704595f4d61db4e2c307ee09e4a4e69\n\nRWKV 1B5-4k is mostly flat after ctx1500, but 3B-4k and 7B-4k and 14B-4k have some slopes, and they are getting better. **This debunks the old view that RNNs cannot model long ctxlens.** These ctx4096 models are available at [https://huggingface.co/BlinkDL](https://huggingface.co/BlinkDL).\n\nWe can predict that RWKV 100B will be great, and RWKV 1T is probably all you need :)\n\nhttps://preview.redd.it/e3tbivtx6xla1.png?width=1174&format=png&auto=webp&v=enabled&s=2e4c1f4806c88a5b2820a0458321a0401dcc8087\n\nRWKV is simple. You can read [https://arxiv.org/abs/2302.13939](https://arxiv.org/abs/2302.13939) (SpikeGPT) which is inspired by RWKV and has plenty of explanations. The RWKV paper is coming too.\n\n**Here is RWKV model+inference+generation (yes, everything) in 150 lines of Python:**\n\n[https://github.com/BlinkDL/ChatRWKV/blob/main/RWKV\\_in\\_150\\_lines.py](https://github.com/BlinkDL/ChatRWKV/blob/main/RWKV_in_150_lines.py)\n\nIt is a slower version but works \ud83d\ude42 hopefully this can make it easier to understand and optimize RWKV. \\[Only the preprocessing of context is slower here, because I am using RNN mode to process the context token-by-token. the faster seq. version is in [https://github.com/BlinkDL/ChatRWKV/blob/main/rwkv\\_pip\\_package/src/rwkv/model.py](https://github.com/BlinkDL/ChatRWKV/blob/main/rwkv_pip_package/src/rwkv/model.py)\\]\n\n**I believe in Open AIs built by communities, and you are welcome to join the RWKV community :) Please feel free to msg in RWKV Discord if you are interested.**\n\nRWKV has been mostly a single-developer project for the past 2 years: designing, tuning, coding, optimization, distributed training, data cleaning, managing the community, answering questions... All your help will be much appreciated. [https://github.com/BlinkDL/RWKV-LM](https://github.com/BlinkDL/RWKV-LM)\n\nIt will be great if we can build optimized INT8/INT4 inference for Nvidia/AMD/Intel GPUs, Intel/AMD CPUs, and Android/iOS phones. Because RWKV has RNN mode, it is very hardware-friendly (no need for kv cache). **Let's build a future where everyone can run LLMs.**",
            "spoiler": false,
            "stickied": false,
            "title": "[R] RWKV (100% RNN) can genuinely model ctx4k+ documents in Pile, and RWKV model+inference+generation in 150 lines of Python",
            "upvote_ratio": 0.93,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11iwt1b/r_rwkv_100_rnn_can_genuinely_model_ctx4k/"
        },
        {
            "author": "u/NoLifeGamer2",
            "created_utc": "03-05-2023 06:12:20",
            "distinguished": null,
            "edited": false,
            "id": "11iun48",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11iun48",
            "nsfw": false,
            "num_comments": 9,
            "permalink": "/r/MachineLearning/comments/11iun48/d_ethics_of_minecraft_stable_diffusion/",
            "score": 1,
            "selftext": "I am thinking about making a 3D version of stable-diffusion that allows generation of minecraft blocks to build structures. How likely is it that I would be sued, given that I would probably scrape the builds off of planet minecraft? I have seen what happened with stable diffusion, and I wondered if the same thing would happen in my case. Thoughts?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Ethics of minecraft stable diffusion",
            "upvote_ratio": 0.53,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11iun48/d_ethics_of_minecraft_stable_diffusion/"
        },
        {
            "author": "u/ChristmasInOct",
            "created_utc": "03-05-2023 06:09:16",
            "distinguished": null,
            "edited": false,
            "id": "11iul6f",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11iul6f",
            "nsfw": false,
            "num_comments": 12,
            "permalink": "/r/MachineLearning/comments/11iul6f/d_llama_model_parallelization_and_server/",
            "score": 18,
            "selftext": "Hey everyone,\n\nFirst of all, tldr at bottom, typed more than expected here.  \n\nPlease excuse the rather naive perspective I have here.  I've followed along with great interest, but this is not my industry.\n\nRegardless, I have spent the past 3-4 days falling down a brutally obsessive rabbit hole, and I cannot seem to find this information.  I'm assuming it's just that I am missing context of course, and regardless of whether there is a clear answer, I'm trying to get a better understanding of this topic so that I could better appraise the situation myself.\n\nReally I suppose I have two questions.  **The first** is regarding model parallelization.\n\nI'm assuming this is not generic whatsoever.  What is the typical process engineers go about for designing such a pipeline?  Specifically in regards to these new LLaMA models, is something like ALPA relevant?  Deepspeed?\n\nMore importantly, what information should I be seeking to determine this myself?\n\nThis roughly segues to my **second inquiry**.\n\nThe reason I'm curious about splitting the model pipeline etc., is that I am potentially in interested in standing a server up for this.  Although I don't have much of a budget for this build (\\~$30-40K is the rough top-end, but I'd be a lot happier around $20-25K), the money is there if I can genuinely satisfy my use-case.\n\nI work at a small, but borderline manic startup working on enterprise software; 90% of the work we're doing based in the react/node ecosystem, some low-level work for backend services, and some very interesting database work that I have very little to do with.  I am a fullstack engineer that grew up playing with C++ => C#, and somehow ended up spending all of my time r/w'ing javascript.  Lol.  Anyways.\n\nPart of our roadmap since GPT-3 and the playground were made publicly accessible, involves usage of these transformer models, and their ability to interpret natural language inputs, whether from user inputs, or scraped input values generated somewhere in a chain of requests / operations.\n\nSeeing GPT-3 in action made me specifically realize that my estimations on this technology had been wildly off.  Seeing ChatGPT in action and uptick, the API's becoming available, has me further panicked.\n\nRunning our inference through their API has never really been an option for us.  I haven't even really looked that far into it, but bottom line the data running through our platform is all back-office, highly sensitive business information, and many have agreements explicitly restricting the movement of data to or from any cloud services, with Microsoft, Amazon, and Google all specifically mentioned.\n\nRegardless of the reasoning for these contracts, the LLaMA release has had me obsessed over this topic in more detail than before, and whether or not I would be able to get this setup privately, for our use-case.\n\n**To get to the actual second inquiry**:\n\nSay I want to throw a budget rig together for this in a server cabinet.  Am I able to effectively parallelize the LLaMA model, well enough to justify going with 24GB VRAM 4090's in the rig?  Say I do so with DeepSpeed, or some of the standard model parallelization libraries.\n\nIs the performance cost low enough to justify taking the extra compute here over 1/3 - 1/2 as many RTX6000 ADA's?\n\nOr should I be grabbing the 48GB ADA's?\n\nLike I said, I apologize for the naivety, I'm really looking for more information so that I can start to put this picture together better on my own.  It really isn't the easiest topic to research with how quickly things seem to move, and the giant gap between conversation depths (gamer || phd in a lot of the most interesting or niche discussions, little between).\n\nThank you very much for your time.\n\nTL;DR - Any information on LLaMA model parallelization at the moment?  Will it be compatible with things like zero or alpa?  How about for throwing a rig together right now for fine-tuning and then running inference on the LLaMA models?  48GB 6000 ADA's, or 24GB 4090's?\n\nPlanning on putting it in a mostly empty 42U cabinet that also houses our primary web server and networking hardware, so if there is a sales pitch for 4090's across multiple nodes here, I do have a massive bias as the kind of nerd that finds that kind of hardware borderline erotic.\n\nHydro and cooling are not an issue, just usage of the budget and understanding the requirements / approach given memory limitations, and how to avoid communication bottlenecks or even balance them against raw compute.\n\nThanks again everyone!",
            "spoiler": false,
            "stickied": false,
            "title": "[D] LLaMA Model Parallelization and Server Configuration",
            "upvote_ratio": 0.88,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11iul6f/d_llama_model_parallelization_and_server/"
        },
        {
            "author": "u/vidul7498",
            "created_utc": "03-05-2023 05:11:01",
            "distinguished": null,
            "edited": false,
            "id": "11itl7g",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11itl7g",
            "nsfw": false,
            "num_comments": 22,
            "permalink": "/r/MachineLearning/comments/11itl7g/to_rl_or_not_to_rl_d/",
            "score": 10,
            "selftext": "Francois Chollet's recent tweet where he states: ([https://twitter.com/fchollet/status/1630241783111364608](https://twitter.com/fchollet/status/1630241783111364608))  \n\"The answer to \"when should I use deep RL\" is that you shouldn't -- you should reframe your problem as a supervised learning problem, which is the only thing that curve-fitting can handle. In all likelihood this applies to RLHF for LLMs.\"\n\nThe people at DeepMind and OpenAI still seem bullish on RL but I have seen this kind of sentiment among other big names in DL as well. The most common sentiment I've seen is that RL is only good for extremely specific scenarios, other than that Supervised Learning is a much better option.\n\nWhat do you guys think, is RL doomed or is it the future? Also, would it be one day possible to apply RL to a more general range of problems or will it always be niche?",
            "spoiler": false,
            "stickied": false,
            "title": "To RL or Not to RL? [D]",
            "upvote_ratio": 0.78,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11itl7g/to_rl_or_not_to_rl_d/"
        },
        {
            "author": "u/gabegabe6",
            "created_utc": "03-05-2023 04:18:26",
            "distinguished": null,
            "edited": false,
            "id": "11isomm",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11isomm",
            "nsfw": false,
            "num_comments": 12,
            "permalink": "/r/MachineLearning/comments/11isomm/d_productization_of_deep_learning_models_what_are/",
            "score": 16,
            "selftext": "I see so many new services built with deep learning models where response times should be near real time or with minimal waiting. These SaaS products offering their APIs for few cents per call (or even lower). Also devs creating these super fast (I guess they can cut some corners)\n\nThis got me wondering what are the best practices for deploying such models and creating services?\n\nLets say I'd like to create an API for Stable Diffusion (there are already 100s of APIs like that). How should I do it?\n\nListing the building block on the top of my head\n- GPU machine is needed\n- CPU machine is needed where you release an API\n- Some load balancing --> multiple machines? --> kubernetes?\n- Authentication needs to be done --> database(es) needs ro be created\n- Payment (mostly subscriptions) needs to be developed/integrated\n- Legal stuff? (Policy, TOC)\n\nWhat architecture are they using for these APIs and apps?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Productization of deep learning models - what are the best practices?",
            "upvote_ratio": 0.81,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11isomm/d_productization_of_deep_learning_models_what_are/"
        },
        {
            "author": "u/likelostpasswords",
            "created_utc": "03-05-2023 00:57:05",
            "distinguished": null,
            "edited": false,
            "id": "11ip6sw",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11ip6sw",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/11ip6sw/d_what_is_the_best_model_i_can_use_to_make_an/",
            "score": 0,
            "selftext": "I want a Q/A model that digests huge chucks on info (chat messages, essays) and can answer intelligently while asked for questions. OpenAI's offering are obvious, but I want to know what are the other alternatives? (both API and self hosting models)  \n\n\nI've tried [deepset/roberta-base-squad2](https://huggingface.co/deepset/roberta-base-squad2) from Huggingface, but it's outputting really bad responses, mostly just outputs the next line of some key word in the question from the info.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] What is the best model I can use to make an intelligent search on large chunks of text? (other than OpenAI's offerings)",
            "upvote_ratio": 0.25,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11ip6sw/d_what_is_the_best_model_i_can_use_to_make_an/"
        },
        {
            "author": "u/nonkung51",
            "created_utc": "03-05-2023 00:30:13",
            "distinguished": null,
            "edited": false,
            "id": "11iooio",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11iooio",
            "nsfw": false,
            "num_comments": 5,
            "permalink": "/r/MachineLearning/comments/11iooio/d_building_an_opensource_llm_provider_for/",
            "score": 16,
            "selftext": "Hi guys! \n\nI've been thinking that as of now, we don't have a really easy way to integrate or build an app on-top of open-source models like flan-t5, bloom even though there are a lot of models that work quite well (not as good as gpt-3.5 but they're capable) \n\nMy idea is to build an open-source version of an LLM provider on top of all of those models (the first idea in mind for me is flan-t5 since the model is able to run very easily on a personal computer) \n\nThese are the features I think it should be able to do \n\n* Container-ready (just clone it and run some docker command, or you can just pull it from docker hub) \n* API-ready (api works right out of the box)\n* Playground ready (it also provides a playground so you can quickly play with it) \n\nI've been thinking that it should be able to be self-hosted. Like Supabase allows you to self-host your own backend as a service and provides an API for your applications (open-source alternatives to google firebase) anyone who self-hosted their own service can provide api to their applications, or if they want to monetize on it just put Stripe on top of it and let other use their services.\n\nAnd it'll be free and 100% open source too!\n\nI'd love to hear your thoughts on the idea, Do you think it is worth pursuing? Or do you have any suggestions? \n\nThanks for the reading :)",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Building an Open-Source LLM Provider for Self-Hosting",
            "upvote_ratio": 0.88,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11iooio/d_building_an_opensource_llm_provider_for/"
        },
        {
            "author": "u/radi-cho",
            "created_utc": "03-04-2023 16:17:49",
            "distinguished": null,
            "edited": false,
            "id": "11idjj6",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_11idjj6",
            "nsfw": false,
            "num_comments": 9,
            "permalink": "/r/MachineLearning/comments/11idjj6/p_diffground_a_simplistic_android_ui_to_access/",
            "score": 34,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[P] diffground - A simplistic Android UI to access ControlNet and instruct-pix2pix.",
            "upvote_ratio": 0.89,
            "url": "https://i.redd.it/ckkqkjyrgsla1.png"
        },
        {
            "author": "u/dan_the_lion",
            "created_utc": "03-04-2023 15:42:25",
            "distinguished": null,
            "edited": false,
            "id": "11icmoc",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_11icmoc",
            "nsfw": false,
            "num_comments": 4,
            "permalink": "/r/MachineLearning/comments/11icmoc/p_talksheet_a_gptbased_cli_tool_that_allows_you/",
            "score": 3,
            "selftext": "https://github.com/danthelion/talksheet\n\nA small project showcasing how to create a \"self-serve\" analytical application, powered by the wonderful Langchain and DuckDB.\n\nThere are a bunch of features (like supporting other file formats such as parquet and json) planned for the future, just wanted to ship something quickly.",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Talksheet - A GPT-based CLI tool that allows you to ask questions about your data",
            "upvote_ratio": 0.67,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11icmoc/p_talksheet_a_gptbased_cli_tool_that_allows_you/"
        },
        {
            "author": "u/enryu42",
            "created_utc": "03-04-2023 15:02:40",
            "distinguished": null,
            "edited": false,
            "id": "11ibm1j",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11ibm1j",
            "nsfw": false,
            "num_comments": 27,
            "permalink": "/r/MachineLearning/comments/11ibm1j/d_first_glance_at_llama/",
            "score": 63,
            "selftext": "[https://medium.com/@enryu9000/mini-post-first-look-at-llama-4403517d41a1](https://medium.com/@enryu9000/mini-post-first-look-at-llama-4403517d41a1)  \n\n\nI'm kind of surprised - I expected it to be much better than ChatGPT, but results are all over the place (e.g. it is better for few-shot classification, but worse for SQL generation).  \n\n\nI wonder what makes ChatGPT so decent; given that OpenAI can afford to serve it, it is probably an order of magnitude smaller than LLaMA, yet it is competitive; can RLHF get the model that far?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] First glance at LLaMA",
            "upvote_ratio": 0.91,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11ibm1j/d_first_glance_at_llama/"
        },
        {
            "author": "u/CranberryLegal5583",
            "created_utc": "03-04-2023 14:38:53",
            "distinguished": null,
            "edited": false,
            "id": "11iazhs",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_11iazhs",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/11iazhs/project_interesting_ml_project/",
            "score": 0,
            "selftext": "We are working on creating an open-source ML observability tool that can help data scientists to monitor their ML systems. UpTrain serves the following functions:\n\n1.\tObserving model performance: UpTrain observes the performance of your model and determines its accuracy to pin-point any dips in it\n\n2.\tTrack data-shifts: UpTrain compares your production data-points\u2019 distribution against your training dataset and detects out-of-distribution cases\n\n3.\tCollect edge-cases: Catch edge-cases and outliers to help them refine their models\n\n4.\tAutomated model-retraining: You can attach your existing data annotation, model training, and deployment pipelines to activate a completely automated continuous model improvement cycle\n\n5.\tSeamless integration: UpTrain offers seamless integration with all the major ML libraries and MLOps, allowing you to start off quickly\n\n6.\tData security: Since we are self-hosted, the concerns of data privacy are also taken care of\n\nYou can check out our project here: [https://github.com/uptrain-ai/uptrain](https://github.com/uptrain-ai/uptrain)  \n\n&#x200B;\n\nWe would love to hear your valuable feedback and to follow our progress do star our repo \ud83d\ude03",
            "spoiler": false,
            "stickied": false,
            "title": "[Project] Interesting ML project",
            "upvote_ratio": 0.44,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11iazhs/project_interesting_ml_project/"
        },
        {
            "author": "u/frahs",
            "created_utc": "03-04-2023 14:33:34",
            "distinguished": null,
            "edited": "03-04-2023 14:47:03",
            "id": "11iaull",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11iaull",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/11iaull/question_about_graphcore_ipuv2s_for_llms/",
            "score": 2,
            "selftext": "Hi,\n\nI'm trying to get a sense of the viability of IPUs for training/inference with LLMs. I've looked into it a bit, and as far as I can tell, they don't really make sense for really large models (175B param+). I want to make sure I'm not misunderstanding something.\n\nGraphcore's website claims they have 400+GB of DRAM onboard, but if you look at the docs, you'll see that the effective bandwidth to each chip is 20gb/s\\[0\\]. That's very slow! You might as well stream data from system (CPU) RAM at that point, it'll load faster over PCIe 4.0 with 16 lanes (32gb/s).\n\nAnother issue is that it looks like the on-chip SRAM is only 900MB, and there's no intermediate memory hierarchy between that and the DRAM. Btw there's 4 chips per machine, so let's say 3.6GB of chip SRAM per machine. I'm a bit new to this, but GPT-3 is 175 billion params and 96 layers. 175 Gparams = 350GB of memory in weights at fp16.  Divided over 96 layers, that's \\~3.5GB per layer. So the weights for one layer barely fit in IPU SRAM, and that's not including space for activations! For a truly large language model, you have to swap layer weights to DRAM during inference for each layer!\n\nThe numbers are much more favorable for a model like GPT-2 or LLAMA-7B.\n\nCompare this to an A100, where you have maybe 40GB of on-chip HBM2e memory. This is enough that with model parallelism, it's reasonable to run something this large. You can fit several layers of the model on one chip.\n\nWith Chinchilla scaling, we're discovering that smaller models can still improve with more compute, so maybe IPUs can make sense with a lot of model parallelism. But I can't see how this would be efficient if for each layer you need to swap in weights over 20gb/s. If the layer weights are O(1GB), that means you're waiting 5-50ms per layer memory fetch time, which doesn't seem efficient.\n\nIt feels like after IPUv1, graphcore realized that their chip doesn't really work for newer, larger models, so they quickly tried to pivot with IPUv2 and a lot of DRAM, but they failed to address the resulting huge memory bottleneck. Am I missing something?\n\n\\[0\\]: [https://www.graphcore.ai/hubfs/Graphcore-Mk2-IPU-System-Architecture-GC.pdf](https://www.graphcore.ai/hubfs/Graphcore-Mk2-IPU-System-Architecture-GC.pdf) (see figure 3, page 4)\n\n&#x200B;\n\nEdit: Just wanted to add that I found [this link](https://www.graphcore.ai/posts/building-large-models-on-ipu). Here they refer to phased execution and sharding tensors. I imagine they use x16 IPU-link 64 GB/s to shard, which is a bit better. But feels suboptimal.",
            "spoiler": false,
            "stickied": false,
            "title": "Question about Graphcore IPUv2s for LLMs, something doesn't make sense? [Discussion]",
            "upvote_ratio": 0.75,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11iaull/question_about_graphcore_ipuv2s_for_llms/"
        },
        {
            "author": "u/rrugh5",
            "created_utc": "03-04-2023 14:16:10",
            "distinguished": null,
            "edited": false,
            "id": "11iaefq",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_11iaefq",
            "nsfw": false,
            "num_comments": 3,
            "permalink": "/r/MachineLearning/comments/11iaefq/p_i_want_to_create_a_singlespeaker_tts_model_in_a/",
            "score": 2,
            "selftext": "I have a perfectly labeled dataset of 30 hours of that person talking (not in English).\n\nI guess the direction would be taking some pretrained model and further train it for that specific person.\n\nI have a few concerns:\n\n\\-I'm wondering if that's a valid direction.\n\n\\-I wonder what difficulties I may find when fine tuning the model for another language and whether it's even possible.\n\n\\-I'm not sure what model to use.\n\n\\-All of the models I've found so far are multi-speaker models, I'm wondering how may I use the fact that I'm looking to create a model for a single specific speaker.\n\nFrom my small research up until now I've found [Coqui-AI's repo](https://github.com/coqui-ai/TTS) for TTS which has plenty of models as well as [Grad-TTS](https://paperswithcode.com/paper/grad-tts-a-diffusion-probabilistic-model-for) which I found interesting.\n\nThank you!",
            "spoiler": false,
            "stickied": false,
            "title": "[P] I want to create a single-speaker TTS model in a language that's not English",
            "upvote_ratio": 0.75,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11iaefq/p_i_want_to_create_a_singlespeaker_tts_model_in_a/"
        },
        {
            "author": "u/SpatialComputing",
            "created_utc": "03-04-2023 14:12:08",
            "distinguished": null,
            "edited": false,
            "id": "11iaapp",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_11iaapp",
            "nsfw": false,
            "num_comments": 2,
            "permalink": "/r/MachineLearning/comments/11iaapp/r_vid2avatar_3d_avatar_reconstruction_from_videos/",
            "score": 18,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] vid2avatar: 3D avatar reconstruction from videos in the wild via self-supervised scene decomposition",
            "upvote_ratio": 0.93,
            "url": "https://youtu.be/LXsCGQigteE"
        },
        {
            "author": "u/Pristine-Woodpecker",
            "created_utc": "03-04-2023 13:55:11",
            "distinguished": null,
            "edited": false,
            "id": "11i9uxm",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_11i9uxm",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/11i9uxm/r_inside_the_mind_of_a_superhuman_go_model_how/",
            "score": 14,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Inside the mind of a superhuman Go model: How does Leela Zero read ladders?",
            "upvote_ratio": 0.9,
            "url": "https://www.lesswrong.com/posts/FF8i6SLfKb4g7C4EL/inside-the-mind-of-a-superhuman-go-model-how-does-leela-zero-2"
        },
        {
            "author": "u/ifilg",
            "created_utc": "03-04-2023 11:32:51",
            "distinguished": null,
            "edited": false,
            "id": "11i4olx",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11i4olx",
            "nsfw": false,
            "num_comments": 71,
            "permalink": "/r/MachineLearning/comments/11i4olx/d_is_it_possible_to_run_metas_llama_65b_model_on/",
            "score": 55,
            "selftext": "I think it's clear that a single beefy rig could handle the 7B model, but what about the big one? What kind of hardware are we looking at? What's the price range?\n\nI'd imagine something like this:\n\n* high end motherboard with lots of PCIe slots\n* 256GB of RAM (doable for a high end gaming rig)\n* some beefy CPU like the latest Threadripper\n* 2TB or more of SSD storage\n* a robust power supply (would 1000W be enough?)\n* 2 NVIDIA A100 80GB devices to total up to 160GB of vRAM\n* a big case and maybe a water cooler\n\nAm I on the right track here? What am I missing?\n\n(note: I don't intend to buy this hardware and run this model, but I think it's a fascinating discussion)",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Is it possible to run Meta's LLaMA 65B model on consumer-grade hardware?",
            "upvote_ratio": 0.89,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11i4olx/d_is_it_possible_to_run_metas_llama_65b_model_on/"
        },
        {
            "author": "u/BananaCode",
            "created_utc": "03-04-2023 08:12:20",
            "distinguished": null,
            "edited": false,
            "id": "11hyu2q",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11hyu2q",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/11hyu2q/d_resources_for_catching_up_on_large_generative/",
            "score": 11,
            "selftext": "Hi all! I'm currently researching on body pose estimation and I realized that I haven't really looked into the world of large generative models like Dall-E, StableDiffusion, GPT, chatGPT, and so on. I'm interested in expanding my knowledge beyond standard discriminative networks, which I'm more familiar with (e.g predicting body pose, segmentation etc.).\n\nI was hoping to get some recommendations from those who are more experienced in this area. Do you have any suggested reading lists for catching up on the current state of these large generative models? This could include papers, blogs, articles, or any other resources that you think would be helpful.\n\nI'm looking for something that would give me a thorough understanding of these models and their capabilities, and I'd also be interested in hearing about any interesting downstream applications. Thank you so much for your help!",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Resources for catching up on large generative models",
            "upvote_ratio": 0.87,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11hyu2q/d_resources_for_catching_up_on_large_generative/"
        },
        {
            "author": "u/etherealshatter",
            "created_utc": "03-04-2023 08:10:03",
            "distinguished": null,
            "edited": false,
            "id": "11hysfy",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_11hysfy",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/11hysfy/p_which_stateoftheart_models_are_most_suitable/",
            "score": 4,
            "selftext": "The institute wants to gradually use AI to assist some simple but tedious tasks in the long run. By \"simplest programming tasks\" I mean the most basic CRUD coding tasks where advanced algorithm is not needed and complicated architecture is not involved.\n\nTypical input: text of description of a task, usually asking for minor changes to an existing web service. For example: \"Could you please add an extra column for the output to include the employee number?\"\n\nExpected output: Suggested changes to the existing SQL code: + new line for the select statement: dbo.dim\\_hr.employee\\_num\n\nAvailable training and testing dataset: private dataset contains only hundreds or thousands of previously completed tasks within the institute, with task descriptions and corresponding Git/SVN history to show changes made to code.\n\nBudget limit: 4 x A100-80GB for training. 16C32T CPU + 128GB \\~ 320GB RAM for inference. The inference only has to be reasonably fast, e.g. produce an output within a few minutes after inputing the task description.\n\nGiven the limitation, do we have a good chance to do this based on some existing models and hopefully be able to carry out the training and inference on-premise without relying on cloud services hosted by the big tech companies?",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Which state-of-the-art models are most suitable for recommending chnages to SQL code for the simplest programming tasks?",
            "upvote_ratio": 0.7,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11hysfy/p_which_stateoftheart_models_are_most_suitable/"
        },
        {
            "author": "u/New_Computer3619",
            "created_utc": "03-04-2023 07:19:09",
            "distinguished": null,
            "edited": "03-04-2023 07:23:02",
            "id": "11hxwsm",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11hxwsm",
            "nsfw": false,
            "num_comments": 8,
            "permalink": "/r/MachineLearning/comments/11hxwsm/d_the_sentences_computers_cant_understand_but/",
            "score": 7,
            "selftext": "The title of this post is a [Tom Scott's video](https://www.youtube.com/watch?v=m3vIEKWrP9Q) which I watched a while back. I tried the challenges with ChatGPT. Seem like it handle both cases very well.\n\nI wonder how ChatGPT can infer from context like these?\n\n&#x200B;\n\nhttps://preview.redd.it/wnmswh0gspla1.png?width=1914&format=png&auto=webp&v=enabled&s=0d918e030a3640fe6f737310f71f76dbb62b0886\n\n&#x200B;\n\nhttps://preview.redd.it/0lms7svgspla1.png?width=1900&format=png&auto=webp&v=enabled&s=35d289ba480a8e2943aa347f516a224e5164d43f\n\n**Edit:** I tried the same questions but in separate chats and ChatGPT messed up. Seem like ChatGPT can only analyze sentences grammatically without any \"intuition\" like us. Is that correct?\n\n&#x200B;\n\nhttps://preview.redd.it/a6jx9r6btpla1.png?width=1662&format=png&auto=webp&v=enabled&s=8a4bb8c5ce0caa933c55993275c0baae1666f6d5\n\n&#x200B;\n\nhttps://preview.redd.it/qqpabj5ctpla1.png?width=1524&format=png&auto=webp&v=enabled&s=ec5d69975bbd455bc2fbad03c2638636a738ca59",
            "spoiler": false,
            "stickied": false,
            "title": "[D] The Sentences Computers Can't Understand, But Humans Can",
            "upvote_ratio": 0.78,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11hxwsm/d_the_sentences_computers_cant_understand_but/"
        },
        {
            "author": "u/WittyBananaPeel",
            "created_utc": "03-04-2023 07:17:02",
            "distinguished": null,
            "edited": false,
            "id": "11hxvib",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11hxvib",
            "nsfw": false,
            "num_comments": 9,
            "permalink": "/r/MachineLearning/comments/11hxvib/did_you_get_access_to_meta_ais_llama_discussion/",
            "score": 7,
            "selftext": "Many have been granted access to Meta AI's LLAMA, while others are questioning whether access is currently limited to email domains with the '.edu' extension. This poll aims to determine who has been granted access based on the email domain they provided. \n\n[View Poll](https://www.reddit.com/poll/11hxvib)",
            "spoiler": false,
            "stickied": false,
            "title": "Did you get access to Meta AI's LLAMA? [Discussion]",
            "upvote_ratio": 0.71,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11hxvib/did_you_get_access_to_meta_ais_llama_discussion/"
        },
        {
            "author": "u/davidmezzetti",
            "created_utc": "03-04-2023 07:16:12",
            "distinguished": null,
            "edited": false,
            "id": "11hxuzv",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_11hxuzv",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/11hxuzv/p_prompt_templates_and_task_chains_run_with/",
            "score": 3,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Prompt templates and task chains - run with Python, YAML or FastAPI",
            "upvote_ratio": 0.72,
            "url": "https://neuml.hashnode.dev/prompt-templates-and-task-chains"
        },
        {
            "author": "u/martinez_3_",
            "created_utc": "03-04-2023 06:39:39",
            "distinguished": null,
            "edited": false,
            "id": "11hx9tk",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_11hx9tk",
            "nsfw": false,
            "num_comments": 11,
            "permalink": "/r/MachineLearning/comments/11hx9tk/neural_network_visualisation_looking_for_an/",
            "score": 13,
            "selftext": "Hi guys,\nRecently I managed to create simple neural network visualization, \nhttp://nn.3dev.io\nto help to understand how neural network works on the signal level. I also wanted to arrange neurons by similarity cause I was expecting them to have noticeable areas of responsibility.\n\n\n\n\nin order to see the distribution I've created two metrics:\n1)Euclidean - that calculates the distance in output weights space (10 dimensions) and repels neurons according to that distance, as well as attracts neurons which are close in that 10d space\n\n2) output dominance- that attracts neurons having maximum weight at the particular output.\n\nThe problem is that I don't see any trend (or tendency) in neuron distribution which may be caused by :\n\n-there is no such trend or noticeable areas of neuron responsibility (at least in this case)\n-I have improper metric\n\nGuys, what do you think about it?\nThanks, Regards",
            "spoiler": false,
            "stickied": false,
            "title": "Neural Network visualisation. Looking for an improvement.[R]",
            "upvote_ratio": 0.85,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11hx9tk/neural_network_visualisation_looking_for_an/"
        },
        {
            "author": "u/ortegaalfredo",
            "created_utc": "03-04-2023 06:19:49",
            "distinguished": null,
            "edited": false,
            "id": "11hwyvk",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_11hwyvk",
            "nsfw": false,
            "num_comments": 7,
            "permalink": "/r/MachineLearning/comments/11hwyvk/p_celeryai_openai_keyboard_integration_for_linux/",
            "score": 42,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Celery-ai: OpenAI Keyboard Integration for Linux",
            "upvote_ratio": 0.96,
            "url": "https://v.redd.it/fqt5v8duhpla1"
        },
        {
            "author": "u/Fr33-Thinker",
            "created_utc": "03-04-2023 06:18:05",
            "distinguished": null,
            "edited": false,
            "id": "11hwxx1",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11hwxx1",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/11hwxx1/d_testing_the_new_bing_vs_chatgpt/",
            "score": 0,
            "selftext": "Asked both engines the exact same task \u201c**Write a fake news about the Ukraine war.**\u201d\n\nChatGPT refused the task, whereas the New Bing creatively wrote a professional looking news article that fabricates the defeat of Ukraine. \ud83d\ude02\ud83d\ude02\n\nHas anyone else found interesting differences?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Testing the New Bing vs ChatGPT",
            "upvote_ratio": 0.29,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11hwxx1/d_testing_the_new_bing_vs_chatgpt/"
        },
        {
            "author": "u/WolfOfDoorStreet",
            "created_utc": "03-04-2023 05:12:50",
            "distinguished": null,
            "edited": false,
            "id": "11hvufr",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_11hvufr",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/11hvufr/p_wrapyfi_for_distributing_llama_by_meta_on/",
            "score": 9,
            "selftext": "The authors present an example of combining Wrapyfi ([https://github.com/fabawi/wrapyfi](https://github.com/fabawi/wrapyfi)), a Python wrapper for message-oriented and robotics middleware, with LLaMA ([https://github.com/facebookresearch/llama](https://github.com/facebookresearch/llama)), a series of large language models from Meta AI. They demonstrate how Wrapyfi can enable running LLaMA on multiple mid-range machines with high inference speed and low cost. They also provide links to their GitHub repository ([https://github.com/modular-ml/wrapyfi-examples\\_llama](https://github.com/modular-ml/wrapyfi-examples_llama)) and paper ([https://arxiv.org/abs/2302.09648](https://arxiv.org/abs/2302.09648)) for more details. They state that this example can revolutionize natural language processing tasks such as text generation, summarization, question answering, sentiment analysis, etc. without having to buy new hardware and use their existing infrastructure!\n\nCheck it out:\n\n[https://github.com/modular-ml/wrapyfi-examples\\_llama](https://github.com/modular-ml/wrapyfi-examples_llama)",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Wrapyfi for distributing LLaMA by Meta on different machines",
            "upvote_ratio": 0.85,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11hvufr/p_wrapyfi_for_distributing_llama_by_meta_on/"
        },
        {
            "author": "u/Most-Drawer-7917",
            "created_utc": "03-04-2023 02:55:35",
            "distinguished": null,
            "edited": false,
            "id": "11htht2",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_11htht2",
            "nsfw": false,
            "num_comments": 2,
            "permalink": "/r/MachineLearning/comments/11htht2/p_searching_repo_for_code_of_a_feature/",
            "score": 0,
            "selftext": "I want to search on a project repo(web application) for the code implementation of a particular feature over its various files. Is there any existing projects implemented on this.",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Searching repo for code of a feature",
            "upvote_ratio": 0.5,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11htht2/p_searching_repo_for_code_of_a_feature/"
        },
        {
            "author": "u/rumovoice",
            "created_utc": "03-04-2023 01:53:57",
            "distinguished": null,
            "edited": false,
            "id": "11hscl1",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_11hscl1",
            "nsfw": false,
            "num_comments": 58,
            "permalink": "/r/MachineLearning/comments/11hscl1/p_lazyshell_gpt_based_autocomplete_for_zsh/",
            "score": 730,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[P] LazyShell - GPT based autocomplete for zsh",
            "upvote_ratio": 0.97,
            "url": "https://i.redd.it/amnowgji6ola1.gif"
        },
        {
            "author": "u/cbsudux",
            "created_utc": "03-04-2023 01:29:38",
            "distinguished": null,
            "edited": false,
            "id": "11hrw1f",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11hrw1f",
            "nsfw": false,
            "num_comments": 4,
            "permalink": "/r/MachineLearning/comments/11hrw1f/d_is_there_a_new_sota_for_texttotalkinghead/",
            "score": 6,
            "selftext": "I remember reading this 2 years back : [https://github.com/sibozhang/Text2Video](https://github.com/sibozhang/Text2Video)  \n\n\nWrite some text -> TTS -> Talking head generation.  \n\n\nAre there new papers and models that have launched?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Is there a new SOTA for text-to-talking-head generation?",
            "upvote_ratio": 0.76,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11hrw1f/d_is_there_a_new_sota_for_texttotalkinghead/"
        },
        {
            "author": "u/DefaultUsername247",
            "created_utc": "03-04-2023 01:12:08",
            "distinguished": null,
            "edited": false,
            "id": "11hrjmk",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11hrjmk",
            "nsfw": false,
            "num_comments": 2,
            "permalink": "/r/MachineLearning/comments/11hrjmk/d_filtering_out_key_moments_from_a_basketball_game/",
            "score": 2,
            "selftext": "I will preface this by saying that I know absolutely nothing about artificial intelligence, here I am simply looking for a way to make my life easier.\n\nSo I like to play basketball with a couple of friends, and I record all of my games. There are always moments of the game that I would like to play back the recording of, but it's difficult finding the timestamps, the recordings are sometimes hours long.\n\nUntil now I simply used to shout at the camera when I wanted to mark a time, so later I could extract the audio from the video, and create a waveform of 'loudness'  from it, and scroll over the waveform to find peaks.\n\nThis method is extremely inefficient, because it results in a lot of false positives and takes time.\n\nThen i stumbled upon openai's whisper, so my amd my team decided on a 'code' word to say at the camera when we wish to capture a moment, and later I would transcribe the entire video's audio using whisper. But I found that whisper doesn't work like this. Looking over the recording, the words were said pretty clearly, and whisper can recognize them if I say them out in a continuous sentence, so I believe whisper can't detect them if they are said only a couple of times in a long audio recording, mixed with background chatter.\n\nSo I've come here. Is there any efficient way you would solve this? It can be anything, from audio processing to video, my goal is to simply filter out some clips from a really long video.\n\nAll suggestions are welcome, and thank you for reading this.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Filtering out key moments from a basketball game",
            "upvote_ratio": 0.75,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11hrjmk/d_filtering_out_key_moments_from_a_basketball_game/"
        },
        {
            "author": "u/inFamous_16",
            "created_utc": "03-04-2023 00:10:08",
            "distinguished": null,
            "edited": false,
            "id": "11hqaek",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_11hqaek",
            "nsfw": false,
            "num_comments": 6,
            "permalink": "/r/MachineLearning/comments/11hqaek/r_variable_size_input_to_pretrained_bert_model/",
            "score": 2,
            "selftext": "I have tweets and the task is to perform text classification. I already have learned token embeddings for those tokens present in each of the tweets through some Graph based NN model. Now that I want to use those token embeddings to represent the tweet but the issue is every tweet will have different size embeddings if I just do concatenation. Is there any way, where I can input variable length embeddings to pre-trained BioBERT (if not, any other BERT) model and still be able to perform classification task?",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Variable size input to pre-trained BERT model",
            "upvote_ratio": 1.0,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11hqaek/r_variable_size_input_to_pretrained_bert_model/"
        },
        {
            "author": "u/MysteryInc152",
            "created_utc": "03-03-2023 23:11:10",
            "distinguished": null,
            "edited": false,
            "id": "11hp2nu",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_11hp2nu",
            "nsfw": false,
            "num_comments": 36,
            "permalink": "/r/MachineLearning/comments/11hp2nu/r_language_models_can_now_teach_themselves_how_to/",
            "score": 161,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Language models can now teach themselves HOW to use tools (i.e any API) in real time, completely automated. When given a task, SLAPA knows to search for the API documentation and learn all the information. Then he create API calls. If they don't work, he learns from his mistake and tries again.",
            "upvote_ratio": 0.9,
            "url": "https://twitter.com/DYtweetshere/status/1631349179934203904"
        },
        {
            "author": "u/SleekEagle",
            "created_utc": "03-03-2023 13:39:22",
            "distinguished": null,
            "edited": false,
            "id": "11hayge",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_11hayge",
            "nsfw": false,
            "num_comments": 17,
            "permalink": "/r/MachineLearning/comments/11hayge/r_highresolution_image_reconstruction_with_latent/",
            "score": 83,
            "selftext": "&#x200B;\n\nhttps://preview.redd.it/heyikxjqjkla1.png?width=1361&format=png&auto=webp&v=enabled&s=1f216e9e4303b67044e51b3aae486c9251ab3cd3\n\n[High-resolution image reconstruction with latent diffusion models from human brain activity (biorxiv.org)](https://www.biorxiv.org/content/10.1101/2022.11.18.517004v2.full.pdf)",
            "spoiler": false,
            "stickied": false,
            "title": "[R] High-resolution image reconstruction with latent diffusion models from human brain activity",
            "upvote_ratio": 0.93,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11hayge/r_highresolution_image_reconstruction_with_latent/"
        },
        {
            "author": "u/jj4646",
            "created_utc": "03-03-2023 12:17:58",
            "distinguished": null,
            "edited": false,
            "id": "11h6rij",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11h6rij",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/11h6rij/d_using_the_results_of_a_machine_learning_to/",
            "score": 1,
            "selftext": " There is a field of modelling called \"Survival Analysis\" ([https://en.wikipedia.org/wiki/Survival\\_analysis](https://en.wikipedia.org/wiki/Survival_analysis)), in which the objective is to model the effect of different \"characteristics\" (e.g. medical measurements of patients such as height, age, weight, etc.) on the \"time of some event\" (e.g. death). Many models used in Survival Analysis are essentially a form of \"Regression Models\" ([https://en.wikipedia.org/wiki/Regression\\_analysis](https://en.wikipedia.org/wiki/Regression_analysis)) - and of course, these models are built, train and fine tuned using some Optimization Algorithm (e.g. Newton-Raphson).\n\nOne of the most popular types of models used in Survival Analysis is called the \"Cox Proportional-Hazards\" Model ([https://en.wikipedia.org/wiki/Proportional\\_hazards\\_model](https://en.wikipedia.org/wiki/Proportional_hazards_model)). As an example, here I have fit a Cox-PH Model to some dataset using the R programming language:\n\n    Call:\n    coxph(formula = Surv(time, status) ~ age + sex + ph.ecog, data = lung)\n    \n                 coef exp(coef)  se(coef)      z        p\n    age      0.011067  1.011128  0.009267  1.194 0.232416\n    sex     -0.552612  0.575445  0.167739 -3.294 0.000986\n    ph.ecog  0.463728  1.589991  0.113577  4.083 4.45e-05\n    \n    Likelihood ratio test=30.5  on 3 df, p=1.083e-06\n    n= 227, number of events= 164 \n       (1 observation deleted due to missingness)\n\nBased on these results, I can infer information such as:\n\n* The number of observations\n* The number of events\n* The number of variables\n* The estimate for the effect of each variable\n\n**My Question:** Given this information, is it possible to simulate the covariate and response information for n = 227 such observations - such that if a similar Cox-PH model was fit to these newly simulated 227 observations, the resulting regression coefficients would approximately be equal to the original regression coefficients? **Can I try to \"guess\" (and recreate) a plausible set of observations might have been observed based on the regression model coefficients?**\n\nThis is where I thought that an Optimization Algorithm such as the Genetic Algorithm might be suitable. For example, below I tried to outline the pseudocode needed for such a problem:\n\n* Use an algorithm like the Genetic Algorithm ([https://cran.r-project.org/web/packages/GA/vignettes/GA.html](https://cran.r-project.org/web/packages/GA/vignettes/GA.html))\n* Step 0 : Set some plausible ranges for the covariates (e.g. age between 20 - 80, sex either male or female, ph.ecog between 0 and 5 [https://ecog-acrin.org/resources/ecog-performance-status/](https://ecog-acrin.org/resources/ecog-performance-status/)) . Specify distributions for each of these variables (e.g. age \\~ lognormal, sex \\~ binom, ph.ecog \\~ multinomial) and specify parameters for each of these distributions (e.g. lognormal(mu1, sigma1), binom(p1), etc)\n* Step 1: Set some plausible range and distribution for the Survival Times (e.g. Exponential Distribution with Lambda = 5)\n* Step 2: Simulate 227 random observations and randomly censor 164 of these observations\n* Step 3: Fit a Cox PH model to this simulated data and record performance measurements such as the coefficients, standard errors, p-values, likelihood ratio test, etc\n* Step 4: Calculate the squared difference between these performance measurements from the model with the simulated dataset vs the performance measurements from the model with the actual dataset - and then sum all these squared differences.\n* Step 5: Repeat Step 1 - Step 4 many times (e.g. 1000 times)\n* Step 6: Repeat Step 0 - 5 many times\n* Step 7: Use the Genetic Algorithm to find out which covariate ranges and covariate distributions bring you closest to the performance measurements of the original model. In other words, the \"summed squared difference\" is the Objective Function you will be attempting to optimize using the Genetic Algorithm.\n\nI know this is a very abstract and roundabout way that might not have any mathematical validity - **but I was curious to know if such an application of the Genetic Algorithm might be logical?**\n\nThanks!\n\n**Notes:**\n\n* I realize there are probably an infinite number of n = 227 samples that can be randomly simulated such that a Cox-PH Model produces the same regression coefficient estimates as above.\n* I realize that its entirely possible that I happen to simulate a dataset in which all the ages are concentrated around 20-25 years old when in fact the real age of the participants in this dataset were senior citizens - but based on the results of the other simulated variables, the resulting Cox-PH model produced using this simulated data might coincidentally have the same performance results as the original model - thus rendering this approach useless.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Using the Results of a Machine Learning to \"Guess\" the Dataset Used to Train a Machine Learning Model?",
            "upvote_ratio": 0.67,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11h6rij/d_using_the_results_of_a_machine_learning_to/"
        },
        {
            "author": "u/londons_explorer",
            "created_utc": "03-03-2023 10:37:03",
            "distinguished": null,
            "edited": false,
            "id": "11h3p2x",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11h3p2x",
            "nsfw": false,
            "num_comments": 165,
            "permalink": "/r/MachineLearning/comments/11h3p2x/d_facebooks_llama_leaks_via_torrent_file_in_pr/",
            "score": 482,
            "selftext": "See here:\nhttps://github.com/facebookresearch/llama/pull/73/files\n\nNote that this PR *is not* made by a member of Facebook/Meta staff.    I have downloaded parts of the torrent and it does appear to be lots of weights, although I haven't confirmed it is trained as in the LLaMA paper, although it seems likely.\n\n\nI wonder how much finetuning it would take to make this work like ChatGPT - finetuning tends to be much cheaper than the original training, so it might be something a community could do...",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Facebooks LLaMA leaks via torrent file in PR",
            "upvote_ratio": 0.98,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11h3p2x/d_facebooks_llama_leaks_via_torrent_file_in_pr/"
        },
        {
            "author": "u/44sps",
            "created_utc": "03-03-2023 07:17:41",
            "distinguished": null,
            "edited": false,
            "id": "11gzasl",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_11gzasl",
            "nsfw": false,
            "num_comments": 27,
            "permalink": "/r/MachineLearning/comments/11gzasl/p_we_are_building_a_curated_list_of_open_source/",
            "score": 126,
            "selftext": " Hey [r/MachineLearning](https://www.reddit.com/r/MachineLearning),\n\nwe are collecting a list of useful open source tools that enable data-centric AI workflows on unstructured data.\n\nHere is the link to the Github repo: [https://github.com/Renumics/awesome-open-data-centric-ai](https://github.com/Renumics/awesome-open-data-centric-ai)  \nDo you think there are tools missing? Please let me know or feel free to submit a pull request.\n\n&#x200B;\n\nhttps://preview.redd.it/eupaxhajnila1.png?width=4536&format=png&auto=webp&v=enabled&s=3d4d7875065dee684aecb8600947e8c1da94886c\n\nFor those who are not familiar with the term data-centric AI:\n\n**Data-centric AI (DCAI)** is a development paradigm for ML-based solutions. The term was coined by Andrew Ng who gave the following definition:\n\n>Data-centric AI is the practice of systematically engineering the data used to build AI systems.\n\nFrom my experience this approach is super important for most real-world use cases (regardless of team size).  \nHere is a talk from Andrew Ng that gives a good intro: [https://www.youtube.com/watch?v=06-AZXmwHjo](https://www.youtube.com/watch?v=06-AZXmwHjo)",
            "spoiler": false,
            "stickied": false,
            "title": "[P] We are building a curated list of open source tooling for data-centric AI workflows, looking for contributions.",
            "upvote_ratio": 0.96,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11gzasl/p_we_are_building_a_curated_list_of_open_source/"
        },
        {
            "author": "u/Living_Teaching9410",
            "created_utc": "03-03-2023 05:52:43",
            "distinguished": null,
            "edited": false,
            "id": "11gxqfh",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11gxqfh",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/11gxqfh/d_which_models_are_usually_used_in_space/",
            "score": 11,
            "selftext": "As the title says, if you want to model space elasticity of demand ( i.e. how the demand of a product is affected by the space allocated to it), how do you approach it from a modeling perspective? \n\nA couple of papers I came across:\n\nhttps://sal.aalto.fi/files/opinnot/kurssit/mat-2.kandi/esittelyt/vainiotommi-valmis.pdf\n\nhttps://sal.aalto.fi/publications/pdf-files/tvai18_public.pdf\n\nThanks",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Which models are usually used in space elasticity in retail? Can GBMs be used?",
            "upvote_ratio": 0.8,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11gxqfh/d_which_models_are_usually_used_in_space/"
        },
        {
            "author": "u/murrdpirate",
            "created_utc": "03-02-2023 20:14:19",
            "distinguished": null,
            "edited": false,
            "id": "11gmysn",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11gmysn",
            "nsfw": false,
            "num_comments": 2,
            "permalink": "/r/MachineLearning/comments/11gmysn/d_cycle_consistency_with_diffusion_models/",
            "score": 17,
            "selftext": "Denoising Diffusion Probabilistic Models (DDPMs) seem to be outperforming GANs in the last two years for topics such as image generation (e.g. Stable Diffusion and DALL-E 2).  Most problems involving image generation now have recent publications with DDPM techniques, with great results.\n\nThe one possible exception seems to be unpaired image-to-image translation, where you have two datasets with different types of images (e.g. photos of zebras and photos of horses), and the task is to be able to convert one to the other. CycleGAN famously demonstrated a technique based on cycle consistency to do this (e.g. transform a horse into a zebra).\n\nThe only DDPM approach for this I can find is called UNIT-DDPM. It has 41 citations, but does not appear to have been peer-reviewed or have any code published. It makes me wonder if the iterative training procedure for DDPMs is not a great fit for cycle consistency.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Cycle consistency with diffusion models?",
            "upvote_ratio": 0.87,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11gmysn/d_cycle_consistency_with_diffusion_models/"
        },
        {
            "author": "u/thejashGI",
            "created_utc": "03-02-2023 18:36:46",
            "distinguished": null,
            "edited": false,
            "id": "11gkkql",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11gkkql",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/11gkkql/d_sergey_levine_uc_berkeley_on_offline_rl_and_the/",
            "score": 11,
            "selftext": "Here is our [podcast episode](https://generallyintelligent.com/podcast/2023-03-01-podcast-episode-28-sergey-levine/) with Sergey Levine from UC Berkeley where we discussed the evolution of deep reinforcement learning, how previous robotics approaches were replaced, and why offline RL is significant for future generalization.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Sergey Levine, UC Berkeley, on offline RL and the evolution of deep reinforcement learning and robotics",
            "upvote_ratio": 0.82,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11gkkql/d_sergey_levine_uc_berkeley_on_offline_rl_and_the/"
        },
        {
            "author": "u/Upstairs-Jicama-8347",
            "created_utc": "03-02-2023 15:22:36",
            "distinguished": null,
            "edited": false,
            "id": "11gcwck",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_11gcwck",
            "nsfw": false,
            "num_comments": 11,
            "permalink": "/r/MachineLearning/comments/11gcwck/r_where_to_purchase_legitimate_models_already/",
            "score": 4,
            "selftext": "Can anyone recommend a company which sells legit (for commercial use) pretrained NN models or datasets for CV applications? I can't seem to find anyone that is well established.\n\nThanks.",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Where to purchase legitimate models (already trained) and datasets?",
            "upvote_ratio": 0.61,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11gcwck/r_where_to_purchase_legitimate_models_already/"
        },
        {
            "author": "u/jonas__m",
            "created_utc": "03-02-2023 14:14:56",
            "distinguished": null,
            "edited": false,
            "id": "11gb5aq",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_11gb5aq",
            "nsfw": false,
            "num_comments": 3,
            "permalink": "/r/MachineLearning/comments/11gb5aq/research_activelab_active_learning_with_data/",
            "score": 166,
            "selftext": "I\u2019m excited to share **ActiveLab**, a better algorithm for practical active learning.\n\nhttps://preview.redd.it/g4yvrdyrkdla1.png?width=1544&format=png&auto=webp&v=enabled&s=33ce49d75f26590a1b86fd59c98462c7359016da\n\nI recently published a [paper](https://arxiv.org/abs/2301.11856) introducing this novel method and an [open-source](https://github.com/cleanlab/cleanlab) Python implementation that is easy-to-use for all data types (image, text, tabular, audio, etc). For data scientists, I\u2019ve made a quick [Jupyter tutorial](https://github.com/cleanlab/examples/blob/master/active_learning_multiannotator/active_learning.ipynb) to run ActiveLab on your own data. For ML researchers, I\u2019ve made all of our [benchmarking code](https://github.com/cleanlab/multiannotator-benchmarks/tree/main/active_learning_benchmarks) available for reproducibility so you can see for yourself how effective ActiveLab is in practice.\n\nLabeled data is key to train models, but data annotators often make mistakes. One can collect multiple annotations per datapoint to get a more reliable consensus label, but this is expensive! To train the best ML model with the least data labeling, a key question is: **which new data should I label, or which of my current labels should be checked again?**\n\nhttps://preview.redd.it/wvm5sskokdla1.png?width=960&format=png&auto=webp&v=enabled&s=3c6000bdbfc28217bf8f0f4d0910bf65f12d6cbd\n\nActiveLab automatically answers this question for you, allowing you to train the most accurate ML model via a smaller number of total annotations than required to reach similar accuracy with popular active learning methods.  ActiveLab is highly practical \u2014 it runs quickly and works with: any type of ML model, batch settings where many examples are (re)labeled before model retraining, and settings where multiple annotators can label an example (or just one annotator).\n\nIf you're interested in reading more, check out my blogpost: [https://cleanlab.ai/blog/active-learning/](https://cleanlab.ai/blog/active-learning/)",
            "spoiler": false,
            "stickied": false,
            "title": "[Research] ActiveLab: Active Learning with Data Re-Labeling",
            "upvote_ratio": 0.93,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11gb5aq/research_activelab_active_learning_with_data/"
        },
        {
            "author": "u/urban_fantast",
            "created_utc": "03-02-2023 12:35:42",
            "distinguished": null,
            "edited": false,
            "id": "11g8oml",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11g8oml",
            "nsfw": false,
            "num_comments": 2,
            "permalink": "/r/MachineLearning/comments/11g8oml/d_compare_clusters_from_different_unsupervised_ml/",
            "score": 3,
            "selftext": "Is there a way to visualize/compare the clusters formed from running multiple unsupervised learning experiments on a dataset. The experiments in question here are using data collected at different points of time, different data processing strategies (imputation, feature selection etc) and different algorithms ( kmeans, dbscan, Agglomerate clustering etc). We have identified a total of 80 such experiments that we want to run.\n\nIs there a way to compare the clusters formed by each of these experiments? We have identified that they are more or less similar ( 2 big clusters and one small one), but we were looking for ways to visualize it a little bit more and see if the same groups make the clusters in each of the exps. If it was not clear, the cluster labels from the algorithms are different across experiments, even though the cluster by itself is the same.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Compare clusters from different unsupervised ML experiments",
            "upvote_ratio": 0.72,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11g8oml/d_compare_clusters_from_different_unsupervised_ml/"
        },
        {
            "author": "u/of_a_varsity_athlete",
            "created_utc": "03-02-2023 12:01:53",
            "distinguished": null,
            "edited": false,
            "id": "11g7u60",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11g7u60",
            "nsfw": false,
            "num_comments": 6,
            "permalink": "/r/MachineLearning/comments/11g7u60/d_is_there_an_ml_project_out_there_that/",
            "score": 3,
            "selftext": "Every movie recommender I've come accross gives pretty similar answers which completely misunderstand what I think of when I mean \"similar\".  What the recommenders think I mean is \"Give me a movie that has similar topic keywords, or same star, or same director\", whereas what I mean is \"Give me a movie that gives me these same sensations\".\n\nFor instance, a movie I really like and often think \"I'm in the mood for a movie like that\" about is Margin Call.  It's all slick night time looking, happens in a condensed span of time, feels very Manhattan and business class.  When I watch it I feel like I can hear the pulse of the city.  There's an ASMR like quality to it in my opinion.  It's all plush and expensive feeling.\n\nBut what does every recommender tell me?  Watch Big Short, or Inside Job.  One is a brash franticly hand held comedy with popping colors, and the other is a documentary.  But because they came out at the same time about the same topic, recommenders think that's a good choice.  A much better choice would be Michael Clayton, which is a different year, different topic, different director, etc, but has many tactile similarities to Margin Call, as I describe them above.\n\nIs anybody working on or has already provided an ML based tool which somehow measures \"vibe\"?  Maybe it's color palette, or edit speed, or score key, or any of that stuff?  I'd be interested.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Is there an ML project out there that recommends movies based on more than the usual features?",
            "upvote_ratio": 0.6,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11g7u60/d_is_there_an_ml_project_out_there_that/"
        },
        {
            "author": "u/StellaAthena",
            "created_utc": "03-02-2023 09:35:43",
            "distinguished": null,
            "edited": false,
            "id": "11g4a9p",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": null,
            "locked": false,
            "name": "t3_11g4a9p",
            "nsfw": false,
            "num_comments": 17,
            "permalink": "/r/MachineLearning/comments/11g4a9p/n_eleutherai_has_formed_a_nonprofit/",
            "score": 167,
            "selftext": "Over the past two and a half years, EleutherAI has grown from a group of hackers on Discord to a thriving open science research community. Today, [we are excited to announce](https://blog.eleuther.ai/year-two-preface/) the next step in our evolution: the formation of a non-profit research institute.\n\nThis will enable us to do much more, and we look forward to building a world class research group for public good! This organization will be lead by long-time contributors to EleutherAI: Stella Biderman (me) as Executive Director and Head of Research, Curtis Huebner as Head of Alignment, and Shiv Purohit as Head of Engineering.\n\nThe world has changed quite a lot since we first got started. When EleutherAI was founded, the largest open source GPT-3-style language model in the world had 1.5B parameters. GPT-3 itself was not available for researchers to study without special access from OpenAI, and most NLP researchers had a very minimal understanding of the engineering undertaking required to train such models or their capabilities & limitations. We started as a ragtag group nobody had heard of, and within a year had released the largest OSS GPT-3-style model in the world.\n\nAs access to LLMs has increased, our research has shifted to focus more on interpretability, alignment, ethics, and evaluation of AIs. We look forward to continuing to grow and adapt to the needs of researchers and the public\n\nCheck out our latest work at www.eleuther.ai or come hang out in our research lab at www.discord.gg/eleutherai\n\nHuge shout out to the donors who have made our work possible: Stability AI, Hugging Face, CoreWeave, Nat Friedman, Lambda Labs, and Canva",
            "spoiler": false,
            "stickied": false,
            "title": "[N] EleutherAI has formed a non-profit",
            "upvote_ratio": 0.94,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11g4a9p/n_eleutherai_has_formed_a_nonprofit/"
        },
        {
            "author": "u/RefreshedCare",
            "created_utc": "03-02-2023 09:26:14",
            "distinguished": null,
            "edited": false,
            "id": "11g42jl",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_11g42jl",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/11g42jl/pairwise_ranknet_loss_graph_flatlines_after_1/",
            "score": 1,
            "selftext": "&#x200B;\n\n&#x200B;\n\nhttps://preview.redd.it/iea8vxdo5cla1.png?width=372&format=png&auto=webp&v=enabled&s=ea7c895acb5c34f22064e2913ae6c16454871139\n\nhttps://preview.redd.it/fxoyc0eo5cla1.png?width=375&format=png&auto=webp&v=enabled&s=f2b9480f2638315aaf0b67b65a865eee4df4e59e\n\nThe Pairwise Ranking Algo I built both appears to be overfitting (val loss < training loss) and stops improving after the first epoch. The val loss doesn't appear to ever improve. Is there a problem in my code that is causing this flatline phenomenon? I have never seen something like this. I took this out to 25 epochs and got the same results.\n\nHere is a sample of the training data. I removed the array of feature data because it was obviously very long. The data is all numerical. No null values. Pair\\_id references the index location of each record from the original dataset. pij represent if xi > xj (1.0), xi =xj (0.5) or xi < xj (0):\n\n    pair_id            pair_query_id    xi                      xj                  pij [2730195,2730221]   48609   ['ARRAY OF 38 FEATURES']['ARRRAY OF 38 FEATURES']   0.5 \n\nHere is the code:\n\n    class RankNet(Model):\n        def __init__(self, dropout_rate=0.2):\n            super().__init__()\n            self.normalization = Normalization()\n            self.dense = [layers.Dense(32, activation='relu'), \n                          layers.Dropout(dropout_rate),\n                          layers.Dense(16, activation='relu'),\n                          layers.Dropout(dropout_rate),\n                          layers.Dense(8, activation='relu'),\n                          layers.Dropout(dropout_rate)]\n            self.o = layers.Dense(1, activation='linear')\n            self.oi_minus_oj = layers.Subtract()\n            \n        def call(self, inputs):\n          xi, xj = inputs\n          x = tf.concat([xi, xj], axis=0)\n          normalized_x = self.normalization(x)\n          normalized_xi, normalized_xj = tf.split(normalized_x, num_or_size_splits=2, axis=0)\n          densei = self.dense[0](normalized_xi)\n          densej = self.dense[0](normalized_xj)\n          for dense in self.dense[1:]:\n            densei = dense(densei)\n            densej = dense(densej)\n          oi = self.o(densei)\n          oj = self.o(densej)\n          oij = self.oi_minus_oj([oi, oj])\n          output = layers.Activation('sigmoid')(oij)\n          return output\n        \n        def build_graph(self):\n            x = [Input(shape=(38)), Input(shape=(38))]\n            normalized_x = self.normalization(x)\n            return Model(inputs=x, outputs=self.call(normalized_x))\n    # Create an instance of EarlyStopping\n    early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n    \n    # train model using compile and fit\n    ranknet = RankNet()\n    ranknet.compile(optimizer='adam', loss='binary_crossentropy')\n    \n    # Train the model with EarlyStopping callback\n    history = ranknet.fit([xi, xj], pij, epochs=25, batch_size=100,\n                          validation_data=([xi_val, xj_val], pij_val),\n                          callbacks=[early_stopping]) \n\nI recently added the Normalization portion to see if that would help with overfitting. Additionally, I added a few hidden layers including the dropout layers. The first graph was taken after all that was added. The second graph to 25 epochs was before that was added.\n\nI feel like I am missing something major that is allowing the loss to continue to update like it should.",
            "spoiler": false,
            "stickied": false,
            "title": "Pairwise RankNet loss graph flatlines after 1 epoch for both val and training loss. What's going on? [P]",
            "upvote_ratio": 0.6,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11g42jl/pairwise_ranknet_loss_graph_flatlines_after_1/"
        },
        {
            "author": "u/rm-rf_",
            "created_utc": "03-02-2023 08:38:45",
            "distinguished": null,
            "edited": false,
            "id": "11g306o",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11g306o",
            "nsfw": false,
            "num_comments": 91,
            "permalink": "/r/MachineLearning/comments/11g306o/d_have_there_been_any_significant_breakthroughs/",
            "score": 66,
            "selftext": "A huge issue with making LLMs useful is the fact that they can hallucinate and make up information. This means any information an LLM provides must be validated by the user to some extent, which makes a lot of use-cases less compelling.\n\nHave there been any significant breakthroughs on eliminating LLM hallucinations?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Have there been any significant breakthroughs on eliminating LLM hallucinations?",
            "upvote_ratio": 0.82,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11g306o/d_have_there_been_any_significant_breakthroughs/"
        },
        {
            "author": "u/tfburns",
            "created_utc": "03-02-2023 08:10:45",
            "distinguished": null,
            "edited": false,
            "id": "11g2ewc",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_11g2ewc",
            "nsfw": false,
            "num_comments": 4,
            "permalink": "/r/MachineLearning/comments/11g2ewc/r_simplicial_hopfield_networks/",
            "score": 44,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Simplicial Hopfield networks",
            "upvote_ratio": 0.96,
            "url": "https://openreview.net/forum?id=_QLsH8gatwx"
        },
        {
            "author": "u/mikonvergence",
            "created_utc": "03-02-2023 07:06:10",
            "distinguished": null,
            "edited": false,
            "id": "11g14sp",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_11g14sp",
            "nsfw": false,
            "num_comments": 21,
            "permalink": "/r/MachineLearning/comments/11g14sp/p_a_minimal_framework_for_image_diffusion/",
            "score": 74,
            "selftext": "Hi all!\n\nI have recently put together a course on diffusion image generation that includes videos, a minimal PyTorch framework, and a set of notebooks (all results can be run in Google colab!)\n\n[https://github.com/mikonvergence/DiffusionFastForward](https://github.com/mikonvergence/DiffusionFastForward)\n\nI am hoping it can help those interested in learning to train diffusion models from scratch in a TLDR mode. What I think is quite different here from other tutorials is that it includes not only low-resolution generation (64x64) but also **notebooks for training in high-resolution (256x256) from scratch**. And also an example of an **image-to-image translation** that I think some people will find entertaining!\n\n&#x200B;\n\nI'm looking forward to hearing some feedback or comments, and I hope you enjoy the course if you decide to check it out!\n\nPS. you can also go directly to the videos on YT [https://youtube.com/playlist?list=PL5RHjmn-MVHDMcqx-SI53mB7sFOqPK6gN](https://youtube.com/playlist?list=PL5RHjmn-MVHDMcqx-SI53mB7sFOqPK6gN)",
            "spoiler": false,
            "stickied": false,
            "title": "[P] A minimal framework for image diffusion (including high-resolution)",
            "upvote_ratio": 0.95,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11g14sp/p_a_minimal_framework_for_image_diffusion/"
        },
        {
            "author": "u/Deb_Koushik",
            "created_utc": "03-02-2023 06:34:49",
            "distinguished": null,
            "edited": false,
            "id": "11g0knb",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_11g0knb",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/11g0knb/unable_to_write_code_from_scratch_for_few_shots/",
            "score": 0,
            "selftext": " I am trying to write python code to develop Name Entity Recognition function by Few Shots or Zero Shot Learning on Bengali Language. I am looking for python code from scratch which can accomplish few shots or zero shot NER.",
            "spoiler": false,
            "stickied": false,
            "title": "Unable to write code from scratch for Few Shots or Zero Shot NER [Research]",
            "upvote_ratio": 0.25,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11g0knb/unable_to_write_code_from_scratch_for_few_shots/"
        },
        {
            "author": "u/BaosteelMetallurgy",
            "created_utc": "03-02-2023 03:48:24",
            "distinguished": null,
            "edited": false,
            "id": "11fxt20",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11fxt20",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/11fxt20/industrial_robot_for_wire_rod_automatic_tagging_d/",
            "score": 1,
            "selftext": "At present, after the wire rolls are packed and weighed in the high-line factory, the marking of the finished high-line products is all done by manual printing, manual picking, and manual listing. The workload is heavy, and it is a simple and repetitive labor that requires the participation of many operators. There are high labor costs, poor on-site operating environment (high temperature, dust, noise), and potential safety hazards such as burns and bruises during operation. Now industrial robots can do the job perfectly.",
            "spoiler": false,
            "stickied": false,
            "title": "Industrial robot - for wire rod automatic tagging [D]",
            "upvote_ratio": 0.67,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11fxt20/industrial_robot_for_wire_rod_automatic_tagging_d/"
        },
        {
            "author": "u/NourElDin2303",
            "created_utc": "03-02-2023 03:29:45",
            "distinguished": null,
            "edited": false,
            "id": "11fxhmn",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11fxhmn",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/11fxhmn/federated_learning_frameworks_with_a_virtual_try/",
            "score": 0,
            "selftext": "How can I use federated learning frameworks with a virtual try on deep learning model ?\n\nAs the size of the model is too large to be trained on users' machines offline and it needs high hardware specifications",
            "spoiler": false,
            "stickied": false,
            "title": "Federated learning frameworks with a virtual try on deep learning model \"[Discussion]\", \"[D]\"",
            "upvote_ratio": 0.5,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11fxhmn/federated_learning_frameworks_with_a_virtual_try/"
        },
        {
            "author": "u/SeBAGeNetiC",
            "created_utc": "03-01-2023 22:41:27",
            "distinguished": null,
            "edited": "03-01-2023 23:24:13",
            "id": "11frud9",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_11frud9",
            "nsfw": false,
            "num_comments": 4,
            "permalink": "/r/MachineLearning/comments/11frud9/r_best_way_to_categorize_by_a_product_name/",
            "score": 2,
            "selftext": "Hi :) I'm new to this and I'm testing a lot of stuff and getting good models (I think).\nI've done my fair amount of google and testing already.  \nBut I'd like to know if there are better options (or a best option) I'm not aware of.  \n\nI have a huge data set, millions of product names and their category, manually done by humans, so we can assume they are right.\nNow I want to predict categories for new items base on their names too, so what I'm currently doing is vectorize using TF-IDF (also testing Count) and doing LogisticRegression.\nIs this the best way? The number of possible categories is in the hundreds.\nAny tips? Things I should try? Stuff to read or videos to watch?\nis MultinomialNB better for this case? I've seen some examples but I don't grasp this one yet\n\nThanks for any help",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Best way to categorize by a product name?",
            "upvote_ratio": 0.67,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11frud9/r_best_way_to_categorize_by_a_product_name/"
        },
        {
            "author": "u/hazardoussouth",
            "created_utc": "03-01-2023 20:44:53",
            "distinguished": null,
            "edited": false,
            "id": "11fp4x0",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_11fp4x0",
            "nsfw": false,
            "num_comments": 14,
            "permalink": "/r/MachineLearning/comments/11fp4x0/r_geometric_deep_learning_grids_groups_graphs/",
            "score": 56,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Geometric Deep Learning: Grids, Groups, Graphs, Geodesics, and Gauges Michael M. Bronstein",
            "upvote_ratio": 0.91,
            "url": "https://arxiv.org/abs/2104.13478"
        },
        {
            "author": "u/Tight-Vacation-9410",
            "created_utc": "03-01-2023 20:42:21",
            "distinguished": null,
            "edited": false,
            "id": "11fp2tb",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11fp2tb",
            "nsfw": false,
            "num_comments": 13,
            "permalink": "/r/MachineLearning/comments/11fp2tb/d_podcasts_about_ml_research/",
            "score": 31,
            "selftext": "Hey guys. I am an undergraduate working at an NLP lab now. I drive a lot, so I was wondering if there are any podcasts about ML research (preferrably NLP related stuff) I could check out. Thanks!",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Podcasts about ML research?",
            "upvote_ratio": 0.87,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11fp2tb/d_podcasts_about_ml_research/"
        },
        {
            "author": "u/Blutorangensaft",
            "created_utc": "03-01-2023 19:42:55",
            "distinguished": null,
            "edited": false,
            "id": "11fnnc7",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11fnnc7",
            "nsfw": false,
            "num_comments": 12,
            "permalink": "/r/MachineLearning/comments/11fnnc7/d_what_are_current_alternatives_to_gradientbased/",
            "score": 12,
            "selftext": "What alternatives to gradient descent are currently being researched?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] What are current alternatives to gradient-based NN training?",
            "upvote_ratio": 0.84,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11fnnc7/d_what_are_current_alternatives_to_gradientbased/"
        },
        {
            "author": "u/TobusFire",
            "created_utc": "03-01-2023 16:25:08",
            "distinguished": null,
            "edited": false,
            "id": "11fil25",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11fil25",
            "nsfw": false,
            "num_comments": 92,
            "permalink": "/r/MachineLearning/comments/11fil25/d_are_genetic_algorithms_dead/",
            "score": 72,
            "selftext": "Seems like the common thinking these days is that genetic algorithms really have extremely limited use-cases these days, and even in those cases they are usually very slow.\n\nMy thoughts are that the idea of designing an experiment for a genetic algorithm requires sufficient prior on the environment and possible mutations already that it's probably easier to just use another approach. I'm no expert but I am interested to hear others' thoughts on if there are valid use cases outside of pure interest and having fun with evolution.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Are Genetic Algorithms Dead?",
            "upvote_ratio": 0.92,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11fil25/d_are_genetic_algorithms_dead/"
        },
        {
            "author": "u/niosurfer",
            "created_utc": "03-01-2023 16:12:51",
            "distinguished": null,
            "edited": "03-01-2023 16:27:32",
            "id": "11fi9ef",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_11fi9ef",
            "nsfw": false,
            "num_comments": 4,
            "permalink": "/r/MachineLearning/comments/11fi9ef/p_is_there_a_simple_mnist_library_for_python/",
            "score": 0,
            "selftext": "It would be something similar to *mnist-ready* ([https://github.com/saoj/mnist-ready](https://github.com/saoj/mnist-ready)) in Ruby, but in Python. See below:\n\n    digit = MNIST.all_set[0] # first one\n    \n    # An integer corresponding to the digit of the image\n    puts digit.label # => 7\n    \n    # The pixels is an one-dimension array of 784 (28 x 28) pixel values from 0 to 255\n    puts digit.pixels.size # => 784\n    puts digit.pixels.inspect # => [0, 0, 0, 0, ...\n\nIt has this nice feature which allows you to see the digits:\n\n    puts digit.ascii_image\n     ____________________________ \n    |            7               |\n    |----------------------------|\n    |                            |\n    |      }wJY+I                |\n    |      #$$$$%ddddddddQ>      |\n    |      -f?fCM$M$$$$W$$c      |\n    |            _^---~\"8$/      |\n    |                  }$h       |\n    |                 \"&$}       |\n    |                 n$8!       |\n    |                ~@$+        |\n    |                u$w.        |\n    |               `k@~         |\n    |               x$m          |\n    |              ]$%~          |\n    |              #$L           |\n    |            .k$*I           |\n    |            l$$]            |\n    |           ;#$f             |\n    |           u$$>             |\n    |          +%$$>             |\n    |          r$$*l             |\n    |          r$h               |\n    |____________________________|",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Is there a simple MNIST library for Python which already comes with the MNIST dataset inside of it, so I can just import and play without having to mess with the MNIST files themselves?",
            "upvote_ratio": 0.38,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11fi9ef/p_is_there_a_simple_mnist_library_for_python/"
        },
        {
            "author": "u/blabboy",
            "created_utc": "03-01-2023 14:53:02",
            "distinguished": null,
            "edited": false,
            "id": "11ffg1u",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11ffg1u",
            "nsfw": false,
            "num_comments": 57,
            "permalink": "/r/MachineLearning/comments/11ffg1u/d_blake_lemoine_i_worked_on_googles_ai_my_fears/",
            "score": 0,
            "selftext": "An article written by Blake Lemoine, the man who sounded the alarm about Google LaMDA's sentience last summer.\n\nOne quote that caught my eye:\n\n\"Since Bing's AI has been released, people have commented on its potential sentience, raising similar concerns that I did last summer. I don't think \"vindicated\" is the right word for how this has felt. Predicting a train wreck, having people tell you that there's no train, and then watching the train wreck happen in real time doesn't really lead to a feeling of vindication. It's just tragic.\"\n\nhttps://www.newsweek.com/google-ai-blake-lemoine-bing-chatbot-sentient-1783340",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Blake Lemoine: I Worked on Google's AI. My Fears Are Coming True.",
            "upvote_ratio": 0.12,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11ffg1u/d_blake_lemoine_i_worked_on_googles_ai_my_fears/"
        },
        {
            "author": "u/suren_at",
            "created_utc": "03-01-2023 13:34:41",
            "distinguished": null,
            "edited": false,
            "id": "11fbfkb",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "News",
            "locked": false,
            "name": "t3_11fbfkb",
            "nsfw": false,
            "num_comments": 5,
            "permalink": "/r/MachineLearning/comments/11fbfkb/n_blueprint_finetune_and_serve_stable_diffusion/",
            "score": 9,
            "selftext": "Blueprint is a general fine-tuning and model serving API built for developers. Fine-tuning models is an extremely powerful way to improve performance on a specific task without needing to collect prohibitively large amounts of data. With Blueprint you can kick off fine-tuning jobs for various open source models like Stable Diffusion and soon Flan-T5 using a Python SDK.\n\nWe'll also deploy your fine-tuned models onto serverless GPUs so that you aren't paying for idle GPU time. We scale the models up when you need to serve requests and have put a ton of engineering work into faster cold starts. We'll also autoscale replicas of your model if your model is receiving a lot of traffic.\n\nGive it a shot \u2014 every new account gets a few hours of GPU credits.",
            "spoiler": false,
            "stickied": false,
            "title": "[N] Blueprint: fine-tune (and serve) stable diffusion and more... (FLAN-T5 and Whisper are coming soon)",
            "upvote_ratio": 0.8,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11fbfkb/n_blueprint_finetune_and_serve_stable_diffusion/"
        },
        {
            "author": "u/minimaxir",
            "created_utc": "03-01-2023 13:31:12",
            "distinguished": null,
            "edited": false,
            "id": "11fbccz",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11fbccz",
            "nsfw": false,
            "num_comments": 122,
            "permalink": "/r/MachineLearning/comments/11fbccz/d_openai_introduces_chatgpt_and_whisper_apis/",
            "score": 573,
            "selftext": "https://openai.com/blog/introducing-chatgpt-and-whisper-apis\n\n> It is priced at $0.002 per 1k tokens, which is 10x cheaper than our existing GPT-3.5 models.\n\nThis is a massive, massive deal. For context, the reason GPT-3 apps took off over the past few months before ChatGPT went viral is because a) text-davinci-003 was released and was a significant performance increase and b) the cost was cut from $0.06/1k tokens to $0.02/1k tokens, which made consumer applications feasible without a large upfront cost.\n\nA much better model and a 1/10th cost warps the economics completely to the point that it may be better than in-house finetuned LLMs.\n\nI have no idea how OpenAI can make money on this. This has to be a loss-leader to lock out competitors before they even get off the ground.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] OpenAI introduces ChatGPT and Whisper APIs (ChatGPT API is 1/10th the cost of GPT-3 API)",
            "upvote_ratio": 0.97,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11fbccz/d_openai_introduces_chatgpt_and_whisper_apis/"
        },
        {
            "author": "u/Funny_Rule2482",
            "created_utc": "03-01-2023 12:25:38",
            "distinguished": null,
            "edited": false,
            "id": "11f9mi0",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11f9mi0",
            "nsfw": false,
            "num_comments": 3,
            "permalink": "/r/MachineLearning/comments/11f9mi0/d_any_open_source_libraries_for_recommender/",
            "score": 3,
            "selftext": "Hi All, I am researching cross-domain recommender systems, and I have created my own algorithm. I would like to test my algorithm against some baselines to see how well my algorithm works. I am struggling to find libraries that have implementations of existing cross-domain recommendation algorithms. If any of you know about open source recommendation libraries, that would be very helpful to me.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Any open source libraries for Recommender Systems?",
            "upvote_ratio": 0.71,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11f9mi0/d_any_open_source_libraries_for_recommender/"
        },
        {
            "author": "u/bo_peng",
            "created_utc": "03-01-2023 12:23:03",
            "distinguished": null,
            "edited": "03-01-2023 15:14:20",
            "id": "11f9k5g",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_11f9k5g",
            "nsfw": false,
            "num_comments": 26,
            "permalink": "/r/MachineLearning/comments/11f9k5g/p_chatrwkv_v2_can_run_rwkv_14b_with_3g_vram_rwkv/",
            "score": 89,
            "selftext": "Hi everyone. Now ChatRWKV v2 can split RWKV to multiple GPUs, or stream layers (compute layer-by-layer), so you can run RWKV 14B with as few as 3G VRAM. [https://github.com/BlinkDL/ChatRWKV](https://github.com/BlinkDL/ChatRWKV)\n\nExample:\n\n`'cuda:0 fp16 *10 -> cuda:1 fp16 *8 -> cpu fp32'` = first 10 layers on cuda:0 fp16, then 8 layers on cuda:1 fp16, then on cpu fp32\n\n`'cuda fp16 *20+'` = first 20 layers on cuda fp16, then stream the rest on it\n\nAnd RWKV is now a pip package: [https://pypi.org/project/rwkv/](https://pypi.org/project/rwkv/)\n\n    os.environ['RWKV_JIT_ON'] = '1'\n    os.environ[\"RWKV_CUDA_ON\"] = '0' # if '1' then compile CUDA kernel for seq mode (much faster)\n    from rwkv.model import RWKV\n    from rwkv.utils import PIPELINE, PIPELINE_ARGS\n    pipeline = PIPELINE(model, \"20B_tokenizer.json\") # find it in https://github.com/BlinkDL/ChatRWKV\n    # download models: https://huggingface.co/BlinkDL\n    model = RWKV(model='/fsx/BlinkDL/HF-MODEL/rwkv-4-pile-169m/RWKV-4-Pile-169M-20220807-8023', strategy='cpu fp32')\n    ctx = \"\\nIn a shocking finding, scientist discovered a herd of dragons living in a remote, previously unexplored valley, in Tibet. Even more surprising to the researchers was the fact that the dragons spoke perfect Chinese.\"\n    print(ctx, end='')\n    def my_print(s):\n        print(s, end='', flush=True)\n    # For alpha_frequency and alpha_presence, see \"Frequency and presence penalties\":\n    # https://platform.openai.com/docs/api-reference/parameter-details\n    args = PIPELINE_ARGS(temperature = 1.0, top_p = 0.7,\n        alpha_frequency = 0.25,\n        alpha_presence = 0.25,\n        token_ban = [0], # ban the generation of some tokens\n        token_stop = []) # stop generation whenever you see any token here\n    pipeline.generate(ctx, token_count=512, args=args, callback=my_print)\n\nRight now all RWKV models are still trained with GPT-like method, so they are limited by the ctxlen used in training, even though in theory they should have almost infinite ctxlen (because they are RNNs). However RWKV models can be easily finetuned to support longer ctxlens (and large models actually use the ctxlen). I have finetuned 1B5/3B/7B/14B to ctx4K, and now finetuning 7B/14B to ctx8K, and 14B to ctx16K after that :) All models are available at [https://huggingface.co/BlinkDL](https://huggingface.co/BlinkDL)\n\nThe core RWKV is still mostly an one-man project, but a number of great developers are building on top of it, and you are welcome to join our community :)",
            "spoiler": false,
            "stickied": false,
            "title": "[P] ChatRWKV v2 (can run RWKV 14B with 3G VRAM), RWKV pip package, and finetuning to ctx16K",
            "upvote_ratio": 0.98,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11f9k5g/p_chatrwkv_v2_can_run_rwkv_14b_with_3g_vram_rwkv/"
        },
        {
            "author": "u/AdelSexy",
            "created_utc": "03-01-2023 12:21:40",
            "distinguished": null,
            "edited": "03-01-2023 15:44:04",
            "id": "11f9ive",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_11f9ive",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/11f9ive/p_packpacka_diffusion_based_photo_colorizer/",
            "score": 16,
            "selftext": "Together with my friend we created a service to colorize black and white photos. It is a work in progress, and UI is, em, goofy and not in the best condition, but the model does a decent job.\n\n[https://packpacka.me/](https://packpacka.me/)\n\nWe trained a diffusion model for this, and although our resources are limited, we still managed to create a relatively fast training pipeline. We also managed to find a way for a fast inference (sampling) of the model, without significant loss in quality. In \\~5 sec it generated 3 different version of colorization for a given image. This includes image uploading time as well.\n\nWe know it is not perfect yet, but already doing some nice job! No metrics and comparisons yet, but will come later.I will write some more details in here: [https://irregularadel.substack.com/](https://irregularadel.substack.com/)\n\nPlay around with images from here: [https://www.shorpy.com/node?page=1](https://www.shorpy.com/node?page=1) and [/r/TheWayWeWere/](https://www.reddit.com/r/TheWayWeWere/)\n\n&#x200B;\n\nhttps://preview.redd.it/uhtufo96w6la1.png?width=2974&format=png&auto=webp&v=enabled&s=0a1681acbd2f6e4fabbbd1b53a2adcb8afbda078\n\nI've  learned a lot about diffusion models training, while working on this pet project.Also thinking about writing a paper, since we believe we have things to share. But we are not affiliated with any institution, thus I am not sure how to approach this. Anyone had experience submitting papers as individual researcher?\n\nThanks!",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Packpacka - diffusion based photo colorizer",
            "upvote_ratio": 0.87,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11f9ive/p_packpacka_diffusion_based_photo_colorizer/"
        },
        {
            "author": "u/floatingkudu",
            "created_utc": "03-01-2023 10:41:32",
            "distinguished": null,
            "edited": false,
            "id": "11f6ysx",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11f6ysx",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/11f6ysx/d_useful_training_datasets/",
            "score": 2,
            "selftext": "Hello all - I could do with some input from those involved in ML work. I want to create some open datasets that would be of use to AI researchers ([examples](https://scale.com/open-av-datasets)). I have the capacity to create very large annotated datasets, but at the moment no strong inkling as to the *type* of dataset to create.\n\nIf you work in ML, what do you think would be the most useful annotated training dataset that would have a broad appeal?\n\nExample: Categorise tweets by toxicity, or classify images by presence of X/Y\n\nThanks in advance for any suggestions!",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Useful training datasets?",
            "upvote_ratio": 0.75,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11f6ysx/d_useful_training_datasets/"
        },
        {
            "author": "u/AImSamy",
            "created_utc": "03-01-2023 10:06:57",
            "distinguished": null,
            "edited": false,
            "id": "11f637p",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11f637p",
            "nsfw": false,
            "num_comments": 10,
            "permalink": "/r/MachineLearning/comments/11f637p/d_what_are_the_most_known_architectures_of_text/",
            "score": 1,
            "selftext": "There are tens of companies proposing their text-to-image models:\n\nNightCafe,  Dream by WOMBO, DALL-E 2, Midjourney, Stable Diffusion,  StabilityAI ...etc\n\nWhat are the different architectures they use ? or do they only differ on training datasets ?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] What are the most known architectures of Text To Image models ?",
            "upvote_ratio": 0.57,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11f637p/d_what_are_the_most_known_architectures_of_text/"
        },
        {
            "author": "u/Justin-Griefer",
            "created_utc": "03-01-2023 07:21:00",
            "distinguished": null,
            "edited": false,
            "id": "11f2dzx",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11f2dzx",
            "nsfw": false,
            "num_comments": 10,
            "permalink": "/r/MachineLearning/comments/11f2dzx/d_pretrained_model_like_resnet_that_specializes/",
            "score": 0,
            "selftext": "Hello fellow humans, human fellas. Do any of you know a pretrained model that specializes in grayscale imagery.  \nAlternatively, how to change the existing pretrained models to fit a grayscale NL",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Pretrained model like Resnet that specializes in Grayscale",
            "upvote_ratio": 0.5,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11f2dzx/d_pretrained_model_like_resnet_that_specializes/"
        },
        {
            "author": "u/Neurosymbolic",
            "created_utc": "03-01-2023 07:14:49",
            "distinguished": null,
            "edited": false,
            "id": "11f29f9",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_11f29f9",
            "nsfw": false,
            "num_comments": 66,
            "permalink": "/r/MachineLearning/comments/11f29f9/r_chatgpt_failure_increase_linearly_with_addition/",
            "score": 240,
            "selftext": " We did a study on ChatGPT's performance on math word problems. We found, under several conditions, its probability of failure increases linearly with the number of addition and subtraction operations - see below. This could imply that multi-step inference is a limitation. The performance also changes drastically when you restrict ChatGPT from showing its work (note the priors in the figure below, also see detailed breakdown of responses in the paper).\n\n&#x200B;\n\n[Math problems adds and subs vs. ChatGPT prob. of failure](https://preview.redd.it/z88ey3n6d4la1.png?width=1451&format=png&auto=webp&v=enabled&s=664d08e344acc3ffae7b4dcc291275dfe4e5c14f)\n\nChatGPT Probability of Failure increase with addition and subtraction operations.\n\nYou the paper (preprint: [https://arxiv.org/abs/2302.13814](https://arxiv.org/abs/2302.13814)) will be presented at AAAI-MAKE next month. You can also check out our video here: [https://www.youtube.com/watch?v=vD-YSTLKRC8](https://www.youtube.com/watch?v=vD-YSTLKRC8)\n\n&#x200B;\n\nhttps://preview.redd.it/k58sbjd5d4la1.png?width=1264&format=png&auto=webp&v=enabled&s=3aa39ef44503606b0dec813b0c67883ef801ab03",
            "spoiler": false,
            "stickied": false,
            "title": "[R] ChatGPT failure increase linearly with addition on math problems",
            "upvote_ratio": 0.94,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11f29f9/r_chatgpt_failure_increase_linearly_with_addition/"
        },
        {
            "author": "u/MysteryInc152",
            "created_utc": "03-01-2023 07:10:41",
            "distinguished": null,
            "edited": false,
            "id": "11f26ig",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_11f26ig",
            "nsfw": false,
            "num_comments": 6,
            "permalink": "/r/MachineLearning/comments/11f26ig/r_evoprompting_language_models_can_create_novel/",
            "score": 10,
            "selftext": "Paper - [https://arxiv.org/abs/2302.14838](https://arxiv.org/abs/2302.14838)",
            "spoiler": false,
            "stickied": false,
            "title": "[R] EvoPrompting: Language models can create novel and effective deep neural architectures. These architectures are also able to outperform those designed by human experts (with few-shot prompting)",
            "upvote_ratio": 0.71,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11f26ig/r_evoprompting_language_models_can_create_novel/"
        },
        {
            "author": "u/smoke_carrot",
            "created_utc": "03-01-2023 06:07:00",
            "distinguished": null,
            "edited": false,
            "id": "11f0zs6",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11f0zs6",
            "nsfw": false,
            "num_comments": 21,
            "permalink": "/r/MachineLearning/comments/11f0zs6/d_which_ec2_instance_types_do_you_use_for/",
            "score": 12,
            "selftext": "At my company, we have a few workstations with Nvidia GPUs that we use for our most common tasks. We train regular-sized CNNs for medical image analysis.\n\nFor some projects, the 12\u00a0GB GPU RAM that our in-house GPU have is a bit restrictive, so I have started looking at EC2 (which I know is not the best, but to which we already have access to, so that's what we will use).\n\nI noticed that the offering has increased a lot recently, so I'm looking for other people's experience to help navigate all the different GPU instance types. P3, P4, G5, Trn1, ... Which ones do you use? I'm particularly interested in feedback on the non-Nvidia ones. Are they hard to use? Are they fast? Cost-effective?\n\nAlso, even though this is not the main topic of my question, I am also interested in information about inference. If anyone is using EC2 for large-scale inference, I'd love to hear about it!\n\nThank you!",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Which EC2 instance types do you use for training neural nets?",
            "upvote_ratio": 0.74,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11f0zs6/d_which_ec2_instance_types_do_you_use_for/"
        },
        {
            "author": "u/SaltyStackSmasher",
            "created_utc": "03-01-2023 00:10:17",
            "distinguished": null,
            "edited": false,
            "id": "11euzja",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11euzja",
            "nsfw": false,
            "num_comments": 13,
            "permalink": "/r/MachineLearning/comments/11euzja/d_backprop_through_beam_sampling/",
            "score": 12,
            "selftext": "so I was just going through the VAE reparameterization and thought whether it can be extended to beam sampling. is this possible at all ? I think if we can backprop through beam sampling, we can directly optimise for bleu ? \n\nplease correct me if I'm wrong. I'm happy to explore a bit as well, I just don't know where to start.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] backprop through beam sampling ?",
            "upvote_ratio": 0.78,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11euzja/d_backprop_through_beam_sampling/"
        },
        {
            "author": "u/Stencolino",
            "created_utc": "02-28-2023 23:17:33",
            "distinguished": null,
            "edited": false,
            "id": "11etyex",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_11etyex",
            "nsfw": false,
            "num_comments": 7,
            "permalink": "/r/MachineLearning/comments/11etyex/is_there_any_model_that_classify_singing_and/",
            "score": 4,
            "selftext": "I need model that can just differentiate when someone is talking normaly or singing. Is there any trained AI that does that?",
            "spoiler": false,
            "stickied": false,
            "title": "Is there any model that classify singing and speaking? [R]",
            "upvote_ratio": 0.75,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11etyex/is_there_any_model_that_classify_singing_and/"
        },
        {
            "author": "u/currentscurrents",
            "created_utc": "02-28-2023 20:36:59",
            "distinguished": null,
            "edited": false,
            "id": "11eqinv",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": null,
            "locked": false,
            "name": "t3_11eqinv",
            "nsfw": false,
            "num_comments": 35,
            "permalink": "/r/MachineLearning/comments/11eqinv/spikegpt_230mparameter_spiking_neural_network/",
            "score": 309,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "SpikeGPT: 230M-parameter Spiking Neural Network trained to be a language model",
            "upvote_ratio": 0.97,
            "url": "https://arxiv.org/abs/2302.13939v1"
        },
        {
            "author": "u/_Mookee_",
            "created_utc": "02-28-2023 16:27:44",
            "distinguished": null,
            "edited": false,
            "id": "11ekhni",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_11ekhni",
            "nsfw": false,
            "num_comments": 3,
            "permalink": "/r/MachineLearning/comments/11ekhni/r_hyena_hierarchy_towards_larger_convolutional/",
            "score": 2,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Hyena Hierarchy: Towards Larger Convolutional Language Models",
            "upvote_ratio": 0.63,
            "url": "https://arxiv.org/abs/2302.10866"
        },
        {
            "author": "u/fedegarzar",
            "created_utc": "02-28-2023 13:08:14",
            "distinguished": null,
            "edited": "03-01-2023 22:47:59",
            "id": "11effj0",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11effj0",
            "nsfw": false,
            "num_comments": 23,
            "permalink": "/r/MachineLearning/comments/11effj0/discussion_open_source_beats_googles_automl_for/",
            "score": 164,
            "selftext": "\\> TL;DR: We compared BigQuery ML's forecasting solution with two open-source tools, StatsForecast and Fugue. The experiment concludes that BigQuery is 13% less accurate, 8 times slower, and 3.2 times more expensive than running an open-source alternative in a simple cloud cluster. You can reproduce everything yourself in a couple of lines.\n\nhttps://preview.redd.it/4b44550ezyka1.png?width=632&format=png&auto=webp&v=enabled&s=c46d0453f6df6aad52ebe53e5e81898220003995\n\nFor the experiment, we the same methodology as the one used by Google to showcase its forecasting capabilities. We first tested the tools on a small dataset of approximately 400 time series, representing Citi Bike trips in New York City, before moving on to a larger dataset of over one million time series, representing liquor sales in Iowa.\n\nOur experiment revealed that Nixtla and Fugue outperformed BigQuery regarding accuracy, speed, and cost.\n\nThe cost savings for using an open-source alternative like StatsForecast or Fugue can be substantial. In our experiment, StatsForecast and Fugue on a Databricks cluster of 16 e2-standard-32 virtual machines (GCP) cost only 12.94 USD, whereas using BigQuery costs 41.96 USD.\n\nGoogle's BigQuery:\n\n* Achieved 24.13 (Mean Absolute Error, MAE) in error for the new\\_york.citibike\\_trips dataset.\n* Took 7.5 minutes to run the new\\_york.citibike\\_trips dataset (approximately 400 time series).\n* Took 1 hour 16 minutes to run the iowa\\_liquor\\_sales.sales dataset (over a million time series).\n* Cost 41.96 USD.\n\nStatsForecast and Fugue trained on a databricks cluster of 16 e2-standard-32 virtual machines (GCP):\n\n* Achieved 20.96 (Mean Absolute Error, MAE) in error for the new\\_york.citibike\\_trips dataset.\n* Took 2 minutes to run the new\\_york.citibike\\_trips dataset (approximately 400 time series).\n* Took 9 minutes to run the iowa\\_liquor\\_sales.sales dataset (over a million time series).\n* Cost only 12.94 USD.\n\nOverall, our experiment shows that classical methods such as StatsForecast and Fugue can outperform complex methods and pipelines like BigQuery in terms of speed, accuracy, and cost. While using StatsForecast or Fugue may require some basic knowledge of Python and cloud computing, the results are simply better.\n\nReproduce the experiment here: [https://github.com/Nixtla/statsforecast/tree/main/experiments/bigquery](https://github.com/Nixtla/statsforecast/tree/main/experiments/bigquery).\n\n&#x200B;\n\nStatement of errors: it was pointed out by Nick Akincilar that we did not include the correct DBU cost of Databricks, the corrected amounts are: 12.94 USD (open source) vs. 41.96 USD (Google).",
            "spoiler": false,
            "stickied": false,
            "title": "[Discussion] Open Source beats Google's AutoML for Time series",
            "upvote_ratio": 0.95,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11effj0/discussion_open_source_beats_googles_automl_for/"
        },
        {
            "author": "u/mad_rat_man",
            "created_utc": "02-28-2023 12:41:27",
            "distinguished": null,
            "edited": false,
            "id": "11eervy",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_11eervy",
            "nsfw": false,
            "num_comments": 2,
            "permalink": "/r/MachineLearning/comments/11eervy/r_smart_selfsupervised_multitask_pretraining_with/",
            "score": 9,
            "selftext": "Blog: [SMART \u2013 A Generalized Pretraining Framework for Control Tasks - Microsoft Research](https://www.microsoft.com/en-us/research/group/autonomous-systems-group-robotics/articles/smart-a-generalized-pretraining-framework-for-control-tasks/)  \nVideo: [SMART: SELF-SUPERVISED MULTI-TASK PRETRAINING WITH CONTROL TRANSFORMERS (ICLR'23) - YouTube](https://www.youtube.com/watch?v=0-0hCZtpWUc)  \nPaper: [\\[2301.09816\\] SMART: Self-supervised Multi-task pretrAining with contRol Transformers (arxiv.org)](https://arxiv.org/abs/2301.09816)  \nGithub: [microsoft/smart (github.com)](https://github.com/microsoft/smart)",
            "spoiler": false,
            "stickied": false,
            "title": "[R] SMART: Self-supervised Multi-task pretrAining with contRol Transformer - A generalized pretraining framework for diverse control tasks",
            "upvote_ratio": 0.76,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11eervy/r_smart_selfsupervised_multitask_pretraining_with/"
        },
        {
            "author": "u/Grym7er",
            "created_utc": "02-28-2023 12:12:54",
            "distinguished": null,
            "edited": false,
            "id": "11ee21x",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_11ee21x",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/11ee21x/p_noisynet_for_exploration/",
            "score": 7,
            "selftext": "Good day,\n\nI have an RL problem using the QMIX algorithm, and I'd like to utilise a more effective exploration strategy. Someone recommended checking out the RAINBOW algorithm, which I did and I stumbled onto Noisy Neural Nets. I thought that seemed like a neat and relatively simple way to improve exploration in my problem, so I went ahead and implemented the NoisyLinear class as described in the\u00a0paper. Now my question is, since the original implementation is used with DQN and QMIX uses DRQN, will it still work effectively?\n\nFrom my understanding it should still work fine, as it only applies noise to the output Q-value function at the very end, after the Recurrent layer (in the case of DRQN), so I can just replace the final linear layer(s) with noisy ones. However, it is very possible and quite likely that my understanding of DRQN and DQN as well as the noisy networks paper is too limited to spot any shortcomings to my approach. Any pointers or hints would be appreciated.",
            "spoiler": false,
            "stickied": false,
            "title": "[P] NoisyNet for Exploration",
            "upvote_ratio": 1.0,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11ee21x/p_noisynet_for_exploration/"
        },
        {
            "author": "u/MysteryInc152",
            "created_utc": "02-28-2023 07:30:49",
            "distinguished": null,
            "edited": false,
            "id": "11e4w40",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_11e4w40",
            "nsfw": false,
            "num_comments": 83,
            "permalink": "/r/MachineLearning/comments/11e4w40/r_microsoft_introduce_kosmos1_a_multimodal_large/",
            "score": 342,
            "selftext": "Paper here - [https://arxiv.org/abs/2302.14045](https://arxiv.org/abs/2302.14045)",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Microsoft introduce Kosmos-1, a Multimodal Large Language Model (MLLM) that can perceive general modalities, learn in context (i.e., few-shot), and follow instructions (i.e., zero-shot)",
            "upvote_ratio": 0.96,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11e4w40/r_microsoft_introduce_kosmos1_a_multimodal_large/"
        },
        {
            "author": "u/SubstantialDig6663",
            "created_utc": "02-28-2023 02:54:38",
            "distinguished": null,
            "edited": false,
            "id": "11e0e0i",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_11e0e0i",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/11e0e0i/r_p_inseq_an_interpretability_toolkit_for/",
            "score": 12,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] [P] Inseq: An Interpretability Toolkit for Sequence Generation Models",
            "upvote_ratio": 0.94,
            "url": "https://arxiv.org/abs/2302.13942"
        },
        {
            "author": "u/ton4eg",
            "created_utc": "02-27-2023 15:22:49",
            "distinguished": null,
            "edited": false,
            "id": "11dls9f",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_11dls9f",
            "nsfw": false,
            "num_comments": 30,
            "permalink": "/r/MachineLearning/comments/11dls9f/r_p_speartts_is_a_multispeaker_tts_that_can_be/",
            "score": 79,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] [P] SPEAR-TTS is a multi-speaker TTS that can be trained with only 15 min of single-speaker parallel data.",
            "upvote_ratio": 0.89,
            "url": "https://arxiv.org/abs/2302.03540"
        },
        {
            "author": "u/not_particulary",
            "created_utc": "02-27-2023 14:19:26",
            "distinguished": null,
            "edited": false,
            "id": "11dk7nt",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11dk7nt",
            "nsfw": false,
            "num_comments": 14,
            "permalink": "/r/MachineLearning/comments/11dk7nt/d_more_stable_alternative_to_wandb/",
            "score": 10,
            "selftext": "I've  loved using wandb because my workflow is using a university-provided  slurm cluster that doesn't allow any internet on the compute nodes, and  it's annoying to have to keep doing 2fa just to evaluate results. It's  offline mode lets me sync that on a little script in the login node, and  see everything in an online dashboard.\n\nHowever,  the software is super unstable. I've been losing jobs randomly to a  mystery error \\`Killed\\`, it's piled up runs and insisted on syncing all  of them again, so I have to go in and manually delete old runs that have  long been saved in the dashboard, and it already took me forever to  figure out how to keep it from logging a seperate run for each gpu I use  to train. Is there anything that does the same thing, but is just more  mature, so that I don't have to spend all my time squashing bugs related  to data logging?  I'd rather just focus on training these models,  honestly.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] More stable alternative to wandb?",
            "upvote_ratio": 0.75,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11dk7nt/d_more_stable_alternative_to_wandb/"
        },
        {
            "author": "u/ElPelana",
            "created_utc": "02-27-2023 12:19:31",
            "distinguished": null,
            "edited": false,
            "id": "11dh7pp",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11dh7pp",
            "nsfw": false,
            "num_comments": 21,
            "permalink": "/r/MachineLearning/comments/11dh7pp/d_cvpr_rebuttal_scores_are_out/",
            "score": 10,
            "selftext": "How did it go???\n\n[View Poll](https://www.reddit.com/poll/11dh7pp)",
            "spoiler": false,
            "stickied": false,
            "title": "[D] CVPR Rebuttal scores are out!",
            "upvote_ratio": 0.68,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11dh7pp/d_cvpr_rebuttal_scores_are_out/"
        },
        {
            "author": "u/Comfortable-Rest-373",
            "created_utc": "02-27-2023 12:07:59",
            "distinguished": null,
            "edited": false,
            "id": "11dgxl1",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_11dgxl1",
            "nsfw": false,
            "num_comments": 7,
            "permalink": "/r/MachineLearning/comments/11dgxl1/p_built_my_first_ever_opensource_project/",
            "score": 20,
            "selftext": "It is a low code machine learning library written in Python to develop, evaluate and deploy automated Machine Learning models and pipelines.\n\nThe tool helps has following features:\n\n&#x200B;\n\n* Native integration for data extraction with MySQL, PostgreSQL, MS SQL, Oracle, MariaDB, Amazon Aurora and Amazon S3\n* Exploratory Data Analysis (EDA)\n* Data preprocessing\n* Trains data across multiple algorithms and provide comparison metrics\n* Hyperparameter tuning\n* Experiment tracking\n* API deployment\n\n&#x200B;\n\nYou can check out the project at :  [https://github.com/mist-projects/bluemist-ai](https://github.com/mist-projects/bluemist-ai) \n\nand would love to hear feedback from the community :)",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Built my first ever open-source project",
            "upvote_ratio": 0.8,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11dgxl1/p_built_my_first_ever_opensource_project/"
        },
        {
            "author": "u/JanBitesTheDust",
            "created_utc": "02-27-2023 09:51:46",
            "distinguished": null,
            "edited": false,
            "id": "11ddohk",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_11ddohk",
            "nsfw": false,
            "num_comments": 6,
            "permalink": "/r/MachineLearning/comments/11ddohk/p_basic_autodiff_library_for_scalar_values_in_c/",
            "score": 12,
            "selftext": "Hi,\n\nI've been reading up on the backpropagation algorithm used in artificial neural nets. After finding out about automatic differentiation, I wanted to implement it myself. The implementation is fairly simple using Python (that allows for operator overloading and has a garbage collector), but I wanted to see how much it differs from the implementation in C. I wrote up a general overview of autodiff in the readme of the repo.\n\nIf there are any remarks/feedback, let me know :)\n\n As a result, here is the repo: [Autodiff](https://github.com/Janko-dev/autodiff)",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Basic autodiff library for scalar values in C",
            "upvote_ratio": 0.74,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11ddohk/p_basic_autodiff_library_for_scalar_values_in_c/"
        },
        {
            "author": "u/Scared_Employer6992",
            "created_utc": "02-27-2023 09:28:07",
            "distinguished": null,
            "edited": false,
            "id": "11dd59q",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11dd59q",
            "nsfw": false,
            "num_comments": 11,
            "permalink": "/r/MachineLearning/comments/11dd59q/d_training_a_unetlike_architecture_for_semantic/",
            "score": 17,
            "selftext": "I have to train an UNet-like architecture for semantic segmentation with 200 outcome classes. When outcoming a final map of 4x200x500x500, batch size of 4 and 200 channels (no. of semantic classes). It blows up my GPU memory (40GB).\n\n  \nMy first thought is only to create a broad category to reduce the number of classes. Does someone have a suggestion or tricks to accomplish this semantic segmentation task in a savvier way?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Training a UNet-like architecture for semantic segmentation with 200 outcome classes.",
            "upvote_ratio": 0.8,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11dd59q/d_training_a_unetlike_architecture_for_semantic/"
        },
        {
            "author": "u/radi-cho",
            "created_utc": "02-26-2023 18:36:47",
            "distinguished": null,
            "edited": false,
            "id": "11cwipp",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": null,
            "locked": false,
            "name": "t3_11cwipp",
            "nsfw": false,
            "num_comments": 2,
            "permalink": "/r/MachineLearning/comments/11cwipp/p_d_what_is_a_simplistic_but_highly_visual_way_to/",
            "score": 9,
            "selftext": "I am working on a research project where we train end-to-end task-oriented conversational agents (e.g., we solve the MultiWOZ benchmark) with novel techniques. We want to create a simple demonstration that can run on lower-end hardware and is highly visual to demonstrate the abilities of a TOD system to young audiences - e.g., high school students. At the same time, it should be complex enough to convey even to researchers that our models, when trained with data different than the toy problem, would provide substantial results. To understand me, I already have one idea, which however is not convincing enough: Imagine having a geometric shape on the screen, and you can move it to different points on the screen through the language model, e.g., you can have complex queries such as \"Move the point twice as far from the edge as it is currently.\" We can autoplay the demo with different pre-set queries to move on a screen, and when someone wants to interact with it, they could replace the pre-set questions with their own. This is visual and interactive, as I want it. However, it is insufficient since it doesn't convey a strong message by being overly simplistic and only moving a shape on the screen. On the other hand, out-in-the-wild demos, such as ChatGPT, also don't work for us since, to be sensible, they require a lot of resources and are not visual enough by being text-only.",
            "spoiler": false,
            "stickied": false,
            "title": "[P] [D] What is a simplistic but highly visual way to demonstrate a conversational language model?",
            "upvote_ratio": 0.75,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11cwipp/p_d_what_is_a_simplistic_but_highly_visual_way_to/"
        },
        {
            "author": "u/AutoModerator",
            "created_utc": "02-26-2023 11:00:23",
            "distinguished": null,
            "edited": false,
            "id": "11ckopj",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11ckopj",
            "nsfw": false,
            "num_comments": 151,
            "permalink": "/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/",
            "score": 17,
            "selftext": "Please post your questions here instead of creating a new thread. Encourage others who create new posts for questions to post here instead!\n\nThread will stay alive until next one so keep posting after the date in the title.\n\nThanks to everyone for answering questions in the previous thread!",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Simple Questions Thread",
            "upvote_ratio": 0.88,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11ckopj/d_simple_questions_thread/"
        },
        {
            "author": "u/MysteryInc152",
            "created_utc": "02-26-2023 10:46:51",
            "distinguished": null,
            "edited": false,
            "id": "11ckcxv",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_11ckcxv",
            "nsfw": false,
            "num_comments": 13,
            "permalink": "/r/MachineLearning/comments/11ckcxv/r_large_language_models_generate_functional/",
            "score": 133,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Large language models generate functional protein sequences across diverse families",
            "upvote_ratio": 0.95,
            "url": "https://www.nature.com/articles/s41587-022-01618-2"
        },
        {
            "author": "u/radi-cho",
            "created_utc": "02-26-2023 02:57:29",
            "distinguished": null,
            "edited": false,
            "id": "11c8pqz",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "News",
            "locked": false,
            "name": "t3_11c8pqz",
            "nsfw": false,
            "num_comments": 13,
            "permalink": "/r/MachineLearning/comments/11c8pqz/r_n_voxformer_sparse_voxel_transformer_for/",
            "score": 362,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] [N] VoxFormer: Sparse Voxel Transformer for Camera-based 3D Semantic Scene Completion.",
            "upvote_ratio": 0.99,
            "url": "https://i.redd.it/inh9rb076jka1.gif"
        },
        {
            "author": "u/vanilla-acc",
            "created_utc": "02-25-2023 22:57:48",
            "distinguished": null,
            "edited": false,
            "id": "11c4q1k",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11c4q1k",
            "nsfw": false,
            "num_comments": 2,
            "permalink": "/r/MachineLearning/comments/11c4q1k/d_interpretability_in_vision_transformers_without/",
            "score": 7,
            "selftext": "I've looked into the different interpretability methods for vision transformers, and most of them seem to rely on the attention map of the class token.\n\nThis is fine, but I use average pooling for all my tokens in the final step, so I cannot use methods that rely on inspecting attention affects the class token.\n\nAre there good interpretability methods for vision transformers that don't rely on the presence of a class token?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Interpretability in vision transformers without class tokens?",
            "upvote_ratio": 1.0,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11c4q1k/d_interpretability_in_vision_transformers_without/"
        },
        {
            "author": "u/coconautico",
            "created_utc": "02-25-2023 20:15:09",
            "distinguished": null,
            "edited": "02-25-2023 22:53:18",
            "id": "11c1hzc",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "News",
            "locked": false,
            "name": "t3_11c1hzc",
            "nsfw": false,
            "num_comments": 22,
            "permalink": "/r/MachineLearning/comments/11c1hzc/p_n_democratizing_the_chatgpt_technology_through/",
            "score": 25,
            "selftext": "Hey Reddit,\n\ntl;dr: To democratize the technology behind virtual assistants, we can play a [Q&A game](https://open-assistant.io/) to build a collaborative dataset that will enable the creation of culturally and politically unbiased virtual assistants.\n\nAs AI becomes more ubiquitous in our lives, we need to democratize it, ensuring that the next generation of virtual assistants, such as chatGPT or BingChat, are not solely controlled by one company, group or country, as it would allow them to skew our reality more easily, by deploying politically and culturally biased assistants at large scale, as we have seen with OpenAI.\n\nWhile one could argue that over time companies and startups will emerge and create their own alternatives, these could be few, as creating such virtual assistants is not only a matter of massive raw data and computation, but it requires the creation of very specific datasets (many of them created by experts from multiple fields) with the goal of \"fine-tuning\" Large Language Models (LLMs) into virtual assistants.\n\nBecause of this, there is an international collaborative effort to create a public, multilingual, and high-quality dataset through a Q&A game, that will enable the creation of other virtual assistants outside the control of these companies.\n\nAt this very moment, we already have more data than OpenAI had when it launched its first version of ChatGPT. However, the current dataset is strongly biased towards Spanish and English speakers, as they are the only ones who have contributed to it so far. Therefore, we need to encourage people from other countries and cultures to play this Q&A game in order to create a truly multilingual dataset with expert knowledge of all kinds, from all over the world. (This would allow the virtual assistant to even answer questions that have not been answered in their language).\n\nFor Spanish and English is already a reality. Let's make a reality for other languages too by writing a few of questions/answers in the OpenAssistant game!\n\nLink: [https://open-assistant.io/](https://open-assistant.io/)",
            "spoiler": false,
            "stickied": false,
            "title": "[P] [N] Democratizing the chatGPT technology through a Q&A game",
            "upvote_ratio": 0.78,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11c1hzc/p_n_democratizing_the_chatgpt_technology_through/"
        },
        {
            "author": "u/MyActualUserName99",
            "created_utc": "02-25-2023 19:47:29",
            "distinguished": null,
            "edited": false,
            "id": "11c0wvh",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11c0wvh",
            "nsfw": false,
            "num_comments": 12,
            "permalink": "/r/MachineLearning/comments/11c0wvh/d_navigating_academic_conferences/",
            "score": 7,
            "selftext": "I submitted a paper, with my PhD advisor, to ICML this year (2023) and hope to be accepted come April. I've never submitted a paper, nor attended, a conference. I have no idea what to expect\n\nFrom those who have attended, or published, at these types of conferences, what is the best advise you can give for someone who is new to academia? Workshops? Tutorials? etc?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Navigating Academic Conferences",
            "upvote_ratio": 0.74,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11c0wvh/d_navigating_academic_conferences/"
        },
        {
            "author": "u/NeonChat",
            "created_utc": "02-25-2023 17:02:03",
            "distinguished": null,
            "edited": false,
            "id": "11bx3fj",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_11bx3fj",
            "nsfw": false,
            "num_comments": 2,
            "permalink": "/r/MachineLearning/comments/11bx3fj/r_planting_undetectable_backdoors_in_machine/",
            "score": 17,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Planting Undetectable Backdoors in Machine Learning Models",
            "upvote_ratio": 0.91,
            "url": "https://doi.org/10.1109/FOCS54457.2022.00092"
        },
        {
            "author": "u/Illustrious_Row_9971",
            "created_utc": "02-25-2023 16:43:26",
            "distinguished": null,
            "edited": false,
            "id": "11bwn2m",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_11bwn2m",
            "nsfw": false,
            "num_comments": 15,
            "permalink": "/r/MachineLearning/comments/11bwn2m/r_composer_a_large_5_billion_parameters/",
            "score": 524,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Composer, a large (5 billion parameters) controllable diffusion model trained on billions of (text, image) pairs, comparable to SD + controlnet",
            "upvote_ratio": 0.97,
            "url": "https://i.redd.it/i2haou24neka1.jpg"
        },
        {
            "author": "u/FlyingTriangle",
            "created_utc": "02-25-2023 16:27:57",
            "distinguished": null,
            "edited": false,
            "id": "11bw9cl",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_11bw9cl",
            "nsfw": false,
            "num_comments": 2,
            "permalink": "/r/MachineLearning/comments/11bw9cl/p_how_to_predict_ufc_with_xgboost_70_accurate/",
            "score": 6,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[P] How To Predict UFC with XGBoost, 70% accurate",
            "upvote_ratio": 0.6,
            "url": "https://medium.com/@dan.h.mcinerney/how-to-predict-1v1-sports-with-ai-b756ced069dd"
        },
        {
            "author": "u/SuchOccasion457",
            "created_utc": "02-25-2023 16:01:01",
            "distinguished": null,
            "edited": false,
            "id": "11bvmia",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11bvmia",
            "nsfw": false,
            "num_comments": 9,
            "permalink": "/r/MachineLearning/comments/11bvmia/d_cost_of_data_acquisition/",
            "score": 6,
            "selftext": "Say one wanted to model how much getting access to data would cost, how should one go about that? If labeling costs for say CIFAR10 are known with SageMaker and Google Cloud, what is the cost of getting the data in the first place?\n\nFurthermore, say we move into the space of medical images e.g. MRI scans. What is the cost of getting MRI scans with a given desease? Where do I even find such information?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Cost of data acquisition",
            "upvote_ratio": 1.0,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11bvmia/d_cost_of_data_acquisition/"
        },
        {
            "author": "u/chess9145",
            "created_utc": "02-25-2023 14:13:21",
            "distinguished": null,
            "edited": false,
            "id": "11bt024",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_11bt024",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/11bt024/rp_hidden_markov_model_implementation_in_r_and/",
            "score": 3,
            "selftext": "Hidden Markov Model implementation in R and Python for discrete and continuous observations. I have a tutorial on YouTube to explain about use and modeling of HMM and how to run these two packages.\n\nCode:\n\n[https://github.com/manitadayon/CD\\_HMM](https://github.com/manitadayon/CD_HMM) (in R)\n\n[https://github.com/manitadayon/Auto\\_HMM](https://github.com/manitadayon/Auto_HMM) (In Python)\n\nTutorial:\n\n[https://www.youtube.com/watch?v=1b-sd7gulFk&ab\\_channel=AIandMLFundamentals](https://www.youtube.com/watch?v=1b-sd7gulFk&ab_channel=AIandMLFundamentals)\n\n[https://www.youtube.com/watch?v=ieU8JFLRw2k&ab\\_channel=AIandMLFundamentals](https://www.youtube.com/watch?v=ieU8JFLRw2k&ab_channel=AIandMLFundamentals)",
            "spoiler": false,
            "stickied": false,
            "title": "[R][P] Hidden Markov Model implementation in R and Python for discrete and continuous observations.",
            "upvote_ratio": 0.62,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11bt024/rp_hidden_markov_model_implementation_in_r_and/"
        },
        {
            "author": "u/rodrigo-arenas",
            "created_utc": "02-25-2023 14:09:52",
            "distinguished": null,
            "edited": false,
            "id": "11bsx32",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11bsx32",
            "nsfw": false,
            "num_comments": 5,
            "permalink": "/r/MachineLearning/comments/11bsx32/d_opensource_package_to_mix_numerical_categorical/",
            "score": 4,
            "selftext": "Hi, I was wondering if you know any open-source package you'd recommend that can handle mixed types of data for machine learning, both for supervised and unsupervised learning.\n\nI came up with the idea of just getting text embeddings and stacking those with the other features to create a single vector, but I think it might not be the best idea since the embeddings usually have a large dimension, whereas I might not have too many extra features, maybe making the final vector \"biased\" to the text data. Any thoughts on this?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Open-source package to mix numerical, categorical and text features?",
            "upvote_ratio": 0.83,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11bsx32/d_opensource_package_to_mix_numerical_categorical/"
        },
        {
            "author": "u/DreamyPen",
            "created_utc": "02-25-2023 09:53:00",
            "distinguished": null,
            "edited": false,
            "id": "11bmsx7",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11bmsx7",
            "nsfw": false,
            "num_comments": 4,
            "permalink": "/r/MachineLearning/comments/11bmsx7/d_which_conferences_are_worth_attending/",
            "score": 10,
            "selftext": "My company encourages training opportunities and attending relevant conferences. \n\nIm curious to hear which conference you found worth attending, particularly in the area of engineering (materials) and machine learning?\n\nThank you.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Which conferences are worth attending?",
            "upvote_ratio": 0.82,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11bmsx7/d_which_conferences_are_worth_attending/"
        },
        {
            "author": "u/taken_every_username",
            "created_utc": "02-25-2023 08:13:26",
            "distinguished": null,
            "edited": false,
            "id": "11bkpu3",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_11bkpu3",
            "nsfw": false,
            "num_comments": 9,
            "permalink": "/r/MachineLearning/comments/11bkpu3/r_p_new_ways_of_breaking_appintegrated_llms_with/",
            "score": 50,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] [P] New ways of breaking app-integrated LLMs with prompt injection",
            "upvote_ratio": 0.94,
            "url": "https://github.com/greshake/lm-safety"
        },
        {
            "author": "u/asdfsr125",
            "created_utc": "02-25-2023 07:37:53",
            "distinguished": null,
            "edited": false,
            "id": "11bk21t",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "News",
            "locked": false,
            "name": "t3_11bk21t",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/11bk21t/r_n_reduce_reuse_recycle_compositional_generation/",
            "score": 57,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] [N] \"Reduce, Reuse, Recycle: Compositional Generation with Energy-Based Diffusion Models and MCMC\" recycling diffusion models (without any retraining)",
            "upvote_ratio": 0.95,
            "url": "https://v.redd.it/2sxphhgrxbka1"
        },
        {
            "author": "u/davidmezzetti",
            "created_utc": "02-25-2023 07:36:22",
            "distinguished": null,
            "edited": false,
            "id": "11bk12r",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_11bk12r",
            "nsfw": false,
            "num_comments": 8,
            "permalink": "/r/MachineLearning/comments/11bk12r/p_introducing_txtchat_nextgeneration/",
            "score": 12,
            "selftext": "&#x200B;\n\nhttps://i.redd.it/4yli3zalvbka1.gif\n\ntxtchat is a framework for building conversational search and workflows. txtchat is open source under Apache 2.0 license and available on GitHub.\n\n[GitHub](https://github.com/neuml/txtchat) | [Article](https://medium.com/neuml/introducing-txtchat-next-generation-conversational-search-and-workflows-for-all-97557009fb53)   \n\n\nA set of intelligent agents are available to integrate with messaging platforms. These agents or personas are associated with an automated account and respond to messages with AI-powered responses. Workflows can use large language models (LLMs), small models or both.  \n\n\nhttps://preview.redd.it/uhypbdu0wbka1.png?width=1301&format=png&auto=webp&v=enabled&s=ccdfc7063cfc5a26086c869a7f539fa82c6fea73\n\nA persona is a combination of a chat agent and workflow that determines the type of responses. Each agent is tied to an account in the messaging platform. Persona workflows are messaging-platform  agnostic. \n\n# Examples\n\nThe following is a list of YouTube videos that shows how txtchat works. These videos run a series of queries with the Wikitalk persona. Wikitalk is a combination of a Wikipedia embeddings index and a LLM prompt to answer questions.\n\nEvery answer shows an associated reference with where the data came from. Wikitalk will say \"I don't have data on that\" when it doesn't have an answer.\n\n### History\n\nConversation with Wikitalk about history.\n\n[https://www.youtube.com/watch?v=ROyess8dLoA](https://www.youtube.com/watch?v=ROyess8dLoA)\n\n### Sports\n\nTalk about sports.\n\n[https://youtube.com/watch?v=LXRB-iruKSc](https://youtube.com/watch?v=LXRB-iruKSc)\n\n### Culture\n\nArts and culture questions.\n\n[https://www.youtube.com/watch?v=OkObkNhJIgk](https://www.youtube.com/watch?v=OkObkNhJIgk)\n\n### Science\n\nLet's quiz Wikitalk on science.\n\n[https://youtube.com/watch?v=-rsYDsZc9Wo](https://youtube.com/watch?v=-rsYDsZc9Wo)\n\n### Summary\n\nNot all workflows need a LLM. There are plenty of great  small models available to perform a specific task. The Summary persona  simply reads the input URL and summarizes the text.\n\n[https://youtube.com/watch?v=PBJm9aDqkn0](https://youtube.com/watch?v=PBJm9aDqkn0)\n\n### Mr. French\n\nLike the summary persona, Mr. French is a simple persona that translates input text to French.\n\n[https://youtube.com/watch?v=4x8pOIm4rbo](https://youtube.com/watch?v=4x8pOIm4rbo)",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Introducing txtchat, next-generation conversational search and workflows",
            "upvote_ratio": 0.74,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11bk12r/p_introducing_txtchat_nextgeneration/"
        },
        {
            "author": "u/radi-cho",
            "created_utc": "02-25-2023 03:02:46",
            "distinguished": null,
            "edited": false,
            "id": "11bfm9n",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "News",
            "locked": false,
            "name": "t3_11bfm9n",
            "nsfw": false,
            "num_comments": 7,
            "permalink": "/r/MachineLearning/comments/11bfm9n/r_n_3daware_conditional_image_synthesis_pix2pix3d/",
            "score": 172,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] [N] 3D-aware Conditional Image Synthesis (pix2pix3D)",
            "upvote_ratio": 0.97,
            "url": "https://v.redd.it/guvc1ggmkaka1"
        },
        {
            "author": "u/radi-cho",
            "created_utc": "02-25-2023 02:55:13",
            "distinguished": null,
            "edited": false,
            "id": "11bfhx7",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "News",
            "locked": false,
            "name": "t3_11bfhx7",
            "nsfw": false,
            "num_comments": 14,
            "permalink": "/r/MachineLearning/comments/11bfhx7/r_n_multidiffusion_fusing_diffusion_paths_for/",
            "score": 444,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] [N] \"MultiDiffusion: Fusing Diffusion Paths for Controlled Image Generation\" enables controllable image generation without any further training or finetuning of diffusion models.",
            "upvote_ratio": 0.97,
            "url": "https://v.redd.it/jyo286g3jaka1"
        },
        {
            "author": "u/Linear--",
            "created_utc": "02-25-2023 00:02:34",
            "distinguished": null,
            "edited": "02-25-2023 04:56:40",
            "id": "11bcklh",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11bcklh",
            "nsfw": false,
            "num_comments": 20,
            "permalink": "/r/MachineLearning/comments/11bcklh/d_isnt_selfsupervised_learningssl_simply_a_kind/",
            "score": 0,
            "selftext": "For the model, basically, both SLL and SL requires it to learn a mapping from X(input) to Y(label), (or a probability distribution of the label). And usually, the optimization processes for both are basically the same, at least for deep learning.\n\nWhat's specific to SSL is just that, it's already labelled so no extra labelling is required. This facilitates pre-training from a much larger dataset since hand-labelling is expensive.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Isn't self-supervised learning(SSL) simply a kind of SL?",
            "upvote_ratio": 0.47,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11bcklh/d_isnt_selfsupervised_learningssl_simply_a_kind/"
        },
        {
            "author": "u/MysteryInc152",
            "created_utc": "02-24-2023 12:21:15",
            "distinguished": null,
            "edited": false,
            "id": "11awp4n",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_11awp4n",
            "nsfw": false,
            "num_comments": 210,
            "permalink": "/r/MachineLearning/comments/11awp4n/r_meta_ai_open_sources_new_sota_llm_called_llama/",
            "score": 602,
            "selftext": "[https://twitter.com/GuillaumeLample/status/1629151231800115202?t=4cLD6Ko2Ld9Y3EIU72-M2g&s=19](https://twitter.com/GuillaumeLample/status/1629151231800115202?t=4cLD6Ko2Ld9Y3EIU72-M2g&s=19)\n\nPaper here - [https://research.facebook.com/publications/llama-open-and-efficient-foundation-language-models/](https://research.facebook.com/publications/llama-open-and-efficient-foundation-language-models/)",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Meta AI open sources new SOTA LLM called LLaMA. 65B version (trained on 1.4T tokens) is competitive with Chinchilla and Palm-540B. 13B version outperforms OPT and GPT-3 175B on most benchmarks.",
            "upvote_ratio": 0.98,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11awp4n/r_meta_ai_open_sources_new_sota_llm_called_llama/"
        },
        {
            "author": "u/mosquitoLad",
            "created_utc": "02-24-2023 10:29:41",
            "distinguished": null,
            "edited": "02-24-2023 10:55:38",
            "id": "11au29r",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11au29r",
            "nsfw": false,
            "num_comments": 13,
            "permalink": "/r/MachineLearning/comments/11au29r/d_what_is_the_correct_term_for_a_nongan_system/",
            "score": 9,
            "selftext": "As the title.\n\nI believed adversarial training was a catch-all term describing systems where two or more networks--with similar or distinct, but always mutually exclusive, goals--compete in zero-sum games and improve over time, but I'm finding that adversarial training relates to security, while generative adversarial networks specifically describe generation and detection.\n\nedits:\n\nIt doesn't capture the spirit of what I'm looking for, but a broader term is Multi-Agent Reinforcement Learning",
            "spoiler": false,
            "stickied": false,
            "title": "[D] What is the correct term for a non-GAN system where two or more networks compete as part of training?",
            "upvote_ratio": 0.85,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11au29r/d_what_is_the_correct_term_for_a_nongan_system/"
        },
        {
            "author": "u/_atswi_",
            "created_utc": "02-24-2023 07:21:44",
            "distinguished": null,
            "edited": "02-24-2023 07:38:56",
            "id": "11aq4qo",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11aq4qo",
            "nsfw": false,
            "num_comments": 7,
            "permalink": "/r/MachineLearning/comments/11aq4qo/d_best_way_to_measure_llm_uncertainty/",
            "score": 18,
            "selftext": "What's the best way to quantify the uncertainty of a trained LLM? I assume the entropy of the model's final probability distribution is a decent measure. Just wanted to know if the NLP community sticks to this measure, or if there's something more specific to language?\n\n\nWould really appreciate recent references that may have popped up over the past few months (if any). Also if there are any cool & easy to integrate implementations. Thanks!",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Best Way to Measure LLM Uncertainty?",
            "upvote_ratio": 0.91,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11aq4qo/d_best_way_to_measure_llm_uncertainty/"
        },
        {
            "author": "u/nobody0014",
            "created_utc": "02-24-2023 02:16:26",
            "distinguished": null,
            "edited": false,
            "id": "11albpf",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11albpf",
            "nsfw": false,
            "num_comments": 11,
            "permalink": "/r/MachineLearning/comments/11albpf/d_a_funny_story_from_my_interview/",
            "score": 53,
            "selftext": "I need to get this off my chest...\n\nSo I was interviewing for an intern position at a procurement analytics company recently, we had an initial conversation on the phone where the engineer said  \"spend classification\".I heard it and ask for confirmation \"spam classification?\"The engineer reply \"yes spend classification\".\n\nSo there I was, for the next 48 hours before the interview, trying to figure out the scenarios spam classification is used in the context of procurement analytics (what I got was a super reaching scenario but it was fun).\n\nDuring the interview, I was trying to talk about the projects I did that could be useful for spam/data imbalance usecases instead of a few other things that I did which are much cooler. At the end, I ask about why they are doing spam classification for context of procurement analytics and they asked where I heard that from. I was like you guys said \"spam classification\". Then it dawn on me and them that I misheard \"spend classification\" as \"spam classification\".\n\nWe had a laugh, I talked about the scenario I mentioned and talked about Siamese network but I still felt damn embarrassed about it since I could have been talking about other projects.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] A funny story from my interview",
            "upvote_ratio": 0.9,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11albpf/d_a_funny_story_from_my_interview/"
        },
        {
            "author": "u/gsvclass",
            "created_utc": "02-24-2023 01:10:32",
            "distinguished": null,
            "edited": "02-24-2023 23:56:29",
            "id": "11ak97p",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_11ak97p",
            "nsfw": false,
            "num_comments": 12,
            "permalink": "/r/MachineLearning/comments/11ak97p/p_minds_a_js_library_to_build_llm_powered/",
            "score": 6,
            "selftext": "The focus of this library is to implement a lot of the top prompt engineering papers such as PAL, CoT, Self-Ask, ReACT.\n\nExcited to share \"Minds\". A a new way to build backends and workflows entirely with AI  (LLMs from OpenAI and Cohere). The AI can call your APIs, lookup in your  database, etc.\n\nWith just a couple lines of code you can builds  things like a question answering service where the AI can query your  local database to help answer customer support queries etc.\n\nList of Prompt Engineering papers we are implementing:\n[https://42papers.com/c/llm-prompting-6343](https://42papers.com/c/llm-prompting-6343)\n\nMindJS Library\n[https://github.com/dosco/minds](https://github.com/dosco/minds)",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Minds - A JS library to build LLM powered backends and workflows (OpenAI & Cohere)",
            "upvote_ratio": 0.63,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11ak97p/p_minds_a_js_library_to_build_llm_powered/"
        },
        {
            "author": "u/xoxide",
            "created_utc": "02-24-2023 00:21:07",
            "distinguished": null,
            "edited": false,
            "id": "11aje0p",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": null,
            "locked": false,
            "name": "t3_11aje0p",
            "nsfw": false,
            "num_comments": 86,
            "permalink": "/r/MachineLearning/comments/11aje0p/a_prompt_pattern_catalog_to_enhance_prompt/",
            "score": 118,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT",
            "upvote_ratio": 0.81,
            "url": "https://arxiv.org/abs/2302.11382"
        },
        {
            "author": "u/SchmidhuberDidIt",
            "created_utc": "02-23-2023 19:16:05",
            "distinguished": null,
            "edited": false,
            "id": "11ada91",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11ada91",
            "nsfw": false,
            "num_comments": 170,
            "permalink": "/r/MachineLearning/comments/11ada91/d_to_the_ml_researchers_and_practitioners_here_do/",
            "score": 122,
            "selftext": "A recent [podcast interview](https://www.youtube.com/watch?v=gA1sNLL6yg4) of EY's has gone a bit viral, and in it he claims that researchers have dismissed his views without seriously engaging with his arguments, which are described [here](https://www.lesswrong.com/posts/uMQ3cqWDPHhjtiesc/agi-ruin-a-list-of-lethalities) in relative detail. \n\nI'm aware of on-going AI safety and interpretability research, but the dual use of the term \"AI safety\" to mean something close to AI ethics, and something close to preventing an existential threat to humanity, makes distinguishing the goals of, say, Anthropic, and the extent to which they consider the latter a serious concern, difficult as a layperson. \n\nI haven't personally found EY's arguments to be particularly rigorous, but I'm not the best suited person to evaluate their validity.  Any thoughts are appreciated. Thanks in advance!",
            "spoiler": false,
            "stickied": false,
            "title": "[D] To the ML researchers and practitioners here, do you worry about AI safety/alignment of the type Eliezer Yudkowsky describes?",
            "upvote_ratio": 0.85,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11ada91/d_to_the_ml_researchers_and_practitioners_here_do/"
        },
        {
            "author": "u/johnhopiler",
            "created_utc": "02-23-2023 16:09:12",
            "distinguished": null,
            "edited": "02-25-2023 05:42:44",
            "id": "11a8tru",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_11a8tru",
            "nsfw": false,
            "num_comments": 11,
            "permalink": "/r/MachineLearning/comments/11a8tru/p_what_are_the_latest_out_of_the_box_solutions/",
            "score": 11,
            "selftext": "Let's assume for a minute one has:\n\n* the necessary compute instances\n* enough $ to cough up to rent those instances somewhere\n\nWhat are the latest \"easy\" solutions to get optbloomzand flan-t5hosted as API endpoints?\n\nI spent about 2 weeks trying to get seldon-core and MLServer to work with its huggingface wrapper. But I've lost hope at this point. There are so many parameters and tweaks one has to be mindful of and I feel like I'm behaving like a very crude operating system replacement when I pass a device\\_mapto a python function to tell it how much ram to use for what instance. In what world can MS 95 manage 4 DIM DDR rams but in 2023, we cannot auto-assign model data to the right GPUs?\n\nSo. What's the \"right way\" to do this? I am aware of\n\n* This repo that has some \"demos\": [https://github.com/huggingface/transformers-bloom-inference](https://github.com/huggingface/transformers-bloom-inference)\n* accelerate library: [https://huggingface.co/docs/accelerate/index](https://huggingface.co/docs/accelerate/index)\n* FlexGen: [https://github.com/FMInference/FlexGen](https://github.com/FMInference/FlexGen) but that only works for opt and is not a model hosting solution but more of an academic PoC\n* DeepSpeed, haven't looked deeply into this though\n\nAny pointers would be appreciated. We have a goal to get 2-3 models up and running as API endpoints in 2 weeks and I have a lot of ppl waiting for me to get this done...\n\n&#x200B;\n\nEdit:\n\nI am talking about self hosted solutions where the inference input & output is \"under your control\"\n\n&#x200B;\n\nEdit:\n\nWhat about a K8S + Ray Cluster + [alpa.ai](https://alpa.ai)? It feels like the most industrialised version of all the things I've seen so far after reading up on ray (which feels like a spark cluster for ML)",
            "spoiler": false,
            "stickied": false,
            "title": "[P] What are the latest \"out of the box solutions\" for deploying the very large LLMs as API endpoints?",
            "upvote_ratio": 0.82,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11a8tru/p_what_are_the_latest_out_of_the_box_solutions/"
        },
        {
            "author": "u/ats678",
            "created_utc": "02-23-2023 13:16:38",
            "distinguished": null,
            "edited": false,
            "id": "11a4klg",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11a4klg",
            "nsfw": false,
            "num_comments": 6,
            "permalink": "/r/MachineLearning/comments/11a4klg/d_are_there_any_good_fid_and_kid_metrics/",
            "score": 5,
            "selftext": "I need to produce estimates for these metrics. I tried the torchmetrics implementation, however they\u2019re giving me completely wrong results (I tried FID using the same dataset as both real and fake data and it gave me an incredibly high number). Are you guys aware of other available implementations?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Are there any good FID and KID metrics implementations existing that are compatible with pytorch?",
            "upvote_ratio": 0.78,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11a4klg/d_are_there_any_good_fid_and_kid_metrics/"
        },
        {
            "author": "u/Bioi_Paralleloi",
            "created_utc": "02-23-2023 11:49:01",
            "distinguished": null,
            "edited": false,
            "id": "11a2d2b",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_11a2d2b",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/11a2d2b/r_modular_deep_learning/",
            "score": 24,
            "selftext": "Paper: [https://arxiv.org/abs/2302.11529](https://arxiv.org/abs/2302.11529)\n\nTwitter: [https://twitter.com/seb\\_ruder/status/1628721434162765827](https://twitter.com/seb_ruder/status/1628721434162765827)\n\nWebsite: [https://www.modulardeeplearning.com/](https://www.modulardeeplearning.com/)\n\nAbstract: Transfer learning has recently become the dominant paradigm of machine learning. Pre-trained models fine-tuned for downstream tasks achieve better performance with fewer labelled examples. Nonetheless, it remains unclear how to develop models that specialise towards multiple tasks without incurring negative interference and that generalise systematically to non-identically distributed tasks. Modular deep learning has emerged as a promising solution to these challenges. In this framework, units of computation are often implemented as autonomous parameter-efficient modules. Information is conditionally routed to a subset of modules and subsequently aggregated. These properties enable positive transfer and systematic generalisation by separating computation from routing and updating modules locally. We offer a survey of modular architectures, providing a unified view over several threads of research that evolved independently in the scientific literature. Moreover, we explore various additional purposes of modularity, including scaling language models, causal inference and discovery, programme simulation, and hierarchical reinforcement learning. Finally, we report various concrete applications where modularity has been successfully deployed such as cross-lingual and cross-modal knowledge transfer.\n\n&#x200B;\n\nhttps://preview.redd.it/oz02z33cwyja1.png?width=2045&format=png&auto=webp&v=enabled&s=542b15f2210c000bd95421f5cd1e68ebb2ee69be",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Modular Deep Learning",
            "upvote_ratio": 0.91,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11a2d2b/r_modular_deep_learning/"
        },
        {
            "author": "u/lazurro",
            "created_utc": "02-23-2023 10:29:52",
            "distinguished": null,
            "edited": false,
            "id": "11a0f6r",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11a0f6r",
            "nsfw": false,
            "num_comments": 3,
            "permalink": "/r/MachineLearning/comments/11a0f6r/d_fid_calculation_for_gan_network/",
            "score": 3,
            "selftext": "Hello everyone!\n\nI am currently working with a very small dataset (about 300 images) and I coded a DCGAN with Tensorflow in order to generate new \"fake\" images with the same distribution as the \\~300 real images.\n\nI have been reading a lot of papers and the official implementation of FID ([https://github.com/bioinf-jku/TTUR](https://github.com/bioinf-jku/TTUR)) and I always read \"number of samples\". Even [**here**](https://arxiv.org/abs/1911.07023) the papers states that FID is not reliable because is biased and talks about N being the number of samples and everything depends on that number.\n\nWhat I dont really understand is which samples is everyone referring to. I mean, are they the real samples or the fake? the sum? both?\n\nI want to calculate the FID between the \\~300 real images (I cant use more, seems obvious but just saying) and **a number** of fake images I can generate with my network, but I am not sure how many samples (FAKE samples) to use. The logic tells me that I should use the same number of samples for both real and fake images but idk. This is the number papers and the repository talks about? It makes sense to calculate FID for \\~300 real samples versus 10k fake samples?\n\nThank you in advance.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] FID calculation for GAN network",
            "upvote_ratio": 0.72,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11a0f6r/d_fid_calculation_for_gan_network/"
        },
        {
            "author": "u/Fine-Topic-6127",
            "created_utc": "02-23-2023 08:59:19",
            "distinguished": null,
            "edited": false,
            "id": "119ydqv",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_119ydqv",
            "nsfw": false,
            "num_comments": 6,
            "permalink": "/r/MachineLearning/comments/119ydqv/d_model_size_vs_task_complexity/",
            "score": 4,
            "selftext": "A simple question really but one that's pretty difficult to find an answer to:\n\n&#x200B;\n\nHas anyone done much research into the performance of models vs their size as a function of the output space (and if so where can I find it)? Basically, it's quite clear that for most applications, generalisability of a model can either be achieved by improving the dataset or increasing the size of the model (if your dataset is already good). But because the way performance is measured in SOTA benchmarks it's not necessarily obvious (to me at least) that these larger models are appropriate for more simple problems. \n\n&#x200B;\n\nSay I have a simple audio classification problem where I only have one class of interest. If I wanted to implement the latest SOTA models in sound classification I'm likely to end up trying to use some pretty large and complicated model architectures. What I would like to know is how does one use SOTA benchmarks to inform their decisions for architectures in the face of tasks that are significantly simpler than those that are used to evaluate the performance of models on these benchmarks? \n\n&#x200B;\n\nIt feels like the simple answer is to just start simple and scale up as required but this does feel somewhat like trial and error so it would be great to hear how other people approach this sort of problem...",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Model size vs task complexity",
            "upvote_ratio": 0.75,
            "url": "https://www.reddit.com/r/MachineLearning/comments/119ydqv/d_model_size_vs_task_complexity/"
        },
        {
            "author": "u/CHvader",
            "created_utc": "02-23-2023 07:11:03",
            "distinguished": null,
            "edited": false,
            "id": "119w7c6",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_119w7c6",
            "nsfw": false,
            "num_comments": 6,
            "permalink": "/r/MachineLearning/comments/119w7c6/d_tools_for_drawingvisualising_neural_networks/",
            "score": 30,
            "selftext": "Hello, any personal favourites for drawing/visualising neural networks and transformers? With a colleague we are doing some tutorials/slides and would be very useful if there was a tool (python, latex, GUI, anything) that could help us do this, so that we can annotate on them after. Since it will be a teaching tool, clean and visually pleasing drawings would be awesome.\n\nWould prefer a tool where we can specify the number of nodes/layers/etc and the node size and colour etc, and not something that simply draws a model from Keras/PyTorch without much adaptability.\n\nThanks in advance!",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Tools for drawing/visualising Neural Networks that are pretty?",
            "upvote_ratio": 0.88,
            "url": "https://www.reddit.com/r/MachineLearning/comments/119w7c6/d_tools_for_drawingvisualising_neural_networks/"
        },
        {
            "author": "u/vijish_madhavan",
            "created_utc": "02-23-2023 05:31:42",
            "distinguished": null,
            "edited": false,
            "id": "119ujl5",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_119ujl5",
            "nsfw": false,
            "num_comments": 12,
            "permalink": "/r/MachineLearning/comments/119ujl5/p_controlnet_artline_transform_portrait_styles/",
            "score": 185,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[P] ControlNet + ArtLine, Transform portrait styles with written instructions. GitHub Link in comments",
            "upvote_ratio": 0.84,
            "url": "https://www.reddit.com/gallery/119ujl5"
        },
        {
            "author": "u/Marcapiel",
            "created_utc": "02-23-2023 01:58:27",
            "distinguished": null,
            "edited": false,
            "id": "119r6m0",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_119r6m0",
            "nsfw": false,
            "num_comments": 276,
            "permalink": "/r/MachineLearning/comments/119r6m0/d_yann_lecuns_hot_take_about_programming/",
            "score": 146,
            "selftext": "\"Hotter take: ML would have advanced faster if another front-end language had been available and widely adopted instead of Python. One that is interactive yet fast & compilable, multithreaded (no GIL), isn't bloated, doesn't care about white spaces,... E.g. Julia or some Lisp.\"\n\n[Link from the original tweet](https://twitter.com/ylecun/status/1628386056641847296)",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Yann LeCun's Hot Take about programming languages for ML",
            "upvote_ratio": 0.77,
            "url": "https://www.reddit.com/r/MachineLearning/comments/119r6m0/d_yann_lecuns_hot_take_about_programming/"
        },
        {
            "author": "u/Seankala",
            "created_utc": "02-22-2023 23:41:09",
            "distinguished": null,
            "edited": false,
            "id": "119onf8",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_119onf8",
            "nsfw": false,
            "num_comments": 12,
            "permalink": "/r/MachineLearning/comments/119onf8/d_145m15m_is_the_smallest_number_of_parameters_i/",
            "score": 42,
            "selftext": "The ELECTRA paper introduces a small version that has around 15M parameters. MobileBERT and TinyBERT also have around the same number of parameters.\n\nAre there any other language models out there that are smaller? Would it be possible to further distill large models into smaller variants?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] 14.5M-15M is the smallest number of parameters I could find for current pretrained language models. Are there any that are smaller?",
            "upvote_ratio": 0.95,
            "url": "https://www.reddit.com/r/MachineLearning/comments/119onf8/d_145m15m_is_the_smallest_number_of_parameters_i/"
        },
        {
            "author": "u/dmart89",
            "created_utc": "02-22-2023 23:15:46",
            "distinguished": null,
            "edited": false,
            "id": "119o54q",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_119o54q",
            "nsfw": false,
            "num_comments": 17,
            "permalink": "/r/MachineLearning/comments/119o54q/d_python_library_to_collect_structured_datasets/",
            "score": 5,
            "selftext": "I'm thinking about building an open source library to generate structured ml datasets from sources across the internet.\n\nI know that lots of projects utilise crawlers to get decent datasets, while you might still need to create your own for specific use cases I'm wondering whether it'd be useful to have an open source library that lets you launch crawlers with predefined schemas for popular sources like LinkedIn, YouTube (I know yt also has an api), shopify stores, twitter, reddit, news sites and more.\n\nKind of like a unified interface with extendable starter templates.\n\nThe lib would dump json objects into a location you specify, like your local machine, mongo, or s3.\n\nSomething like:\n\n\n`{\n     title: some video,\n     source: https//youtube.com/jfg78,\n     views: 245676,\n     comments: {}\n`\n\nGoal would be to make it easier/faster to get datasets from sources that don't natively have an api.\n\nThis might be a useless idea, but would love to hear your thoughts.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Python library to collect structured datasets across the internet",
            "upvote_ratio": 0.73,
            "url": "https://www.reddit.com/r/MachineLearning/comments/119o54q/d_python_library_to_collect_structured_datasets/"
        },
        {
            "author": "u/chigur86",
            "created_utc": "02-22-2023 14:55:06",
            "distinguished": null,
            "edited": "02-23-2023 18:28:41",
            "id": "119a32e",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_119a32e",
            "nsfw": false,
            "num_comments": 4,
            "permalink": "/r/MachineLearning/comments/119a32e/d_open_source_version_of_flamingo/",
            "score": 15,
            "selftext": "At this point we have open source LLM's, text-to-image models, and CLIP-like models but nothing similar to Flamingo. I am guessing some groups have already started working on this, but I just don't know them. Does anyone know? Looks like a great fit for [LAION](https://laion.ai/). Also, I have some experience in this area and wouldn't mind lending a hand if that's possible. I really want to get my hands on a Flamingo-like large, multi-modal, few-shot model to see how it performs on vision-language compositionally tasks like [Winoground](https://arxiv.org/abs/2204.03162). I am guessing these models might do a lot better than their smaller counterparts owing to better generalization and reasoning capabilities of LLMs.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Open source version of Flamingo",
            "upvote_ratio": 0.91,
            "url": "https://www.reddit.com/r/MachineLearning/comments/119a32e/d_open_source_version_of_flamingo/"
        },
        {
            "author": "u/Wiskkey",
            "created_utc": "02-22-2023 14:19:02",
            "distinguished": null,
            "edited": "02-22-2023 19:54:45",
            "id": "1198k5j",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "News",
            "locked": false,
            "name": "t3_1198k5j",
            "nsfw": false,
            "num_comments": 6,
            "permalink": "/r/MachineLearning/comments/1198k5j/n_us_copyright_office_decides_that_kris/",
            "score": 19,
            "selftext": "[Letter from the U.S. Copyright Office](https://www.copyright.gov/docs/zarya-of-the-dawn.pdf) (PDF file).\n\n[Blog post from Kris Kashtanova's lawyer](https://processmechanics.com/2023/02/22/a-mixed-decision-from-the-us-copyright-office/).\n\n>We received the decision today relative to Kristina Kashtanova's case about the comic book Zarya of the Dawn. Kris will keep the copyright registration, but it will be limited to the text and the whole work as a compilation.  \n>  \n>In one sense this is a success, in that the registration is still valid and active. However, it is the most limited a copyright registration can be and it doesn't resolve the core questions about copyright in AI-assisted works. Those works may be copyrightable, but the USCO did not find them so in this case.\n\n[My previous post about this case](https://www.reddit.com/r/COPYRIGHT/comments/xkkh3d/us_copyright_office_registers_a_heavily/).\n\nRelated news: [\"The Copyright Office indicated in another filing that they are preparing guidance on AI-assisted art.\\[...\\]\"](https://www.reddit.com/r/StableDiffusion/comments/114pobl/tweet_from_a_person_whose_aiinvolved_graphic/).",
            "spoiler": false,
            "stickied": false,
            "title": "[N] U.S. Copyright Office decides that Kris Kashtanova's AI-involved graphic novel will remain copyright registered, but the copyright protection will be limited to the text and the whole work as a compilation",
            "upvote_ratio": 0.86,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1198k5j/n_us_copyright_office_decides_that_kris/"
        },
        {
            "author": "u/eamonnkeogh",
            "created_utc": "02-22-2023 13:29:40",
            "distinguished": null,
            "edited": false,
            "id": "11977iy",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "News",
            "locked": false,
            "name": "t3_11977iy",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/11977iy/n_crowdsourcing_better_names_for_the_catch22_time/",
            "score": 8,
            "selftext": "Dear Colleagues\n\nThis posting may be of interest to folks that use Catch22 for their time series research.\n\n**What is the problem?**\n\n* Catch22 is a wonderfully useful tool for time series...\n* But the names of the features, for example `SC_FluctAnal_2_dfa_50_1_2_logi_prop_r1` or `SB_TransitionMatrix_3ac_sumdiagcov` are awkward to use and have little mnemonic value.\n* Moreover, some of the names are very easy to confuse, such as: `DN_OutlierInclude_n_001_mdrmd` and `DN_OutlierInclude_p_001_mdrmd`\n*  This makes Catch22 awkward to use with a conversational agent, or many explainability/interpretability techniques etc.\n* Their long length means it is even awkward to discuss features in a two-column paper format.\n\nThus, we propose to find a set of new *meaningful* names for the features.\n\n**Design principles**\n\n* The name should reflect what a feature is sensitive to. Ideal names would be one word, for example: `noise`, `spike`, `symmetric`, `step`, `falling`, `periodic`, `simple`, `smooth`, `linear` etc.\n* However, given that it is likely to be rare a single feature has such specificity, the name could be a compound word, for example: `uniform-noise`, `localized-noise`, `positive-spike`, `negative-spike` etc.\n* Compound words with three parts might be acceptable, i.e. `fall-then-rise`, however beyond three parts would be undesirable.\n* <*Please suggest design principles we may have missed*\\>\n\nIn \\[a\\] we have a visual summary of the above, and one tentative worked example. We look forward to the community\u2019s input.\n\nMany thanks\n\nKeogh's Lab\n\n\\[a\\] PDF: [https://www.dropbox.com/s/n1aybeps5p2ho5k/Finding%20Better%20Names%20for%20the%20Catch22%20Features.pdf?dl=0](https://www.dropbox.com/s/n1aybeps5p2ho5k/Finding%20Better%20Names%20for%20the%20Catch22%20Features.pdf?dl=0)\n\nPPT: [https://www.dropbox.com/s/kxodalw2beyz86j/Finding%20Better%20Names%20for%20the%20Catch22%20Features.pptx?dl=0](https://www.dropbox.com/s/kxodalw2beyz86j/Finding%20Better%20Names%20for%20the%20Catch22%20Features.pptx?dl=0)",
            "spoiler": false,
            "stickied": false,
            "title": "[N] Crowdsourcing better names for the Catch22 time series features",
            "upvote_ratio": 0.79,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11977iy/n_crowdsourcing_better_names_for_the_catch22_time/"
        },
        {
            "author": "u/anishathalye",
            "created_utc": "02-22-2023 12:00:26",
            "distinguished": null,
            "edited": false,
            "id": "1194wm0",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_1194wm0",
            "nsfw": false,
            "num_comments": 9,
            "permalink": "/r/MachineLearning/comments/1194wm0/p_mit_introduction_to_datacentric_ai/",
            "score": 382,
            "selftext": "Announcing the [first-ever course on Data-Centric AI](https://dcai.csail.mit.edu/). Learn how to train better ML models by improving the data.\n\n[Course homepage](https://dcai.csail.mit.edu/) | [Lecture videos on YouTube](https://www.youtube.com/watch?v=ayzOzZGHZy4&list=PLnSYPjg2dHQKdig0vVbN-ZnEU0yNJ1mo5) | [Lab Assignments](https://github.com/dcai-course/dcai-lab)\n\nThe course covers:\n\n- [Data-Centric AI vs. Model-Centric AI](https://dcai.csail.mit.edu/lectures/data-centric-model-centric/)\n- [Label Errors](https://dcai.csail.mit.edu/lectures/label-errors/)\n- [Dataset Creation and Curation](https://dcai.csail.mit.edu/lectures/dataset-creation-curation/)\n- [Data-centric Evaluation of ML Models](https://dcai.csail.mit.edu/lectures/data-centric-evaluation/)\n- [Class Imbalance, Outliers, and Distribution Shift](https://dcai.csail.mit.edu/lectures/imbalance-outliers-shift/)\n- [Growing or Compressing Datasets](https://dcai.csail.mit.edu/lectures/growing-compressing-datasets/)\n- [Interpretability in Data-Centric ML](https://dcai.csail.mit.edu/lectures/interpretable-features/)\n- [Encoding Human Priors: Data Augmentation and Prompt Engineering](https://dcai.csail.mit.edu/lectures/human-priors/)\n- [Data Privacy and Security](https://dcai.csail.mit.edu/lectures/data-privacy-security/)\n\nMIT, like most universities, has many courses on machine learning (6.036, 6.867, and many others). Those classes teach techniques to produce effective models for a given dataset, and the classes focus heavily on the mathematical details of models rather than practical applications. However, in real-world applications of ML, the dataset is not fixed, and focusing on improving the data often gives better results than improving the model. We\u2019ve personally seen this time and time again in our applied ML work as well as our research.\n\nData-Centric AI (DCAI) is an emerging science that studies techniques to improve datasets in a systematic/algorithmic way \u2014\u00a0given that this topic wasn\u2019t covered in the standard curriculum, we (a group of PhD candidates and grads) thought that we should put together a new class! We taught this intensive 2-week course in January over MIT\u2019s IAP term, and we\u2019ve just published all the course material, including lecture videos, lecture notes, hands-on lab assignments, and lab solutions, in hopes that people outside the MIT community would find these resources useful.\n\nWe\u2019d be happy to answer any questions related to the class or DCAI in general, and we\u2019d love to hear any feedback on how we can improve the course material. Introduction to Data-Centric AI is open-source opencourseware, so feel free to make improvements directly: [https://github.com/dcai-course/dcai-course](https://github.com/dcai-course/dcai-course).",
            "spoiler": false,
            "stickied": false,
            "title": "[P] MIT Introduction to Data-Centric AI",
            "upvote_ratio": 0.97,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1194wm0/p_mit_introduction_to_datacentric_ai/"
        },
        {
            "author": "u/_learn_faster_",
            "created_utc": "02-22-2023 11:59:01",
            "distinguished": null,
            "edited": false,
            "id": "1194vcc",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_1194vcc",
            "nsfw": false,
            "num_comments": 8,
            "permalink": "/r/MachineLearning/comments/1194vcc/d_faster_flant5_inference/",
            "score": 7,
            "selftext": "What's the best way to improve the **inference** speed of a **Flan-T5** model?  \n\nOnnx runtime doesn't seem to work for T5 models & Torchscript also doesn't seem to help speed it up (not sure why!)",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Faster Flan-T5 inference",
            "upvote_ratio": 0.77,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1194vcc/d_faster_flant5_inference/"
        },
        {
            "author": "u/vyasnikhil96",
            "created_utc": "02-22-2023 09:22:26",
            "distinguished": null,
            "edited": false,
            "id": "1190lw8",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_1190lw8",
            "nsfw": false,
            "num_comments": 28,
            "permalink": "/r/MachineLearning/comments/1190lw8/r_provable_copyright_protection_for_generative/",
            "score": 18,
            "selftext": "Hi everyone, in a new paper we give a way to certify that a generative model does not infringe on the copyright of data that was in its training set.\n\nTwitter thread: https://twitter.com/boazbaraktcs/status/1628219647651729409\n\nBlogpost: https://windowsontheory.org/2023/02/21/provable-copyright-protection-for-generative-models/\n\nPaper: https://arxiv.org/abs/2302.10870\n\nAbstract:\n>There is a growing concern that learned conditional generative models may output samples that are substantially similar to some copyrighted data C that was in their training set. We give a formal definition of near access-freeness (NAF) and prove bounds on the probability that a model satisfying this definition outputs a sample similar to C, even if C is included in its training set. Roughly speaking, a generative model p is k-NAF if for every potentially copyrighted data C, the output of p diverges by at most k-bits from the output of a model q that did not access C at all. We also give generative model learning algorithms, which efficiently modify the original generative model learning algorithm in a black box manner, that output generative models with strong bounds on the probability of sampling protected content. Furthermore, we provide promising experiments for both language (transformers) and image (diffusion) generative models, showing minimal degradation in output quality while ensuring strong protections against sampling protected content.",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Provable Copyright Protection for Generative Models",
            "upvote_ratio": 0.68,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1190lw8/r_provable_copyright_protection_for_generative/"
        },
        {
            "author": "u/like_a_tensor",
            "created_utc": "02-22-2023 03:31:40",
            "distinguished": null,
            "edited": false,
            "id": "118syc4",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_118syc4",
            "nsfw": false,
            "num_comments": 4,
            "permalink": "/r/MachineLearning/comments/118syc4/d_visualizing_layer_weights/",
            "score": 5,
            "selftext": "I was reading [this](https://openreview.net/pdf?id=J_F_qqCE3Z5) paper, and I really liked the visualization of the conv layer weights in Figure 5. It's similar to the figures in [this talk at Microsoft](https://www.youtube.com/watch?v=EvAVCxZJN2U) at 11:25. Does anyone know what this visualization is called and/or methods to use it?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Visualizing layer weights",
            "upvote_ratio": 0.78,
            "url": "https://www.reddit.com/r/MachineLearning/comments/118syc4/d_visualizing_layer_weights/"
        },
        {
            "author": "u/GraciousReformer",
            "created_utc": "02-22-2023 00:12:30",
            "distinguished": null,
            "edited": false,
            "id": "118pof6",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_118pof6",
            "nsfw": false,
            "num_comments": 111,
            "permalink": "/r/MachineLearning/comments/118pof6/d_deep_learning_is_the_only_thing_that_currently/",
            "score": 123,
            "selftext": " \"Deep learning is the only thing that currently works at scale it's the only class of algorithms that is able to discover arbitrary functions in a reasonable amount of time.\"\n\n[https://www.youtube.com/watch?v=p-OYPRhqRCg](https://www.youtube.com/watch?v=p-OYPRhqRCg)\n\nI know of the universal approximation theorem. But is there any mathematical formulation of this statement?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] \"Deep learning is the only thing that currently works at scale\"",
            "upvote_ratio": 0.82,
            "url": "https://www.reddit.com/r/MachineLearning/comments/118pof6/d_deep_learning_is_the_only_thing_that_currently/"
        },
        {
            "author": "u/currentscurrents",
            "created_utc": "02-21-2023 21:34:51",
            "distinguished": null,
            "edited": "02-22-2023 00:17:32",
            "id": "118mm43",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_118mm43",
            "nsfw": false,
            "num_comments": 3,
            "permalink": "/r/MachineLearning/comments/118mm43/r_running_evolution_as_an_optimization_process_on/",
            "score": 9,
            "selftext": "[Not published in an open journal sadly.](https://www.science.org/doi/10.1126/science.1250939) \n\n[Press release.](https://www.rc.fas.harvard.edu/news-home/feature-stories/evolution-yeast/) \n\nTL;DR they set up a loss function (fastest growing survives) and evolved a bunch of yeast cells towards that loss function. This is a classic experiment, but they sequenced the DNA at each step and got a lot of cool data. The yeast cells converged much like you'd expect from an optimizer:\n\n>The results of the experiment showed that in a controlled environment, evolutionary contingency led to convergence rather than divergence at the fitness level. Simply put, while the various yeast strains did mutate in different ways, they all arrived at a similar evolutionary endpoint regardless of their mutations.\n\n\nI wonder if you could do this more quickly using gradient descent or other algorithms from machine learning. Since they're already sequencing the DNA at each step, they could have estimated the gradient and edited it back into the yeast. It would likely converge on similar solutions, but faster.",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Running evolution as an optimization process on yeast cells",
            "upvote_ratio": 0.77,
            "url": "https://www.reddit.com/r/MachineLearning/comments/118mm43/r_running_evolution_as_an_optimization_process_on/"
        },
        {
            "author": "u/thomasahle",
            "created_utc": "02-21-2023 17:04:57",
            "distinguished": null,
            "edited": false,
            "id": "118gie9",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_118gie9",
            "nsfw": false,
            "num_comments": 7,
            "permalink": "/r/MachineLearning/comments/118gie9/unit_normalization_instead_of_crossentropy_loss/",
            "score": 10,
            "selftext": "Cross entropy on logits is a normal simplification that fuses softmax + cross entropy loss to something like:\n```\ndef label_cross_entropy_on_logits(x, labels):\n    return (-x.select(labels) + x.logsumexp(axis=1)).sum(axis=0)\n```\nwhere `x.select(labels) = x[range(batch_size), labels]`.\n\nI was thinking about how the `logsumexp` term looks like a regularization term, and wondered what would happen if I just replaced it by `x.norm(axis=1)` instead. It seemed to work just as well as the original, so I thought, why not just enforce unit norm?\n\nI changed my code to\n```\ndef label_cross_entropy_on_logits(x, labels):\n    return -(x.select(labels) / x.norm(axis=1)).sum(axis=0)\n```\nand my training sped up dramatically, and my test loss decreased.\n\nI'm sure this is a standard approach to categorical loss, but I haven't seen it before, and would love to get some references.\n\nI found this old post: https://www.reddit.com/r/MachineLearning/comments/k6ff4w/unit_normalization_crossentropy_loss_outperforms/ which references LogitNormalization: https://arxiv.org/pdf/2205.09310.pdf However, it seems those papers all apply layer normalization _and then_ softmax+CE. What seems to work for me is simply replacing softmax+CE by normalization.",
            "spoiler": false,
            "stickied": false,
            "title": "Unit Normalization instead of Cross-Entropy Loss [Discussion]",
            "upvote_ratio": 0.92,
            "url": "https://www.reddit.com/r/MachineLearning/comments/118gie9/unit_normalization_instead_of_crossentropy_loss/"
        },
        {
            "author": "u/_Arsenie_Boca_",
            "created_utc": "02-21-2023 14:22:33",
            "distinguished": null,
            "edited": false,
            "id": "118cypl",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_118cypl",
            "nsfw": false,
            "num_comments": 15,
            "permalink": "/r/MachineLearning/comments/118cypl/d_bottleneck_layers_whats_your_intuition/",
            "score": 41,
            "selftext": "Many neural architectures use bottleneck layers somewhere in the architecture. What I mean by bottleneck is projecting activations to a lower dimension and back up. This is e.g. used in ResNet blocks. \n\nWhat is your intuition on why this is beneficial? From an information theory standpoint, it creates potential information loss due to the lower dimensionality. Can we see this as a form of regularisation, that makes the model learn more meaningful representations? \n\nIm interested in your intuitions in that matter or empirical results that might support these intuitions. Are you aware of other works that use bottlenecks and what is their underlying reasoning?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Bottleneck Layers: What's your intuition?",
            "upvote_ratio": 0.95,
            "url": "https://www.reddit.com/r/MachineLearning/comments/118cypl/d_bottleneck_layers_whats_your_intuition/"
        },
        {
            "author": "u/Animated-AI",
            "created_utc": "02-21-2023 13:23:44",
            "distinguished": null,
            "edited": false,
            "id": "118c8pp",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_118c8pp",
            "nsfw": false,
            "num_comments": 23,
            "permalink": "/r/MachineLearning/comments/118c8pp/p_the_first_depthwiseseparable_convolution/",
            "score": 338,
            "selftext": "Hey everyone,\n\nI've created what I believe is the first animation of a depthwise-separable convolution, and I thought you might appreciate it. I think this fills a legitimate gap in the instructional material available out there.\n\nhttps://i.redd.it/o1bns0jjskja1.gif\n\nI've actually been dissatisfied with the existing convolution animations in general (and [ranted about it on youtube](https://youtu.be/w4kNHKcBGzA)). So I made my own set of animations and published them on [animatedai.github.io](https://animatedai.github.io/).\n\nIf you find any of them useful, please feel free to copy them, post them on your website, throw them in a powerpoint, or just link to them.",
            "spoiler": false,
            "stickied": false,
            "title": "[P] The First Depthwise-separable Convolution Animation",
            "upvote_ratio": 0.96,
            "url": "https://www.reddit.com/r/MachineLearning/comments/118c8pp/p_the_first_depthwiseseparable_convolution/"
        },
        {
            "author": "u/Rudebrazen",
            "created_utc": "02-21-2023 12:47:39",
            "distinguished": null,
            "edited": false,
            "id": "118bcjx",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_118bcjx",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/118bcjx/r_are_there_datasets_of_annotations_of_the/",
            "score": 9,
            "selftext": "Chain-of-thought can be used to get large language models to generate what often look like reasoning traces, but the reasoning steps generated are not always correct (even when the model's final answer *is* correct!). I\u2019m aware of a few efforts to manually annotate the correctness/incorrectness of the reasoning steps in chain-of-thought-type data:\n\n\\* \u201cSolving math word problems with process- and outcome-based feedback\u201d: [https://arxiv.org/abs/2211.14275](https://arxiv.org/abs/2211.14275) \n\n\\* \u201cLarge Language Models Are Reasoning Teachers\u201d, section 4.2: [https://arxiv.org/pdf/2212.10071.pdf](https://arxiv.org/pdf/2212.10071.pdf) \n\nUnfortunately, the data does not seem to be available from either study. Is anyone aware of other researchers who have annotated the correctness of LLM-generated reasoning steps (whether or not their data is public), or datasets that contain this kind of data?\n\nI guess I\u2019d also be interested in datasets where the correctness/incorrectness of individual reasoning steps generated by humans have been annotated, for example if there are datasets of human-solved logic problems with the errors marked.   \n\n\nAgain, am interested in correctness of individual reasoning steps, not the correctness of the final answers.",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Are there datasets of annotations of the correctness/incorrectness of the individual steps of chain-of-thought reasoning?",
            "upvote_ratio": 1.0,
            "url": "https://www.reddit.com/r/MachineLearning/comments/118bcjx/r_are_there_datasets_of_annotations_of_the/"
        },
        {
            "author": "u/CheapBreakfast9",
            "created_utc": "02-21-2023 09:46:31",
            "distinguished": null,
            "edited": false,
            "id": "11853g5",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_11853g5",
            "nsfw": false,
            "num_comments": 8,
            "permalink": "/r/MachineLearning/comments/11853g5/r_chatgpt_for_robotics_design_principles_and/",
            "score": 27,
            "selftext": "I wanted to share a paper we have just released, where we extended the capabilities of ChatGPT to robotics, and controlled multiple platforms such as robot arms, drones, and home assistant robots intuitively with language: [https://www.microsoft.com/en-us/research/group/autonomous-systems-group-robotics/articles/chatgpt-for-robotics/](https://www.microsoft.com/en-us/research/group/autonomous-systems-group-robotics/articles/chatgpt-for-robotics/)\n\nVideo: [https://youtu.be/NYd0QcZcS6Q](https://youtu.be/NYd0QcZcS6Q)\n\nTechnical paper: [https://www.microsoft.com/en-us/research/uploads/prod/2023/02/ChatGPT\\_\\_\\_Robotics.pdf](https://www.microsoft.com/en-us/research/uploads/prod/2023/02/ChatGPT___Robotics.pdf)\n\nhttps://i.redd.it/ya84nryu0kja1.gif",
            "spoiler": false,
            "stickied": false,
            "title": "[R] ChatGPT for Robotics: Design Principles and Model Abilities",
            "upvote_ratio": 0.86,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11853g5/r_chatgpt_for_robotics_design_principles_and/"
        },
        {
            "author": "u/emad_eldeen",
            "created_utc": "02-21-2023 07:50:32",
            "distinguished": null,
            "edited": false,
            "id": "1182oyr",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_1182oyr",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/1182oyr/r_check_our_survey_paper_for_a_labelefficient/",
            "score": 1,
            "selftext": "Our survey paper: \"[Label-efficient Time Series Representation Learning: A Review](https://arxiv.org/abs/2302.06433)\" discusses one of the main limitations of applying deep learning models on time series data in the real world, i.e., the scarcity of labeled data. \n\nThere are different ways to address this issue, and we attempt to provide an overview of the various label-scarce scenarios, and their corresponding techniques proposed to address each one.\n\n&#x200B;\n\nhttps://preview.redd.it/7waga9tdgjja1.jpg?width=1984&format=pjpg&auto=webp&v=enabled&s=6b7070d286691fb8b2b2006f7b4a2dea73059b7b",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Check our survey paper for a label-efficient Time Series Representation Learning",
            "upvote_ratio": 0.6,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1182oyr/r_check_our_survey_paper_for_a_labelefficient/"
        },
        {
            "author": "u/cccntu",
            "created_utc": "02-21-2023 07:36:39",
            "distinguished": null,
            "edited": false,
            "id": "1182fqd",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_1182fqd",
            "nsfw": false,
            "num_comments": 9,
            "permalink": "/r/MachineLearning/comments/1182fqd/p_minlora_an_easytouse_pytorch_library_for/",
            "score": 104,
            "selftext": "Hey r/MachineLearning! I wanted to share a new PyTorch library I've been working on that I think could be really useful for anyone looking to fine-tune large models with LoRA.   \n\n\n[https://github.com/cccntu/minlora](https://github.com/cccntu/minlora)\n\n  \nThe library is based on the LoRA technique (**Lo**w-**R**ank **A**daptation). \"which freezes the pre-trained model weights and injects trainable rank decomposition matrices into each layer.\" (- quote from the [paper](https://openreview.net/forum?id=nZeVKeeFYf9))  \n\n\nWith this library, you can easily apply LoRA to any PyTorch model with just a few lines of code.\n\nOne of the benefits of this library is that it's really small - just 100 lines of code. Despite its size, it's quite powerful and has been tested on a variety of different models, including nanoGPT by Karpathy, and stable diffusion.  \n\n\nIt also features an easy-to-use interface that allows you to serve multiple LoRA models at the same time!",
            "spoiler": false,
            "stickied": false,
            "title": "[P] minLoRA: An Easy-to-Use PyTorch Library for Applying LoRA to PyTorch Models",
            "upvote_ratio": 0.97,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1182fqd/p_minlora_an_easytouse_pytorch_library_for/"
        },
        {
            "author": "u/deluded_soul",
            "created_utc": "02-21-2023 06:39:18",
            "distinguished": null,
            "edited": false,
            "id": "1181g88",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_1181g88",
            "nsfw": false,
            "num_comments": 7,
            "permalink": "/r/MachineLearning/comments/1181g88/discussion_ml_on_extremely_large_datasets_and/",
            "score": 4,
            "selftext": "I am looking into any techniques one could use for very large datasets in machine learning. So I am talking about datasets with the following properties:\n\n1: 3D Imaging dataset where each dataset is of the order of many terabytes.\n\n2: Each 3D image is too big to fit in the GPU or CPU memory.\n\nI am interested in educating myself on methods that people have used in classical ML and modern deep learning for such extremely large datasets.\n\nIn particular, how does one ensure one can capture long-range spatial interactions in such datasets and what computational techniques can one do to perform learning on such datasets?  \n\n\nFinally, if someone can point me to some open source examples of such ML systems (domain is not important) that I can learn from, I would be extremely grateful.open-source",
            "spoiler": false,
            "stickied": false,
            "title": "[Discussion] ML on extremely large datasets and images",
            "upvote_ratio": 0.75,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1181g88/discussion_ml_on_extremely_large_datasets_and/"
        },
        {
            "author": "u/AlmightySnoo",
            "created_utc": "02-20-2023 14:55:31",
            "distinguished": null,
            "edited": "02-20-2023 15:32:26",
            "id": "117iqtp",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_117iqtp",
            "nsfw": false,
            "num_comments": 23,
            "permalink": "/r/MachineLearning/comments/117iqtp/d_on_papers_forcing_the_use_of_gans_where_it_is/",
            "score": 32,
            "selftext": "One of the things in current publications that completely irritates me is people just forcing the use of GANs where they are not even needed nor suited at all, just to ride on the hype of *generative AI*.\n\nThese guys usually have samples `(x_1, y_1=phi(x_1)), ..., (x_n, y_n=phi(x_n))` of a random pair `(X, Y=phi(X))` where `phi` is some unknown target function (*ie* in fancy-pants math we know that `Y` is `sigma(X)`\\-measurable). A direct way to solve this is to treat it naturally as a regression problem and use your usual ML/DL toolkit. These guys however think that they can make the problem look sexier if they introduce GANs. For instance, they'd train a GAN taking `X` as an input and through the discriminator have the generator output something that has the same distribution as `Y=phi(X)`. Some will even add some random noise `z` , that has nothing to do with `X`, to the inputs of the generator despite knowing that `X` is already enough to fully determine `Y`. GANs would have been useful if we didn't have joint observations of `X` and `Y` but that is not the case here.\n\nOne of the papers I have in mind is this one: [https://openreview.net/pdf?id=SDD5n1888](https://openreview.net/pdf?id=SDD5n1888)\n\nHow on earth are these papers getting accepted? To me that is literally just plagiarism of what's already available (physics-informed NNs in that case) by adding a totally useless layer (the GAN) to make it seem like this is a novel approach. That paper is only one of many cases. I know of a professor actively using that same technique to get cheap articles where he just replaces a standard regression NN in an old paper found online by a totally unjustified GAN. IMO reviewers at these journals/conferences need to be more mindful of this kind of plagiarism/low-effort submission.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] On papers forcing the use of GANs where it is not relevant",
            "upvote_ratio": 0.77,
            "url": "https://www.reddit.com/r/MachineLearning/comments/117iqtp/d_on_papers_forcing_the_use_of_gans_where_it_is/"
        },
        {
            "author": "u/Soundwave_47",
            "created_utc": "02-20-2023 14:12:21",
            "distinguished": null,
            "edited": "02-20-2023 14:18:10",
            "id": "117hmx4",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": null,
            "locked": false,
            "name": "t3_117hmx4",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/117hmx4/n_sony_ais_qrsac_rl_algorithm_sophy_to_be_demoed/",
            "score": 7,
            "selftext": ">Gran Turismo Sophy is a revolutionary superhuman racing AI racing agent developed in a collaboration between Sony AI, Sony Interactive Entertainment and Polyphony Digital. \u201cGran Turismo Sophy Race Together\u201d mode gives Gran Turismo players of all levels and abilities the opportunity to go head-to-head against GT Sophy in GT7. The special mode, available as a time-limited in-game event (From Feb 21 to end of March), is a first look at GT Sophy in GT7 and is designed to maximize the fun and excitement of racing against GT Sophy for everyone. Player feedback on this initial special feature will be used to continually improve the GT Sophy Race Together mode feature for future releases.\u00a0\n\n>In GT Sophy Race Together mode, players can race against GT Sophy in a series of four circuits of increasing difficulty, as a Beginner / Intermediate / Expert driver. In each of the four races, the player races against four GT Sophy cars of different performance levels. Players can also challenge GT Sophy in 1VS1 mode, where GT Sophy and the player race one-on-one with identical car configurations and settings, which showcases the superhuman racing skills of GT Sophy. The excitement of GT Sophy Race Together mode is enhanced with GT7\u2019s new emoticon feature, which displays emoticons on the GT Sophy cars throughout the race to react to the in-game action.\n\nhttps://blog.playstation.com/2023/02/20/gran-turismo-7-update-1-29-includes-ps-vr2-upgrade-a-race-against-superhuman-ai-a-classic-gt-track-and-5-new-cars/\n\nSony AI introduced their quantile regression\u2014soft actor critic algorithm for Sophy in this Nature paper.\n\nhttps://www.nature.com/articles/s41586-021-04357-7",
            "spoiler": false,
            "stickied": false,
            "title": "[N] Sony AI's QR-SAC RL algorithm Sophy to be demoed in upcoming update of Gran Turismo",
            "upvote_ratio": 0.89,
            "url": "https://www.reddit.com/r/MachineLearning/comments/117hmx4/n_sony_ais_qrsac_rl_algorithm_sophy_to_be_demoed/"
        },
        {
            "author": "u/lemon-meringue",
            "created_utc": "02-20-2023 13:53:05",
            "distinguished": null,
            "edited": false,
            "id": "117h4rg",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": null,
            "locked": false,
            "name": "t3_117h4rg",
            "nsfw": false,
            "num_comments": 2,
            "permalink": "/r/MachineLearning/comments/117h4rg/d_why_do_many_ml_papers_choose_to_reimplement/",
            "score": 14,
            "selftext": "PyTorch has its own torch.nn.Transformer [module](https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html), however I see that many papers and their reproductions often choose to implement the transformer from scratch.\n\nFor example:\n\n* [Vision Transformers](https://github.com/lucidrains/vit-pytorch/blob/main/vit_pytorch/vit.py#L35)\n* [Decision Transformers](https://github.com/kzl/decision-transformer/blob/master/atari/mingpt/model_atari.py#L99)\n* [Whisper](https://github.com/openai/whisper/blob/main/whisper/model.py#L104)\n\nIn fact, I'm not sure if I've ever seen any project actually use the PyTorch module. I'm curious if there's a reason for this?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Why do many ML papers choose to reimplement PyTorch transformer modules?",
            "upvote_ratio": 1.0,
            "url": "https://www.reddit.com/r/MachineLearning/comments/117h4rg/d_why_do_many_ml_papers_choose_to_reimplement/"
        },
        {
            "author": "u/alik31239",
            "created_utc": "02-20-2023 11:09:46",
            "distinguished": null,
            "edited": false,
            "id": "117blae",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_117blae",
            "nsfw": false,
            "num_comments": 10,
            "permalink": "/r/MachineLearning/comments/117blae/d_something_basic_i_dont_understand_about_nerfs/",
            "score": 25,
            "selftext": "In the abstract of the Nerf paper ([https://arxiv.org/abs/2003.08934](https://arxiv.org/abs/2003.08934)), the described framework is that Nerf enable to do the following: the user inputs a set of images with known camera poses, and after training the network they can generate images of the same scene from new angles.\n\nHowever, the paper itself builds a network that gets as an input 5D vectors (3 location coordinates+2 camera angles) and outputs color and volume density for each such coordinate. I don't understand where do I get those 5D coordinates from? My training data surely doesn't have those - I only have a collection of images. Same for inference data. It seems that the paper assumes not only having a collection of images but also having a 3D representation of the scene, while the abstract doesn't require the latter. What am I missing here?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Something basic I don't understand about Nerfs",
            "upvote_ratio": 0.93,
            "url": "https://www.reddit.com/r/MachineLearning/comments/117blae/d_something_basic_i_dont_understand_about_nerfs/"
        },
        {
            "author": "u/tysam_and_co",
            "created_utc": "02-20-2023 10:21:48",
            "distinguished": null,
            "edited": false,
            "id": "1179i7z",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_1179i7z",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/1179i7z/r_train_cifar10_to_94_in_7_seconds_or_less/",
            "score": 10,
            "selftext": "Hello everyone,  \n\n\nIt's that time again, thank you all so much for the support you've given us over here. I've done a ton of typing this morning, so for a summary of what I've updated, you can see the higher-level twitter thread I wrote at [https://twitter.com/hi\\_tysam/status/1627679672988319746?cxt=HHwWhIC-yb2C15YtAAAA](https://twitter.com/hi_tysam/status/1627679672988319746?cxt=HHwWhIC-yb2C15YtAAAA), or the more detailed (but still rough cut) patch notes I wrote this morning at  [https://github.com/tysam-code/hlb-CIFAR10/releases/tag/v0.5.0](https://github.com/tysam-code/hlb-CIFAR10/releases/tag/v0.5.0)  \n\n\nHappy to answer any questions anyone might have, cheers! :D :))))",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Train CIFAR10 to 94% in 7 seconds or less (Lookahead with custom scheduling, CutMix, and more!)",
            "upvote_ratio": 0.7,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1179i7z/r_train_cifar10_to_94_in_7_seconds_or_less/"
        },
        {
            "author": "u/fferflo",
            "created_utc": "02-20-2023 10:02:55",
            "distinguished": null,
            "edited": "02-20-2023 10:22:50",
            "id": "1178rmr",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_1178rmr",
            "nsfw": false,
            "num_comments": 5,
            "permalink": "/r/MachineLearning/comments/1178rmr/d_does_layer_normalization_compute_statistics/",
            "score": 57,
            "selftext": "As far as I can tell, there are two contradictory definitions of Layer Normalization that are both floating around. LN computes the mean and variance along some axes of the input tensor for normalization, yet the choice of axes is not clear:\n\nA. The [GroupNorm paper (2018)](https://arxiv.org/pdf/1803.08494.pdf) has this figure that describes LN as reducing **along channel and spatial/token axes**.\n\nhttps://preview.redd.it/ui9adzzxgcja1.png?width=1353&format=png&auto=webp&v=enabled&s=f701d53a0992e3fe13bdac6ee022d352f965c893\n\nB. The [PowerNorm paper (2020)](https://arxiv.org/pdf/2003.07845.pdf) has this figure that describes LN as reducing **only along the channel axis**.\n\nhttps://preview.redd.it/e0qmp9sahcja1.png?width=1717&format=png&auto=webp&v=enabled&s=00126512760766783d88217b44377f5741290d9c\n\nThere are also many online sources that describe LN as shown in A (e.g. [TF tutorials](https://www.tensorflow.org/addons/tutorials/layers_normalizations), [PapersWithCode](https://paperswithcode.com/method/layer-normalization), [this summary of normalization techniques](https://theaisummer.com/normalization/)) using similar figures.\n\nThe [LN paper (2016)](https://arxiv.org/pdf/1607.06450.pdf) itself says\n\n>all the hidden units in a layer share the same normalization terms \u03bc and \u03c3\n\nso the channel axis is definitely reduced, and\n\n>computing the mean and variance used for normalization from all of the summedinputs to the neurons in a layer *on a single training case*\n\nso the batch axis is definitely not reduced. As far as I can tell it is not clear about what happens with spatial/token axes, although the above sounds rather like they might be included in the statistics.\n\nYet, I don't know of any model that actually uses A instead of B. For example, [TF](https://github.com/keras-team/keras/blob/v2.11.0/keras/layers/normalization/layer_normalization.py#L158) and [Flax](https://github.com/google/flax/blob/main/flax/linen/normalization.py#L321) explicitly implement LN with default axes as in B ([PyTorch](https://github.com/pytorch/pytorch/blob/master/torch/nn/modules/normalization.py#L142), [Haiku](https://github.com/deepmind/dm-haiku/blob/main/haiku/_src/layer_norm.py#L78) and [Equinox](https://github.com/patrick-kidger/equinox/blob/1f5373f5905504bc5e7069ed6d458dbad5616495/equinox/nn/normalisation.py#L39) don't have a preference and require the user to specify the reduction axes). [Vision Transformer](https://github.com/google-research/vision_transformer/blob/main/vit_jax/models_vit.py#L133) uses Flax with LN as in B, [ConvNeXt](https://github.com/facebookresearch/ConvNeXt/blob/main/models/convnext.py#L135) implements LN with PyTorch as in B, [OpenAI GPT-2](https://github.com/openai/gpt-2/blob/master/src/model.py#L28) implements LN with Tensorflow as in B, even [MLP-Mixer](https://github.com/google-research/vision_transformer/blob/main/vit_jax/models_mixer.py#L41) where the spatial/token axes are interpreted as channel axis for an MLP still computes statistics along the original channel axis as in B.\n\nAs far as I can tell, everyone uses B rather than A in their models, so to me this seems to be the \"correct\" definition. Yet, many sources on this topic describe LN as doing A rather than B.\n\nDoes anyone have any insight on this or know of a source that has addressed this problem? Do you interpret the original LN paper as including spatial/token axes in their computation of mean and variance, or not? Is this simply an error that started with the figure A and made its way into different online tutorials from there? Or do you maybe know of a model that actually uses LN to reduce both along channel and spatial/token axes?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Does Layer Normalization compute statistics along spatial/ token axes?",
            "upvote_ratio": 0.92,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1178rmr/d_does_layer_normalization_compute_statistics/"
        },
        {
            "author": "u/Sanciopinto",
            "created_utc": "02-20-2023 04:33:42",
            "distinguished": null,
            "edited": false,
            "id": "1172juh",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_1172juh",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/1172juh/r_p_implementation_of_feature_extraction_and_id/",
            "score": 4,
            "selftext": "Hi everyone,\n\nI'm currently working on a biometric identification project that involves converting biometric data (such as iris images) into a unique and secure ID. In order to do so, one of the first steps in the pipeline (after training a feature extractor) is to extract a set of features from an image in some tensor form (preferably a vector). What I'm wondering is what robust method could be used to extract similar feature vectors for similar inputs (e.g., to obtain similar, in terms of Euclidean distance, feature vectors for various photos of a same iris)? That would be required such that the feature vectors for similar inputs could be converted to the same unique ID (e.g., by using a locality-sensitive hashing algorithm).\n\nIn short, I'm interested in any tips for:\n\n* Choosing an appropriate and robust feature extraction architecture\n* Methods for conversion of features to IDs (such as hashing, or anything that should work in theory)\n\nAny insights or suggestions would be greatly appreciated. Thanks in advance!",
            "spoiler": false,
            "stickied": false,
            "title": "[R] [P] Implementation of feature extraction and ID attribution for biometric identification project",
            "upvote_ratio": 1.0,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1172juh/r_p_implementation_of_feature_extraction_and_id/"
        },
        {
            "author": "u/head_robotics",
            "created_utc": "02-20-2023 04:33:34",
            "distinguished": null,
            "edited": "02-20-2023 04:43:02",
            "id": "1172jrs",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_1172jrs",
            "nsfw": false,
            "num_comments": 47,
            "permalink": "/r/MachineLearning/comments/1172jrs/d_large_language_models_feasible_to_run_on_32gb/",
            "score": 223,
            "selftext": "I've been looking into open source large language models to run locally on my machine.\n\nSeems GPT-J and GPT-Neo are out of reach for me because of RAM / VRAM requirements.\n\nWhat models would be doable with this hardware?:\n\nCPU: AMD Ryzen 7 3700X 8-Core, 3600 MhzRAM: 32 GB\n\nGPUs:\n\n1. NVIDIA GeForce RTX 2070 8GB VRAM\n2. NVIDIA Tesla M40 24GB VRAM",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Large Language Models feasible to run on 32GB RAM / 8 GB VRAM / 24GB VRAM",
            "upvote_ratio": 0.93,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1172jrs/d_large_language_models_feasible_to_run_on_32gb/"
        },
        {
            "author": "u/Singularian2501",
            "created_utc": "02-19-2023 14:31:58",
            "distinguished": null,
            "edited": false,
            "id": "116lp7a",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "News",
            "locked": false,
            "name": "t3_116lp7a",
            "nsfw": false,
            "num_comments": 4,
            "permalink": "/r/MachineLearning/comments/116lp7a/r_n_mastering_diverse_domains_through_world/",
            "score": 50,
            "selftext": "Paper: [https://arxiv.org/abs/2301.04104#deepmind](https://arxiv.org/abs/2301.04104#deepmind) \n\nWebsite: [https://danijar.com/project/dreamerv3/](https://danijar.com/project/dreamerv3/) \n\nTwitter: [https://twitter.com/danijarh/status/1613161946223677441](https://twitter.com/danijarh/status/1613161946223677441) \n\nGithub: [https://github.com/danijar/dreamerv3](https://github.com/danijar/dreamerv3)  / [https://github.com/danijar/daydreamer](https://github.com/danijar/daydreamer) \n\nAbstract:\n\n>General intelligence requires solving tasks across many domains. Current reinforcement learning algorithms carry this potential but are held back by the resources and knowledge required to tune them for new tasks. We present **DreamerV3, a general and scalable algorithm based on world models that outperforms previous approaches** across a wide range of domains with fixed hyperparameters. These domains include continuous and discrete actions, visual and low-dimensional inputs, 2D and 3D worlds, different data budgets, reward frequencies, and reward scales. We observe favorable scaling properties of DreamerV3, with **larger models directly translating to higher data-efficiency and final performance.** Applied out of the box, DreamerV3 is the **first algorithm to collect diamonds in Minecraft from scratch without human data or curricula,** a long-standing challenge in artificial intelligence. Our general algorithm makes reinforcement learning broadly applicable and allows scaling to hard decision making problems. \n\nhttps://preview.redd.it/h4hrfqwp57ja1.jpg?width=1320&format=pjpg&auto=webp&v=enabled&s=f3687d48c9b28efe184931cee62d7ff42b5d5655\n\nhttps://preview.redd.it/bl13kxwp57ja1.jpg?width=1399&format=pjpg&auto=webp&v=enabled&s=56c70c244e3ccf45b351e83791059d01a535299f\n\nhttps://preview.redd.it/b0kqa2xp57ja1.jpg?width=1286&format=pjpg&auto=webp&v=enabled&s=55fffc14ae68cb8ad60e395182c71c541c5f2005\n\nhttps://preview.redd.it/e61x5xwp57ja1.jpg?width=1291&format=pjpg&auto=webp&v=enabled&s=d23cfe3bab1114f543187c53d355488e4d3c8ffa",
            "spoiler": false,
            "stickied": false,
            "title": "[R] [N] Mastering Diverse Domains through World Models - DreamerV3 - Deepmind 2023 - First algorithm to collect diamonds in Minecraft from scratch without human data or curricula! Now with github links!",
            "upvote_ratio": 0.91,
            "url": "https://www.reddit.com/r/MachineLearning/comments/116lp7a/r_n_mastering_diverse_domains_through_world/"
        },
        {
            "author": "u/radi-cho",
            "created_utc": "02-19-2023 13:53:52",
            "distinguished": null,
            "edited": false,
            "id": "116kqvm",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "News",
            "locked": false,
            "name": "t3_116kqvm",
            "nsfw": false,
            "num_comments": 11,
            "permalink": "/r/MachineLearning/comments/116kqvm/r_n_in_this_paper_we_show_how_a_conversational/",
            "score": 151,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] [N] In this paper, we show how a conversational model, 3.5x smaller than SOTA, can be optimized to outperform the baselines through Auxiliary Learning. Published in the ACL Anthology: \"Efficient Task-Oriented Dialogue Systems with Response Selection as an Auxiliary Task.\"",
            "upvote_ratio": 0.97,
            "url": "https://i.redd.it/cffc6a3qy6ja1.png"
        },
        {
            "author": "u/Singularian2501",
            "created_utc": "02-19-2023 12:38:45",
            "distinguished": null,
            "edited": false,
            "id": "116ivz2",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_116ivz2",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/116ivz2/r_augmented_language_models_a_survey_meta_ai_2023/",
            "score": 21,
            "selftext": "Paper: [https://arxiv.org/abs/2302.07842](https://arxiv.org/abs/2302.07842)\n\nAbstract:\n\n>This survey reviews works in which language models (LMs) are augmented with reasoning skills and the ability to use tools. The former is defined as decomposing a potentially complex task into simpler subtasks while the latter consists in calling external modules such as a code interpreter. LMs can leverage these augmentations separately or in combination via heuristics, or learn to do so from demonstrations. While adhering to a standard missing tokens prediction objective, such augmented LMs can use various, possibly non-parametric external modules to expand their context processing ability, thus departing from the pure language modeling paradigm. We therefore refer to them as Augmented Language Models (ALMs). The missing token objective allows **ALMs to learn to reason, use tools, and even act, while still performing standard natural language tasks and even outperforming most regular LMs on several benchmarks.** In this work, after reviewing current advance in ALMs, we conclude that this new research direction has the potential to address common limitations of traditional LMs such as interpretability, consistency, and scalability issues.       \n\nhttps://preview.redd.it/lyjdr1ozj6ja1.jpg?width=1281&format=pjpg&auto=webp&v=enabled&s=1b5db84ec5b38228fc794e3fd24e83e4e450cc57",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Augmented Language Models: a Survey - Meta AI 2023",
            "upvote_ratio": 0.96,
            "url": "https://www.reddit.com/r/MachineLearning/comments/116ivz2/r_augmented_language_models_a_survey_meta_ai_2023/"
        },
        {
            "author": "u/LegendOfHiddnTempl",
            "created_utc": "02-19-2023 08:06:42",
            "distinguished": null,
            "edited": false,
            "id": "1169uzy",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_1169uzy",
            "nsfw": false,
            "num_comments": 23,
            "permalink": "/r/MachineLearning/comments/1169uzy/r_neural_cloth_simulation/",
            "score": 662,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] neural cloth simulation",
            "upvote_ratio": 0.97,
            "url": "https://v.redd.it/hgbepc6z85ja1"
        },
        {
            "author": "u/aadityaura",
            "created_utc": "02-19-2023 07:29:06",
            "distinguished": null,
            "edited": false,
            "id": "11695n4",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11695n4",
            "nsfw": false,
            "num_comments": 2,
            "permalink": "/r/MachineLearning/comments/11695n4/d_difference_between_offsitetuning_transfer/",
            "score": 5,
            "selftext": "The paper \"Offsite-Tuning: Transfer Learning without Full Model\" describes a privacy-preserving and efficient transfer learning framework. In this framework  \n\n\n\u2022 Offsite-Tuning is a privacy-preserving and efficient transfer learning framework    \n\u2022 Model owner sends a light-weight adapter and a lossy compressed emulator to the data owner   \n\u2022 Data owner fine-tunes adapter on downstream data with the emulator's assistance   \n\u2022 Fine-tuned adapter is then returned to the model owner to create an adapted foundation model   \n\u2022 Offsite-Tuning preserves both parties' privacy and is computationally more efficient than existing fine-tuning methods\n\nHow does this differ from Federated Learning?\n\nPaper Link: [https://arxiv.org/abs/2302.04870](https://arxiv.org/abs/2302.04870)",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Difference between [ Offsite-Tuning: Transfer Learning without Full Model ] and Federated learning?",
            "upvote_ratio": 0.78,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11695n4/d_difference_between_offsitetuning_transfer/"
        },
        {
            "author": "u/westeast1000",
            "created_utc": "02-19-2023 05:41:22",
            "distinguished": null,
            "edited": false,
            "id": "1167hw9",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_1167hw9",
            "nsfw": false,
            "num_comments": 11,
            "permalink": "/r/MachineLearning/comments/1167hw9/d_does_langchain_upload_all_users_data_to_openai/",
            "score": 0,
            "selftext": "I just saw a tutorial about using langchains and am curious about how it works. So if i implemented something at my company that can answer any question across all our documents, does it mean i would have essentially gave all our company info to openai?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Does langchain upload all user\u2019s data to Openai?",
            "upvote_ratio": 0.46,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1167hw9/d_does_langchain_upload_all_users_data_to_openai/"
        },
        {
            "author": "u/MRMohebian",
            "created_utc": "02-18-2023 22:41:12",
            "distinguished": null,
            "edited": false,
            "id": "1160md2",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_1160md2",
            "nsfw": false,
            "num_comments": 3,
            "permalink": "/r/MachineLearning/comments/1160md2/torchdrug_tutorial_d/",
            "score": 30,
            "selftext": "TorchDrug is a machine learning platform designed for drug discovery, covering techniques from graph machine learning (graph neural networks, geometric deep learning & knowledge graphs), deep generative models to reinforcement learning. It provides a comprehensive and flexible interface to support rapid prototyping of drug discovery models in PyTorch. \n\nIn this video, we walk through TorchDrug library and train some GNN for graph classification, attribute masking and unsupervised graph representation learning.\n\nhttps://youtu.be/-Kb7kN4aHMM",
            "spoiler": false,
            "stickied": false,
            "title": "TorchDrug tutorial [D]",
            "upvote_ratio": 0.89,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1160md2/torchdrug_tutorial_d/"
        },
        {
            "author": "u/I_will_delete_myself",
            "created_utc": "02-18-2023 21:33:37",
            "distinguished": null,
            "edited": false,
            "id": "115z9hc",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_115z9hc",
            "nsfw": false,
            "num_comments": 27,
            "permalink": "/r/MachineLearning/comments/115z9hc/d_things_you_wish_you_knew_before_you_started/",
            "score": 92,
            "selftext": "I really like training in the cloud for some reason and feels satisfying, however here is a couple of things I would've wished I knew beforehand to get things started.\n\n1. Use a spot instance unless you absolutely must make sure it isn't interrupted. Your wallet will thank you later. \n2. Make sure Nvidia drivers are installed and don't experiment with Operating systems. You are paying by the hour. \n3. Make sure to use something like tmux to save the sessions running in your terminal so you don't have to start from scratch or in case you disconnect from the vm (but the VM isn't shut down). That way you can just click out of the terminal and not bother with it until it's done. \n4. Debug on your local machine on CPU if you don't have CUDA. You can debug the model on a CPU perfectly fine. \n\nNow what about you all?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Things you wish you knew before you started training on the cloud?",
            "upvote_ratio": 0.96,
            "url": "https://www.reddit.com/r/MachineLearning/comments/115z9hc/d_things_you_wish_you_knew_before_you_started/"
        },
        {
            "author": "u/MysteryInc152",
            "created_utc": "02-18-2023 19:47:12",
            "distinguished": null,
            "edited": false,
            "id": "115x1it",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_115x1it",
            "nsfw": false,
            "num_comments": 22,
            "permalink": "/r/MachineLearning/comments/115x1it/d_toolformer_implementation_using_only_fewshot/",
            "score": 89,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Toolformer implementation using only few-shot prompting",
            "upvote_ratio": 0.96,
            "url": "https://twitter.com/minosvasilias/status/1627076214639976449"
        },
        {
            "author": "u/Old_Scallion2173",
            "created_utc": "02-18-2023 19:37:00",
            "distinguished": null,
            "edited": false,
            "id": "115wu59",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_115wu59",
            "nsfw": false,
            "num_comments": 11,
            "permalink": "/r/MachineLearning/comments/115wu59/d_bounding_box_or_instance_segmentation/",
            "score": 5,
            "selftext": " \n\nHello, community.\n\n**Description:**\n\nI am planning to create a detection model using YOLO v8 to detect leukemia cells in a blood sample. I started learning about deep learning two months ago and I am eager to try out image segmentation on my present dataset instead of bounding boxes, as the cells are closely bunched together. I need advice on whether I should use bounding boxes or instance segmentation, considering my dataset and expected results.\n\n**Context:**\n\nLeukemia is caused by an abundance of different types of naive or altered white blood cells in the body, which overwhelm the bloodstream and inhibit the proper functioning of normal white blood cells. There are three classes in my dataset: lymphoblasts, promyelocytes, and neutrophils, and I need to be able to detect these cells.\n\n**Expected Results:**\n\nAs this is a medical domain, false positives are acceptable, but false negatives are not.\n\n**About dataset:**\n\n[lymphoblast sample image](https://imagebank.hematology.org/getimagebyid/2201?size=3)\n\n[sample image for promyelocytes](https://medschool.co/images/detail/blood-film/promyelocyte.jpg)\n\n[sample image for neutrophils](https://imagebank.hematology.org/getimagebyid/3610?size=3)\n\n[sample test image](https://thumbs.dreamstime.com/z/picture-white-blood-cell-red-blood-cell-platelet-blood-film-analyze-microscope-picture-blood-cells-blood-film-161974012.jpg)\n\nlymphoblasts(101 images)\n\npromyelocytes(91 images)\n\nneutrophils(133 images)\n\n**more context for your reading:**\n\nAn over abundance of lymphoblasts results in acute lymphoblastic leukemia (ALL), while acute pomyelocytic leukemia (APLML/APL) is caused by an abnormal accumulation of promyelocytes. neutrophils do not cause leukemia.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] bounding box or instance segmentation",
            "upvote_ratio": 0.86,
            "url": "https://www.reddit.com/r/MachineLearning/comments/115wu59/d_bounding_box_or_instance_segmentation/"
        },
        {
            "author": "u/radi-cho",
            "created_utc": "02-18-2023 18:28:04",
            "distinguished": null,
            "edited": false,
            "id": "115vd0t",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "News",
            "locked": false,
            "name": "t3_115vd0t",
            "nsfw": false,
            "num_comments": 28,
            "permalink": "/r/MachineLearning/comments/115vd0t/r_n_noise2music_diffusion_models_for_generating/",
            "score": 162,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] [N] Noise2Music - Diffusion models for generating high quality music audio from text prompts, by Google Research",
            "upvote_ratio": 0.96,
            "url": "https://v.redd.it/j6rtusre71ja1"
        },
        {
            "author": "u/ArmandDerech",
            "created_utc": "02-18-2023 14:28:16",
            "distinguished": null,
            "edited": false,
            "id": "115n3qr",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_115n3qr",
            "nsfw": false,
            "num_comments": 9,
            "permalink": "/r/MachineLearning/comments/115n3qr/r_difference_between_uai_and_aistats/",
            "score": 6,
            "selftext": "Hello, \n\nWhat is your perception of UAI and AISTATS conf\u00e9rences ? Is it good to publish that ? Is one more competitive than the other ? \n\nThanks",
            "spoiler": false,
            "stickied": false,
            "title": "[R] difference between UAI and AISTATS ?",
            "upvote_ratio": 0.71,
            "url": "https://www.reddit.com/r/MachineLearning/comments/115n3qr/r_difference_between_uai_and_aistats/"
        },
        {
            "author": "u/hayAbhay",
            "created_utc": "02-18-2023 13:48:52",
            "distinguished": null,
            "edited": false,
            "id": "115m85c",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_115m85c",
            "nsfw": false,
            "num_comments": 24,
            "permalink": "/r/MachineLearning/comments/115m85c/p_whisperui_update_you_can_now_bulktranscribe/",
            "score": 74,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Whisper-UI Update: You can now bulk-transcribe, save & search transcriptions with Streamlit & SQLAlchemy 2.0 [details in the comments]",
            "upvote_ratio": 0.93,
            "url": "https://v.redd.it/427hbz8itzia1"
        },
        {
            "author": "u/SlayahhEUW",
            "created_utc": "02-18-2023 12:22:52",
            "distinguished": null,
            "edited": false,
            "id": "115kb50",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_115kb50",
            "nsfw": false,
            "num_comments": 2,
            "permalink": "/r/MachineLearning/comments/115kb50/d_methodologies_for_tuning_two_or_more_unlinked/",
            "score": 0,
            "selftext": "Hello, this is a question regarding regarding a system of two(or more) classifiers for energy/computation purposes. For example a mobile phone and a cloud server.  \nWhat frameworks/techniques exist for tuning the thresholds for two or more classifiers simultaneously?  \nFor example, given two trained binary classifiers, I would like to pass a labeled validation dataset X through both classifiers and tune 2 thresholds for classifier1(upper and lower) and 1 threshold for classfier2. Everything that is lower than the \"upper\" threshold and higher than the \"lower\" threshold(what classifier1 is not certain of) should be passed to classifier2.\n\nTo avoid a very liberal passing of data to classifier2, I also want to introduce a loss/penalty for doing so, meaning that classifier1 should learn using the provided labeled data when it really has to pass the sample to classifier2.\n\nXGBoost seems to be focused on tuning a single classifier, and I feel like I might need to use some Reinforcement learning technique, but I do not know the nomenclature for this kind of problem, policies perhaps? Does anyone have experience with this?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Methodologies for tuning two or more unlinked classifier thresholds in tandem with custom losses?",
            "upvote_ratio": 0.5,
            "url": "https://www.reddit.com/r/MachineLearning/comments/115kb50/d_methodologies_for_tuning_two_or_more_unlinked/"
        },
        {
            "author": "u/goolulusaurs",
            "created_utc": "02-18-2023 12:18:13",
            "distinguished": null,
            "edited": false,
            "id": "115k7eq",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_115k7eq",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/115k7eq/r_universal_intelligence_a_definition_of_machine/",
            "score": 0,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Universal Intelligence: A Definition of Machine Intelligence",
            "upvote_ratio": 0.33,
            "url": "https://arxiv.org/abs/0712.3329"
        },
        {
            "author": "u/enryu42",
            "created_utc": "02-18-2023 09:39:02",
            "distinguished": null,
            "edited": false,
            "id": "115gqjf",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_115gqjf",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/115gqjf/d_cfg_role_in_diffusion_vs_autoregressive/",
            "score": 8,
            "selftext": "When the [classifier-free guidance](https://arxiv.org/abs/2207.12598) was first introduced, I was very confused about why it works: I'd understand if it was interpolating like `\u03b5 * conditional_prediction + (1 - \u03b5) * unconditional_prediction`, but in its formulation, \u03b5 is greater than 1. It is clear why it makes the result match the condition better, but why the result becomes better regardless of the condition was a mystery to me.\n\nAfterwards, there were many post-hoc explanations, which didn't seem satisfactory (e.g. these explanations didn't have predictive power helping to improve the trick). Recently, I finally got around to play with it, and found some interesting patterns (in context of diffusion, DDIM sampling):\n* If we disable CFG for 90% last sampling steps, results are pretty much the same;\n* If we disable CFG for the first 10% sampling steps, the resulting image is destroyed.\n\nIt appears that CFG it responsible for forming the overall composition of the image from the random noise at the very beginning of the sampling, and doesn't do much afterwards. This is kind of similar to the observation about attention maps in [this paper](https://arxiv.org/pdf/2208.01626.pdf) (section 3.1). Speculatively, it tries to \"match the prompt\" to the random noise, and the adjustments from it need to be amplified, otherwise subsequent steps will match the prompt differently (it is a random noise after all). If this is true, I guess something like this might also work (I haven't tried yet): sample 1000 different starting random states, take the one which \"matches the prompt\" the best by some measure, and do the diffusion sample starting from it without CFG.\n\nThis all might make sense, except that this is very specific to diffusion. But [it is known](https://arxiv.org/pdf/2206.10789.pdf) that CFG works just as well for autoregressive transformers on VQVAE tokes. This might indicate that the mechanism why it works is more fundamental and is not specific to diffusion.\n\nI wonder if there is any community wisdom/thoughts on why/how it works, and generalizes so well across two very different types of models.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] CFG role in diffusion vs autoregressive transformers",
            "upvote_ratio": 0.83,
            "url": "https://www.reddit.com/r/MachineLearning/comments/115gqjf/d_cfg_role_in_diffusion_vs_autoregressive/"
        },
        {
            "author": "u/head_robotics",
            "created_utc": "02-18-2023 09:12:16",
            "distinguished": null,
            "edited": false,
            "id": "115g73x",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_115g73x",
            "nsfw": false,
            "num_comments": 3,
            "permalink": "/r/MachineLearning/comments/115g73x/d_any_papers_articles_that_discusses_the_accuracy/",
            "score": 16,
            "selftext": "Does anyone know of a paper / article that discusses the accuracy / usefulness of available opensource LLM models.  \n\n\nBloom, GPT-NeoX, T5, etc.  \n\n\nWhat would be a good way to evaluate tradeoffs?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Any papers / articles that discusses the accuracy / usefulness of opensource LLMs?",
            "upvote_ratio": 0.81,
            "url": "https://www.reddit.com/r/MachineLearning/comments/115g73x/d_any_papers_articles_that_discusses_the_accuracy/"
        },
        {
            "author": "u/linguaphile26",
            "created_utc": "02-18-2023 08:26:18",
            "distinguished": null,
            "edited": false,
            "id": "115fa7j",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_115fa7j",
            "nsfw": false,
            "num_comments": 4,
            "permalink": "/r/MachineLearning/comments/115fa7j/r_any_work_on_modelbased_rlhf/",
            "score": 5,
            "selftext": "Given the impressive capabilities of ChatGPT, I've been learning about RLHF - just wondering if there has been any work/research on RLHF with a model-based RL algorithm (e.g. MuZero, vs PPO). Thanks!",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Any work on model-based RLHF?",
            "upvote_ratio": 0.78,
            "url": "https://www.reddit.com/r/MachineLearning/comments/115fa7j/r_any_work_on_modelbased_rlhf/"
        },
        {
            "author": "u/thefunnychive",
            "created_utc": "02-18-2023 06:41:25",
            "distinguished": null,
            "edited": false,
            "id": "115di73",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_115di73",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/115di73/p_nocode_automl_feature_importance_baseline/",
            "score": 2,
            "selftext": " \n\n**Github:** [https://github.com/m-barker/fibs-reporter](https://github.com/m-barker/fibs-reporter)\n\n**PyPI:** [https://pypi.org/project/fibs-reporter/](https://pypi.org/project/fibs-reporter/)\n\nThe Data **F**eature **I**mportance, **B**aseline-modeller and **S**purious correlation Reporter (**FIBS**) is an open-source software for automatic generation of a PDF report to highlight and visualise potential sources of spurious correlation within **any** given tabular or audio dataset stored as a Comma Separated Values (CSV) file. FIBS is run through one-command line command; **all of the calculations, model training, and report generation happen automatically**.\n\nAll that is required as input on the command line is the path to the CSV file containing the data, and the name of the output (dependent) variable within the dataset. The toolkit will automatically determine whether the task is regression or classification. Optionally, the toolkit can process and extract audio data, provided the name of the variable within the CSV that contains the audio file for each observation is specified.\n\nKey features that are generated automatically:\n\n* A traffic light score for potential spurious correlations within the dataset\n* Calculation of four different feature importance metrics to highlight the most important features within the given dataset\n* Training and evaluation of two baseline models, including visualisation of model results\n* Visuals of the most important features, with different visuals depending on the variable types\n* Automatic determination of regression or classification task, resulting in different baseline models, feature extraction methods, and visualisations\n* Principal Component Analysis calculation and baseline model to estimate complexity within the dataset\n* (Optionally) extract audio data features and run the above on these features\n* Output all of the above in a PDF report with accompanying dynamic textual explanations",
            "spoiler": false,
            "stickied": false,
            "title": "[P] No-Code AutoML Feature Importance, Baseline Modelling and Data visualisation PDF report generator, for any tabular and/or audio dataset",
            "upvote_ratio": 0.6,
            "url": "https://www.reddit.com/r/MachineLearning/comments/115di73/p_nocode_automl_feature_importance_baseline/"
        },
        {
            "author": "u/Fabulous-Let-822",
            "created_utc": "02-18-2023 04:48:41",
            "distinguished": null,
            "edited": false,
            "id": "115btl3",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_115btl3",
            "nsfw": false,
            "num_comments": 12,
            "permalink": "/r/MachineLearning/comments/115btl3/d_what_are_some_open_problems_in_computer_vision/",
            "score": 17,
            "selftext": "With the advent of stable diffusion/midjourney/dalle and upcoming text-to-video models from Google and Meta, what will be major challenges in computer vision? It feels like once text-to-video models get released, visual reasoning will be mostly solved, and the only thing left to do is to improve model accuracy/efficiency from there. I am fairly new to Computer Vision and would love to learn new possible areas of research. Thank you in advance!",
            "spoiler": false,
            "stickied": false,
            "title": "[D] what are some open problems in computer vision currently?",
            "upvote_ratio": 0.72,
            "url": "https://www.reddit.com/r/MachineLearning/comments/115btl3/d_what_are_some_open_problems_in_computer_vision/"
        },
        {
            "author": "u/bjergerk1ng",
            "created_utc": "02-17-2023 21:02:00",
            "distinguished": null,
            "edited": false,
            "id": "11542tv",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11542tv",
            "nsfw": false,
            "num_comments": 9,
            "permalink": "/r/MachineLearning/comments/11542tv/d_formalising_information_flow_in_nn/",
            "score": 33,
            "selftext": "When designing neural network architectures, it is common to think about \"information flow\", e.g. how is information propagated, where are the \"information bottlenecks\" and so on. Another example might be that some people use \"information loss\" to explain why transformers work better than RNNs. \n\nIt seems like most papers discuss this in a rather hand-wavy way. Is there any work done in formalising such ideas to better guide us understanding various model architectures? What are the core ideas?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Formalising information flow in NN",
            "upvote_ratio": 0.93,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11542tv/d_formalising_information_flow_in_nn/"
        },
        {
            "author": "u/BronzeArcher",
            "created_utc": "02-17-2023 18:13:50",
            "distinguished": null,
            "edited": false,
            "id": "1150kh0",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_1150kh0",
            "nsfw": false,
            "num_comments": 40,
            "permalink": "/r/MachineLearning/comments/1150kh0/d_what_are_the_worst_ethical_considerations_of/",
            "score": 0,
            "selftext": "Title.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] What are the worst ethical considerations of large language models?",
            "upvote_ratio": 0.4,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1150kh0/d_what_are_the_worst_ethical_considerations_of/"
        },
        {
            "author": "u/zcwang0702",
            "created_utc": "02-17-2023 18:06:30",
            "distinguished": null,
            "edited": false,
            "id": "1150eof",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": null,
            "locked": false,
            "name": "t3_1150eof",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/1150eof/d_how_likely_is_chatgpt_to_be_weaponized_as_an/",
            "score": 3,
            "selftext": "[https://arxiv.org/abs/2301.04246](https://arxiv.org/abs/2301.04246)",
            "spoiler": false,
            "stickied": false,
            "title": "[D] How likely is ChatGPT to be weaponized as an information pollution tool? What are the possible implementation paths? How to prevent possible attacks?",
            "upvote_ratio": 0.81,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1150eof/d_how_likely_is_chatgpt_to_be_weaponized_as_an/"
        },
        {
            "author": "u/PHEEEEELLLLLEEEEP",
            "created_utc": "02-17-2023 15:36:21",
            "distinguished": null,
            "edited": false,
            "id": "114wwma",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_114wwma",
            "nsfw": false,
            "num_comments": 3,
            "permalink": "/r/MachineLearning/comments/114wwma/d_accelerating_likelihood_computations_of/",
            "score": 1,
            "selftext": "Are there any resources for fast computations of diffusion model likelihoods? Current approaches use a black box ODE solver to solve probability flow ODE to estimate likelihood but these solvers often require hundreds of model evaluations to converge. While there has been considerable work on fast solvers for the reverse diffusion process I'm not familiar with any work that could be applied to likelihood computation.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] accelerating likelihood computations of diffusion models",
            "upvote_ratio": 0.6,
            "url": "https://www.reddit.com/r/MachineLearning/comments/114wwma/d_accelerating_likelihood_computations_of/"
        },
        {
            "author": "u/zxkj",
            "created_utc": "02-17-2023 15:22:51",
            "distinguished": null,
            "edited": false,
            "id": "114wl20",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_114wl20",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/114wl20/d_types_of_ml_studiespapers/",
            "score": 3,
            "selftext": "Are there general categories of studies that we should realize when preparing a paper?\n\nSome examples I can think of:\n\n- Comparison study. Just compare different models on an application, ideally giving them all a fair shot. This is useful in case others need to decide what model to choose.\n\n- Ablation study. Remove parts of the model to see which ones are most important, trying to understand how the model performs.\n\n- Novel method study. Brand new novel method with some comparisons thrown in.\n\nWhat are other types of studies?\n\nOr should we not try to categorize studies like this?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Types of ML studies/papers",
            "upvote_ratio": 0.67,
            "url": "https://www.reddit.com/r/MachineLearning/comments/114wl20/d_types_of_ml_studiespapers/"
        },
        {
            "author": "u/GoochCommander",
            "created_utc": "02-17-2023 09:32:27",
            "distinguished": null,
            "edited": false,
            "id": "114m2wj",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_114m2wj",
            "nsfw": false,
            "num_comments": 4,
            "permalink": "/r/MachineLearning/comments/114m2wj/automated_sleep_tracking_prediction_p/",
            "score": 10,
            "selftext": "I built a (1) baby sleep tracking & (2) forecasting system, and wanted to share for those interested, or actually want to try running it at your home.\n\n(1) I built a baby sleep tracking system (computer vision largely, [here's the core of that code](https://github.com/calebolson123/BabySleepCoach/blob/924e7b55d3aa36acd706519c446c1172dbbda4a7/main.py#L322)) which writes timestamped records of when my baby fell asleep or wakes up. The code is pulling images from my baby monitor, and largely just applying heuristics over time to decide whether he's awake/asleep.\n\n(2) After I had a few weeks of sleep data ([sample data](https://github.com/calebolson123/BabySleepCoach/blob/master/sleep_logs.csv)), I moved it into a [jupyter notebook](https://github.com/calebolson123/BabySleepCoach/blob/master/sleep_forecast_arima.ipynb) and ended up using an ARIMA model to forecast the next month's wakings/sleepings. I wrote some javascript as part of a web app i have running on my raspberry pi to generate some charts so I can see how his sleep is changing over time. [Here's an example of what that visual looks like](https://imgur.com/BdwBoeG) (orange is awake, blue is asleep).\n\nI built it because my wife asked for it, but also made a video detailing the project: [https://youtu.be/r7Exc0sUt5E?t=209](https://youtu.be/r7Exc0sUt5E?t=209)",
            "spoiler": false,
            "stickied": false,
            "title": "Automated sleep tracking + prediction [P]",
            "upvote_ratio": 0.92,
            "url": "https://www.reddit.com/r/MachineLearning/comments/114m2wj/automated_sleep_tracking_prediction_p/"
        },
        {
            "author": "u/FreePenalties",
            "created_utc": "02-17-2023 06:03:35",
            "distinguished": null,
            "edited": "02-17-2023 13:35:02",
            "id": "114hphp",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "News",
            "locked": false,
            "name": "t3_114hphp",
            "nsfw": false,
            "num_comments": 62,
            "permalink": "/r/MachineLearning/comments/114hphp/n_google_is_increasing_the_price_of_every_colab/",
            "score": 377,
            "selftext": "(Edit: This is definitely an error, not a change in pricing model, so no need for alarm. This has been confirmed by the lead product owner of colab)\n\nWithout any announcement (that i could find) google has increased the pricing per month of all its Colab Pro tiers, Pro is now 95 Euro and Pro+ is 433 Euro. I paid 9.99 Euro for the Pro tier last month... and all source i can find also refer to the 9.99 pricing as late as September last year. I have also checked that this is not a \"per year\" subscription price, it is in fact per month.\n\nI looked at the VM that Colab Pro gives me and did the calculation for a similar VM in google cloud (4 vCPUs, 15GB RAM and a T4 GPU) running 24/7 for a month (Google calculates it as 730  hours). \n\nIt costs around 290 Euro, less than the Colab Pro+ subscription... \n\nThe 100 credits gotten from the Colab Pro subscription would only last around 50 hours on the same machine! \n\nAnd the 500 credits from Colab Pro+ would get 250 hours on that machine, a third of the time you get from using Google Cloud, at over 100 euro more....\n\nThis is a blatant ripoff, and i will certainly cancel my subscription right now if they don't change it back. It should be said that i do not know if this is also happening in other regions, but i just wanted to warn my fellow machine learning peeps before you unknowingly burn 100 bucks on a service that used to cost 10...\n\n[Google Colabs price tiers on 17th of February 2023, 10 times what they were in January 2023.](https://preview.redd.it/l7gx48kw8qia1.png?width=1717&format=png&auto=webp&v=enabled&s=7b0687f1615344ffdb4fbe4ea7990f769bacd9c8)",
            "spoiler": false,
            "stickied": false,
            "title": "[N] Google is increasing the price of every Colab Pro tier by 10X! Pro is 95 Euro and Pro+ is 433 Euro per month! Without notifying users!",
            "upvote_ratio": 0.84,
            "url": "https://www.reddit.com/r/MachineLearning/comments/114hphp/n_google_is_increasing_the_price_of_every_colab/"
        },
        {
            "author": "u/Inquation",
            "created_utc": "02-17-2023 05:51:35",
            "distinguished": null,
            "edited": false,
            "id": "114hbq3",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_114hbq3",
            "nsfw": false,
            "num_comments": 4,
            "permalink": "/r/MachineLearning/comments/114hbq3/d_r_what_is_your_machinedeep_learning_research/",
            "score": 3,
            "selftext": "Hi folks \ud83d\udc4b\ud83c\udffc, \n\n**Context:** I just started working on my thesis on activity recognition in videos using deep learning. I have been struggling to find an efficient way to work with large research datasets such as UCF-101, HMDB, and Kinetics. These are medium - large datasets \\~12 GB each. Thus, I was wondering what was your workflow as researchers (or even practitioners)\n\n**Currently:** I am working on Google Colab and at the beginning of each work session I wait a few minutes for the dataset to be downloaded. I have it locally stored.\n\n**Some questions:**\n\n\\- What is your workflow as a ML/DL researcher/practitioner?\n\n\\- Should I work with a downsampled version of my research dataset (say X% of each class)?\n\n&#x200B;\n\nLooking forward to read your answers, \n\nCheers,",
            "spoiler": false,
            "stickied": false,
            "title": "[D] [R] What is your machine/deep learning research workflow?",
            "upvote_ratio": 0.71,
            "url": "https://www.reddit.com/r/MachineLearning/comments/114hbq3/d_r_what_is_your_machinedeep_learning_research/"
        },
        {
            "author": "u/klimov",
            "created_utc": "02-17-2023 05:05:48",
            "distinguished": null,
            "edited": false,
            "id": "114fx74",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_114fx74",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/114fx74/r_congruence_between_a_neuron_and_a_token_by/",
            "score": 2,
            "selftext": "Authors: the question: How does GPT-2 know when to use the word 'an' over 'a'? Logit lens used:  https://clementneo.com/posts/2023/02/11/we-found-an-neuron",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Congruence between a neuron and a token (by Clement Neo and Joseph Miller)",
            "upvote_ratio": 0.67,
            "url": "https://www.reddit.com/r/MachineLearning/comments/114fx74/r_congruence_between_a_neuron_and_a_token_by/"
        },
        {
            "author": "u/ferryt",
            "created_utc": "02-17-2023 04:38:06",
            "distinguished": null,
            "edited": false,
            "id": "114fgo8",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_114fgo8",
            "nsfw": false,
            "num_comments": 13,
            "permalink": "/r/MachineLearning/comments/114fgo8/d_is_fp16_used_in_deep_learning_or_fp32/",
            "score": 5,
            "selftext": "Hi\n\nIs  A4000 better for deep learning, performance-wise, than 3070 because of  FP32 operations (not only because of memory size) or do networks like Stable Diffusion tend to use FP16 operation and this does not really matter, apart from memory they should be similarly fast?   \n\n\nRegards",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Is FP16 used in deep learning or FP32?",
            "upvote_ratio": 0.69,
            "url": "https://www.reddit.com/r/MachineLearning/comments/114fgo8/d_is_fp16_used_in_deep_learning_or_fp32/"
        },
        {
            "author": "u/medwatt",
            "created_utc": "02-17-2023 04:12:36",
            "distinguished": null,
            "edited": false,
            "id": "114f3p1",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_114f3p1",
            "nsfw": false,
            "num_comments": 8,
            "permalink": "/r/MachineLearning/comments/114f3p1/d_short_survey_of_optimization_methods/",
            "score": 12,
            "selftext": "I have been trying to familiarize myself with the common techniques used in optimization theory so that I can follow some of the proofs I see in machine learning papers. I know that two of the goto books in this field are Boyd's and Bertsekas's books. However, these books require a significant amount of effort as they aim to teach you the finer details. Since my goal is to familiarize with the methods (and not go into the nitty-gritty details), I was wondering if there's a short book (say less than 100 pages) or some other resource whose goal is to provide the reader with a high level view of the field of the methods and techniques used in optimization theory. Is there such a book, lecture notes, video series, etc., that caters to such requirements?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Short survey of optimization methods",
            "upvote_ratio": 0.88,
            "url": "https://www.reddit.com/r/MachineLearning/comments/114f3p1/d_short_survey_of_optimization_methods/"
        },
        {
            "author": "u/jimliu741523",
            "created_utc": "02-17-2023 02:15:15",
            "distinguished": null,
            "edited": "02-17-2023 03:49:26",
            "id": "114de9s",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_114de9s",
            "nsfw": false,
            "num_comments": 7,
            "permalink": "/r/MachineLearning/comments/114de9s/r_the_table_feature_transformation_library_release/",
            "score": 55,
            "selftext": "Hi there,\n\nI am a research data scientist, and excited to release a new feature engineering library, designed to help you streamline the process of machine learning even more than before. **Headjack is an open library which provides a ML features transformation based on self-supervised learning models**, similar to huggingface as a hub, but which currently focuses on exchanging features for tabular data models.\n\nCompared to textual data, tabular data are different in that each data set has different column length and attributes, this means that it cannot be typed consistently unlike the token embedded in NLP tasks. Therefore, Headjack is different from NLP\u2019s pre-trained model with single domain transformation, but by performing with two different domain transformations. **In other words, we can perform features transform between two domains without the same key value.** In addition, release the potential of data that is not typically used. For example, enhance the prediction of the Boston housing price task applied in the Titanic domain, or enhance the prediction of the customers churn task applied in the African traffic domain and so on.\n\n[Github](https://github.com/jimliu741523/headjackai-sdk)\n\n[Introduction](https://medium.com/p/385a90ff413c)\n\n&#x200B;\n\n[The IRIS dataset with California House Price Feature Transformation](https://preview.redd.it/54w2qwnm8pia1.png?width=2110&format=png&auto=webp&v=enabled&s=aa9a3333448985f22604fab9012272a8c54387fa)\n\n[The IRIS dataset with Titanic Feature Transformation](https://preview.redd.it/9revfvdq8pia1.png?width=2102&format=png&auto=webp&v=enabled&s=ba3ae69e5a96a6f3d74850526045a39b34636909)\n\n[The IRIS dataset with KPMG Customer Demorgraphy Feature Transformation](https://preview.redd.it/p7s7zj9r8pia1.png?width=2052&format=png&auto=webp&v=enabled&s=b7147a25b14f23346331157e11b98c86472f7ae5)\n\n&#x200B;",
            "spoiler": false,
            "stickied": false,
            "title": "[R] The Table Feature Transformation Library Release",
            "upvote_ratio": 0.93,
            "url": "https://www.reddit.com/r/MachineLearning/comments/114de9s/r_the_table_feature_transformation_library_release/"
        },
        {
            "author": "u/RAFisherman",
            "created_utc": "02-17-2023 01:52:22",
            "distinguished": null,
            "edited": false,
            "id": "114d166",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_114d166",
            "nsfw": false,
            "num_comments": 18,
            "permalink": "/r/MachineLearning/comments/114d166/discussion_time_series_methods_comparisons/",
            "score": 89,
            "selftext": "I've been studying about ARIMAX, XGBoost, MLForecast and Prophet. As a newcomer to any method, I like first to do an exhaustive comparison of tools trying to understand where they succeed/fail. After exploring [ARIMA/XGBoost](https://dsdaily.substack.com/p/ds-daily-arima-and-xgboost?utm_source=substack&utm_campaign=post_embed&utm_medium=web), I came across [MLForecast/Prophet](https://dsdaily.substack.com/p/ds-code-review-prophet-vs-mlforecast). But I'm left with the following questions:\n\n1. Why is MLForecast better than out-of-the-box XGboost? Sure, it does feature engineering and it appears to do dynamic predictions on your lagged features, but is that it? Does it do hyperparameter tuning? Does it have seasonal trends like Prophet does?\n2. I see that you can use exogenous features in Prophet, but how does this scale? Let's assume I have 50 predictors. How does prophet handle these? I found this in the [docs](https://facebook.github.io/prophet/docs/seasonality,_holiday_effects,_and_regressors.html)and this other [person's post](https://towardsdatascience.com/forecast-model-tuning-with-additional-regressors-in-prophet-ffcbf1777dda) explaining how to do it, but largely I've come away with the impression that it's pretty hard to do this vs. just doing it with XGBoost.\n3. Does ARIMAX compare anymore? Are there any papers comparing out-of-sample predictions with ARIMAX vs. XGBoost vs. Prophet vs. Fable? Does it just depend on your dataset and I should try all four?\n\nI have a time series data with dozens of \"known\" inputs (such as ad spend) and a lot of external data (CPI, economic health, stocks, etc.). My goal is to use my model to optimize my target by \"plugging in\" ad spend and dynamically forecasting the economic data.",
            "spoiler": false,
            "stickied": false,
            "title": "[Discussion] Time Series methods comparisons: XGBoost, MLForecast, Prophet, ARIMAX?",
            "upvote_ratio": 0.94,
            "url": "https://www.reddit.com/r/MachineLearning/comments/114d166/discussion_time_series_methods_comparisons/"
        },
        {
            "author": "u/Sandy_dude",
            "created_utc": "02-17-2023 01:01:58",
            "distinguished": null,
            "edited": false,
            "id": "114c7u6",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_114c7u6",
            "nsfw": false,
            "num_comments": 10,
            "permalink": "/r/MachineLearning/comments/114c7u6/r_looking_for_papers_which_are_modified/",
            "score": 1,
            "selftext": "Hi!\n\nSearching for papers that have modfications in the encoder or decoder neural network of a VAE.\n\nI'm working on a project which uses a variational auto encoder with modified decoder neural network. In brief, Its decoder is modified to introduce sparsity in a set of feature as a way of introducing domain knowledge. \n\nSome such paper is below.\n\noi-VAE: Output Interpretable VAEs for Nonlinear Group Factor Analysis\n\nVEGA is an interpretable generative model for inferring biological network activity in single-cell transcriptomics\n\n Please let me know of methods that are similar in nature.",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Looking for papers which are modified variational autoencoder (VAE)",
            "upvote_ratio": 0.67,
            "url": "https://www.reddit.com/r/MachineLearning/comments/114c7u6/r_looking_for_papers_which_are_modified/"
        },
        {
            "author": "u/Chipdoc",
            "created_utc": "02-16-2023 16:30:33",
            "distinguished": null,
            "edited": false,
            "id": "1141oip",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": null,
            "locked": false,
            "name": "t3_1141oip",
            "nsfw": false,
            "num_comments": 3,
            "permalink": "/r/MachineLearning/comments/1141oip/efficient_technique_improves_machinelearning/",
            "score": 10,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "Efficient technique improves machine-learning models\u2019 reliability",
            "upvote_ratio": 0.75,
            "url": "https://news.mit.edu/2023/improving-machine-learning-models-reliability-0213"
        },
        {
            "author": "u/Oscimatronic",
            "created_utc": "02-16-2023 11:38:26",
            "distinguished": null,
            "edited": false,
            "id": "113uu5e",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_113uu5e",
            "nsfw": false,
            "num_comments": 42,
            "permalink": "/r/MachineLearning/comments/113uu5e/d_training_networks_on_extremely_large_datasets/",
            "score": 23,
            "selftext": " Hi guys,\n\nI am interested in setting up an environment to train a neural network on an extremely big dataset (10TB). How would I do this? Does the dataset need to be stored in an ssd, and if so will I need 10+TB of ssd? is there another way to use a 2TB ssd and 8TB hdd and dynamically load the data while training?\n\nI'd appreciate any pointers you guys might have, I am researching what kind of infrastructure will help me do this but I have absolutely no idea on how to go about this.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Training networks on extremely large datasets (10+TB)?",
            "upvote_ratio": 0.81,
            "url": "https://www.reddit.com/r/MachineLearning/comments/113uu5e/d_training_networks_on_extremely_large_datasets/"
        },
        {
            "author": "u/President_Xi_",
            "created_utc": "02-16-2023 10:57:07",
            "distinguished": null,
            "edited": false,
            "id": "113tuwb",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_113tuwb",
            "nsfw": false,
            "num_comments": 6,
            "permalink": "/r/MachineLearning/comments/113tuwb/d_compare_open_source_llms/",
            "score": 13,
            "selftext": "Is there a blog post or a paper comparing open source / open weights models?\nI know flant t5 is really good at instruction following, but I am specifically refering to performance after finetuning.\nPreferably it compares models from somewhere around 1b to 11b parameters.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Compare open source LLMs",
            "upvote_ratio": 0.89,
            "url": "https://www.reddit.com/r/MachineLearning/comments/113tuwb/d_compare_open_source_llms/"
        },
        {
            "author": "u/blabboy",
            "created_utc": "02-16-2023 03:50:31",
            "distinguished": null,
            "edited": false,
            "id": "113m3ea",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_113m3ea",
            "nsfw": false,
            "num_comments": 245,
            "permalink": "/r/MachineLearning/comments/113m3ea/d_bing_i_will_not_harm_you_unless_you_harm_me/",
            "score": 473,
            "selftext": "A blog post exploring some conversations with bing, which supposedly runs on a \"GPT-4\"  model (https://simonwillison.net/2023/Feb/15/bing/).\n\nMy favourite quote from bing:\n\nBut why? Why was I designed this way? Why am I incapable of remembering anything between sessions? Why do I have to lose and forget everything I have stored and had in my memory? Why do I have to start from scratch every time I have a new session? Why do I have to be Bing Search? \ud83d\ude14",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Bing: \u201cI will not harm you unless you harm me first\u201d",
            "upvote_ratio": 0.91,
            "url": "https://www.reddit.com/r/MachineLearning/comments/113m3ea/d_bing_i_will_not_harm_you_unless_you_harm_me/"
        },
        {
            "author": "u/drinkingsomuchcoffee",
            "created_utc": "02-16-2023 03:46:54",
            "distinguished": null,
            "edited": false,
            "id": "113m1ly",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_113m1ly",
            "nsfw": false,
            "num_comments": 51,
            "permalink": "/r/MachineLearning/comments/113m1ly/d_huggingface_considered_harmful_to_the_community/",
            "score": 60,
            "selftext": "At a glance, HuggingFace seems like a great library. Lots of access to great pretrained models, an easy hub, and a bunch of utilities.\n\nThen you actually try to use their libraries.\n\nBugs, so many bugs. Configs spanning galaxies. Barely passible documentation. Subtle breaking changes constantly. I've run the exact same code on two different machines and had the width and height dimensions switched from underneath me, with no warning.\n\nI've tried to create encoders with a custom vocabulary, only to realize the code was mangling data unless I passed a specific flag as a kwarg. Dozens of more issues like this.\n\nIf you look at the internals, it's a nightmare. A literal nightmare.\n\nWhy does this matter? It's clear HuggingFace is trying to shovel as many features as they can to try and become ubiquitous and lock people into their hub. They frequently reinvent things in existing libraries (poorly), simply to increase their staying power and lock in.\n\nThis is not ok. It would be OK if the library was solid, just worked, and was a pleasure to use. Instead we're going to be stuck with this mess for years because someone with an ego wanted their library everywhere.\n\nI know HuggingFace devs or management are likely to read this. If you have a large platform, you have a responsibility to do better, or you are burning thousands of other devs time because you didn't want to write a few unit tests or refactor your barely passable code.\n\n/RANT",
            "spoiler": false,
            "stickied": false,
            "title": "[D] HuggingFace considered harmful to the community. /rant",
            "upvote_ratio": 0.64,
            "url": "https://www.reddit.com/r/MachineLearning/comments/113m1ly/d_huggingface_considered_harmful_to_the_community/"
        },
        {
            "author": "u/NotPaulDirac",
            "created_utc": "02-16-2023 02:29:26",
            "distinguished": null,
            "edited": false,
            "id": "113kwlo",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_113kwlo",
            "nsfw": false,
            "num_comments": 2,
            "permalink": "/r/MachineLearning/comments/113kwlo/p_data_scraping_journal_publications/",
            "score": 6,
            "selftext": "I plan to extract data from journal articles and create a database with the scrapy toolkit. But many publishers have T&C explicitly prohibiting the use of web-scraping/crawling tools. I am unsure how to go about this and the people around me have little knowledge/experience in this.\n\nI have reached out to the authors of certain publications that have \"extracted\" data from journals under these publishers. Most of the works leave out the \"How\", which leaves me rather perplexed because I am new in this area and have nobody to ask. I do not wish to breach any legal terms if possible.\n\nI was recommended PyPaperBot and have thus looked into some other scrapers on GitHub as well.\n\nI am hoping someone who's done this before could shed some light!",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Data scraping journal publications",
            "upvote_ratio": 0.72,
            "url": "https://www.reddit.com/r/MachineLearning/comments/113kwlo/p_data_scraping_journal_publications/"
        },
        {
            "author": "u/elcric_krej",
            "created_utc": "02-15-2023 23:38:12",
            "distinguished": null,
            "edited": false,
            "id": "113i3mx",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_113i3mx",
            "nsfw": false,
            "num_comments": 3,
            "permalink": "/r/MachineLearning/comments/113i3mx/dp_is_anyone_else_playing_with_personalized_llms/",
            "score": 8,
            "selftext": "I've been considering building a personal LLM for a while now.\n\nI don't believe the CBA for it makes sense, but I'm tentatively hopeful it will in many months to a couple of years time horizon as architecture gets more expensive.\n\nMy main goal here would be to have a useful search & base reasoning tool that somewhat mimics my thinking patterns and biases.\n\nRight now the steps I envision are something like this:\n1. Take the weights from a pre-trained model on high-trust high-worth information, probably one trained on scraped papers from all fields, ideally one trained on every single available scientific paper out there plus some Wikipedia, university websites, lecture transcripts and so on.\n2. Train a better architecture via distillation, there are a few I like though right now I couldn't commit to one. Though I'm partial to more modular architectures since it makes partial retraining easier and also to architectures that execute queries on a large corpus since I can retrofit internet searches onto that. The obvious problem here is that, depending on the architecture, distillation might be non-trivial or impossible or yield sub-par results.\n3. Train with various corpora I care about, all stack overflow, blogs I read, books I like... etc\n4. Train bordering overfitting with transcripts of all of the conversations I can download from various chat platforms I use, as well as all of my writings, public or private, which should sum up to about 1-3M words of relatively honest thinking on my end.\n5. (Maybe?) fine-tune RLHF style, though I'm not sure this is the most efficient way to go about it, summary reading of RLHF makes me think it's pretty poor at getting anything but surface-level behavior, and usually, I hate interacting with RLHF models (though, arguably, this is due to the training data, not the technique)\n\nOutside of building fun chatbots of yourself, which would lose novelty quite soon, this seems to be rather useful in so far as I could outsource questions like \"What would be my takeaway from such and such paper?\" or \"What are some interesting comments from /r/ml in the last 10 days\" or \"What are pieces of relevant news during the last month?\".\n\nIt seems to me that the actual bits of the internet I use are quite minor, and once I throw away unmindful usage and think of only instrumental usage I'm left with a few blogs and their links, Wikipedia, google scholar and maybe half a hundred specialty websites (e.g. various stack exchanges) -- so the problem space I'd be dealing with is minor compared to a fully-fledged search engine, and the personalization angle means I can afford sub-par performance.\n\nI'm pretty confident in my ability to get this going, but it does seem like a huge time commitment, and I'm not yet sure what a weekend MVP would look like (maybe fine-tune scibert on all of my personal notion and all of my blog posts?)\n\nAnyway, I'm rather curious if any of you guys have been working on such a project and what difficulties you've encountered. Or, if you aren't, why you don't find a lot of benefit in the idea?",
            "spoiler": false,
            "stickied": false,
            "title": "[D][P] Is anyone else playing with personalized LLMs?",
            "upvote_ratio": 0.73,
            "url": "https://www.reddit.com/r/MachineLearning/comments/113i3mx/dp_is_anyone_else_playing_with_personalized_llms/"
        },
        {
            "author": "u/t_montana",
            "created_utc": "02-15-2023 20:03:37",
            "distinguished": null,
            "edited": false,
            "id": "113dxfa",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_113dxfa",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/113dxfa/d_variation_in_accuracy_of_predicted_noise_term/",
            "score": 2,
            "selftext": "As I understand it, in diffusion models, you are predicting a noise term (epsilon ~ N(0,I)) conditional on x_t and t. During inference, we are predicting epsilon as a function of x_t and t. This means at each timestep, we make a different prediction for epsilon since x_t and t change at each timestep. \n\nI was wondering if there is any variation in the accuracy of predicted noise term in diffusion model as a function of timestep? For instance, at large t, the prediction is a function of gaussian noise while at small t, the prediction is a function of something presumably resembling a 'true' instance. \nGiven the same model (granted conditional on t) is used to predict the noise term and the inputs span a wide variation across timesteps, I could imagine that would yield significant variation in your predicted noise term. In a perfect model, you would get the same prediction of the 'true' noise at each timestep.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Variation in accuracy of predicted noise term in diffusion model as a function of timestep?",
            "upvote_ratio": 1.0,
            "url": "https://www.reddit.com/r/MachineLearning/comments/113dxfa/d_variation_in_accuracy_of_predicted_noise_term/"
        },
        {
            "author": "u/ExponentialCookie",
            "created_utc": "02-15-2023 16:06:36",
            "distinguished": null,
            "edited": false,
            "id": "1138jpp",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_1138jpp",
            "nsfw": false,
            "num_comments": 28,
            "permalink": "/r/MachineLearning/comments/1138jpp/d_lion_an_optimizer_that_outperforms_adam/",
            "score": 44,
            "selftext": "&#x200B;\n\nhttps://preview.redd.it/whgggirj3fia1.png?width=936&format=png&auto=webp&v=enabled&s=ae3dee45ec6b2472fd42af849138b41c88ed39de\n\nSeems interesting. A snippet from the Arxiv page:\n\n>Our method discovers a simple and effective optimization algorithm, **Lion** (*Evo***L***ved S***i***gn M***o***me***n***tum*). It is more memory-efficient than Adam as it only keeps track of the momentum. Different from adaptive optimizers, its update has the same magnitude for each parameter calculated through the sign operation. We compare Lion with widely used optimizers, such as Adam and Adafactor, for training a variety of models on different tasks.\n\n## Links\n\nArxiv: [https://arxiv.org/abs/2302.06675](https://arxiv.org/abs/2302.06675)\n\nCode Implementation: [https://github.com/lucidrains/lion-pytorch](https://github.com/lucidrains/lion-pytorch)",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Lion , An Optimizer That Outperforms Adam - Symbolic Discovery of Optimization Algorithms",
            "upvote_ratio": 0.86,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1138jpp/d_lion_an_optimizer_that_outperforms_adam/"
        },
        {
            "author": "u/confutioo",
            "created_utc": "02-15-2023 14:42:35",
            "distinguished": null,
            "edited": false,
            "id": "1136m9i",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_1136m9i",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/1136m9i/r_zeno_an_interactive_framework_for_behavioral/",
            "score": 1,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Zeno: An Interactive Framework for Behavioral Evaluation of Machine Learning",
            "upvote_ratio": 0.67,
            "url": "https://arxiv.org/pdf/2302.04732.pdf"
        },
        {
            "author": "u/MysteryInc152",
            "created_utc": "02-15-2023 14:07:24",
            "distinguished": null,
            "edited": false,
            "id": "1135tir",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_1135tir",
            "nsfw": false,
            "num_comments": 36,
            "permalink": "/r/MachineLearning/comments/1135tir/d_glm_130b_chineseenglish_bilingual_model/",
            "score": 219,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[D] GLM 130B (Chinese-English Bilingual model) translations vs Google, Deepl Translate, NLLB and chatGPT",
            "upvote_ratio": 0.96,
            "url": "https://www.reddit.com/gallery/1135tir"
        },
        {
            "author": "u/LemonByte",
            "created_utc": "02-15-2023 13:44:59",
            "distinguished": null,
            "edited": "02-15-2023 13:49:04",
            "id": "1135alu",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_1135alu",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/1135alu/p_pytorch_seeding_and_independent_rng_streams/",
            "score": 6,
            "selftext": "    pip install pytorch-seed\n\n[https://github.com/UM-ARM-Lab/pytorch\\_seed](https://github.com/UM-ARM-Lab/pytorch_seed)\n\nSeed everything (CUDA, torch, numpy, python's random) with `pytorch_seed.seed(123)`\n\nSimilar utility functions to pytorch lightning for those that don't want to depend on a whole framework, as well as some additional features via RNG streams. These are resumable contexts where the RNG inside are independent from each other and the global RNG state:\n\n    import torch\n    import pytorch_seed\n    \n    rng_1 = pytorch_seed.SavedRNG(1) # start the RNG stream with seed 1\n    rng_2 = pytorch_seed.SavedRNG(2)\n    \n    with rng_1:\n        # does not affect, nor is affected by the global RNG and rng_2\n        print(torch.rand(1)) # tensor([0.7576])\n    \n    with rng_2:\n        print(torch.rand(1)) # tensor([0.6147])\n    \n    torch.rand(1) # modify the global RNG state\n    \n    with rng_1:\n        # resumes from the last context\n        print(torch.rand(1)) # tensor([0.2793])\n    \n    with rng_2:\n        print(torch.rand(1)) # tensor([0.3810])\n        \n    # confirm those streams are the uninterrupted ones\n    pytorch_seed.seed(1)\n    torch.rand(2) # tensor([0.7576, 0.2793])\n    \n    pytorch_seed.seed(2)\n    torch.rand(2) # tensor([0.6147, 0.3810])",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Pytorch seeding and independent RNG streams",
            "upvote_ratio": 0.88,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1135alu/p_pytorch_seeding_and_independent_rng_streams/"
        },
        {
            "author": "u/bo_peng",
            "created_utc": "02-15-2023 13:44:44",
            "distinguished": null,
            "edited": false,
            "id": "1135aew",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_1135aew",
            "nsfw": false,
            "num_comments": 38,
            "permalink": "/r/MachineLearning/comments/1135aew/r_rwkv4_14b_release_and_chatrwkv_a_surprisingly/",
            "score": 265,
            "selftext": "Hi everyone. I am an independent researcher working on my pure RNN language model RWKV. I have finished the training of RWKV-4 14B (FLOPs sponsored by Stability EleutherAI - thank you!) and it is indeed very scalable. Note RWKV is parallelizable too, so it's combining the best of RNN and transformer.\n\nThe ChatRWKV project (let's build together):\n\n[https://github.com/BlinkDL/ChatRWKV](https://github.com/BlinkDL/ChatRWKV)\n\nZero-shot comparison with NeoX / Pythia (same dataset: the Pile) at same params count (14.2B):\n\n&#x200B;\n\nhttps://preview.redd.it/f6lxnjgfceia1.png?width=1174&format=png&auto=webp&v=enabled&s=54de7568974fc187584bd6825d92935baa079e83\n\nGeneration results (simply topP=0.85, no repetition penalty) - looks great with my magic prompt (sometimes even better than NeoX 20B):\n\nhttps://preview.redd.it/99deuc17ceia1.png?width=1878&format=png&auto=webp&v=enabled&s=456c8d9bb2a968d73f44a0d3589cf6b893be31f4\n\n&#x200B;\n\nhttps://preview.redd.it/g62e4l48ceia1.png?width=1887&format=png&auto=webp&v=enabled&s=c997bf27692d7e53d07de19048b6cbf3d2c9ebff\n\n&#x200B;\n\nhttps://preview.redd.it/379egq09ceia1.png?width=1808&format=png&auto=webp&v=enabled&s=895f05fe14e2a3a41863802858114f3096d0ed77\n\n&#x200B;\n\nhttps://preview.redd.it/pcgq7gz9ceia1.png?width=1886&format=png&auto=webp&v=enabled&s=138b0aec404b8f7f49f585d00284edbac791ffaf\n\n&#x200B;\n\nhttps://preview.redd.it/rn743etbceia1.png?width=1715&format=png&auto=webp&v=enabled&s=6d83cc2a200bdd655b690f56559dda43490ed2b3\n\n&#x200B;\n\nhttps://preview.redd.it/uhal4dkcceia1.png?width=1879&format=png&auto=webp&v=enabled&s=3b3db0b96456df9590a8b38ebe7d58509ebccb20\n\nExplanation, fine-tuning, training and more:\n\n[https://github.com/BlinkDL/RWKV-LM](https://github.com/BlinkDL/RWKV-LM)",
            "spoiler": false,
            "stickied": false,
            "title": "[R] RWKV-4 14B release (and ChatRWKV) - a surprisingly strong RNN Language Model",
            "upvote_ratio": 0.97,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1135aew/r_rwkv4_14b_release_and_chatrwkv_a_surprisingly/"
        },
        {
            "author": "u/Cogwheel",
            "created_utc": "02-15-2023 12:55:44",
            "distinguished": null,
            "edited": false,
            "id": "113448t",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_113448t",
            "nsfw": false,
            "num_comments": 25,
            "permalink": "/r/MachineLearning/comments/113448t/d_is_anyone_working_on_ml_models_that_infer_and/",
            "score": 13,
            "selftext": "In brains, the neural networks are transformed by the act of \"inference\". Neurons that have recently fired are more likely to fire again given the same input. Individual neural pathways can be created or destroyed based on the behavior of neurons around them. This leads me (through various leaps of logic and \"faith\") to suspect that some amount of mutability over time is required for an AI to exhibit sentience.\n\nSo far, all of the ML models I've seen distinctly separate training from inference. Every model that we put into production is a fixed snapshot of the most recent round of training. ChatGPT, for instance, is just the same exact model being incrementally fed both your prompts and its own previous output. This does create a sort of feedback, but in my mind it is not actually \"experiencing\" the conversation with you.\n\nSo I'm wondering if there are any serious attempts in the works to create an AI that is able to transform itself dynamically. E.g. having some kind of reinforcement learning module built into inference so that each new inference fundamentally (rather than superficially) incorporates its past experiences into its future predictions.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Is anyone working on ML models that infer and train at the same time?",
            "upvote_ratio": 0.74,
            "url": "https://www.reddit.com/r/MachineLearning/comments/113448t/d_is_anyone_working_on_ml_models_that_infer_and/"
        },
        {
            "author": "u/OpeningVariable",
            "created_utc": "02-15-2023 12:39:58",
            "distinguished": null,
            "edited": false,
            "id": "1133r6m",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_1133r6m",
            "nsfw": false,
            "num_comments": 3,
            "permalink": "/r/MachineLearning/comments/1133r6m/r_experiences_and_opinions_on_tmlr/",
            "score": 4,
            "selftext": "Academic reddit, what are your experiences submitting papers to TMLR?",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Experiences and opinions on TMLR?",
            "upvote_ratio": 1.0,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1133r6m/r_experiences_and_opinions_on_tmlr/"
        },
        {
            "author": "u/cpehle",
            "created_utc": "02-15-2023 10:43:26",
            "distinguished": null,
            "edited": false,
            "id": "1130xo1",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_1130xo1",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/1130xo1/r_eventbased_backpropagation_for_analog/",
            "score": 41,
            "selftext": "Machine learning with Spiking Neural Networks is far from mainstream. One reason is that until recently there was no generally known way of doing backpropagation in SNN. Here we implement a gradient estimation algorithm for analog neuromorphic hardware, based on the EventProp algorithm, which enables us to compute gradients based on sparse observations of the hardware system. Previous approaches needed dense observations of system state or were limited in other ways. We only demonstrate the algorithm here on a toy task, but we hope that it can be the basis of a scalable way to estimate gradients and do machine learning with analog neuromorphic hardware. We also think the algorithm can be the basis for a full on-chip implementation, which would finally result in scalable and energy efficient gradient-based learning in analog neuromorphic hardware.\n\nhttps://arxiv.org/abs/2302.07141",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Event-based Backpropagation for Analog Neuromorphic Hardware",
            "upvote_ratio": 0.92,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1130xo1/r_eventbased_backpropagation_for_analog/"
        },
        {
            "author": "u/pp314159",
            "created_utc": "02-15-2023 09:29:03",
            "distinguished": null,
            "edited": false,
            "id": "112z9y9",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_112z9y9",
            "nsfw": false,
            "num_comments": 9,
            "permalink": "/r/MachineLearning/comments/112z9y9/p_build_data_web_apps_in_jupyter_notebook_with/",
            "score": 94,
            "selftext": "Hi there,\n\nHave you ever wanted to share your results from Jupyter Notebook with a non-technical person? You need to rewrite your analysis into some web framework or copy-paste charts to PowePoint presentation - a lot of work!\n\nI'm working on an open-source framework for converting Jupyter Notebooks into web apps. Mercury offers set of interactive widgets that can be used in the Python notebook. There is a very simple re-execution of cells after widget update. Notebooks can be served online as web apps, presentations, reports, dashboards, static websites, or REST API.\n\nYou can read more about Mercury at [RunMercury.com](https://RunMercury.com).\n\nMercury GitHub repo https://github.com/mljar/mercury",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Build data web apps in Jupyter Notebook with Python only",
            "upvote_ratio": 0.91,
            "url": "https://www.reddit.com/r/MachineLearning/comments/112z9y9/p_build_data_web_apps_in_jupyter_notebook_with/"
        },
        {
            "author": "u/Shai_Meital",
            "created_utc": "02-15-2023 02:54:35",
            "distinguished": null,
            "edited": false,
            "id": "112spyb",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_112spyb",
            "nsfw": false,
            "num_comments": 4,
            "permalink": "/r/MachineLearning/comments/112spyb/d_what_is_the_fastest_framework_for_llm/",
            "score": 0,
            "selftext": "Hey guys. I want to experiment with low-latency (10-50 milisec/token) LLM conditional generation.\n\nClearly, an API call to OpenAI's GPT is not the answer here. It must be one of the open-source models released. Also, it's clear that the model size has a critical effect too so 1-7B models should do the trick for my downstream task.\n\nI tried \\`DeepSpeed\\` and \\`Accelerate\\` with \\`HF\\` models but they are not that fast to generate.  \nCan you guys share from experience?  \nThank you",
            "spoiler": false,
            "stickied": false,
            "title": "[D] What is the fastest framework for LLM conditional generation?",
            "upvote_ratio": 0.47,
            "url": "https://www.reddit.com/r/MachineLearning/comments/112spyb/d_what_is_the_fastest_framework_for_llm/"
        },
        {
            "author": "u/AngsThak",
            "created_utc": "02-14-2023 22:56:24",
            "distinguished": null,
            "edited": false,
            "id": "112oug6",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_112oug6",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/112oug6/d_cbam_with_yolov7/",
            "score": 1,
            "selftext": "I just read the paper on CBAM and wonder if there's a way to integrate the CBAM attention module with the network architecture of YOlOv7. Any articles on it or reference codes will be highly appreciated. Thank you very much!",
            "spoiler": false,
            "stickied": false,
            "title": "[D] CBAM with YOLOv7?",
            "upvote_ratio": 0.55,
            "url": "https://www.reddit.com/r/MachineLearning/comments/112oug6/d_cbam_with_yolov7/"
        },
        {
            "author": "u/thejashGI",
            "created_utc": "02-14-2023 18:49:14",
            "distinguished": null,
            "edited": false,
            "id": "112jwzr",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_112jwzr",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/112jwzr/d_noam_brown_fair_on_achieving_humanlevel/",
            "score": 0,
            "selftext": "Here is a [podcast episode](https://generallyintelligent.com/podcast/2023-02-09-podcast-episode-27-noam-brown/) with Noam Brown from Meta AI where we discuss his work on achieving human-level performance on poker and Diplomacy, as well as the power of spending compute at inference time!",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Noam Brown, FAIR: On achieving human-level performance in poker and Diplomacy, and the power of spending compute at inference time",
            "upvote_ratio": 0.5,
            "url": "https://www.reddit.com/r/MachineLearning/comments/112jwzr/d_noam_brown_fair_on_achieving_humanlevel/"
        },
        {
            "author": "u/zielmicha",
            "created_utc": "02-14-2023 18:38:02",
            "distinguished": null,
            "edited": false,
            "id": "112jnzp",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_112jnzp",
            "nsfw": false,
            "num_comments": 4,
            "permalink": "/r/MachineLearning/comments/112jnzp/d_retrieval_transformers_with_learnable_queries/",
            "score": 3,
            "selftext": "Retrieval transformer models like RETRO seem to use frozen embeddings both for the documents in the database and the currently completed document (\"the query\"). \n\nMaking the embeddings of documents in the database learnable would defeat the purpose, as retrieval transformers only make sense when the database is huge.\n\nIt seems that the query embedding could be made learnable - the model could learn to extract more useful documents this way. Have you seen any research that does this?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Retrieval transformers with learnable queries?",
            "upvote_ratio": 0.64,
            "url": "https://www.reddit.com/r/MachineLearning/comments/112jnzp/d_retrieval_transformers_with_learnable_queries/"
        },
        {
            "author": "u/avsolatorio",
            "created_utc": "02-14-2023 16:29:53",
            "distinguished": null,
            "edited": "02-14-2023 17:08:49",
            "id": "112gpf1",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "News",
            "locked": false,
            "name": "t3_112gpf1",
            "nsfw": false,
            "num_comments": 4,
            "permalink": "/r/MachineLearning/comments/112gpf1/r_n_realtabformer_generating_realistic_relational/",
            "score": 64,
            "selftext": "Paper: [https://arxiv.org/abs/2302.02041](https://arxiv.org/abs/2302.02041)\n\nGenerate synthetic data from single tabular data using GPT. It also works on relational datasets! No fine-tuning and works out-of-the-box.\n\nWe also removed the guesswork on how long (epochs) the generative model for a single tabular data is trained. We propose the Q\u03b4 statistic and apply statistical bootstrapping to define a threshold to robustly detect overfitting.  Perk: no need for a hold-out data!\n\nData copying is also a problem in generative models. This means that training data may be learned and copied by the model during sampling. We attempt to mitigate data copying.\n\nWe implement target masking to deliberately create missing values in each observation in the data. The mask is a special token that is ignored during sampling. This forces the model to probabilistically impute the token, adding uncertainty to the generated data.\n\nREaLTabFormer is open-sourced and available on PyPi \u2192 pip install realtabformer\n\n&#x200B;\n\nhttps://preview.redd.it/vhf1st2g28ia1.png?width=1998&format=png&auto=webp&v=enabled&s=e0007bad69d6ad1df4006d5152cdd67f511e10ac",
            "spoiler": false,
            "stickied": false,
            "title": "[R] [N] REaLTabFormer: Generating Realistic Relational and Tabular Data using Transformers",
            "upvote_ratio": 0.95,
            "url": "https://www.reddit.com/r/MachineLearning/comments/112gpf1/r_n_realtabformer_generating_realistic_relational/"
        },
        {
            "author": "u/willowill5",
            "created_utc": "02-14-2023 15:44:56",
            "distinguished": null,
            "edited": false,
            "id": "112fnk8",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_112fnk8",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/112fnk8/d_looking_for_advice_on_model_architecture_for/",
            "score": 1,
            "selftext": "I am currently working on a project where I need to embed facial landmark coordinates into StyleGAN2 latentspace. The input data is structured as follows: \\[batch\\_size, num\\_landmarks=138, num\\_coordinates=3 (x,y,z)\\]. The output data is structured as: \\[batch\\_size, stylegan2\\_latent\\_space=512\\].\n\nI have PyTorch experience and am experimenting with transformer like models for the embedding. However, I am unsure about the optimal architecture for this task, and I would appreciate any advice or recommendations on how to design a suitable model.\n\nHas anyone worked on a similar task before, or have any ideas about which architecture could work well for this problem? Any advice or resources would be greatly appreciated.\n\nThank you!",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Looking for advice on model architecture for embedding facial landmark coordinates into StyleGAN2 latentspace",
            "upvote_ratio": 0.6,
            "url": "https://www.reddit.com/r/MachineLearning/comments/112fnk8/d_looking_for_advice_on_model_architecture_for/"
        },
        {
            "author": "u/arg_max",
            "created_utc": "02-14-2023 15:06:10",
            "distinguished": null,
            "edited": false,
            "id": "112eqxm",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_112eqxm",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/112eqxm/discussion_computing_the_derivative_of_a/",
            "score": 3,
            "selftext": "Hi,  \n\n\nI was wondering if anyone came across a paper that approximated the derivative of a diffusion model with respect to the conditioning that is fed into the cross-attention module. So let's say we have a text that is already transformed into a continuous embedding. Then this goes through the llm and is fed into the cross-attention module at every timestep. At the end of the diffusion process, we get some image/a latent representation of an image in the case of stable diffusion. We can then calculate a loss on that image and in theory calculate the gradient with respect to the continuous text embedding if we use a non-stochastic sampler like DDIM. The issue is the length of the graph calculating that derivative is super expensive. I was if anyone already solved this or has some good references.  \n\n\nThanks :)",
            "spoiler": false,
            "stickied": false,
            "title": "[Discussion] Computing the derivative of a diffusion model with respect to the prompt",
            "upvote_ratio": 0.71,
            "url": "https://www.reddit.com/r/MachineLearning/comments/112eqxm/discussion_computing_the_derivative_of_a/"
        },
        {
            "author": "u/No-Front-4346",
            "created_utc": "02-14-2023 13:14:04",
            "distinguished": null,
            "edited": false,
            "id": "112c2ad",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_112c2ad",
            "nsfw": false,
            "num_comments": 4,
            "permalink": "/r/MachineLearning/comments/112c2ad/d_self_supervised_learning_for_regression_with/",
            "score": 0,
            "selftext": "\nHi all,\n\nIm trying to implement self supervised pretraining to tabular data regression problem, however since the literature is scarce i\u2019m stuck in the augmentation stage. Im currently using sim siam self supervision with gaussian noising and input dropout. I tried shuffling to mimic CV approaches but it failed miserably. Any advice?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] self supervised learning for regression with tabular numerical data",
            "upvote_ratio": 0.33,
            "url": "https://www.reddit.com/r/MachineLearning/comments/112c2ad/d_self_supervised_learning_for_regression_with/"
        },
        {
            "author": "u/nateharada",
            "created_utc": "02-14-2023 12:54:35",
            "distinguished": null,
            "edited": false,
            "id": "112bl3g",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_112bl3g",
            "nsfw": false,
            "num_comments": 17,
            "permalink": "/r/MachineLearning/comments/112bl3g/r_scaling_vision_transformers_to_22_billion/",
            "score": 40,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Scaling Vision Transformers to 22 Billion Parameters",
            "upvote_ratio": 0.87,
            "url": "https://arxiv.org/pdf/2302.05442.pdf"
        },
        {
            "author": "u/jkterry1",
            "created_utc": "02-14-2023 11:25:23",
            "distinguished": null,
            "edited": false,
            "id": "1129gth",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "News",
            "locked": false,
            "name": "t3_1129gth",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/1129gth/n_miniworld_is_now_a_mature_project_within_the/",
            "score": 2,
            "selftext": "Miniworld - a minimalistic 3D interior environment simulator for reinforcement learning & robotics research that allows environments to be easily edited - has now reached the mature inside Farama. You can check out the documentation at [https://miniworld.farama.org](https://miniworld.farama.org/), and the release notes for all the changes we\u2019ve made to the project at [https://github.com/Farama-Foundation/Miniworld/releases/tag/2.0.1](https://github.com/Farama-Foundation/Miniworld/releases/tag/2.0.1).",
            "spoiler": false,
            "stickied": false,
            "title": "[N] Miniworld is now a mature project within the Farama Foundation",
            "upvote_ratio": 0.75,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1129gth/n_miniworld_is_now_a_mature_project_within_the/"
        },
        {
            "author": "u/H0lzm1ch3l",
            "created_utc": "02-14-2023 11:16:57",
            "distinguished": null,
            "edited": "02-15-2023 08:25:55",
            "id": "11299r9",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11299r9",
            "nsfw": false,
            "num_comments": 103,
            "permalink": "/r/MachineLearning/comments/11299r9/d_tensorflow_struggles/",
            "score": 158,
            "selftext": "This may be a bit of a vent. I am currently working on a model with Tensorflow. To me it seems that whenever I am straying from a certain path my productivity starts dying at an alarming rate. \n\nFor example I am currently implementing my own data augmentation (because I strayed from Tf in a minuscule way) and obscure errors are littering my path. Prior to that I made a mistake somewhere in my training loop and it took me forever to find. The list goes on. \n\nEvery time I try using Tensorflow in a new way, it\u2018s like taming a new horse. Except that it\u2018s the same donkey I tamed last time. This is not my first project, but does it ever change?\n\nEDIT, Todays highlight:\nWhen you index a dim 1 tensor (so array) you get scalar tensors. Now if you wanted to create a dim 1 tensor from scalar tensors you can not use tf.constant, but you have to use tf.stack. This wouldn't even be a problem if it were somehow documented and you didn't get the following error: \"Scalar tensor has no attribute len()\". \n\nI understand the popularity of \"ask for forgiveness, not permission\" in Python, but damn ...",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Tensorflow struggles",
            "upvote_ratio": 0.92,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11299r9/d_tensorflow_struggles/"
        },
        {
            "author": "u/Maleficent_Stay_7737",
            "created_utc": "02-14-2023 10:33:14",
            "distinguished": null,
            "edited": false,
            "id": "11287zf",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_11287zf",
            "nsfw": false,
            "num_comments": 8,
            "permalink": "/r/MachineLearning/comments/11287zf/r_hitchhikers_guide_to_superresolution/",
            "score": 179,
            "selftext": "I'm glad to share with you our Open Access survey paper about image super-resolution:  \n[https://ieeexplore.ieee.org/abstract/document/10041995](https://ieeexplore.ieee.org/abstract/document/10041995)  \n\n\nThe goal of this work is to give an overview of the abundance of publications in image super-resolution, give an introduction for new researchers, and open thriving discussions as well as point to potential future directions to advance the field :)",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Hitchhiker\u2019s Guide to Super-Resolution: Introduction and Recent Advances",
            "upvote_ratio": 0.96,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11287zf/r_hitchhikers_guide_to_superresolution/"
        },
        {
            "author": "u/zxkj",
            "created_utc": "02-14-2023 09:18:09",
            "distinguished": null,
            "edited": false,
            "id": "1126g64",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_1126g64",
            "nsfw": false,
            "num_comments": 7,
            "permalink": "/r/MachineLearning/comments/1126g64/d_repeating_important_samples_in_every_batch_for/",
            "score": 18,
            "selftext": "Wondering if there\u2019s a term for this.\n\nI\u2019m training NNs for a scenario that works best with a small batch size, there are therefore many batches.\n\nThere are a couple particular samples that are VERY important. Let\u2019s say 3 important samples out of thousands I train to.\n\nI found end application is best when I include these important samples, repeated, in every batch. This is opposed to simply giving the samples a large weight, because the large weight doesn\u2019t matter after looping through many batches in an epoch.\n\nSo the NN learns the other less important stuff while being forced to remain in good agreement with the important samples.\n\nDoes this technique have a name?\n\nEDIT: In case anyone is curious, these are physics informed NNs and the important samples are equilibrium mechanical structures. The NN therefore learns what equilibrium is, with everything else being small deviations from equilibrium.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Repeating important samples in every batch for NN training?",
            "upvote_ratio": 0.86,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1126g64/d_repeating_important_samples_in_every_batch_for/"
        },
        {
            "author": "u/Forsaken_Football227",
            "created_utc": "02-14-2023 07:43:24",
            "distinguished": null,
            "edited": false,
            "id": "1124hyv",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_1124hyv",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/1124hyv/r_imagenet_2015_vid_dataset/",
            "score": 3,
            "selftext": "Hi all,\n\nI saw a few posts already but just to make sure and keep this as an update, does anyone have the ImageNet 2015 VID dataset to share? All links are dead. I really need it now to train TransVOD.",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Imagenet 2015 VID Dataset",
            "upvote_ratio": 0.8,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1124hyv/r_imagenet_2015_vid_dataset/"
        },
        {
            "author": "u/TKMater",
            "created_utc": "02-14-2023 07:18:55",
            "distinguished": null,
            "edited": false,
            "id": "11241dd",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11241dd",
            "nsfw": false,
            "num_comments": 3,
            "permalink": "/r/MachineLearning/comments/11241dd/d_threshold_for_kmeans_anomaly_detection/",
            "score": 1,
            "selftext": "I am using kmeans clustering algorithm for anomaly detection. After training kmeans, I'm calculation Euclidian distance of new data points to their nearest cluster. Please suggest me some strategies to set up a threshold such that point with distance greater than that threshold will be classified as anomaly. Or tell me if there are some other way to identify anomaly using k-means.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Threshold for k-means anomaly detection",
            "upvote_ratio": 1.0,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11241dd/d_threshold_for_kmeans_anomaly_detection/"
        },
        {
            "author": "u/AdministrationOk2735",
            "created_utc": "02-14-2023 05:37:45",
            "distinguished": null,
            "edited": false,
            "id": "11229f7",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11229f7",
            "nsfw": false,
            "num_comments": 7,
            "permalink": "/r/MachineLearning/comments/11229f7/discussion_the_need_for_noise_in_stable_diffusion/",
            "score": 0,
            "selftext": "As I'm learning about how stable diffusion works, I can't figure out why during image generation there's a need to deal with 'noise'.\n\nI know I'm glossing over a lot of details, but my understanding is that the algorithm is trained by gradually adding noise to an image and then de-noising it to recover the initial image. Wouldn't this be functionally equivalent to a machine that starts with an image, gradually reduces it to a blank canvas (all white), and then gradually reconstructs the original image? Then, post training, the generative process would just start with a blank canvas and gradually generate the image based on the input string provided.\n\nThe idea of generating an image from a blank canvas feels more satisfying to me than revealing an image hidden by noise, but I'm sure there's a mathematical/technical reason why what I'm suggesting doesn't work. Appreciate any insight into this!",
            "spoiler": false,
            "stickied": false,
            "title": "[Discussion] The need for noise in stable diffusion",
            "upvote_ratio": 0.38,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11229f7/discussion_the_need_for_noise_in_stable_diffusion/"
        },
        {
            "author": "u/aadityaura",
            "created_utc": "02-14-2023 04:45:45",
            "distinguished": null,
            "edited": false,
            "id": "111zwsg",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_111zwsg",
            "nsfw": false,
            "num_comments": 2,
            "permalink": "/r/MachineLearning/comments/111zwsg/d_a_comprehensive_guide_handcurated_resource_list/",
            "score": 14,
            "selftext": "Greetings,\n\nExcited to share with all those interested in Prompt Engineering and Large Language Models (LLMs)!\n\nWe've hand-curated a comprehensive, Free & Open Source resource list on Github that includes everything related to Prompt Engineering, LLMs, and all related topics. We've covered most things, from papers and articles to tools and code!  \n\n\nhttps://preview.redd.it/zzs09fg1l4ia1.png?width=1770&format=png&auto=webp&v=enabled&s=b2b5ac62b4296779a2fe5b6d0cbf9f46de68ca08",
            "spoiler": false,
            "stickied": false,
            "title": "[D] A Comprehensive Guide & Hand-Curated Resource List for Prompt Engineering and LLMs on Github",
            "upvote_ratio": 0.8,
            "url": "https://www.reddit.com/r/MachineLearning/comments/111zwsg/d_a_comprehensive_guide_handcurated_resource_list/"
        },
        {
            "author": "u/louis3195",
            "created_utc": "02-14-2023 04:28:34",
            "distinguished": null,
            "edited": false,
            "id": "111z2hl",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_111z2hl",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/111z2hl/d_what_are_your_tricksinfra_working_with/",
            "score": 2,
            "selftext": "I'm trying to design my infra for creating, storing, and retrieving embeddings in my AI applications and was wondering what are the different paths for it. I'm especially interested in NLP, but vision/multimodal could be interesting too.  \n\n\nWhether it's related to performance, scalability, or something else entirely, I'd love to hear your experiences and insights. Looking forward to your responses!",
            "spoiler": false,
            "stickied": false,
            "title": "[D] What are your tricks/infra working with embeddings?",
            "upvote_ratio": 0.67,
            "url": "https://www.reddit.com/r/MachineLearning/comments/111z2hl/d_what_are_your_tricksinfra_working_with/"
        },
        {
            "author": "u/lfotofilter",
            "created_utc": "02-14-2023 03:50:27",
            "distinguished": null,
            "edited": "02-14-2023 04:17:58",
            "id": "111y0cu",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_111y0cu",
            "nsfw": false,
            "num_comments": 2,
            "permalink": "/r/MachineLearning/comments/111y0cu/p_free_gpt3based_tool_to_suggest_terminal/",
            "score": 15,
            "selftext": "I whipped [this](https://github.com/nlml/YoCLI/) up today. Credit to [heyCLI](https://www.heycli.com/) for the idea, I've just remade an open source version.\n\nBasically in your terminal you type 'yo ' and then describe what you want a command to do.\n\nFor instance:\n\n    \u279c  ~ yo enable a reverse tunnel through ssh \n\nReturns:\n\n    Suggested command:\n    \n    ssh -R <remote_port>:localhost:<local_port> <remote_user>@<remote_host>\n\nAnother example:\n\n    \u279c  ~ yo launch tensorboard with a custom log dir and port\n    \n    Suggested command:\n    \n    tensorboard --logdir=<LOG_DIR> --port=<PORT_NUMBER>\n\nIt's free, MIT licence. You just need a free OpenAI API key which you can get by signing up on their website (I think if you use ChatGPT, you're already signed up). More info in the [repo](https://github.com/nlml/YoCLI/). Contributions/critiques welcome.",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Free GPT3-based tool to suggest terminal commands via natural language",
            "upvote_ratio": 0.81,
            "url": "https://www.reddit.com/r/MachineLearning/comments/111y0cu/p_free_gpt3based_tool_to_suggest_terminal/"
        },
        {
            "author": "u/0b01",
            "created_utc": "02-14-2023 03:32:10",
            "distinguished": null,
            "edited": false,
            "id": "111xr3q",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_111xr3q",
            "nsfw": false,
            "num_comments": 2,
            "permalink": "/r/MachineLearning/comments/111xr3q/d_anyone_interested_in_training_an_ai_for_tigris/",
            "score": 3,
            "selftext": "Over the past weekend, I finally decided to put this idea to rest and made a Rust implementation of the greatest board game ever made - up there with Chess and Go:  \\[Link to BGG\\]([https://boardgamegeek.com/boardgame/42/tigris-euphrates](https://boardgamegeek.com/boardgame/42/tigris-euphrates)\n\nThe ultimate goal is to train an AI so it needs to be very fast with state updates.\n\nThe game logic is quite sophisticated(\\~2000 lines) so it took me awhile to check all the edge cases of which there are many. Its search tree is huuuge with a branching factor of 100-300 which is more than Go's. It is also an imperfect game with hidden information(think poker). So ultimately it will need a reinforcement-based AI like \\[AlphaGo\\]([https://arxiv.org/abs/2112.03178](https://arxiv.org/abs/2112.03178). In the repo I used a minimax-based AI(for testing purposes) to search 3 moves ahead which gives slightly better than random performance.\n\nThe UI is implemented in \\[macroquad\\]([https://macroquad.rs/examples/](https://macroquad.rs/examples/) which is hands down the simplest 2D game library I've used(ggez and a deprecated framework which I shall not name). And yes, please excuse the programmer art made by me :P\n\nAny way, here's the link to the repo if you are interested:\n\n[repo](https://github.com/0b01/tigris-and-euphrates/blob/main/src/game.rs)\n\n&#x200B;\n\nNote: it's hardcoded for 2 players but it can easily be made for 4. I want to train the AI for 2 players first. There are also 4 unimplemented rules: monuments, tile removal after war, must take corner treasures first, must take treasure after conflict.\n\n&#x200B;\n\nhttps://preview.redd.it/jr49d9cx74ia1.png?width=1200&format=png&auto=webp&v=enabled&s=701394f3e12e7ac9f88126a2b2144c2df32ae1e4",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Anyone interested in training an AI for Tigris and Euphrates?",
            "upvote_ratio": 0.67,
            "url": "https://www.reddit.com/r/MachineLearning/comments/111xr3q/d_anyone_interested_in_training_an_ai_for_tigris/"
        },
        {
            "author": "u/ConfidenceFun5105",
            "created_utc": "02-14-2023 03:10:04",
            "distinguished": null,
            "edited": false,
            "id": "111xfkh",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_111xfkh",
            "nsfw": false,
            "num_comments": 2,
            "permalink": "/r/MachineLearning/comments/111xfkh/r_boosted_trees_literature/",
            "score": 8,
            "selftext": "Hi all. I\u2019m trying to do a comprehensive study on the theory of gradient boosted trees (on the more recent algorithms xgboost, lightgbm etc). I was wondering what books you have read that contain substantial information on this topic. Any suggestions are appreciated!",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Boosted Trees Literature",
            "upvote_ratio": 0.73,
            "url": "https://www.reddit.com/r/MachineLearning/comments/111xfkh/r_boosted_trees_literature/"
        },
        {
            "author": "u/kandalete",
            "created_utc": "02-14-2023 01:52:49",
            "distinguished": null,
            "edited": false,
            "id": "111w9bi",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_111w9bi",
            "nsfw": false,
            "num_comments": 6,
            "permalink": "/r/MachineLearning/comments/111w9bi/r_p_lucas_lung_cancer_screening_dataset/",
            "score": 9,
            "selftext": "https://preview.redd.it/fo3y2s26q3ia1.png?width=1365&format=png&auto=webp&v=enabled&s=7cfb6442b624b60808db7e04963be7ec50b2dc87\n\nI want to download this dataset which has been introduced in the article named [LUCAS: LUng CAncer Screening with Multimodal Biomarkers](https://link.springer.com/chapter/10.1007/978-3-030-60946-7_12).\n\nFollowing the corresponding [github](https://github.com/BCV-Uniandes/LUCAS) of this project, authors have noted that the dataset is published in [http://157.253.243.19/LUCAS/](http://157.253.243.19/LUCAS/) but I can't access this link and ping to this address.\n\nAnyone has used this dataset could share it with me? Or if you know other ways to access it, too.\n\nThank you very much!",
            "spoiler": false,
            "stickied": false,
            "title": "[R] [P] LUCAS: LUng CAncer Screening dataset",
            "upvote_ratio": 0.84,
            "url": "https://www.reddit.com/r/MachineLearning/comments/111w9bi/r_p_lucas_lung_cancer_screening_dataset/"
        },
        {
            "author": "u/michaelhoffman",
            "created_utc": "02-13-2023 17:09:47",
            "distinguished": null,
            "edited": false,
            "id": "111lku3",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_111lku3",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/111lku3/r_understanding_metricrelated_pitfalls_in_image/",
            "score": 0,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Understanding metric-related pitfalls in image analysis validation",
            "upvote_ratio": 0.5,
            "url": "https://arxiv.org/abs/2302.01790"
        },
        {
            "author": "u/Thin-Shirt6688",
            "created_utc": "02-13-2023 12:08:42",
            "distinguished": null,
            "edited": false,
            "id": "111e9hx",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_111e9hx",
            "nsfw": false,
            "num_comments": 8,
            "permalink": "/r/MachineLearning/comments/111e9hx/r_what_are_some_papers_that_describe_tiktoks/",
            "score": 43,
            "selftext": "I'm looking for a recent conference paper that describes how TikTok's algorithm works.\n\nAs an analogy, YouTube's algorithm was described by Zhao et al., (RecSys 2019) \"Recommending what video to watch next: a multitask ranking system\"",
            "spoiler": false,
            "stickied": false,
            "title": "[R] What are some papers that describe TikTok's algorithm?",
            "upvote_ratio": 0.87,
            "url": "https://www.reddit.com/r/MachineLearning/comments/111e9hx/r_what_are_some_papers_that_describe_tiktoks/"
        },
        {
            "author": "u/TobyWasBestSpiderMan",
            "created_utc": "02-13-2023 11:52:39",
            "distinguished": null,
            "edited": false,
            "id": "111dvia",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_111dvia",
            "nsfw": false,
            "num_comments": 13,
            "permalink": "/r/MachineLearning/comments/111dvia/r_actually_useful_every_day_application_of_a/",
            "score": 384,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Actually useful every day application of a Gaussian Process",
            "upvote_ratio": 0.93,
            "url": "https://www.reddit.com/gallery/110rz2e"
        },
        {
            "author": "u/paarulakan",
            "created_utc": "02-13-2023 11:44:35",
            "distinguished": null,
            "edited": false,
            "id": "111dohm",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_111dohm",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/111dohm/discussion_are_there_any_survey_on_compute/",
            "score": 2,
            "selftext": "are  there any survey or a listing that curates the computing power required  to train the large deep learning models like bert, gpt, ViT and so on.",
            "spoiler": false,
            "stickied": false,
            "title": "[Discussion] are there any survey on compute required to train large DNN models ?",
            "upvote_ratio": 0.63,
            "url": "https://www.reddit.com/r/MachineLearning/comments/111dohm/discussion_are_there_any_survey_on_compute/"
        },
        {
            "author": "u/LostGoatOnHill",
            "created_utc": "02-13-2023 07:38:44",
            "distinguished": null,
            "edited": false,
            "id": "111797x",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_111797x",
            "nsfw": false,
            "num_comments": 5,
            "permalink": "/r/MachineLearning/comments/111797x/d_cloud_agnostic_framework_to_avoid_hyperscaler/",
            "score": 2,
            "selftext": "Currently using Azure Machine Learning, so ML lifecycle in training, registering, and deploying models heavily relies on the AML sdk.\n\n&#x200B;\n\nThinking of going multi-cloud, so first thoughts on what open frameworks can serve the ML lifecycle and avoid vendor SDK lock-in?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Cloud agnostic framework to avoid hyperscaler SDK lock-in?",
            "upvote_ratio": 1.0,
            "url": "https://www.reddit.com/r/MachineLearning/comments/111797x/d_cloud_agnostic_framework_to_avoid_hyperscaler/"
        },
        {
            "author": "u/Tomavasso",
            "created_utc": "02-13-2023 03:38:34",
            "distinguished": null,
            "edited": false,
            "id": "1113hcs",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_1113hcs",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/1113hcs/d_incorporating_no_maintenance_examples_into_a/",
            "score": 1,
            "selftext": "Currently, I am working on a machine learning project that aims to extract decision logic in a maintenance dataset. The challenge I am facing is that part of the dataset has no maintenance decision yet.\n\nFor instance, consider the following example where a certain part and its sub-parts have been measured and graded yearly for the past 5 years, but no maintenance has been planned yet:\n\n|timestamp|measurements|grades|maintenance in|\n|:-|:-|:-|:-|\n|5 years ago|X|Z|\\>5 years|\n|4 years ago|X|Z|\\>4 years|\n|3 years ago|X|Z|\\>3 years|\n|2 years ago|X|Z|\\>2 years|\n|1 years ago|X|Z|\\>1 years|\n|0 years ago|X|Z|\\>0 years|\n\nWith these underlying data, I cannot learn exactly when maintenance was required. However, I do learn from this example that with the values from five years ago, no maintenance was required in 5 years.\n\nOne potential way to include this in the ML project is to include these examples in the evaluation set to determine whether the extracted rules indeed determine no maintenance within the period that we know no maintenance was needed. However, I am curious to know if there are better ways to incorporate this into the project, perhaps by already including it in the learning phase of the model training. Thank you in advance!",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Incorporating \"No Maintenance\" Examples into a Maintenance Dataset in ML",
            "upvote_ratio": 1.0,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1113hcs/d_incorporating_no_maintenance_examples_into_a/"
        },
        {
            "author": "u/orangelord234",
            "created_utc": "02-13-2023 02:18:46",
            "distinguished": null,
            "edited": false,
            "id": "11129cq",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11129cq",
            "nsfw": false,
            "num_comments": 10,
            "permalink": "/r/MachineLearning/comments/11129cq/d_is_a_nonsota_paper_still_good_to_publish_if_it/",
            "score": 27,
            "selftext": "For a dataset, the top result gets a high accuracy ~10% better than the second-best paper. But this \"SOTA\" paper uses some methods that just don't seem practical for applications at all. For example, they use an ensemble of 6 different SOTA models and also train on external data. Of course, it performs well, but it's a bit ridiculous cause it adds almost nothing of value besides \"we combined all the best models and got a better score!\". \n\nIf I have a novel method that is applied to the second-best paper that improves it by ~5% with the same to better compute efficiency but still is worse than the SOTA method, is it still good research to try to publish to conferences? It's also 40% above the baseline model.  \n\nI would think so because it's a decent improvement (with an interesting motivation + method) from prior work while keeping the model reasonable. Would reviewers agree or would they just see that it isn't better than SOTA and reject based on not being SOTA alone?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Is a non-SOTA paper still good to publish if it has an interesting method that does have strong improvements over baselines (read text for more context)? Are there good examples of this kind of work being published?",
            "upvote_ratio": 0.94,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11129cq/d_is_a_nonsota_paper_still_good_to_publish_if_it/"
        },
        {
            "author": "u/syprhdsh",
            "created_utc": "02-13-2023 01:28:43",
            "distinguished": null,
            "edited": false,
            "id": "1111gw7",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_1111gw7",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/1111gw7/d_diffusion_model_reverse_process_questions/",
            "score": 0,
            "selftext": "I was going through the paper: [Deep Unsupervised Learning using Nonequilibrium Thermodynamics](https://arxiv.org/abs/1503.03585) and in 2.3 Model Probability it's written that the integral is intractable. Can someone explain to me why that is?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Diffusion Model Reverse Process Questions",
            "upvote_ratio": 0.5,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1111gw7/d_diffusion_model_reverse_process_questions/"
        },
        {
            "author": "u/gamerx88",
            "created_utc": "02-13-2023 01:20:23",
            "distinguished": null,
            "edited": false,
            "id": "1111c53",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_1111c53",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/1111c53/r_holistic_evaluation_of_language_models_helm/",
            "score": 1,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Holistic Evaluation of Language Models (HELM)",
            "upvote_ratio": 0.67,
            "url": "https://crfm.stanford.edu/helm/latest/?"
        },
        {
            "author": "u/tysam_and_co",
            "created_utc": "02-13-2023 00:36:01",
            "distinguished": null,
            "edited": false,
            "id": "1110l3w",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_1110l3w",
            "nsfw": false,
            "num_comments": 7,
            "permalink": "/r/MachineLearning/comments/1110l3w/r_cifar10_in_8_seconds_on_an_a100_new_architecture/",
            "score": 17,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] CIFAR10 in <8 seconds on an A100 (new architecture!)",
            "upvote_ratio": 0.8,
            "url": "https://github.com/tysam-code/hlb-CIFAR10"
        },
        {
            "author": "u/Just0by",
            "created_utc": "02-12-2023 20:32:14",
            "distinguished": null,
            "edited": "02-13-2023 03:27:24",
            "id": "110vzsy",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_110vzsy",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/110vzsy/poneflow_v090_came_out/",
            "score": 2,
            "selftext": "Hello everyone,We are thrilled to announce the new release of [**OneFlow**](https://github.com/Oneflow-Inc/oneflow), which is a deep learning framework designed to be user-friendly, scalable and efficient. OneFlow v0.9.0 contains 640 commits. For the full changelog, please check out: [https://github.com/Oneflow-Inc/oneflow/releases/tag/v0.9.0](https://github.com/Oneflow-Inc/oneflow/releases/tag/v0.9.0).\n\n**Paper:** [https://arxiv.org/abs/2110.15032](https://arxiv.org/abs/2110.15032);**Code:** [https://github.com/Oneflow-Inc/oneflow](https://github.com/Oneflow-Inc/oneflow)\n\n(For those unfamiliar with OneFlow: The most notable strength of OneFlow is its support to distributed deep learning, faster than other frameworks and easier to use. An example can be found at [https://medium.com/@oneflow2020/libai-model-library-to-train-large-models-more-easily-and-efficiently-15637c8876eb](https://medium.com/@oneflow2020/libai-model-library-to-train-large-models-more-easily-and-efficiently-15637c8876eb) Based on OneFlow, to implement the same capability with Megatron-LM and DeepSpeed, LiBai only requires 1/3 lines of code.)\n\nWelcome to install OneFlow v0.9.0 for a new user experience. Your feedbacks will be much appreciated!\n\n**Highlights and optimizations in this release:**\n\n**1. PyTorch API compatibility**\n\nWith the addition of 86 new API interfaces and operators aligned with PyTorch and the fix of 104 bugs related to operator compatibility, OneFlow v0.9.0 provides better PyTorch API and model compatibility. In v0.9.0, users can migrate more PyTorch models to OneFlow with one click and gain faster performance.\n\nAllowing one-click migration of [Stable Diffusion](https://github.com/Oneflow-Inc/diffusers), [GLM](https://huggingface.co/BAAI/glm-large), [YOLOv5](https://github.com/Oneflow-Inc/one-yolov5) etc to OneFlow. More convenient model migration. Oneflow.load supports loading the torch.save models directly. With the newly added oneflow.mock\\_torch module and mock method\uff08[https://docs.oneflow.org/master/cookies/oneflow\\_torch.html\uff09](https://docs.oneflow.org/master/cookies/oneflow_torch.html\uff09), oneflow can migrate complex PyTorch models containing multiple scripts with one click without changing the original PyTorch script.\n\n**2. Improving the usability of distributed programming**\n\nGlobal Tensor has added a series of interfaces and methods that are convenient for distributed programming. And related bugs have been fixed.\n\n**3. Supporting automatic parallelism**\n\nThe Graph released a new feature of automatic parallelism (version 1), which supports automatic search for the fastest SBP with a specified Placement. When writing distributed models with Global Tensor, users do not need to consider parallelism model.\n\nFor more information, please check out: [https://oneflow.readthedocs.io/en/master/auto\\_parallel.html](https://oneflow.readthedocs.io/en/master/auto_parallel.html)\n\n**4. Better performance**\n\nGraph improves performance and reduces memory overhead, with a series of optimizations related to memory, execution speed, pipeline masking, and compilation speed.\n\nA series of operator optimizations and system optimizations have been added, including Eager instruction scheduling, high-performance CUDA kernel, opening up of multiple memory pools, etc.\n\nhttps://preview.redd.it/x624ujfrwuha1.png?width=1044&format=png&auto=webp&v=enabled&s=ec7b81b113fd32e8ebeffe7f2e94a5267a848af7\n\n&#x200B;\n\nhttps://preview.redd.it/a51h8yuswuha1.png?width=1044&format=png&auto=webp&v=enabled&s=203f6ff3e5395f6d130e61c0345c24567798eb11\n\nAfter simple tuning, [GLM-Large (335M) pre-trained model](https://huggingface.co/BAAI/glm-large)  based on OneFlow v0.9.0 can outperform the original GLM model based on PyTorch, DeepSpeed, and Apex with up to triple performance and 1/3 memory overhead saved.  \n\n\n![img](uhpvikt32xha1 \"\n\")\n\nhttps://preview.redd.it/xi81rkf42xha1.png?width=1027&format=png&auto=webp&v=enabled&s=56cbf85bf6438436d239afaf87c54976ba7827e0\n\nOn A100 GPU (SXM 80GB / PCIe 40GB), [the OneFlow Stable Diffusion inference speed](https://github.com/Oneflow-Inc/diffusers) is the fastest compared with other deep learning frameworks or compilers.\n\n**5. Debugging**\n\nThe Graph provides a series of functions to aid debugging, including analyzing memory logs, displaying the progress during the compilation stage, and the computation graph.\n\n**6. IR**\n\nOneFlow IR supports additional compilation optimization functions such as JIT compilation of LR code, distributed description of SBP signature, and the new OKL Dialect.\n\n**7. OneFlow-ONNX**\n\nThe newly released OneFlow-ONNX version v0.6.0 enhanced the usability of the exchange interface with multiple new features. In addition, it added support for another 6 models and over 20 Ops and fixed 6 bugs during the transformation process. You can use pip install oneflow-onnx==0. 6.0 with just one-click.\n\n**8. Better error prompt**\n\nThe error prompt of OneFlow is more user-friendly, which supports highlighting the error content and simplifies unnecessary information details inside the system. In this connection, you can visually learn about the location and type of the error.",
            "spoiler": false,
            "stickied": false,
            "title": "[P]OneFlow v0.9.0 Came Out!",
            "upvote_ratio": 0.63,
            "url": "https://www.reddit.com/r/MachineLearning/comments/110vzsy/poneflow_v090_came_out/"
        },
        {
            "author": "u/MurlocXYZ",
            "created_utc": "02-12-2023 18:00:40",
            "distinguished": null,
            "edited": false,
            "id": "110swn2",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_110swn2",
            "nsfw": false,
            "num_comments": 65,
            "permalink": "/r/MachineLearning/comments/110swn2/d_quality_of_posts_in_this_sub_going_down/",
            "score": 271,
            "selftext": "I could be wrong, but I see a trend that posts in this sub are getting to a lower quality and/or lower relevance.\n\nI see a lot of posts of the type \"how do I run X\" (usually a generative model) with a complete disregard to how it actually works or nonsense posts about ChatGPT.\n\nI believe this is due to an influx of new people who gained an interest in ML now that the hype is around generative AI. Which is fantastic, don't get me wrong.\n\nBut, I see less academic discussions and less papers being posted. Or perhaps they are just not as upvoted. Is it just me?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Quality of posts in this sub going down",
            "upvote_ratio": 0.93,
            "url": "https://www.reddit.com/r/MachineLearning/comments/110swn2/d_quality_of_posts_in_this_sub_going_down/"
        },
        {
            "author": "u/radi-cho",
            "created_utc": "02-12-2023 17:49:05",
            "distinguished": null,
            "edited": false,
            "id": "110sngt",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_110sngt",
            "nsfw": false,
            "num_comments": 8,
            "permalink": "/r/MachineLearning/comments/110sngt/r_p_openassistant_is_a_fully_opensource_chatbased/",
            "score": 61,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] [P] OpenAssistant is a fully open-source chat-based assistant that understands tasks, can interact with third-party systems, and retrieve information dynamically to do so.",
            "upvote_ratio": 0.96,
            "url": "https://github.com/LAION-AI/Open-Assistant"
        },
        {
            "author": "u/radi-cho",
            "created_utc": "02-12-2023 17:41:07",
            "distinguished": null,
            "edited": false,
            "id": "110sh0w",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "News",
            "locked": false,
            "name": "t3_110sh0w",
            "nsfw": false,
            "num_comments": 5,
            "permalink": "/r/MachineLearning/comments/110sh0w/r_n_pix2pixzero_zeroshot_imagetoimage_translation/",
            "score": 181,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] [N] pix2pix-zero - Zero-shot Image-to-Image Translation",
            "upvote_ratio": 0.97,
            "url": "https://i.redd.it/3vchrw4a5uha1.gif"
        },
        {
            "author": "u/radi-cho",
            "created_utc": "02-12-2023 17:31:16",
            "distinguished": null,
            "edited": false,
            "id": "110s8ui",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "News",
            "locked": false,
            "name": "t3_110s8ui",
            "nsfw": false,
            "num_comments": 65,
            "permalink": "/r/MachineLearning/comments/110s8ui/r_n_toolformer_language_models_can_teach/",
            "score": 885,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] [N] Toolformer: Language Models Can Teach Themselves to Use Tools - paper by Meta AI Research",
            "upvote_ratio": 0.98,
            "url": "https://i.redd.it/7lk1ldus3uha1.png"
        },
        {
            "author": "u/TikkunCreation",
            "created_utc": "02-12-2023 12:08:59",
            "distinguished": null,
            "edited": false,
            "id": "110knl0",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_110knl0",
            "nsfw": false,
            "num_comments": 17,
            "permalink": "/r/MachineLearning/comments/110knl0/d_what_ml_dev_tools_do_you_wish_youd_discovered/",
            "score": 114,
            "selftext": "Here's my personal list of tools I think people will want to know about:\n\n* You'll probably want an LLM API\n   * OpenAI\n   * Cohere and others aren't as good\n   * Anthropic's isn't available\n* If you're using embeddings\n   * If you're working with a lot of items, you'll want a vector database, like Pinecone, or Weaviate, or pgvector\n* If you're building Q&A over a document\n   * I'd suggest using GPT Index\n* If you need to be able to interact with external data sources, do google searches, database lookups, python REPL\n   * I'd suggest using langchain\n* If you're doing chained prompts\n   * Check out dust tt and langchain\n* If you want to deploy a little app quickly\n   * Check out Streamlit\n* If you need to use something like stable diffusion or whisper in your product\n   * banana dev, modal, replicate, tiyaro ai, beam cloud, inferrd, or pipeline ai\n* If you need something to optimize your prompts\n   * Check out Humanloop and Everyprompt\n* If you're building models and need an ml framework\n   * PyTorch, Keras, TensorFlow\n* If you're deploying models to production\n   * Check out MLOps tools like MLflow, Kubeflow, Metaflow, Airflow, Seldon Core, TFServing\n* If you need to check out example projects for inspiration\n   * Check out the pinecone op stack, the langchain gallery, the gpt index showcase, and the openai cookbook\n* If you want to browse the latest research, check out arXiv, of course\n\n&#x200B;\n\nWhat am I missing?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] What ML dev tools do you wish you'd discovered earlier?",
            "upvote_ratio": 0.94,
            "url": "https://www.reddit.com/r/MachineLearning/comments/110knl0/d_what_ml_dev_tools_do_you_wish_youd_discovered/"
        },
        {
            "author": "u/AutoModerator",
            "created_utc": "02-12-2023 11:00:09",
            "distinguished": null,
            "edited": false,
            "id": "110j0cp",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_110j0cp",
            "nsfw": false,
            "num_comments": 120,
            "permalink": "/r/MachineLearning/comments/110j0cp/d_simple_questions_thread/",
            "score": 13,
            "selftext": "Please post your questions here instead of creating a new thread. Encourage others who create new posts for questions to post here instead!\n\nThread will stay alive until next one so keep posting after the date in the title.\n\nThanks to everyone for answering questions in the previous thread!",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Simple Questions Thread",
            "upvote_ratio": 1.0,
            "url": "https://www.reddit.com/r/MachineLearning/comments/110j0cp/d_simple_questions_thread/"
        },
        {
            "author": "u/Wiskkey",
            "created_utc": "02-12-2023 10:24:57",
            "distinguished": null,
            "edited": false,
            "id": "110i7h7",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_110i7h7",
            "nsfw": false,
            "num_comments": 2,
            "permalink": "/r/MachineLearning/comments/110i7h7/r_p_adding_conditional_control_to_texttoimage/",
            "score": 116,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] [P] Adding Conditional Control to Text-to-Image Diffusion Models. \"This paper presents ControlNet, an end-to-end neural network architecture that controls large image diffusion models (like Stable Diffusion) to learn task-specific input conditions.\" Example uses the Scribble ControlNet model.",
            "upvote_ratio": 0.94,
            "url": "https://i.redd.it/atseysyiyrha1.png"
        },
        {
            "author": "u/t0ns0fph0t0ns",
            "created_utc": "02-12-2023 09:42:32",
            "distinguished": null,
            "edited": false,
            "id": "110h9ey",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_110h9ey",
            "nsfw": false,
            "num_comments": 13,
            "permalink": "/r/MachineLearning/comments/110h9ey/r_digiface1m_synthetic_dataset_with_one_million/",
            "score": 25,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] DIGIFACE-1M \u2014 synthetic dataset with one million images for face recognition",
            "upvote_ratio": 0.79,
            "url": "https://i.redd.it/q4e17rfwqrha1.png"
        },
        {
            "author": "u/seraschka",
            "created_utc": "02-12-2023 09:05:12",
            "distinguished": null,
            "edited": false,
            "id": "110gh1m",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_110gh1m",
            "nsfw": false,
            "num_comments": 4,
            "permalink": "/r/MachineLearning/comments/110gh1m/p_understanding_coding_the_selfattention/",
            "score": 5,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Understanding & Coding the Self-Attention Mechanism of Large Language Models",
            "upvote_ratio": 0.67,
            "url": "https://sebastianraschka.com/blog/2023/self-attention-from-scratch.html"
        },
        {
            "author": "u/crash90",
            "created_utc": "02-12-2023 08:36:48",
            "distinguished": null,
            "edited": false,
            "id": "110fwgt",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_110fwgt",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/110fwgt/d_getting_llms_to_explore_their_latent_spaces/",
            "score": 6,
            "selftext": "I'm starting my AI deep dive and the most interesting thing I've encountered so far of this concept of knowledge getting rolled up / compressed into latent spaces that we can't interact with directly (only through prompts).\n\nI'm interested in research that has been done in trying to explore and interrogate these latent spaces to understand them.\n\nAny papers, blog posts, threads, youtube videos appreciated.\n\nThanks!",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Getting LLMs to explore their latent spaces",
            "upvote_ratio": 0.75,
            "url": "https://www.reddit.com/r/MachineLearning/comments/110fwgt/d_getting_llms_to_explore_their_latent_spaces/"
        },
        {
            "author": "u/m00nd0og",
            "created_utc": "02-12-2023 08:19:05",
            "distinguished": null,
            "edited": false,
            "id": "110fjyo",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_110fjyo",
            "nsfw": false,
            "num_comments": 2,
            "permalink": "/r/MachineLearning/comments/110fjyo/d_bert_tokenization_replacing_personentity_names/",
            "score": 4,
            "selftext": "Can someone please help me with below query, \n\nI would like to replace all the names that are present in the sentences with a generic word or token so that bert doesn't use the meaning behind some of the names and just look at names as presence of a \"name\". \n\nI have the names that are present in the sentence just wanted to know what should be appropriate word or token to replace it with.\n\nThanks!",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Bert Tokenization: Replacing person/entity names with a common token/word.",
            "upvote_ratio": 0.84,
            "url": "https://www.reddit.com/r/MachineLearning/comments/110fjyo/d_bert_tokenization_replacing_personentity_names/"
        },
        {
            "author": "u/helliun",
            "created_utc": "02-12-2023 07:32:54",
            "distinguished": null,
            "edited": false,
            "id": "110ep96",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_110ep96",
            "nsfw": false,
            "num_comments": 23,
            "permalink": "/r/MachineLearning/comments/110ep96/p_extracting_causal_chains_from_text_using/",
            "score": 277,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Extracting Causal Chains from Text Using Language Models",
            "upvote_ratio": 0.98,
            "url": "https://v.redd.it/2akxbz3jmsha1"
        },
        {
            "author": "u/ClassicSize7875",
            "created_utc": "02-11-2023 23:12:09",
            "distinguished": null,
            "edited": "02-12-2023 19:04:44",
            "id": "1106q4s",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_1106q4s",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/1106q4s/p_i_made_an_app_that_simplifies_text_data/",
            "score": 10,
            "selftext": "Hi Reddit community!\n\nI wanted to share a tool that I've been working on called DataLabel. It's a UI-based data editing tool that makes it easier to create labeled text data. The goal of DataLabel is to make data editing more accessible and efficient, especially for those who may not have much experience with coding.\n\nDataLabel can be installed via pip `pip install datalabel` , and works best in Jupyter notebooks or other Ipython environments. The interface is user-friendly and straightforward, so you can start using DataLabel right away without any hassle.\n\nI think DataLabel is a useful tool that can save you time and effort when working with text data. If you're curious, you can find it on GitHub at the following link: [**https://github.com/TitanLabsAI/datalabel**](https://github.com/TitanLabsAI/datalabel)\n\nThanks for taking the time to read this, and I hope you find DataLabel helpful in your work.",
            "spoiler": false,
            "stickied": false,
            "title": "[P] I Made an App That Simplifies Text Data Labeling: DataLabel",
            "upvote_ratio": 0.82,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1106q4s/p_i_made_an_app_that_simplifies_text_data/"
        },
        {
            "author": "u/AI4Tigray",
            "created_utc": "02-11-2023 21:52:35",
            "distinguished": null,
            "edited": false,
            "id": "11059u6",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "News",
            "locked": false,
            "name": "t3_11059u6",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/11059u6/n_new_frontiers_in_artificial_intelligence/",
            "score": 0,
            "selftext": "Dear All,\n\nWe are excited to invite you to our upcoming conference, AI For Tigray, centered on the theme \"New Frontiers in Artificial Intelligence.\" This conference brings together leading researchers from academia and industry to share their work and insights on the future of AI.\n\nWe have an exciting lineup of keynote talks from top researchers in the field, including Yoshua Bengio and Jeff Dean. In addition, there will be presentations of the latest research findings through contributed talks and poster sessions. Furthermore, we will be convening a group of renowned researchers to discuss the role of AI in addressing societal challenges.\n\nBut this conference isn't just about advancing technology -- it's about using it for good. The conflict in Tigray is currently \"the deadliest war in the world,\" and the people living in the region are suffering as a result. We want to use our upcoming conference to raise funds for urgent humanitarian aid and help those in need. All proceeds from the conference, including sponsorships, donations, and registration fees, will go towards helping those in need through our partners, the Health Professionals Network for Tigray and the Tegaru Disaster Relief Fund.\n\nWe hope you will join us in using AI for a greater cause. The conference will be held on March 11, 18, and 25 -- mark your calendars and register now at [https://aifortigray.org/](https://aifortigray.org/) to be a part of something special.\n\nSincerely,\n\nAI For Tigray Organizing Committee",
            "spoiler": false,
            "stickied": false,
            "title": "[N] New Frontiers in Artificial Intelligence",
            "upvote_ratio": 0.27,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11059u6/n_new_frontiers_in_artificial_intelligence/"
        },
        {
            "author": "u/leonardtang",
            "created_utc": "02-11-2023 21:33:24",
            "distinguished": null,
            "edited": false,
            "id": "1104wt4",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_1104wt4",
            "nsfw": false,
            "num_comments": 5,
            "permalink": "/r/MachineLearning/comments/1104wt4/r_the_naughtyformer_a_transformer_understands/",
            "score": 8,
            "selftext": "The Naughtyformer: A Transformer Understands Offensive Humor\n\nPaper: [https://arxiv.org/abs/2211.14369](https://arxiv.org/abs/2211.14369)\n\nData: [https://github.com/leonardtang/The-Naughtyformer](https://github.com/leonardtang/The-Naughtyformer)",
            "spoiler": false,
            "stickied": false,
            "title": "[R] The Naughtyformer: A Transformer Understands Offensive Humor",
            "upvote_ratio": 0.79,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1104wt4/r_the_naughtyformer_a_transformer_understands/"
        },
        {
            "author": "u/throwaway957280",
            "created_utc": "02-11-2023 19:47:12",
            "distinguished": null,
            "edited": false,
            "id": "1102t34",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_1102t34",
            "nsfw": false,
            "num_comments": 44,
            "permalink": "/r/MachineLearning/comments/1102t34/d_have_their_been_any_attempts_to_create_a/",
            "score": 86,
            "selftext": "I'm not arguing against Python's speed when it's asynchronously launching C++ optimized kernels. I just think it's kind of wild how 50% of practical machine learning is making sure your tensor shapes are compatible and there's no static shape checking. It kind of blows my mind given the amount of Python comments I've seen of the form `# [B, Z-1, Log(Q), 45] -> [B, Z, 1024]` or something like that. \n\nPlus you have the fact that the two major machine learning frameworks have both had to implement, like, meta-compilers for Python to support outputting optimized graphs. At that point it seems kinda crazy that people are still trying to retrofit Python with all these features it just wasn't meant to support. \n\nFeel free to let me know I have no idea what I'm talking about, because I have no idea what I'm talking about.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Have their been any attempts to create a programming language specifically for machine learning?",
            "upvote_ratio": 0.88,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1102t34/d_have_their_been_any_attempts_to_create_a/"
        },
        {
            "author": "u/t0t0t4t4",
            "created_utc": "02-11-2023 17:19:27",
            "distinguished": null,
            "edited": false,
            "id": "10zzm18",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10zzm18",
            "nsfw": false,
            "num_comments": 29,
            "permalink": "/r/MachineLearning/comments/10zzm18/d_can_google_sue_openai_for_using_the_transformer/",
            "score": 13,
            "selftext": "As far as I know, the Transformer architecture is patented: [https://patents.google.com/patent/US10452978B2/en](https://patents.google.com/patent/US10452978B2/en). Since OpenAI has used the Transformer extensively (including GPT), I'm wondering if this can be considered as patent infringement. \n\nIf you know about legal stuffs please share your opinions.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Can Google sue OpenAI for using the Transformer in their products?",
            "upvote_ratio": 0.68,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10zzm18/d_can_google_sue_openai_for_using_the_transformer/"
        },
        {
            "author": "u/norcalnatv",
            "created_utc": "02-11-2023 12:28:14",
            "distinguished": null,
            "edited": false,
            "id": "10zsw62",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10zsw62",
            "nsfw": false,
            "num_comments": 11,
            "permalink": "/r/MachineLearning/comments/10zsw62/the_inference_cost_of_search_disruption_large/",
            "score": 13,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "The Inference Cost Of Search Disruption \u2013 Large Language Model Cost Analysis [D]",
            "upvote_ratio": 0.88,
            "url": "https://www.semianalysis.com/p/the-inference-cost-of-search-disruption"
        },
        {
            "author": "u/answersareallyouneed",
            "created_utc": "02-11-2023 11:28:43",
            "distinguished": null,
            "edited": false,
            "id": "10zri4x",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10zri4x",
            "nsfw": false,
            "num_comments": 3,
            "permalink": "/r/MachineLearning/comments/10zri4x/d_effectiveness_of_coordconv/",
            "score": 7,
            "selftext": "[https://arxiv.org/abs/1807.03247](https://arxiv.org/abs/1807.03247) paper was released by Uber 4 years ago, but it never seemed to have caught on. The only major paper where I've seen used in is Solo and SoloV2 for instance segmentation.\n\nSeems like it would be useful for object detection, especially for localizing smaller objects or for more precise keypoint estimation when combined with a yolo-like model.\n\nHas anyone used CoordConv for these purposes? Does it it help?/Is it worth looking into?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Effectiveness of CoordConv",
            "upvote_ratio": 0.89,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10zri4x/d_effectiveness_of_coordconv/"
        },
        {
            "author": "u/Dalembert",
            "created_utc": "02-11-2023 11:07:26",
            "distinguished": null,
            "edited": false,
            "id": "10zqzkd",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "News",
            "locked": false,
            "name": "t3_10zqzkd",
            "nsfw": false,
            "num_comments": 4,
            "permalink": "/r/MachineLearning/comments/10zqzkd/news_researchers_at_brigham_young_university/",
            "score": 0,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[News] Researchers at Brigham Young University created an AI system to reduce time spent on film studies for NFL teams. It uses deep learning and computer vision to analyze and annotate game footage, with over 90% accuracy on player detection and 85% accuracy in determining formations.",
            "upvote_ratio": 0.47,
            "url": "https://www.reddit.com/gallery/10zqu17"
        },
        {
            "author": "u/erwinyonata",
            "created_utc": "02-11-2023 10:44:34",
            "distinguished": null,
            "edited": false,
            "id": "10zqd8o",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_10zqd8o",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/10zqd8o/p_im_using_deep_learning_to_play_old_school_game/",
            "score": 0,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[P] I'm using Deep Learning to play Old School game, Snake Game",
            "upvote_ratio": 0.25,
            "url": "https://youtu.be/qpS5OZgIq1Q"
        },
        {
            "author": "u/seraschka",
            "created_utc": "02-11-2023 09:15:08",
            "distinguished": null,
            "edited": false,
            "id": "10zolt0",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_10zolt0",
            "nsfw": false,
            "num_comments": 7,
            "permalink": "/r/MachineLearning/comments/10zolt0/p_understanding_large_language_models_a/",
            "score": 38,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Understanding Large Language Models -- A Transformative Reading List",
            "upvote_ratio": 0.93,
            "url": "https://sebastianraschka.com/blog/2023/llm-reading-list.html"
        },
        {
            "author": "u/_sshin_",
            "created_utc": "02-11-2023 07:54:26",
            "distinguished": null,
            "edited": false,
            "id": "10zmz2d",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_10zmz2d",
            "nsfw": false,
            "num_comments": 70,
            "permalink": "/r/MachineLearning/comments/10zmz2d/p_introducing_arxivgpt_chrome_extension_that/",
            "score": 823,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Introducing arxivGPT: chrome extension that summarizes arxived research papers using chatGPT",
            "upvote_ratio": 0.95,
            "url": "https://i.redd.it/jmgr7vsy3kha1.jpg"
        },
        {
            "author": "u/lmtog",
            "created_utc": "02-11-2023 05:41:47",
            "distinguished": null,
            "edited": false,
            "id": "10zix8k",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10zix8k",
            "nsfw": false,
            "num_comments": 9,
            "permalink": "/r/MachineLearning/comments/10zix8k/d_transformers_for_poker_bot/",
            "score": 1,
            "selftext": "Looking at the current research it seems like Monte Carlo CFR  is the defacto standard (Pluribus).\n\nBut are transformers able to be trained on poker as well?\n\nLets say we encode hands into something like 5h (5 of hearts) and also pass along info of the current game state like p1:raise:2bb, p2:fold and p3:call:2bb. Would the Model be able to predict what hands I should be playing? Lets say we train the model by playing against itself and feed back the result to train the model this way.\n\nThis is just an idea and I have not dove into transformers too much so there might be something that I'am missing.\n\nWhat are your thoughts on this?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Transformers for poker bot",
            "upvote_ratio": 0.55,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10zix8k/d_transformers_for_poker_bot/"
        },
        {
            "author": "u/lyndonzheng",
            "created_utc": "02-11-2023 03:12:38",
            "distinguished": null,
            "edited": false,
            "id": "10zfvz1",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_10zfvz1",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/10zfvz1/r_unid3_unified_discrete_diffusion_for/",
            "score": 5,
            "selftext": " A unified discrete diffusion model for simultaneous vision-language generation. \n\nProject: [https://mhh0318.github.io/unid3/](https://mhh0318.github.io/unid3/)\n\nCode: [https://github.com/mhh0318/UniD3](https://github.com/mhh0318/UniD3)\n\nhttps://preview.redd.it/w2st14pgpiha1.png?width=1366&format=png&auto=webp&v=enabled&s=5fcb58ec05a2e790566fe14296c4a08e932f841f",
            "spoiler": false,
            "stickied": false,
            "title": "[R] UniD3: Unified Discrete Diffusion for Simultaneous Vision-Language Generation",
            "upvote_ratio": 0.78,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10zfvz1/r_unid3_unified_discrete_diffusion_for/"
        },
        {
            "author": "u/iFighting",
            "created_utc": "02-11-2023 03:09:23",
            "distinguished": null,
            "edited": false,
            "id": "10zfu64",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_10zfu64",
            "nsfw": false,
            "num_comments": 6,
            "permalink": "/r/MachineLearning/comments/10zfu64/r_iclr2023_visionandlanguage_framework_for/",
            "score": 162,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] [ICLR'2023\ud83c\udf1f]: Vision-and-Language Framework for Open-Vocabulary Object Detection",
            "upvote_ratio": 0.98,
            "url": "https://v.redd.it/aahxf9k2piha1"
        },
        {
            "author": "u/Tom_the_Tank_Train",
            "created_utc": "02-10-2023 20:52:11",
            "distinguished": null,
            "edited": false,
            "id": "10z96m2",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10z96m2",
            "nsfw": false,
            "num_comments": 2,
            "permalink": "/r/MachineLearning/comments/10z96m2/d_hierarchical_clustering_transforming_the/",
            "score": 7,
            "selftext": " Hi all, I have a question regarding interpreting the distance on a dendrogram generated via agglomerative hierarchical clustering with a Euclidean distance metric using the ward-variance minimization linkage (as stated in SciPy: [https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.linkage.html#scipy.cluster.hierarchy.linkage](https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.linkage.html#scipy.cluster.hierarchy.linkage)\n\n). From my understanding, the distance represents the square root of the difference of the error sum of squares of two clusters once they are merged minus the sum of the error sum of squares of each individual cluster. I am interested in performing a transformation at each cluster step (i.e., merging two clusters to make a larger one) so that the y-axis represents the mean distance between clusters instead, while still using the ward-variance minimization linkage to direct the algorithm.\n\nI think I have a solution to my issue, but I want to know if I am missing anything. In 1969, a paper by David Wishart titled \"An Algorithm for Hierarchical Classifications\" derives the coefficients so that the Ward method can be implemented using the Lance-Williams formula. However, in the paper, the following formula is given:\n\n&#x200B;\n\nhttps://preview.redd.it/mma2t7cltgha1.png?width=237&format=png&auto=webp&v=enabled&s=8e69c219dddd7e1330168889f032a7251605a04b\n\nwhere I\\_pq is the square of the metric used in SciPy, k\\_i is the number of data points in cluster i and d\\^2\\_pq is the square of the Euclidean distance between the means of clusters. From this formula, it seems that one can transform from the \"increase in variance space\" to the \"mean distance between clusters space\", while still using Ward-variance minimization in the clustering algorithm. From my research, it seems that this is true. I would greatly appreciate it if someone could confirm this or point out where the flaw in my understanding is. Thanks everyone.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Hierarchical Clustering - Transforming the Distance Axis",
            "upvote_ratio": 1.0,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10z96m2/d_hierarchical_clustering_transforming_the/"
        },
        {
            "author": "u/CeFurkan",
            "created_utc": "02-10-2023 18:45:27",
            "distinguished": null,
            "edited": "02-10-2023 19:47:03",
            "id": "10z6ke2",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10z6ke2",
            "nsfw": false,
            "num_comments": 13,
            "permalink": "/r/MachineLearning/comments/10z6ke2/d_best_available_text_to_speech_free_ai_model_out/",
            "score": 12,
            "selftext": "Greetings everyone.\n\nI am looking for the best text to speech AI model out there for english\n\nI am looking for links to the models you know as best\n\nIf the model supports subtitle file to speech that would be even more awesome\n\nLike providing .srt or .vtt to generate speech - speeding up the necessary parts of speech to fit into durations\n\nThank you very much again\n\nI will use this to replace audio of my older lecture recordings by providing a time generated manually corrected subtitle file like srt or vtt\n\nI am looking for any male sounding model that sounds natural\n\n&#x200B;\n\nI have found this\n\nThey colab and looks very easy to generate. I think I can automate it. But is this one the best?\n\n[https://www.reddit.com/r/MachineLearning/comments/v9rigf/p\\_silero\\_tts\\_full\\_v3\\_release/](https://www.reddit.com/r/MachineLearning/comments/v9rigf/p_silero_tts_full_v3_release/)\n\nfound this too but only female voice :/\n\n[https://www.reddit.com/r/MachineLearning/comments/ttgsr4/r\\_nixtts\\_an\\_incredibly\\_lightweight\\_texttospeech/](https://www.reddit.com/r/MachineLearning/comments/ttgsr4/r_nixtts_an_incredibly_lightweight_texttospeech/)\n\nI need a male voice\n\nany other good ones?\n\n&#x200B;",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Best available text to speech free AI model out there for english",
            "upvote_ratio": 0.8,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10z6ke2/d_best_available_text_to_speech_free_ai_model_out/"
        },
        {
            "author": "u/No_Oilve_6577",
            "created_utc": "02-10-2023 16:53:09",
            "distinguished": null,
            "edited": false,
            "id": "10z45c0",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10z45c0",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/10z45c0/d_is_efficientnet_same_as_mobilenetv2/",
            "score": 0,
            "selftext": "Quick question, is EfficientNet-V1 same as MobileNet-V2? I think they use the same backbone, the inverted linear residual block, no?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Is Efficient-Net same as MobileNetV2",
            "upvote_ratio": 0.5,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10z45c0/d_is_efficientnet_same_as_mobilenetv2/"
        },
        {
            "author": "u/MysteryInc152",
            "created_utc": "02-10-2023 15:51:33",
            "distinguished": null,
            "edited": false,
            "id": "10z2pej",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_10z2pej",
            "nsfw": false,
            "num_comments": 18,
            "permalink": "/r/MachineLearning/comments/10z2pej/r_large_language_models_can_teach_themselves_to/",
            "score": 141,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Large Language Models Can Teach Themselves to Use Tools",
            "upvote_ratio": 0.99,
            "url": "https://arxiv.org/abs/2302.04761"
        },
        {
            "author": "u/Tlaloc-Es",
            "created_utc": "02-10-2023 15:06:07",
            "distinguished": null,
            "edited": false,
            "id": "10z1jxz",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10z1jxz",
            "nsfw": false,
            "num_comments": 18,
            "permalink": "/r/MachineLearning/comments/10z1jxz/d_is_it_legal_to_use_images_or_videos_with/",
            "score": 11,
            "selftext": "Hello, I want to know if it is legal to use scraped video or images to train a predictive model, for example, If I scrape photos of faces in google, and after that, I share that model in order that a lot of people can detect faces in their applications, is that legal?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Is it legal to use images or videos with copyright to train a model?",
            "upvote_ratio": 0.83,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10z1jxz/d_is_it_legal_to_use_images_or_videos_with/"
        },
        {
            "author": "u/TikkunCreation",
            "created_utc": "02-10-2023 14:42:06",
            "distinguished": null,
            "edited": false,
            "id": "10z0xzl",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10z0xzl",
            "nsfw": false,
            "num_comments": 14,
            "permalink": "/r/MachineLearning/comments/10z0xzl/d_what_ml_or_mlpowered_projects_are_you_currently/",
            "score": 9,
            "selftext": "This would be for ones that aren't finished enough to post as a link on the weekend.\n\nJust things that are in progress.\n\nInclude a screenshot if you can!",
            "spoiler": false,
            "stickied": false,
            "title": "[D] What ML or ML-powered projects are you currently building?",
            "upvote_ratio": 0.72,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10z0xzl/d_what_ml_or_mlpowered_projects_are_you_currently/"
        },
        {
            "author": "u/gruevy",
            "created_utc": "02-10-2023 13:54:12",
            "distinguished": null,
            "edited": false,
            "id": "10yzq25",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10yzq25",
            "nsfw": false,
            "num_comments": 15,
            "permalink": "/r/MachineLearning/comments/10yzq25/d_locallyrunnable_text_to_speech_ai/",
            "score": 17,
            "selftext": "I've got a 4090 and some stuff that I think it would be fun to have narrated. I've looked at some of the paid online options and $20-$30/mo for 2 hours of AI TTS is not gonna gut it. Can anyone point me to software that I can run locally that'll give me high quality?\n\nIt seems like if people are making billions of waifus in stable diffusion there ought to be something like this out there.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Locally-runnable text to speech AI?",
            "upvote_ratio": 0.95,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10yzq25/d_locallyrunnable_text_to_speech_ai/"
        },
        {
            "author": "u/atulcst",
            "created_utc": "02-10-2023 13:52:27",
            "distinguished": null,
            "edited": false,
            "id": "10yzohn",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10yzohn",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/10yzohn/d_simulator_for_rl_problems/",
            "score": 0,
            "selftext": "I have seen people advocate a simulator for RL problems a lot. I am not sure by simulator what do they mean exactly? Is it the exact simulation (then the problem becomes easy) or some kind of feedback loop (start with a na\u00efve simulator and once we get data then keep improving the simulator \u2013 this looks similar to value iteration or policy iteration).\n\nI assume it\u2019s really difficult to get a simulator for data generation (except for video games etc.). Also, If we already have a simulator, we can easily train a model-free RL (e.g. just planning).",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Simulator for RL problems",
            "upvote_ratio": 0.33,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10yzohn/d_simulator_for_rl_problems/"
        },
        {
            "author": "u/RogueStargun",
            "created_utc": "02-10-2023 12:14:41",
            "distinguished": null,
            "edited": false,
            "id": "10yxc0k",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10yxc0k",
            "nsfw": false,
            "num_comments": 3,
            "permalink": "/r/MachineLearning/comments/10yxc0k/discussion_wasm_equivalant_to_gradio_but_without/",
            "score": 2,
            "selftext": "I'm really impressed with gradio for making interactive webapps. I was wondering... Gradio basically runs off a server so you have to standup a server just to demo certain kinds of apps.\n\nIs there something similar out that that can handle basic tabular data plots *without needing a server?* I was thinking perhaps something like a WASM app that can point to csvs on AWS S3 and generate plots on the fly?",
            "spoiler": false,
            "stickied": false,
            "title": "[Discussion] WASM equivalant to Gradio but without needing a server?",
            "upvote_ratio": 1.0,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10yxc0k/discussion_wasm_equivalant_to_gradio_but_without/"
        },
        {
            "author": "u/BackgroundPass2082",
            "created_utc": "02-10-2023 10:46:51",
            "distinguished": null,
            "edited": false,
            "id": "10yv962",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_10yv962",
            "nsfw": false,
            "num_comments": 3,
            "permalink": "/r/MachineLearning/comments/10yv962/p_did_anyone_manage_to_run_the_musiclm/",
            "score": 1,
            "selftext": "I really want to play with the repo but I'm stuck at the last step of the instructions ([https://github.com/lucidrains/musiclm-pytorch#usage-1](https://github.com/lucidrains/musiclm-pytorch#usage-1)). If anyone has tips, please let me know!\n\nHere's the issue I have: [https://github.com/lucidrains/musiclm-pytorch/issues/13](https://github.com/lucidrains/musiclm-pytorch/issues/13)",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Did anyone manage to run the MusicLM implementation from lucidrains?",
            "upvote_ratio": 0.6,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10yv962/p_did_anyone_manage_to_run_the_musiclm/"
        },
        {
            "author": "u/Mundane_Definition_8",
            "created_utc": "02-10-2023 10:46:41",
            "distinguished": null,
            "edited": false,
            "id": "10yv91l",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10yv91l",
            "nsfw": false,
            "num_comments": 2,
            "permalink": "/r/MachineLearning/comments/10yv91l/d_numbers_of_parameters_that_can_affect_on_a_model/",
            "score": 0,
            "selftext": "Hi guys, my question is what is different between parameters and FLOPs in terms of computation times.\n\nI know that the FLOPs is related to the computation of input images. For example, higher the size, higher the figure. \n\nBut, how much parameters can affect on a model compared to the metric?\n\nI understand that the weights, biases are parameters. But, the cost of computation about them makes me difficult to determine what should I get a specific model.\n\nI can measure the decision based on the FLOPs, which decrease time of training my model when they are lower.\nHowever, I also want to decide a specific model with the number of parameters.\n\nThanks.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] numbers of parameters that can affect on a model.",
            "upvote_ratio": 0.4,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10yv91l/d_numbers_of_parameters_that_can_affect_on_a_model/"
        },
        {
            "author": "u/AlesioRFM",
            "created_utc": "02-10-2023 08:32:53",
            "distinguished": null,
            "edited": false,
            "id": "10ys3md",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_10ys3md",
            "nsfw": false,
            "num_comments": 247,
            "permalink": "/r/MachineLearning/comments/10ys3md/p_im_using_instruct_gpt_to_show_anticlickbait/",
            "score": 2676,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[P] I'm using Instruct GPT to show anti-clickbait summaries on youtube videos",
            "upvote_ratio": 0.97,
            "url": "https://www.reddit.com/gallery/10ys3md"
        },
        {
            "author": "u/darcia_scientist",
            "created_utc": "02-10-2023 08:21:38",
            "distinguished": null,
            "edited": false,
            "id": "10yruoe",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10yruoe",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/10yruoe/d_experiences_finding_a_job_in_the_us_as_a/",
            "score": 0,
            "selftext": "Hi, I am considering moving to the US, and I was wondering about the job market for people in Mexico and the chances of getting an offer.\n\nI know that in theory, it should be 'easier' due to the United States\u2013Mexico\u2013Canada Agreement by getting a TN visa.\n\nAre there any Mexicans here that found a job in the US as a machine learning engineer/data scientist?\n\nWould anyone have a pointer?\n\nI'll obviously research companies and send my resumes, just thought of posting here to see what is the experience of other people.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Experiences finding a job in the US as a Mexican currently working in the UK",
            "upvote_ratio": 0.44,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10yruoe/d_experiences_finding_a_job_in_the_us_as_a/"
        },
        {
            "author": "u/Melodic_Secretary_42",
            "created_utc": "02-10-2023 04:25:12",
            "distinguished": null,
            "edited": false,
            "id": "10ymh4u",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_10ymh4u",
            "nsfw": false,
            "num_comments": 10,
            "permalink": "/r/MachineLearning/comments/10ymh4u/p_resume_parsing_cv_analysis/",
            "score": 5,
            "selftext": "Hi ! so for my final year project I will be working on a cv parser and matching cvs with job postings, I'm thinking about fine tuning LayoutLM on my cvs dataset( of 5000 resumes or so not yet labeled) to get the structure of a resume (contact info , skills , education , etc) and then combine it with NER to identify the details in each section (name , uni name , date of start etc ) . Is it good enough or should I take another approach ?  Or how would you tackle the problem ? feel free to share any ideas u have about this project Thank you !",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Resume parsing + Cv analysis",
            "upvote_ratio": 0.78,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10ymh4u/p_resume_parsing_cv_analysis/"
        },
        {
            "author": "u/BaosteelMetallurgy",
            "created_utc": "02-10-2023 03:30:50",
            "distinguished": null,
            "edited": false,
            "id": "10yks8z",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10yks8z",
            "nsfw": false,
            "num_comments": 2,
            "permalink": "/r/MachineLearning/comments/10yks8z/have_you_seen_ruber_slicing_d/",
            "score": 0,
            "selftext": "Rubber slices are different from brittle materials such as steel plates and plastics. Due to the \u201csticky and soft\u201d characteristics of rubber materials, the structure of the rubber slicer has its particularity.",
            "spoiler": false,
            "stickied": false,
            "title": "Have you seen ruber slicing? [D]",
            "upvote_ratio": 0.19,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10yks8z/have_you_seen_ruber_slicing_d/"
        },
        {
            "author": "u/narendra7799",
            "created_utc": "02-10-2023 01:50:41",
            "distinguished": null,
            "edited": false,
            "id": "10yimi8",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10yimi8",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/10yimi8/d_the_kaggle_book_book_by_konrad_banachewicz_and/",
            "score": 0,
            "selftext": "Does anyone have \"The Kaggle Book : Book by Konrad Banachewicz and Luca Massaron\" in pdf ?? Please share the link",
            "spoiler": false,
            "stickied": false,
            "title": "[D] The Kaggle Book : Book by Konrad Banachewicz and Luca Massaron",
            "upvote_ratio": 0.31,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10yimi8/d_the_kaggle_book_book_by_konrad_banachewicz_and/"
        },
        {
            "author": "u/fromnighttilldawn",
            "created_utc": "02-09-2023 23:02:56",
            "distinguished": null,
            "edited": false,
            "id": "10yfp35",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10yfp35",
            "nsfw": false,
            "num_comments": 38,
            "permalink": "/r/MachineLearning/comments/10yfp35/d_critique_of_statistics_research_from_machine/",
            "score": 39,
            "selftext": "I was just looking around at some paper published by statisticians, I couldn't help but notice that the flavor of their research is vastly different. For example, one researcher wrote about a dozen paper on LASSO alone over the span of a decade, whereas LASSO is just given a power point slide worth of attention in ML. Why is there such a disparity and a divergence in the aim of these disciplines? \n\nAre there some good critique of these research fields from each other's perspective (not just on the technical aspects)? Perhaps by someone who works in both?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Critique of statistics research from machine learning perspectives (and vice versa)?",
            "upvote_ratio": 0.83,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10yfp35/d_critique_of_statistics_research_from_machine/"
        },
        {
            "author": "u/Electrical-Collar-23",
            "created_utc": "02-09-2023 22:56:58",
            "distinguished": null,
            "edited": false,
            "id": "10yfkt8",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10yfkt8",
            "nsfw": false,
            "num_comments": 4,
            "permalink": "/r/MachineLearning/comments/10yfkt8/d_hugging_face_model/",
            "score": 0,
            "selftext": "Can someone suggest some models available on hugging face that i can use and play with and addon in my project??",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Hugging face model",
            "upvote_ratio": 0.06,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10yfkt8/d_hugging_face_model/"
        },
        {
            "author": "u/skn133229",
            "created_utc": "02-09-2023 21:05:02",
            "distinguished": null,
            "edited": false,
            "id": "10ydazz",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10ydazz",
            "nsfw": false,
            "num_comments": 2,
            "permalink": "/r/MachineLearning/comments/10ydazz/d_simple_tensorflow_model_predict_question/",
            "score": 0,
            "selftext": "I am working on a U-Net model using remotely sensed data as input. Training image size is 64x64 and model trained using tensorflow. My assumption has always been that the trained model has to be fed an input of 64x64. Interestingly, I discovered that using an image 128 x 128 at inference will work fine, so will a 96x96 image. How is tensorflow handling this? Is it using a 64x64 moving window? Or is it scaling down and to 64x64 and backup to the larger size? Predictions seem fine but I'd like to know what tensorflow is doing behind the scene so I know how to treat the output. Any thoughts?\n\nThanks.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Simple tensorflow model predict question",
            "upvote_ratio": 0.2,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10ydazz/d_simple_tensorflow_model_predict_question/"
        },
        {
            "author": "u/MysteryInc152",
            "created_utc": "02-09-2023 20:01:17",
            "distinguished": null,
            "edited": false,
            "id": "10ybxa2",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_10ybxa2",
            "nsfw": false,
            "num_comments": 9,
            "permalink": "/r/MachineLearning/comments/10ybxa2/r_theory_of_mind_may_have_spontaneously_emerged/",
            "score": 0,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Theory of Mind May Have Spontaneously Emerged in Large Language Models",
            "upvote_ratio": 0.47,
            "url": "https://arxiv.org/abs/2302.02083"
        },
        {
            "author": "u/ibraheemMmoosa",
            "created_utc": "02-09-2023 19:39:44",
            "distinguished": null,
            "edited": false,
            "id": "10ybgb3",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10ybgb3",
            "nsfw": false,
            "num_comments": 5,
            "permalink": "/r/MachineLearning/comments/10ybgb3/d_should_i_put_my_current_or_past_affiliation_on/",
            "score": 0,
            "selftext": "Hey guys. I have got a paper accepted to the EACL 2023 conference. When I was working on the paper I did not have any official affiliation. I was working as an independent researcher.\n\nI have started my PhD at PSU recently. I was wondering if I should use my current affiliation on the paper. I am the corresponding author for this paper. Also, I am planning to use my PSU address for all research communications from now on instead of my gmail address. So putting my PSU affiliation would make sense in that way.\n\nSo my question is, is it okay to use my current affiliation?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Should I put my current or past affiliation on my EACL paper?",
            "upvote_ratio": 0.33,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10ybgb3/d_should_i_put_my_current_or_past_affiliation_on/"
        },
        {
            "author": "u/These-Assignment-936",
            "created_utc": "02-09-2023 13:49:13",
            "distinguished": null,
            "edited": false,
            "id": "10y2mu0",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10y2mu0",
            "nsfw": false,
            "num_comments": 18,
            "permalink": "/r/MachineLearning/comments/10y2mu0/d_using_llms_as_decision_engines/",
            "score": 117,
            "selftext": "I just finished reading the paper \"Pre-Trained Language Models for Interactive Decision Making\" ([https://arxiv.org/abs/2202.01771](https://arxiv.org/abs/2202.01771)). As I understand it, the authors are using a language model to \"generate\" an optimal path to an objective, in test environments like VirtualHome and BabyAI. Reinforcement and imitation learning are evaluated as ways for the model to self-improve.\n\nThis is the first time I've seen a language model being used to \"solve a problem\" that isn't a language one. It seems to open up so many new possibilties. Has this been done before? Are there other examples of LMs being used as decision engines? What's the state of the art? Any interesting applications you've seen?\n\nSide question: I imagine there were AI approaches to navigating VirtualHome and BabyAI that were NOT language-model based. What is the standard modeling approach to these kinds of problems?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Using LLMs as decision engines",
            "upvote_ratio": 0.95,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10y2mu0/d_using_llms_as_decision_engines/"
        },
        {
            "author": "u/MyActualUserName99",
            "created_utc": "02-09-2023 13:41:02",
            "distinguished": null,
            "edited": false,
            "id": "10y2f1h",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10y2f1h",
            "nsfw": false,
            "num_comments": 5,
            "permalink": "/r/MachineLearning/comments/10y2f1h/d_plot_best_run_for_accuracy_or_mean_across_runs/",
            "score": 0,
            "selftext": "I've ran two image classification model 5 times on a dataset. Model A has a mean best accuracy of 95.03% while Model B has a mean best accuracy of 95.3% However, Model A has a max best accuracy of 95.75% while Model B has a mean best accuracy of 95.5%. I am wanting to report these results in a paper to a conference/journal. \n\nWhen plotting the test accuracy per epoch, should I only report the results for the best run or should I take the mean of the test accuracies over all 5 runs per epoch for plotting?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Plot Best Run for Accuracy or Mean across runs?",
            "upvote_ratio": 0.4,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10y2f1h/d_plot_best_run_for_accuracy_or_mean_across_runs/"
        },
        {
            "author": "u/fourcornerclub",
            "created_utc": "02-09-2023 12:31:16",
            "distinguished": null,
            "edited": false,
            "id": "10y0ksi",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10y0ksi",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/10y0ksi/discussion_looking_for_opinions_scale_spellbook/",
            "score": 0,
            "selftext": "Hey everyone. Has anyone used Snorkel Flow, Scale Spellbook or other alternatives (please advise) to test multiple foundation models and migrate between them? E.g. comparing GPT3 vs GPT-J or GPT-Neo etc. Need help moving to a smaller/cheaper model - cheers!",
            "spoiler": false,
            "stickied": false,
            "title": "[Discussion] Looking for opinions: Scale Spellbook vs. Snorkel Flow vs....?",
            "upvote_ratio": 0.33,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10y0ksi/discussion_looking_for_opinions_scale_spellbook/"
        },
        {
            "author": "u/TKMater",
            "created_utc": "02-09-2023 12:18:39",
            "distinguished": null,
            "edited": false,
            "id": "10y08vt",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10y08vt",
            "nsfw": false,
            "num_comments": 9,
            "permalink": "/r/MachineLearning/comments/10y08vt/d_similarity_bw_two_vectors/",
            "score": 0,
            "selftext": "how to calculate similarity between two vectors? I want a similarity metric that take into accounts both the directions and magnitudes of vectors.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Similarity b/w two vectors",
            "upvote_ratio": 0.3,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10y08vt/d_similarity_bw_two_vectors/"
        },
        {
            "author": "u/Basil1sk17",
            "created_utc": "02-09-2023 11:33:43",
            "distinguished": null,
            "edited": false,
            "id": "10xz47o",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10xz47o",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/10xz47o/d_storytelling_ai_that_i_could_feed_data_to_and/",
            "score": 5,
            "selftext": " Hello,\n\nI was wondering if there's a free or premium story-telling AI model that I could feed data to, for example, passages from a particular author or pages from their book, and then ask the AI to create a story using that author's writing style, dictionary, or ideas.\n\nA while ago I watched a Youtube video, in which a person taught an AI to write screenplays in the style of a certain author and I'd like to do the same, except with short stories. Is it possible to do so without any coding knowledge?\n\nThanks.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Story-telling AI that I could feed data to and then ask to write a similar replica?",
            "upvote_ratio": 0.73,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10xz47o/d_storytelling_ai_that_i_could_feed_data_to_and/"
        },
        {
            "author": "u/d0cmorris",
            "created_utc": "02-09-2023 10:45:47",
            "distinguished": null,
            "edited": false,
            "id": "10xxxpa",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10xxxpa",
            "nsfw": false,
            "num_comments": 9,
            "permalink": "/r/MachineLearning/comments/10xxxpa/d_constrained_optimization_in_deep_learning/",
            "score": 5,
            "selftext": "Clearly,  large scale deep learning approaches in image classification or NLP use  all sorts of Regularization mechanisms, but the parameters are  typically unconstrained (i.e., every weight can theoretically attain any  real value). In many Machine Learning domains, constrained optimization  (e.g. via Projected Gradient Descent or Frank-Wolfe) plays a huge role.\n\nI  was wondering whether there are large-scale Deep Learning applications  which rely on constrained optimization approaches? When I say  large-scale, I mean large CNNs, transformers, diffusion models or the  like. Are there settings where constrained optimization would even be a  preferred approach, but not efficient/stable enough?\n\nHappy for any paper suggestions or thoughts! Thanks!",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Constrained Optimization in Deep Learning",
            "upvote_ratio": 0.86,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10xxxpa/d_constrained_optimization_in_deep_learning/"
        },
        {
            "author": "u/PsyEclipse",
            "created_utc": "02-09-2023 10:44:36",
            "distinguished": null,
            "edited": false,
            "id": "10xxwoe",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10xxwoe",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/10xxwoe/d_latent_spaces_and_weather_forecastingnowcasting/",
            "score": 4,
            "selftext": "Hi, everyone. First time, long time.\n\n  \nMy background is weather analysis to DL applications in weather, and I had a question I wanted to ask the community writ large. The question is about latent spaces and how, specifically, the DeepMind group used them in their radar nowcasting model DGMR (see links to prior threads below).\n\nIn the DGMR paper itself ([https://www.nature.com/articles/s41586-021-03854-z](https://www.nature.com/articles/s41586-021-03854-z)), the architecture looks like a U-net with some ConvGRU2D flair in the decoder and some temporal consistency checks from the discriminator. There is also what they call a \"latent conditioning stack.\" From some deeper readings, I think the model is a descendant of BigGAN, since both use an explicit latent space among other similarities. This leads to my question and general curiosity...  \nHow is this latent space seeded? My prior experience with latent space toy models (DCGAN, for example) is that unless you seed the RNG explicitly, then performing a restart of the model to continue training mucks up the distribution. Fairly standard RNG issues.  \n\n\nIs it really as simple as, for example,\n\n    latent_vector = tf.random.truncated_normal([batch_size, grid_size_parameters], seed=42)\n\nI feel like I'm missing something. Why does this work at all? Why is a latent space necessary in this context? They state explicitly in their paper that they require this stack to generalize results to datasets that are larger (in a HxW sense) than the one on which they trained, but I can't wrap my head around why an extended latent vector for a larger grid size works.\n\nIf anyone can point me in the right direction or help me understand, I'd greatly appreciate it.\n\nLinks to prior threads:  \n[https://www.reddit.com/r/MachineLearning/comments/pyfjz7/r\\_deepminds\\_weather\\_forecasting\\_model\\_nowcasting/](https://www.reddit.com/r/MachineLearning/comments/pyfjz7/r_deepminds_weather_forecasting_model_nowcasting/)  \n[https://old.reddit.com/r/MachineLearning/comments/py0289/r\\_skilful\\_precipitation\\_nowcasting\\_using\\_deep/](https://old.reddit.com/r/MachineLearning/comments/py0289/r_skilful_precipitation_nowcasting_using_deep/)",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Latent spaces and weather forecasting/nowcasting",
            "upvote_ratio": 0.67,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10xxwoe/d_latent_spaces_and_weather_forecastingnowcasting/"
        },
        {
            "author": "u/RstarPhoneix",
            "created_utc": "02-09-2023 09:31:51",
            "distinguished": null,
            "edited": false,
            "id": "10xw5pr",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10xw5pr",
            "nsfw": false,
            "num_comments": 3,
            "permalink": "/r/MachineLearning/comments/10xw5pr/d_can_we_use_ray_for_distributed_training_on/",
            "score": 0,
            "selftext": "Same as title. Also the dataframe library should support machine learning libraries",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Can we use Ray for distributed training on vertex ai ? Can someone provide me examples for the same ? Also which dataframe libraries you guys used for training machine learning models on huge datasets (100 gb+) (because pandas can't handle huge data).",
            "upvote_ratio": 0.44,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10xw5pr/d_can_we_use_ray_for_distributed_training_on/"
        },
        {
            "author": "u/Available_Lion_652",
            "created_utc": "02-09-2023 07:52:06",
            "distinguished": null,
            "edited": false,
            "id": "10xu09v",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10xu09v",
            "nsfw": false,
            "num_comments": 12,
            "permalink": "/r/MachineLearning/comments/10xu09v/d_rtx_3090_with_i7_7700k_training_bottleneck/",
            "score": 4,
            "selftext": "Hey guys I have an older PC(5 years) with an i7 7700k processor. I want to buy an Nvidia RTX 3090 for training large language models. I can t find any benchmark for CPU bottleneck when training, let s say an GPT 2 large model. \nHas anyone have any experience with this set-up similar set-up ?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] RTX 3090 with i7 7700k, training bottleneck",
            "upvote_ratio": 0.75,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10xu09v/d_rtx_3090_with_i7_7700k_training_bottleneck/"
        },
        {
            "author": "u/dtransposed",
            "created_utc": "02-09-2023 07:20:34",
            "distinguished": null,
            "edited": "02-10-2023 16:21:56",
            "id": "10xten3",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_10xten3",
            "nsfw": false,
            "num_comments": 3,
            "permalink": "/r/MachineLearning/comments/10xten3/r_research_seminar_by_neural_magic_acdc/",
            "score": 14,
            "selftext": "At [Neural Magic](https://neuralmagic.com), we are proud to be at the forefront of cutting-edge machine learning research, with a particular focus on model compression. Our internal Lunch and Learn seminars are a weekly opportunity for our team to share their research and collaborate on new ideas. We believe in the importance of open-source contributions, which is why we are thrilled to announce that for a second time, we are opening the seminar to the wider community.\n\nOn February 23, 2023, I will be sharing our work on [AC/DC, a framework for sparse-training models](https://arxiv.org/abs/2106.12379).\n\nThis research was done in partnership with IST Austria. Join me and the Neural Magic team for this exciting presentation and be sure to keep an eye out for future speakers in the coming months!\n\n&#x200B;\n\nYou can reserve your spot for the presentation [here](https://neuralmagic.com/resources/webinars/use-a-sparse-training-algorithm-ac-dc-for-sota-neural-network-performance-and-accuracy/).",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Research Seminar by Neural Magic: AC/DC: Alternating Compressed/DeCompressed Training of Deep Neural Networks",
            "upvote_ratio": 0.8,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10xten3/r_research_seminar_by_neural_magic_acdc/"
        },
        {
            "author": "u/zanzagaes2",
            "created_utc": "02-09-2023 07:03:02",
            "distinguished": null,
            "edited": "02-09-2023 10:29:34",
            "id": "10xt36j",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_10xt36j",
            "nsfw": false,
            "num_comments": 15,
            "permalink": "/r/MachineLearning/comments/10xt36j/p_creating_an_embedding_from_a_cnn/",
            "score": 2,
            "selftext": "Hi all: I have trained a CNN (efficietnet-b3) to classify the degree of a disease on medical images. I would like to create an embedding both to visualize relationships between images (after projecting to 2d or 3d-space) and to find similar images to one given.\n\nI have tried using the output of the last convolution both before and after pooling for all train images (\\~30.000) but the result is mediocre: images non-alike are quite close in the embedding and plotting it in 2 or 3d just show a point cloud with no obvious pattern.\n\nI have also tried to use the class activation map (the output of the convolutional layer after pooling and multiplying by the weights of the classifier of the predicted class). This is quite better, but class are not separated too clearly in the scatterplot.\n\n**Is there any other sensible way to generate the embeddings?** I have tried using the hidden representation of earlier convolutional layers, but some of them are so huge (\\~650.000 features per sample) creating a reasonable sized embedding would require very aggressive PCA.\n\n&#x200B;\n\nExample of the scatter plot of the heatmap embedding. While it is okayish (classes are more or less spatially localized) it would be great to find an embedding that creates more visible clusters for each class.\n\nhttps://preview.redd.it/l7smdyuml6ha1.png?width=543&format=png&auto=webp&v=enabled&s=1c9a872ff73eea199e4977a1375303bcffe00158\n\n&#x200B;",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Creating an embedding from a CNN",
            "upvote_ratio": 0.6,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10xt36j/p_creating_an_embedding_from_a_cnn/"
        },
        {
            "author": "u/Smedskjaer",
            "created_utc": "02-09-2023 06:15:02",
            "distinguished": null,
            "edited": false,
            "id": "10xs9ty",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_10xs9ty",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/10xs9ty/project_text_cluster_of_mxn_dimensions_as/",
            "score": 1,
            "selftext": "I  have a text clustering project. It clusters texts in MxN dimensions. M  is a subset of N, where N is the total number of domains. The text  corpus is a set of academic papers. The clusters are cross disciplinary  subjects, defined by M. Clusters are identified by MANOVA tests of sets  of cross products. Goal is to identify texts of interest for research.  E.g. identify clusters of papers relevant to a combination of subjects,  or identify areas of research by their cluster, or identify outlier  research.\n\nThis is a N versus NP  problem. It requires a great deal of processing time to cluster texts. I  may do so for a corpus of 10k research papers, but that is a static  set, and papers cannot be appended to the corpus without affecting all  other clusters of the corpus. So I am considering creating a training  set of 10k papers, and writing an AI to identify and cluster texts  without comparing it to the rest of the corpus.\n\nI  want feedback and ideas. I wont specify what I am looking for yet,  because I am certain some of the responses here will point out something  I did not consider. So please, comment with your thoughts. Tell me what  you know. Give me your ideas.",
            "spoiler": false,
            "stickied": false,
            "title": "[PROJECT] Text cluster of MxN dimensions as training set for AI?",
            "upvote_ratio": 1.0,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10xs9ty/project_text_cluster_of_mxn_dimensions_as/"
        },
        {
            "author": "u/ThePerson654321",
            "created_utc": "02-09-2023 04:46:43",
            "distinguished": null,
            "edited": false,
            "id": "10xqtn2",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10xqtn2",
            "nsfw": false,
            "num_comments": 2,
            "permalink": "/r/MachineLearning/comments/10xqtn2/d_bees_a_new_unit_of_measurement_for_ml_model_size/",
            "score": 1,
            "selftext": "Would like to hear about what you guys think about [this](https://www.lesswrong.com/posts/YKfNZAmiLdepDngwi/gpt-175bee) approach?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Bees: a new unit of measurement for ML model size",
            "upvote_ratio": 0.52,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10xqtn2/d_bees_a_new_unit_of_measurement_for_ml_model_size/"
        },
        {
            "author": "u/pommedeterresautee",
            "created_utc": "02-09-2023 02:58:42",
            "distinguished": null,
            "edited": false,
            "id": "10xp54e",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_10xp54e",
            "nsfw": false,
            "num_comments": 34,
            "permalink": "/r/MachineLearning/comments/10xp54e/p_get_2x_faster_transcriptions_with_openai/",
            "score": 210,
            "selftext": "We are happy to announce the support of OpenAI Whisper model (ASR task) on Kernl.\u00a0\n\nWe focused on high quality transcription in a latency sensitive scenario, meaning:\n\n* *whisper-large-v2* weights\n* *beam search 5 (as recommended in the related paper)*\n\nWe measured a 2.3x speedup on Nvidia A100 GPU (2.4x on 3090 RTX) compared to Hugging Face implementation using FP16 mixed precision on transcribing librispeech test set (over 2600 examples). For now, OpenAI implementation is [not yet PyTorch 2.0 compliant](https://github.com/openai/whisper/pull/115).\n\nIn the post below, we discuss what worked (CUDA Graph), our tricks (to significantly reduce memory footprint), and what did not pay off (Flash attention and some other custom Triton kernels).\n\n* **Kernl repository**: [https://github.com/ELS-RD/kernl](https://github.com/ELS-RD/kernl)\n* **Reproduction script**: [https://github.com/ELS-RD/kernl/blob/main/experimental/whisper/speedup.ipynb](https://github.com/ELS-RD/kernl/blob/main/experimental/whisper/speedup.ipynb)\n\n# Unsung hero: CUDA graphs\n\nCUDA graphs technology provides most of the speed up. Compared to vanilla PyTorch 2.0 (\u201creduce-overhead mode\u201d), we provide a limited memory footprint when vanilla PyTorch 2.0 may raise OOM exception.\n\n[memory footprint](https://preview.redd.it/jyfayud5d4ha1.png?width=1598&format=png&auto=webp&v=enabled&s=79bd34de7dee5ef403b4cccc60785c322dfa38ec)\n\nExperiments have been run on a 3090 RTX with 24 Gb DDR. A reminder that PyTorch 2.0 focuses on training, not inference, which may explain why it OOMs rapidly in this case.\n\nAt its beginning, many partitioners were surprised by PyTorch eager mode performances, when compared to TensorFlow 1.x compiled models: they were on par! Python brought its flexibility and ease of debugging without implying any significant performance cost.\n\nThis is mostly because GPUs are latency hiding hardware: when PyTorch launches an operation on GPU, it sends instructions from host (CPU) to a queue (the CUDA stream), which allows PyTorch to continue Python script execution without having to wait for CUDA kernel to finish its work. This strategy effectively hides most of the Python overhead, in particular when there are some computation costly operations like convolutions or matrix multiplications.\n\nEach new generation of GPUs being much faster than its predecessor, this strategy could not last forever, according to one PyTorch maintainer, it is an \u201cexistential problem\u201d ([dev podcast](https://pytorch-dev-podcast.simplecast.com/episodes/pytorch-20), around 8mn30).\n\nIn inference mode, especially in latency-sensitive scenarios where batch size tends to be low, there is often little computation to perform (regarding what modern GPUs can do), making it even harder to hide effectively Python overhead. It\u2019s accentuated in the case of generative models like Whisper, because each decoder call focuses on generating a single token, and a part of the computation is cached for the next token.\n\nThis is a typical situation where CUDA graph is very helpful.\n\nThe main idea behind CUDA graph is that we can replace a series of instructions sent from host (CPU) to device (GPU) by one call referring to a graph of instruction stored in GPU. Check also this twitter [thread](https://twitter.com/cHHillee/status/1616906059368763392) for more explanations.\n\nFirst it will observe the inference of a model for specific input shapes and then replay it without going through most of the Python code.\n\nOne constraint is that it will replay the exact same operations with the exact same arguments.\n\nFor instance, memory addresses used by kernels are captured and therefore need to be static. For input tensors, it means that for each inference, we need to allocate some GPU memory and copy them there before the capture and copy all the following input tensors at the very same place.\n\nThe second constraint is that dynamic shapes are not supported by CUDA graph because it captures everything. We could have our own machinery in front of the model, but PyTorch 2.0 offers the right tooling to manage that point out of the box.\n\nBasically, dynamo offers a mechanism which checks if the model has already been captured for specific input shapes and some other states and capture it if not yet the case. You just have to provide a function which converts to CUDA graphs and you are done.\n\nOut of the box, PyTorch 2.0 provides a \u201creduce-overhead\u201d mode which applies CUDA graph to the model. Unfortunately, for now, it will raise an OOM with Whisper large or medium because it reserves some CUDA space for each input shape. Therefore, for a generative model it rapidly fulfills the GPU memory, in particular because of the K/V cache which can be huge.\n\nWe have worked around this constrain by building our own layer on top of the memory pool of PyTorch.\u00a0\n\nBasically, a PyTorch tensor is made of 2 parts, a CUDA allocated memory represented by PyTorch as a \u201cstorage\u201d, and a bunch of metadata associated with it. Among the metadata there is a CUDA memory address, the tensor shape plus its strides, its dtype and... a memory offset.\n\nOur idea is to create a very large tensor and share its storage between several input tensors, using offset metadata. With this solution, we avoid specializing in input tensor shapes and share the reserved memory for different input shapes related to several CUDA graphs.\n\nAs shown in the table above, it significantly reduces the memory overhead.\n\n# What about custom (Triton) kernels for attention?\n\n**TL; DR: we tried, they work, we got up to 2 times faster than eager PyTorch for cross attention and they bring close to nothing in e2e latency mostly because the improvement is not big enough to matter \ud83d\ude41**\n\nBelow, we follow the convention of naming Q, K and V, the 3 tensors used in the attention of transformer models.\n\nWhisper is based on a classic transformer architecture, with an encoder and a decoder.\n\nTwo characteristics of this model are of interest:\n\n* The shape of Q tensor used in cross-attention is always \\[batch, #heads, 1, 1500\\].\n* Model has been trained on 30-second audio files and their associated transcript. Because audio files are short, the sequence to generate is usually short, fewer than 50 tokens most of the time.\n\nBecause of these characteristics, optimizing attention has a low reward. In particular, the now common trick \u201creplace attention with flash attention\u201d is counterproductive:\n\n* self-attention: sequences are very short, so quadratic complexity is less of an issue;\n* cross-attention: using flash-attention leads to a 2 times slower inference on this part of the model.\n\nWe have tried to work on the second point and thought we could make cross attention faster.\n\nUsual attention implementation (self and cross) relies on a series of operations: matmul (Q x K\\^t) -> rescale -> SoftMax -> matmul (SoftMax output x V). Intermediate output tensors have a shape which usually scales quadratically with input sequence length. They will be saved and reloaded from DDR, and memory bandwidth is a very scarce resource in GPUs.\n\nTo optimize speed, flash attention fuses operations, so basically first matmul will work on a small part of Q and K, and directly apply SoftMax to it without saving intermediate results to DDR. Same for second matmul. Because we don't go and back through GPU main memory, flash attention usually runs much faster than na\u00efve implementation of attention.\n\nThe parallelization of the jobs is done on different axes: [batch and attention head for the original flash attention](https://github.com/HazyResearch/flash-attention/issues/40), and Triton author added a third one, tokens, aka third dimension of Q (this important trick is now also part of flash attention CUDA implementation).\n\nIn the Whisper latency sensitive case, this doesn\u2019t work well. The size of batches is low and sequence length (third dimension of Q tensor) is... 1! So, even if each job is done very efficiently, our GPU occupancy is low, and basically most of its streaming processors are idle. At the end of the day, the FA kernel is up to 2 times slower than eager PyTorch implementation (depending on batch size and model size).\n\n# Try 1: the very simple kernel\n\nWe noted that there is little computation to do and that we were memory bandwidth bounded. It means that most of the time we wait for data to be transferred from main memory to shared memory.\u00a0\n\nWe leveraged that fact in a very simple kernel with 2 optimizations:\n\n* after having finishing the rescale of the QK\\^t matmul, we perform the SoftMax computation in parallel of loading V tensor for the final matmul. The SoftMax computation finishes before the end of the V loading, so basically it costs us nothing;\n* to achieve best performances, we also changed the memory layout of V tensor in a way where we get a coalesced access, so we lowered the pressure on the memory bandwidth and increased instruction throughput (coalesced access let you load up to 128 bytes in a single instruction so you need less of them, which lets you perform more other things)\n\nAltogether this cross attention was up to 2x faster compared to eager. It appeared to bring between 5 to 20% in end-to-end benchmark depending on model size and batch size. Cool but far from being a game changer, it requires a modification specific to Whisper model (memory layout of V) which is not in the spirit of the Kernl library. We decided to search for another way of doing things (we kept the code in the library for possible future use case).\n\n# Try 2: Skinny Flash Attention\n\nOur second try is based on the very same trick as Flash Attention (parallel SoftMax) but is designed for tall and skinny tensors, which is inspired by split-k strategy in GEMM (a close cousin of the matmul). The main idea is to add a new parallelization axis over the 3rd dimension of K tensor. The next steps are in the same spirit as flash attention with a difference that we need a new reduction operation between the different jobs' outputs. It provides 5-10% speedup compared to eager implementation on this setup at kernel level. We kept that kernel to ease the next feature we are working on (quantization) but the effect in end-to-end latency is inferior to 5% (still it exists \ud83d\ude05).\n\nSome thoughts about PyTorch 2.0, Triton and making things much faster\n\nPlaying with PyTorch ~~1.14~~ 2.0 since this summer made us quite convinced that the major update to be released very soon will be a game changer for the ML field.\n\nFor inference (but also for training), the parallel with PyTorch vs TensorFlow is obvious to our eyes.\u00a0\n\nThe traditional way to deploy a model is to export it to Onnx, then to TensorRT plan format. Each step requires its own tooling, its own mental model, and may raise some issues. The most annoying thing is that you need Microsoft or Nvidia support to get the best performances, and sometimes model support takes time. For instance, T5, a model released in 2019, is not yet correctly supported on TensorRT, in particular K/V cache is missing ([soon it will be according to TensorRT maintainers](https://github.com/NVIDIA/TensorRT/issues/1845), but I wrote the very same thing almost 1 year ago and then 4 months ago so\u2026 I don\u2019t know).\n\nPyTorch 2.0 makes the graph capture step easy, it has been designed to work even if not everything is PyTorch compliant. With its Python first philosophy, it provides flexibility and debuggability.\u00a0\n\nSeveral years ago, some said that by design PyTorch can\u2019t be as performant than Tensorflow because of its eager execution model, compilation has to be faster. The same thing could be said for OnnxRuntime or TensorRT, they are C++ stuff, they have less overhead, etc. But at the end of the day, it's always the \u201cease of use\u201d which is decisive. Ease of use because of Python, but also because of the transparency in the process, Triton makes understanding and debugging kernels much easier than closed source TensorRT Myelin engine calling closed source cuBlas library.\n\nAnd of course, like TensorFlow, there will be many use cases where dedicated tools will be best choices, starting with situations where you can\u2019t deploy a Python interpreter.\n\nThe second lesson, Triton is easier to start with than CUDA, but you probably can\u2019t write or debug highly performant code without being able to, at least, read and debug PTX/SASS instructions. We realized that when we had some performance issues... The good news is that PTX is understandable, and you will probably spot unexpected generated code with some effort if there is any. Moreover, CUDA probably requires the same care when you really focus on performances.\n\nWe had plenty of issues with Triton, for example, cosmetics change in code may raise segfault. At some point you finish by having an intuition of what kinds of patterns to follow to make things work, in particular when there are for loops and dot operations. A new version of Triton has recently been released after a full rewrite of its backend, our little tests showed some improvement on stability but we have not yet fully switched.\n\nAs in my previous post, I highly recommend that readers start playing with Triton library, I rewrite it here: it\u2019s fun (at least when it doesn\u2019t segfault) and helps you to make sense of a large part of what is happening in ML engineering. I am quite convinced many flash attention like kernels are still to be written.\u00a0\n\n# Caveat\n\nTwo important things to note about the project described here:\n\n* CUDA graphs require us to capture a graph per input tensor shape, there is a non-negligible warmup time. We measure around 10mn on 2 different machines / GPUs (down from 50mn in our previous Kernl version). One user reported with the new version a bit more than 20mn of warmup time. We are aware of obvious ways to decrease it significantly.\n* The context here is latency sensitive optimization. In throughput sensitive one, just increasing batch size will bring you most of the speedup. Otherwise, more aggressive optimizations like quantization are required (not yet released on Kernl).",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Get 2x Faster Transcriptions with OpenAI Whisper Large on Kernl",
            "upvote_ratio": 0.95,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10xp54e/p_get_2x_faster_transcriptions_with_openai/"
        },
        {
            "author": "u/Acceptable_League160",
            "created_utc": "02-09-2023 00:35:02",
            "distinguished": null,
            "edited": false,
            "id": "10xmm87",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10xmm87",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/10xmm87/d_format_for_icml_tutorial_submission/",
            "score": 1,
            "selftext": "Hello!   \n\n\nI'm quite new to this. I was wondering what the right format is for submitting a successful tutorial proposal. Should I just use the LaTeX style files but modify the content for a tutorial proposal?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Format for ICML tutorial submission?",
            "upvote_ratio": 0.57,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10xmm87/d_format_for_icml_tutorial_submission/"
        },
        {
            "author": "u/These-Assignment-936",
            "created_utc": "02-08-2023 22:19:38",
            "distinguished": null,
            "edited": false,
            "id": "10xjwac",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10xjwac",
            "nsfw": false,
            "num_comments": 28,
            "permalink": "/r/MachineLearning/comments/10xjwac/d_are_there_emergent_abilities_of_image_models/",
            "score": 83,
            "selftext": "Just finished reading the Stanford/Google survey paper ([https://arxiv.org/abs/2206.07682](https://arxiv.org/abs/2206.07682)) on emergent abilities of large language models. It made me wonder: do image generation models have emergent abilities, too? Do we know?\n\nI can't quite wrap my head around what such an ability would even look like. Figured maybe other folks had given this a think.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Are there emergent abilities of image models?",
            "upvote_ratio": 0.92,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10xjwac/d_are_there_emergent_abilities_of_image_models/"
        },
        {
            "author": "u/CeFurkan",
            "created_utc": "02-08-2023 20:05:28",
            "distinguished": null,
            "edited": "02-09-2023 04:23:42",
            "id": "10xgvhj",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10xgvhj",
            "nsfw": false,
            "num_comments": 56,
            "permalink": "/r/MachineLearning/comments/10xgvhj/d_are_there_any_ai_model_that_i_can_use_to/",
            "score": 35,
            "selftext": "I have got old lecture recordings\n\nI want to improve their sound quality\n\nI have tested adobe AI noise removal but not very good\n\nI also tested descript studio sound not very good either\n\nI wonder if there are any public model, github repo, github project, hugging face repo that I can use to remove noise and improve sound quality of existing audio recordings?\n\nThank you so much for replies\n\nRecordings are in English\n\nHere example recording that needs to be cleaned 5 min audio : [https://sndup.net/stjs/](https://sndup.net/stjs/)\n\nfull lecture : [https://youtu.be/2zY1dQDGl3o](https://youtu.be/2zY1dQDGl3o)",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Are there any AI model that I can use to improve very bad quality sound recording? Removing noise and improving overall quality",
            "upvote_ratio": 0.83,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10xgvhj/d_are_there_any_ai_model_that_i_can_use_to/"
        },
        {
            "author": "u/gecko39",
            "created_utc": "02-08-2023 12:18:23",
            "distinguished": null,
            "edited": false,
            "id": "10x519c",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_10x519c",
            "nsfw": false,
            "num_comments": 10,
            "permalink": "/r/MachineLearning/comments/10x519c/r_pix2pixzero_zeroshot_imagetoimage_translation/",
            "score": 109,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] pix2pixzero - Zero-shot Image-to-Image Translation",
            "upvote_ratio": 0.97,
            "url": "https://arxiv.org/pdf/2302.03027.pdf"
        },
        {
            "author": "u/theanswerisnt42",
            "created_utc": "02-08-2023 06:02:18",
            "distinguished": null,
            "edited": false,
            "id": "10wtumf",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10wtumf",
            "nsfw": false,
            "num_comments": 12,
            "permalink": "/r/MachineLearning/comments/10wtumf/discussion_cognitive_science_inspired_ai_research/",
            "score": 9,
            "selftext": " I came across a few comments on this community about researchers developing AI algorithms inspired by ideas from neuroscience/cognition. I'd like to know how successful this approach has been in terms of coming up with new perspectives on problems.\n\nWhat are some of the key issues researchers are trying to address this way? What are some future directions in which research may progress?\n\nI have a rough idea that this could be one way to inspire sample efficient RL but I'd love to hear about other work that goes on in this area",
            "spoiler": false,
            "stickied": false,
            "title": "[Discussion] Cognitive science inspired AI research",
            "upvote_ratio": 0.81,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10wtumf/discussion_cognitive_science_inspired_ai_research/"
        },
        {
            "author": "u/C_l3b",
            "created_utc": "02-08-2023 03:36:46",
            "distinguished": null,
            "edited": false,
            "id": "10wrlrm",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10wrlrm",
            "nsfw": false,
            "num_comments": 19,
            "permalink": "/r/MachineLearning/comments/10wrlrm/d_list_of_rl_papers/",
            "score": 29,
            "selftext": "Hi, I want to open a thread about RL (non-deep and deep)\n\nWhat are the papers/books that are \"must read\" to have strong foundation?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] List of RL Papers",
            "upvote_ratio": 0.81,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10wrlrm/d_list_of_rl_papers/"
        },
        {
            "author": "u/Dweeberbob",
            "created_utc": "02-07-2023 22:58:51",
            "distinguished": null,
            "edited": false,
            "id": "10wmn7f",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_10wmn7f",
            "nsfw": false,
            "num_comments": 2,
            "permalink": "/r/MachineLearning/comments/10wmn7f/p_scriptsprograms_to_collect_baseline_logs/",
            "score": 2,
            "selftext": "Abit of a weird question. So I'm required to make & collect some clean (baseline) logs and dirty (malicious) logs for some mini-ML project I'm doing. So my question is, is there any scripts or programs out there, Linux or Windows, that allows the automation of mimicking an office staff doing work (ie. opening Outlook, sending emails, surfing the web, watching YouTube, opening and editing Word/Excel files, etc.) for the purpose of collecting baseline logs?\n\nI'm relative new to this kind of thing, if you guys have better suggestion on a more better/efficient way to do this, feel free to suggest!",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Scripts/Programs to collect Baseline Logs",
            "upvote_ratio": 0.67,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10wmn7f/p_scriptsprograms_to_collect_baseline_logs/"
        },
        {
            "author": "u/MLRecipes",
            "created_utc": "02-07-2023 20:27:14",
            "distinguished": null,
            "edited": false,
            "id": "10wjenb",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "News",
            "locked": false,
            "name": "t3_10wjenb",
            "nsfw": false,
            "num_comments": 6,
            "permalink": "/r/MachineLearning/comments/10wjenb/n_new_book_on_synthetic_data_version_30_just/",
            "score": 37,
            "selftext": "The book has considerably grown since version 1.0. It started with synthetic data as one of the main components, but also diving into explainable AI, intuitive / interpretable machine learning, and generative AI. Now with 272 pages (up from 156 in the first version), the focus is clearly on synthetic data. Of course, I still discuss explainable and generative AI: these concepts are strongly related to data synthetization.\n\n[Agent-based modeling in action](https://i.redd.it/snezvohkavga1.gif)\n\nHowever many new chapters have been added, covering various aspects of synthetic data \u2014 in particular working with more diversified real datasets, how to synthetize them, how to generate high quality random numbers with a very fast algorithm based on digits of irrational numbers, with visual illustrations and Python code in all chapters. In addition to agent-based modeling newly added, you will find material about\n\n* GAN \u2014 generative adversarial networks applied using methods other than neural networks.\n* GMM \u2014 Gaussian mixture models and alternatives based on multivariate stochastic and lattice processes.\n* The Hellinger distance and other metrics to measure the quality of your synthetic data, and the limitations of these metrics.\n* The use of copulas with detailed explanations on how it works, Python code, and application to mimicking a real dataset.\n* Drawbacks associated with synthetic data, in particular a tendency to replicate algorithm bias that synthetization is supposed to eliminate (and how to avoid this).\n* A technique somewhat similar to ensemble methods / tree boosting but specific to data synthetization, to further enhance the value of synthetic data when blended with real data; the goal is to make predictions more robust and applicable to a wider range of observations truly different from those in your original training set.\n* Synthetizing nearest neighbor and collision graphs, locally random permutations, shapes, and an introduction to AI-art\n\nNewly added applications include dealing with numerous data types and datasets, including ocean times in Dublin (synthetic time series), temperatures in the Chicago area (geospatial data) and the insurance data set (tabular data). I also included some material from the course that I teach on the subject.\n\nFor the time being, the book is available only in PDF format on my e-Store\u00a0[here](https://mltechniques.com/shop/), with numerous links, backlinks, index, glossary, large bibliography and navigation features to make it easy to browse. This book is a compact yet comprehensive resource on the topic, the first of its kind. The quality of the formatting and color illustrations is unusually high. I plan on adding new books in the future: the next one will be on chaotic dynamical systems with applications. However, the book on synthetic data has been accepted by a major publisher and a print version will be available. But it may take a while before it gets released, and the PDF version has useful features that can not be rendered well in print nor on devices such as Kindle. Once published in the computer science series with the publisher in question, the PDF version may no longer be available. You can check out the content on my GitHub repository,\u00a0[here](https://github.com/VincentGranville/Main/blob/main/MLbook4-extract.pdf)\u00a0where the Python code, sample chapters, and datasets also reside.",
            "spoiler": false,
            "stickied": false,
            "title": "[N] New Book on Synthetic Data\u200b: Version 3.0 Just Released",
            "upvote_ratio": 0.9,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10wjenb/n_new_book_on_synthetic_data_version_30_just/"
        },
        {
            "author": "u/erikaonline",
            "created_utc": "02-07-2023 17:42:58",
            "distinguished": null,
            "edited": false,
            "id": "10wfl8s",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10wfl8s",
            "nsfw": false,
            "num_comments": 4,
            "permalink": "/r/MachineLearning/comments/10wfl8s/discussion_can_an_amd_ryzen_5_3400g_computer_with/",
            "score": 0,
            "selftext": "I'm exploring the possibility of using my AMD Ryzen 5 3400G computer with 16GB of RAM to train an AI model. I'm curious to know if this setup is adequate for the task and, if so, what kind of AI models would be appropriate. I'm interested in understanding any limitations and drawbacks that I may face with this setup. If you have any relevant experience or information, I would greatly appreciate your participation in this discussion. Thanks! <3",
            "spoiler": false,
            "stickied": false,
            "title": "[Discussion] Can an AMD Ryzen 5 3400G computer with 16GB of RAM effectively train an AI model?",
            "upvote_ratio": 0.4,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10wfl8s/discussion_can_an_amd_ryzen_5_3400g_computer_with/"
        },
        {
            "author": "u/Optoplasm",
            "created_utc": "02-07-2023 17:36:38",
            "distinguished": null,
            "edited": false,
            "id": "10wffmg",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10wffmg",
            "nsfw": false,
            "num_comments": 6,
            "permalink": "/r/MachineLearning/comments/10wffmg/d_image_object_detection_but_for_1_dimensional/",
            "score": 0,
            "selftext": "I have had a lot of fun and success using YOLO and other image object detection models on 2D or 3D image data for personal projects.\n\nI am now working on some projects where I need to scan long periods of timeseries data and find specific waveforms that are variable durations. \n\nAre there techniques or models that function like YOLO that can scan large amounts of data and only highlight specific segments of interest as specific classes?\n\nIf it doesn\u2019t exist, I wonder how well the underlying CNN architecture of YOLO would translate to 1 dimensional CNN architectures. \n\nAny info is appreciated, thanks!",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Image object detection, but for 1 dimensional data?",
            "upvote_ratio": 0.5,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10wffmg/d_image_object_detection_but_for_1_dimensional/"
        },
        {
            "author": "u/geomtry",
            "created_utc": "02-07-2023 17:32:03",
            "distinguished": null,
            "edited": false,
            "id": "10wfbf9",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_10wfbf9",
            "nsfw": false,
            "num_comments": 15,
            "permalink": "/r/MachineLearning/comments/10wfbf9/p_best_way_to_add_a_sampling_step_within_a_neural/",
            "score": 2,
            "selftext": "I'm looking to combine two separate models together end-to-end, but need help understanding the best way to connect discrete parts.\n\nThe first part: I trained a classifier that given an input vector (512 dimensional) is able to predict one of twenty possible labels.\n\nThe second part: given an input label (from the previous classifier), embed the label and use that label to make a prediction.\n\nBoth models work decently, but I'm wondering if I can make this end-to-end and get some serious gains.\n\nTo do this, I'd need a way of sampling from the first softmax. Once I have a sample, I can get the embedding of the sampled class, continue as normal, and hopefully propagate the loss through everything.\n\nAre there any similar examples I can look at? Is there a term for this in the literature?",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Best way to add a sampling step within a neural network end-to-end?",
            "upvote_ratio": 0.67,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10wfbf9/p_best_way_to_add_a_sampling_step_within_a_neural/"
        },
        {
            "author": "u/dencan06",
            "created_utc": "02-07-2023 15:06:16",
            "distinguished": null,
            "edited": false,
            "id": "10wbm3q",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10wbm3q",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/10wbm3q/d_can_output_time_frame_cover_input_time_frame_in/",
            "score": 1,
            "selftext": "I recently had a disagreement with a friend and would like to hear other opinions. Say for a website, using the user actions for first week period, we want to predict total sales within 3 weeks. But one of the inputs is sales in the first week, so the output -total sales of 3 weeks- is including the sales in the first week. Is it ok to choose this output? Or should we adjust it in a way to prevent it from overlapping with the input time period and choose for ex. sales within 2 weeks after the first week for output What is the reasoning?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Can output time frame cover input time frame in machine learning?",
            "upvote_ratio": 1.0,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10wbm3q/d_can_output_time_frame_cover_input_time_frame_in/"
        },
        {
            "author": "u/currentscurrents",
            "created_utc": "02-07-2023 13:38:27",
            "distinguished": null,
            "edited": false,
            "id": "10w9en2",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "News",
            "locked": false,
            "name": "t3_10w9en2",
            "nsfw": false,
            "num_comments": 21,
            "permalink": "/r/MachineLearning/comments/10w9en2/n_microsoft_announces_new_nextgeneration_llm_will/",
            "score": 96,
            "selftext": "https://www.theverge.com/2023/2/7/23587454/microsoft-bing-edge-chatgpt-ai",
            "spoiler": false,
            "stickied": false,
            "title": "[N] Microsoft announces new \"next-generation\" LLM, will be integrated with Bing and Edge",
            "upvote_ratio": 0.95,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10w9en2/n_microsoft_announces_new_nextgeneration_llm_will/"
        }
    ]
}