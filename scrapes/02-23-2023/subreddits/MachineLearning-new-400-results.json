{
    "scrape_settings": {
        "subreddit": "MachineLearning",
        "category": "new",
        "n_results_or_keywords": "400",
        "time_filter": null
    },
    "data": [
        {
            "author": "u/Seankala",
            "created_utc": "02-22-2023 22:41:09",
            "distinguished": null,
            "edited": false,
            "id": "119onf8",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_119onf8",
            "nsfw": false,
            "num_comments": 2,
            "permalink": "/r/MachineLearning/comments/119onf8/d_145m15m_is_the_smallest_number_of_parameters_i/",
            "score": 5,
            "selftext": "The ELECTRA paper introduces a small version that has around 15M parameters. MobileBERT and TinyBERT also have around the same number of parameters.\n\nAre there any other language models out there that are smaller? Would it be possible to further distill large models into smaller variants?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] 14.5M-15M is the smallest number of parameters I could find for current pretrained language models. Are there any that are smaller?",
            "upvote_ratio": 1.0,
            "url": "https://www.reddit.com/r/MachineLearning/comments/119onf8/d_145m15m_is_the_smallest_number_of_parameters_i/"
        },
        {
            "author": "u/dmart89",
            "created_utc": "02-22-2023 22:15:46",
            "distinguished": null,
            "edited": false,
            "id": "119o54q",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_119o54q",
            "nsfw": false,
            "num_comments": 3,
            "permalink": "/r/MachineLearning/comments/119o54q/d_python_library_to_collect_structured_datasets/",
            "score": 2,
            "selftext": "I'm thinking about building an open source library to generate structured ml datasets from sources across the internet.\n\nI know that lots of projects utilise crawlers to get decent datasets, while you might still need to create your own for specific use cases I'm wondering whether it'd be useful to have an open source library that lets you launch crawlers with predefined schemas for popular sources like LinkedIn, YouTube (I know yt also has an api), shopify stores, twitter, reddit, news sites and more.\n\nKind of like a unified interface with extendable starter templates.\n\nThe lib would dump json objects into a location you specify, like your local machine, mongo, or s3.\n\nSomething like:\n\n\n`{\n     title: some video,\n     source: https//youtube.com/jfg78,\n     views: 245676,\n     comments: {}\n`\n\nGoal would be to make it easier/faster to get datasets from sources that don't natively have an api.\n\nThis might be a useless idea, but would love to hear your thoughts.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Python library to collect structured datasets across the internet",
            "upvote_ratio": 0.75,
            "url": "https://www.reddit.com/r/MachineLearning/comments/119o54q/d_python_library_to_collect_structured_datasets/"
        },
        {
            "author": "u/chigur86",
            "created_utc": "02-22-2023 13:55:06",
            "distinguished": null,
            "edited": false,
            "id": "119a32e",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_119a32e",
            "nsfw": false,
            "num_comments": 2,
            "permalink": "/r/MachineLearning/comments/119a32e/d_open_source_version_of_flamingo/",
            "score": 11,
            "selftext": "At this point we have open source LLM's, text-to-image models, and CLIP-like models but nothing similar to Flamingo. I am guessing some groups have already started working on this, but I just don't know them. Does anyone know? Looks like a great fit for [LAION](https://laion.ai/). Also, I have some experience in this area and wouldn't mind lending a hand if that's possible. I really want to get my hands on a Flamingo-like large, multi-modal, few-shot model to see how it performs on vision-language compositionally tasks like [Winoground](https://arxiv.org/abs/2204.03162). I am guessing these models might do a lot better than their smaller counterparts owing better generalization and reasoning capabilities of LLMs.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Open source version of Flamingo",
            "upvote_ratio": 1.0,
            "url": "https://www.reddit.com/r/MachineLearning/comments/119a32e/d_open_source_version_of_flamingo/"
        },
        {
            "author": "u/Wiskkey",
            "created_utc": "02-22-2023 13:19:02",
            "distinguished": null,
            "edited": "02-22-2023 18:54:45",
            "id": "1198k5j",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "News",
            "locked": false,
            "name": "t3_1198k5j",
            "nsfw": false,
            "num_comments": 5,
            "permalink": "/r/MachineLearning/comments/1198k5j/n_us_copyright_office_decides_that_kris/",
            "score": 9,
            "selftext": "[Letter from the U.S. Copyright Office](https://www.copyright.gov/docs/zarya-of-the-dawn.pdf) (PDF file).\n\n[Blog post from Kris Kashtanova's lawyer](https://processmechanics.com/2023/02/22/a-mixed-decision-from-the-us-copyright-office/).\n\n>We received the decision today relative to Kristina Kashtanova's case about the comic book Zarya of the Dawn. Kris will keep the copyright registration, but it will be limited to the text and the whole work as a compilation.  \n>  \n>In one sense this is a success, in that the registration is still valid and active. However, it is the most limited a copyright registration can be and it doesn't resolve the core questions about copyright in AI-assisted works. Those works may be copyrightable, but the USCO did not find them so in this case.\n\n[My previous post about this case](https://www.reddit.com/r/COPYRIGHT/comments/xkkh3d/us_copyright_office_registers_a_heavily/).\n\nRelated news: [\"The Copyright Office indicated in another filing that they are preparing guidance on AI-assisted art.\\[...\\]\"](https://www.reddit.com/r/StableDiffusion/comments/114pobl/tweet_from_a_person_whose_aiinvolved_graphic/).",
            "spoiler": false,
            "stickied": false,
            "title": "[N] U.S. Copyright Office decides that Kris Kashtanova's AI-involved graphic novel will remain copyright registered, but the copyright protection will be limited to the text and the whole work as a compilation",
            "upvote_ratio": 0.91,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1198k5j/n_us_copyright_office_decides_that_kris/"
        },
        {
            "author": "u/eamonnkeogh",
            "created_utc": "02-22-2023 12:29:40",
            "distinguished": null,
            "edited": false,
            "id": "11977iy",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "News",
            "locked": false,
            "name": "t3_11977iy",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/11977iy/n_crowdsourcing_better_names_for_the_catch22_time/",
            "score": 6,
            "selftext": "Dear Colleagues\n\nThis posting may be of interest to folks that use Catch22 for their time series research.\n\n**What is the problem?**\n\n* Catch22 is a wonderfully useful tool for time series...\n* But the names of the features, for example `SC_FluctAnal_2_dfa_50_1_2_logi_prop_r1` or `SB_TransitionMatrix_3ac_sumdiagcov` are awkward to use and have little mnemonic value.\n* Moreover, some of the names are very easy to confuse, such as: `DN_OutlierInclude_n_001_mdrmd` and `DN_OutlierInclude_p_001_mdrmd`\n*  This makes Catch22 awkward to use with a conversational agent, or many explainability/interpretability techniques etc.\n* Their long length means it is even awkward to discuss features in a two-column paper format.\n\nThus, we propose to find a set of new *meaningful* names for the features.\n\n**Design principles**\n\n* The name should reflect what a feature is sensitive to. Ideal names would be one word, for example: `noise`, `spike`, `symmetric`, `step`, `falling`, `periodic`, `simple`, `smooth`, `linear` etc.\n* However, given that it is likely to be rare a single feature has such specificity, the name could be a compound word, for example: `uniform-noise`, `localized-noise`, `positive-spike`, `negative-spike` etc.\n* Compound words with three parts might be acceptable, i.e. `fall-then-rise`, however beyond three parts would be undesirable.\n* <*Please suggest design principles we may have missed*\\>\n\nIn \\[a\\] we have a visual summary of the above, and one tentative worked example. We look forward to the community\u2019s input.\n\nMany thanks\n\nKeogh's Lab\n\n\\[a\\] PDF: [https://www.dropbox.com/s/n1aybeps5p2ho5k/Finding%20Better%20Names%20for%20the%20Catch22%20Features.pdf?dl=0](https://www.dropbox.com/s/n1aybeps5p2ho5k/Finding%20Better%20Names%20for%20the%20Catch22%20Features.pdf?dl=0)\n\nPPT: [https://www.dropbox.com/s/kxodalw2beyz86j/Finding%20Better%20Names%20for%20the%20Catch22%20Features.pptx?dl=0](https://www.dropbox.com/s/kxodalw2beyz86j/Finding%20Better%20Names%20for%20the%20Catch22%20Features.pptx?dl=0)",
            "spoiler": false,
            "stickied": false,
            "title": "[N] Crowdsourcing better names for the Catch22 time series features",
            "upvote_ratio": 0.8,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11977iy/n_crowdsourcing_better_names_for_the_catch22_time/"
        },
        {
            "author": "u/anishathalye",
            "created_utc": "02-22-2023 11:00:26",
            "distinguished": null,
            "edited": false,
            "id": "1194wm0",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_1194wm0",
            "nsfw": false,
            "num_comments": 8,
            "permalink": "/r/MachineLearning/comments/1194wm0/p_mit_introduction_to_datacentric_ai/",
            "score": 246,
            "selftext": "Announcing the [first-ever course on Data-Centric AI](https://dcai.csail.mit.edu/). Learn how to train better ML models by improving the data.\n\n[Course homepage](https://dcai.csail.mit.edu/) | [Lecture videos on YouTube](https://www.youtube.com/watch?v=ayzOzZGHZy4&list=PLnSYPjg2dHQKdig0vVbN-ZnEU0yNJ1mo5) | [Lab Assignments](https://github.com/dcai-course/dcai-lab)\n\nThe course covers:\n\n- [Data-Centric AI vs. Model-Centric AI](https://dcai.csail.mit.edu/lectures/data-centric-model-centric/)\n- [Label Errors](https://dcai.csail.mit.edu/lectures/label-errors/)\n- [Dataset Creation and Curation](https://dcai.csail.mit.edu/lectures/dataset-creation-curation/)\n- [Data-centric Evaluation of ML Models](https://dcai.csail.mit.edu/lectures/data-centric-evaluation/)\n- [Class Imbalance, Outliers, and Distribution Shift](https://dcai.csail.mit.edu/lectures/imbalance-outliers-shift/)\n- [Growing or Compressing Datasets](https://dcai.csail.mit.edu/lectures/growing-compressing-datasets/)\n- [Interpretability in Data-Centric ML](https://dcai.csail.mit.edu/lectures/interpretable-features/)\n- [Encoding Human Priors: Data Augmentation and Prompt Engineering](https://dcai.csail.mit.edu/lectures/human-priors/)\n- [Data Privacy and Security](https://dcai.csail.mit.edu/lectures/data-privacy-security/)\n\nMIT, like most universities, has many courses on machine learning (6.036, 6.867, and many others). Those classes teach techniques to produce effective models for a given dataset, and the classes focus heavily on the mathematical details of models rather than practical applications. However, in real-world applications of ML, the dataset is not fixed, and focusing on improving the data often gives better results than improving the model. We\u2019ve personally seen this time and time again in our applied ML work as well as our research.\n\nData-Centric AI (DCAI) is an emerging science that studies techniques to improve datasets in a systematic/algorithmic way \u2014\u00a0given that this topic wasn\u2019t covered in the standard curriculum, we (a group of PhD candidates and grads) thought that we should put together a new class! We taught this intensive 2-week course in January over MIT\u2019s IAP term, and we\u2019ve just published all the course material, including lecture videos, lecture notes, hands-on lab assignments, and lab solutions, in hopes that people outside the MIT community would find these resources useful.\n\nWe\u2019d be happy to answer any questions related to the class or DCAI in general, and we\u2019d love to hear any feedback on how we can improve the course material. Introduction to Data-Centric AI is open-source opencourseware, so feel free to make improvements directly: [https://github.com/dcai-course/dcai-course](https://github.com/dcai-course/dcai-course).",
            "spoiler": false,
            "stickied": false,
            "title": "[P] MIT Introduction to Data-Centric AI",
            "upvote_ratio": 0.96,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1194wm0/p_mit_introduction_to_datacentric_ai/"
        },
        {
            "author": "u/_learn_faster_",
            "created_utc": "02-22-2023 10:59:01",
            "distinguished": null,
            "edited": false,
            "id": "1194vcc",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_1194vcc",
            "nsfw": false,
            "num_comments": 3,
            "permalink": "/r/MachineLearning/comments/1194vcc/d_faster_flant5_inference/",
            "score": 3,
            "selftext": "What's the best way to improve the **inference** speed of a **Flan-T5** model?  \n\nOnnx runtime doesn't seem to work for T5 models & Torchscript also doesn't seem to help speed it up (not sure why!)",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Faster Flan-T5 inference",
            "upvote_ratio": 0.71,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1194vcc/d_faster_flant5_inference/"
        },
        {
            "author": "u/vyasnikhil96",
            "created_utc": "02-22-2023 08:22:26",
            "distinguished": null,
            "edited": false,
            "id": "1190lw8",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_1190lw8",
            "nsfw": false,
            "num_comments": 20,
            "permalink": "/r/MachineLearning/comments/1190lw8/r_provable_copyright_protection_for_generative/",
            "score": 17,
            "selftext": "Hi everyone, in a new paper we give a way to certify that a generative model does not infringe on the copyright of data that was in its training set.\n\nTwitter thread: https://twitter.com/boazbaraktcs/status/1628219647651729409\n\nBlogpost: https://windowsontheory.org/2023/02/21/provable-copyright-protection-for-generative-models/\n\nPaper: https://arxiv.org/abs/2302.10870\n\nAbstract:\n>There is a growing concern that learned conditional generative models may output samples that are substantially similar to some copyrighted data C that was in their training set. We give a formal definition of near access-freeness (NAF) and prove bounds on the probability that a model satisfying this definition outputs a sample similar to C, even if C is included in its training set. Roughly speaking, a generative model p is k-NAF if for every potentially copyrighted data C, the output of p diverges by at most k-bits from the output of a model q that did not access C at all. We also give generative model learning algorithms, which efficiently modify the original generative model learning algorithm in a black box manner, that output generative models with strong bounds on the probability of sampling protected content. Furthermore, we provide promising experiments for both language (transformers) and image (diffusion) generative models, showing minimal degradation in output quality while ensuring strong protections against sampling protected content.",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Provable Copyright Protection for Generative Models",
            "upvote_ratio": 0.7,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1190lw8/r_provable_copyright_protection_for_generative/"
        },
        {
            "author": "u/zx2zx",
            "created_utc": "02-22-2023 05:59:19",
            "distinguished": null,
            "edited": false,
            "id": "118wcki",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_118wcki",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/118wcki/p_discretization_equalwidth_trumps_equalfrequency/",
            "score": 1,
            "selftext": "So it seems in this test of the four popular scikit-learn datasets. \n\nThe test uses as judging criteria the accuracy reported by a special classifier.\nIn two of the datasets (iris and digits) the equal-width method markedly outperforms equal-frequency. In the other two datasets evaluated the differences are much narrower and could be considered as a tie result. The observations appear to be rather consistent when varying the number of bins used to discretize the attribute values.\n\nThis seems counter-intuitive; equal-frequency should have an advantage by providing better immunity in the presence of outliers. \n\nAny thoughts?\n\nThe used classifier, \"deodel\", discretizes continuous attributes using one of the two methods. After discretization, it behaves like a Hamming distance nearest neighbor classifier.\n\nThe equal-width and equal-frequency are methods that are referred to as unsupervised methods. Supervised methods take into account the training output in order to establish the thresholds for the bins. In the selected output, the decision tree classifier is used as a proxy for such methods. Although the deodel classifier can be seen as a collapsed decision tree, the algorithms differ and comparison is not straightforward. \n\nYou can easily modify the code and test it with other datasets. If you do, please share your findings. The code is available at:\n\n\nhttps://github.com/c4pub/deodel\n\n\nHere is the summarized output:\n\n    - - - - - - - - - \n    accuracy  classifier\n\n    - - - - dataset: .. _iris\n\n    0.946800  DecisionTreeClassifier() \n\n    0.544400  DeodelClassifier({'split_no': 2, 'mode': 'eq_freq'}) \n    0.719999  DeodelClassifier({'split_no': 2, 'mode': 'eq_width'}) \n\n    0.788000  DeodelClassifier({'split_no': 3, 'mode': 'eq_freq'}) \n    0.944000  DeodelClassifier({'split_no': 3, 'mode': 'eq_width'}) \n\n    0.779999  DeodelClassifier({'split_no': 5, 'mode': 'eq_freq'}) \n    0.930800  DeodelClassifier({'split_no': 5, 'mode': 'eq_width'}) \n\n    0.8556    DeodelClassifier({'split_no': 10, 'mode': 'eq_freq'}) \n    0.936     DeodelClassifier({'split_no': 10, 'mode': 'eq_width'}) \n\n    - - - - dataset: .. _digits\n     \n    0.844974  DecisionTreeClassifier() \n\n    0.671686  DeodelClassifier({'split_no': 2, 'mode': 'eq_freq'}) \n    0.947178  DeodelClassifier({'split_no': 2, 'mode': 'eq_width'}) \n\n    0.674123  DeodelClassifier({'split_no': 3, 'mode': 'eq_freq'}) \n    0.946577  DeodelClassifier({'split_no': 3, 'mode': 'eq_width'}) \n\n    0.694323  DeodelClassifier({'split_no': 5, 'mode': 'eq_freq'}) \n    0.938063  DeodelClassifier({'split_no': 5, 'mode': 'eq_width'}) \n\n    0.723939  DeodelClassifier({'split_no': 10, 'mode': 'eq_freq'}) \n    0.910050  DeodelClassifier({'split_no': 10, 'mode': 'eq_width'}) \n\n    - - - - dataset: .. _breast_cancer\n\n    0.923052  DecisionTreeClassifier() \n\n    0.921684  DeodelClassifier({'split_no': 2, 'mode': 'eq_freq'}) \n    0.913473  DeodelClassifier({'split_no': 2, 'mode': 'eq_width'}) \n\n    0.939473  DeodelClassifier({'split_no': 3, 'mode': 'eq_freq'}) \n    0.940105  DeodelClassifier({'split_no': 3, 'mode': 'eq_width'}) \n\n    0.942315  DeodelClassifier({'split_no': 5, 'mode': 'eq_freq'}) \n    0.940315  DeodelClassifier({'split_no': 5, 'mode': 'eq_width'}) \n\n    0.942105  DeodelClassifier({'split_no': 10, 'mode': 'eq_freq'}) \n    0.936315  DeodelClassifier({'split_no': 10, 'mode': 'eq_width'}) \n\n    - - - - dataset: .. _wine\n\n    0.909666  DecisionTreeClassifier() \n\n    0.875999  DeodelClassifier({'split_no': 2, 'mode': 'eq_freq'}) \n    0.889999  DeodelClassifier({'split_no': 2, 'mode': 'eq_width'}) \n\n    0.927999  DeodelClassifier({'split_no': 3, 'mode': 'eq_freq'}) \n    0.925666  DeodelClassifier({'split_no': 3, 'mode': 'eq_width'}) \n\n    0.943333  DeodelClassifier({'split_no': 5, 'mode': 'eq_freq'}) \n    0.947000  DeodelClassifier({'split_no': 5, 'mode': 'eq_width'}) \n\n    0.935666  DeodelClassifier({'split_no': 10, 'mode': 'eq_freq'}) \n    0.934333  DeodelClassifier({'split_no': 10, 'mode': 'eq_width'}) \n\n    - - - - - - - - -",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Discretization: equal-width trumps equal-frequency?",
            "upvote_ratio": 0.6,
            "url": "https://www.reddit.com/r/MachineLearning/comments/118wcki/p_discretization_equalwidth_trumps_equalfrequency/"
        },
        {
            "author": "u/like_a_tensor",
            "created_utc": "02-22-2023 02:31:40",
            "distinguished": null,
            "edited": false,
            "id": "118syc4",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_118syc4",
            "nsfw": false,
            "num_comments": 3,
            "permalink": "/r/MachineLearning/comments/118syc4/d_visualizing_layer_weights/",
            "score": 3,
            "selftext": "I was reading [this](https://openreview.net/pdf?id=J_F_qqCE3Z5) paper, and I really liked the visualization of the conv layer weights in Figure 5. It's similar to the figures in [this talk at Microsoft](https://www.youtube.com/watch?v=EvAVCxZJN2U) at 11:25. Does anyone know what this visualization is called and/or methods to use it?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Visualizing layer weights",
            "upvote_ratio": 0.8,
            "url": "https://www.reddit.com/r/MachineLearning/comments/118syc4/d_visualizing_layer_weights/"
        },
        {
            "author": "u/GraciousReformer",
            "created_utc": "02-21-2023 23:12:30",
            "distinguished": null,
            "edited": false,
            "id": "118pof6",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_118pof6",
            "nsfw": false,
            "num_comments": 107,
            "permalink": "/r/MachineLearning/comments/118pof6/d_deep_learning_is_the_only_thing_that_currently/",
            "score": 115,
            "selftext": " \"Deep learning is the only thing that currently works at scale it's the only class of algorithms that is able to discover arbitrary functions in a reasonable amount of time.\"\n\n[https://www.youtube.com/watch?v=p-OYPRhqRCg](https://www.youtube.com/watch?v=p-OYPRhqRCg)\n\nI know of the universal approximation theorem. But is there any mathematical formulation of this statement?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] \"Deep learning is the only thing that currently works at scale\"",
            "upvote_ratio": 0.8,
            "url": "https://www.reddit.com/r/MachineLearning/comments/118pof6/d_deep_learning_is_the_only_thing_that_currently/"
        },
        {
            "author": "u/currentscurrents",
            "created_utc": "02-21-2023 20:34:51",
            "distinguished": null,
            "edited": "02-21-2023 23:17:32",
            "id": "118mm43",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_118mm43",
            "nsfw": false,
            "num_comments": 3,
            "permalink": "/r/MachineLearning/comments/118mm43/r_running_evolution_as_an_optimization_process_on/",
            "score": 10,
            "selftext": "[Not published in an open journal sadly.](https://www.science.org/doi/10.1126/science.1250939) \n\n[Press release.](https://www.rc.fas.harvard.edu/news-home/feature-stories/evolution-yeast/) \n\nTL;DR they set up a loss function (fastest growing survives) and evolved a bunch of yeast cells towards that loss function. This is a classic experiment, but they sequenced the DNA at each step and got a lot of cool data. The yeast cells converged much like you'd expect from an optimizer:\n\n>The results of the experiment showed that in a controlled environment, evolutionary contingency led to convergence rather than divergence at the fitness level. Simply put, while the various yeast strains did mutate in different ways, they all arrived at a similar evolutionary endpoint regardless of their mutations.\n\n\nI wonder if you could do this more quickly using gradient descent or other algorithms from machine learning. Since they're already sequencing the DNA at each step, they could have estimated the gradient and edited it back into the yeast. It would likely converge on similar solutions, but faster.",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Running evolution as an optimization process on yeast cells",
            "upvote_ratio": 0.78,
            "url": "https://www.reddit.com/r/MachineLearning/comments/118mm43/r_running_evolution_as_an_optimization_process_on/"
        },
        {
            "author": "u/thomasahle",
            "created_utc": "02-21-2023 16:04:57",
            "distinguished": null,
            "edited": false,
            "id": "118gie9",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_118gie9",
            "nsfw": false,
            "num_comments": 6,
            "permalink": "/r/MachineLearning/comments/118gie9/unit_normalization_instead_of_crossentropy_loss/",
            "score": 6,
            "selftext": "Cross entropy on logits is a normal simplification that fuses softmax + cross entropy loss to something like:\n```\ndef label_cross_entropy_on_logits(x, labels):\n    return (-x.select(labels) + x.logsumexp(axis=1)).sum(axis=0)\n```\nwhere `x.select(labels) = x[range(batch_size), labels]`.\n\nI was thinking about how the `logsumexp` term looks like a regularization term, and wondered what would happen if I just replaced it by `x.norm(axis=1)` instead. It seemed to work just as well as the original, so I thought, why not just enforce unit norm?\n\nI changed my code to\n```\ndef label_cross_entropy_on_logits(x, labels):\n    return -(x.select(labels) / x.norm(axis=1)).sum(axis=0)\n```\nand my training sped up dramatically, and my test loss decreased.\n\nI'm sure this is a standard approach to categorical loss, but I haven't seen it before, and would love to get some references.\n\nI found this old post: https://www.reddit.com/r/MachineLearning/comments/k6ff4w/unit_normalization_crossentropy_loss_outperforms/ which references LogitNormalization: https://arxiv.org/pdf/2205.09310.pdf However, it seems those papers all apply layer normalization _and then_ softmax+CE. What seems to work for me is simply replacing softmax+CE by normalization.",
            "spoiler": false,
            "stickied": false,
            "title": "Unit Normalization instead of Cross-Entropy Loss [Discussion]",
            "upvote_ratio": 0.76,
            "url": "https://www.reddit.com/r/MachineLearning/comments/118gie9/unit_normalization_instead_of_crossentropy_loss/"
        },
        {
            "author": "u/_Arsenie_Boca_",
            "created_utc": "02-21-2023 13:22:33",
            "distinguished": null,
            "edited": false,
            "id": "118cypl",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_118cypl",
            "nsfw": false,
            "num_comments": 16,
            "permalink": "/r/MachineLearning/comments/118cypl/d_bottleneck_layers_whats_your_intuition/",
            "score": 44,
            "selftext": "Many neural architectures use bottleneck layers somewhere in the architecture. What I mean by bottleneck is projecting activations to a lower dimension and back up. This is e.g. used in ResNet blocks. \n\nWhat is your intuition on why this is beneficial? From an information theory standpoint, it creates potential information loss due to the lower dimensionality. Can we see this as a form of regularisation, that makes the model learn more meaningful representations? \n\nIm interested in your intuitions in that matter or empirical results that might support these intuitions. Are you aware of other works that use bottlenecks and what is their underlying reasoning?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Bottleneck Layers: What's your intuition?",
            "upvote_ratio": 0.98,
            "url": "https://www.reddit.com/r/MachineLearning/comments/118cypl/d_bottleneck_layers_whats_your_intuition/"
        },
        {
            "author": "u/Animated-AI",
            "created_utc": "02-21-2023 12:23:44",
            "distinguished": null,
            "edited": false,
            "id": "118c8pp",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_118c8pp",
            "nsfw": false,
            "num_comments": 21,
            "permalink": "/r/MachineLearning/comments/118c8pp/p_the_first_depthwiseseparable_convolution/",
            "score": 315,
            "selftext": "Hey everyone,\n\nI've created what I believe is the first animation of a depthwise-separable convolution, and I thought you might appreciate it. I think this fills a legitimate gap in the instructional material available out there.\n\nhttps://i.redd.it/o1bns0jjskja1.gif\n\nI've actually been dissatisfied with the existing convolution animations in general (and [ranted about it on youtube](https://youtu.be/w4kNHKcBGzA)). So I made my own set of animations and published them on [animatedai.github.io](https://animatedai.github.io/).\n\nIf you find any of them useful, please feel free to copy them, post them on your website, throw them in a powerpoint, or just link to them.",
            "spoiler": false,
            "stickied": false,
            "title": "[P] The First Depthwise-separable Convolution Animation",
            "upvote_ratio": 0.96,
            "url": "https://www.reddit.com/r/MachineLearning/comments/118c8pp/p_the_first_depthwiseseparable_convolution/"
        },
        {
            "author": "u/Rudebrazen",
            "created_utc": "02-21-2023 11:47:39",
            "distinguished": null,
            "edited": false,
            "id": "118bcjx",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_118bcjx",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/118bcjx/r_are_there_datasets_of_annotations_of_the/",
            "score": 4,
            "selftext": "Chain-of-thought can be used to get large language models to generate what often look like reasoning traces, but the reasoning steps generated are not always correct (even when the model's final answer *is* correct!). I\u2019m aware of a few efforts to manually annotate the correctness/incorrectness of the reasoning steps in chain-of-thought-type data:\n\n\\* \u201cSolving math word problems with process- and outcome-based feedback\u201d: [https://arxiv.org/abs/2211.14275](https://arxiv.org/abs/2211.14275) \n\n\\* \u201cLarge Language Models Are Reasoning Teachers\u201d, section 4.2: [https://arxiv.org/pdf/2212.10071.pdf](https://arxiv.org/pdf/2212.10071.pdf) \n\nUnfortunately, the data does not seem to be available from either study. Is anyone aware of other researchers who have annotated the correctness of LLM-generated reasoning steps (whether or not their data is public), or datasets that contain this kind of data?\n\nI guess I\u2019d also be interested in datasets where the correctness/incorrectness of individual reasoning steps generated by humans have been annotated, for example if there are datasets of human-solved logic problems with the errors marked.   \n\n\nAgain, am interested in correctness of individual reasoning steps, not the correctness of the final answers.",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Are there datasets of annotations of the correctness/incorrectness of the individual steps of chain-of-thought reasoning?",
            "upvote_ratio": 0.84,
            "url": "https://www.reddit.com/r/MachineLearning/comments/118bcjx/r_are_there_datasets_of_annotations_of_the/"
        },
        {
            "author": "u/CheapBreakfast9",
            "created_utc": "02-21-2023 08:46:31",
            "distinguished": null,
            "edited": false,
            "id": "11853g5",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_11853g5",
            "nsfw": false,
            "num_comments": 8,
            "permalink": "/r/MachineLearning/comments/11853g5/r_chatgpt_for_robotics_design_principles_and/",
            "score": 26,
            "selftext": "I wanted to share a paper we have just released, where we extended the capabilities of ChatGPT to robotics, and controlled multiple platforms such as robot arms, drones, and home assistant robots intuitively with language: [https://www.microsoft.com/en-us/research/group/autonomous-systems-group-robotics/articles/chatgpt-for-robotics/](https://www.microsoft.com/en-us/research/group/autonomous-systems-group-robotics/articles/chatgpt-for-robotics/)\n\nVideo: [https://youtu.be/NYd0QcZcS6Q](https://youtu.be/NYd0QcZcS6Q)\n\nTechnical paper: [https://www.microsoft.com/en-us/research/uploads/prod/2023/02/ChatGPT\\_\\_\\_Robotics.pdf](https://www.microsoft.com/en-us/research/uploads/prod/2023/02/ChatGPT___Robotics.pdf)\n\nhttps://i.redd.it/ya84nryu0kja1.gif",
            "spoiler": false,
            "stickied": false,
            "title": "[R] ChatGPT for Robotics: Design Principles and Model Abilities",
            "upvote_ratio": 0.85,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11853g5/r_chatgpt_for_robotics_design_principles_and/"
        },
        {
            "author": "u/emad_eldeen",
            "created_utc": "02-21-2023 06:50:32",
            "distinguished": null,
            "edited": false,
            "id": "1182oyr",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_1182oyr",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/1182oyr/r_check_our_survey_paper_for_a_labelefficient/",
            "score": 1,
            "selftext": "Our survey paper: \"[Label-efficient Time Series Representation Learning: A Review](https://arxiv.org/abs/2302.06433)\" discusses one of the main limitations of applying deep learning models on time series data in the real world, i.e., the scarcity of labeled data. \n\nThere are different ways to address this issue, and we attempt to provide an overview of the various label-scarce scenarios, and their corresponding techniques proposed to address each one.\n\n&#x200B;\n\nhttps://preview.redd.it/7waga9tdgjja1.jpg?width=1984&format=pjpg&auto=webp&v=enabled&s=6b7070d286691fb8b2b2006f7b4a2dea73059b7b",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Check our survey paper for a label-efficient Time Series Representation Learning",
            "upvote_ratio": 0.6,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1182oyr/r_check_our_survey_paper_for_a_labelefficient/"
        },
        {
            "author": "u/cccntu",
            "created_utc": "02-21-2023 06:36:39",
            "distinguished": null,
            "edited": false,
            "id": "1182fqd",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_1182fqd",
            "nsfw": false,
            "num_comments": 6,
            "permalink": "/r/MachineLearning/comments/1182fqd/p_minlora_an_easytouse_pytorch_library_for/",
            "score": 98,
            "selftext": "Hey r/MachineLearning! I wanted to share a new PyTorch library I've been working on that I think could be really useful for anyone looking to fine-tune large models with LoRA.   \n\n\n[https://github.com/cccntu/minlora](https://github.com/cccntu/minlora)\n\n  \nThe library is based on the LoRA technique (**Lo**w-**R**ank **A**daptation). \"which freezes the pre-trained model weights and injects trainable rank decomposition matrices into each layer.\" (- quote from the [paper](https://openreview.net/forum?id=nZeVKeeFYf9))  \n\n\nWith this library, you can easily apply LoRA to any PyTorch model with just a few lines of code.\n\nOne of the benefits of this library is that it's really small - just 100 lines of code. Despite its size, it's quite powerful and has been tested on a variety of different models, including nanoGPT by Karpathy, and stable diffusion.  \n\n\nIt also features an easy-to-use interface that allows you to serve multiple LoRA models at the same time!",
            "spoiler": false,
            "stickied": false,
            "title": "[P] minLoRA: An Easy-to-Use PyTorch Library for Applying LoRA to PyTorch Models",
            "upvote_ratio": 0.96,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1182fqd/p_minlora_an_easytouse_pytorch_library_for/"
        },
        {
            "author": "u/deluded_soul",
            "created_utc": "02-21-2023 05:39:18",
            "distinguished": null,
            "edited": false,
            "id": "1181g88",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_1181g88",
            "nsfw": false,
            "num_comments": 5,
            "permalink": "/r/MachineLearning/comments/1181g88/discussion_ml_on_extremely_large_datasets_and/",
            "score": 4,
            "selftext": "I am looking into any techniques one could use for very large datasets in machine learning. So I am talking about datasets with the following properties:\n\n1: 3D Imaging dataset where each dataset is of the order of many terabytes.\n\n2: Each 3D image is too big to fit in the GPU or CPU memory.\n\nI am interested in educating myself on methods that people have used in classical ML and modern deep learning for such extremely large datasets.\n\nIn particular, how does one ensure one can capture long-range spatial interactions in such datasets and what computational techniques can one do to perform learning on such datasets?  \n\n\nFinally, if someone can point me to some open source examples of such ML systems (domain is not important) that I can learn from, I would be extremely grateful.open-source",
            "spoiler": false,
            "stickied": false,
            "title": "[Discussion] ML on extremely large datasets and images",
            "upvote_ratio": 0.75,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1181g88/discussion_ml_on_extremely_large_datasets_and/"
        },
        {
            "author": "u/AlmightySnoo",
            "created_utc": "02-20-2023 13:55:31",
            "distinguished": null,
            "edited": "02-20-2023 14:32:26",
            "id": "117iqtp",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_117iqtp",
            "nsfw": false,
            "num_comments": 22,
            "permalink": "/r/MachineLearning/comments/117iqtp/d_on_papers_forcing_the_use_of_gans_where_it_is/",
            "score": 27,
            "selftext": "One of the things in current publications that completely irritates me is people just forcing the use of GANs where they are not even needed nor suited at all, just to ride on the hype of *generative AI*.\n\nThese guys usually have samples `(x_1, y_1=phi(x_1)), ..., (x_n, y_n=phi(x_n))` of a random pair `(X, Y=phi(X))` where `phi` is some unknown target function (*ie* in fancy-pants math we know that `Y` is `sigma(X)`\\-measurable). A direct way to solve this is to treat it naturally as a regression problem and use your usual ML/DL toolkit. These guys however think that they can make the problem look sexier if they introduce GANs. For instance, they'd train a GAN taking `X` as an input and through the discriminator have the generator output something that has the same distribution as `Y=phi(X)`. Some will even add some random noise `z` , that has nothing to do with `X`, to the inputs of the generator despite knowing that `X` is already enough to fully determine `Y`. GANs would have been useful if we didn't have joint observations of `X` and `Y` but that is not the case here.\n\nOne of the papers I have in mind is this one: [https://openreview.net/pdf?id=SDD5n1888](https://openreview.net/pdf?id=SDD5n1888)\n\nHow on earth are these papers getting accepted? To me that is literally just plagiarism of what's already available (physics-informed NNs in that case) by adding a totally useless layer (the GAN) to make it seem like this is a novel approach. That paper is only one of many cases. I know of a professor actively using that same technique to get cheap articles where he just replaces a standard regression NN in an old paper found online by a totally unjustified GAN. IMO reviewers at these journals/conferences need to be more mindful of this kind of plagiarism/low-effort submission.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] On papers forcing the use of GANs where it is not relevant",
            "upvote_ratio": 0.75,
            "url": "https://www.reddit.com/r/MachineLearning/comments/117iqtp/d_on_papers_forcing_the_use_of_gans_where_it_is/"
        },
        {
            "author": "u/Soundwave_47",
            "created_utc": "02-20-2023 13:12:21",
            "distinguished": null,
            "edited": "02-20-2023 13:18:10",
            "id": "117hmx4",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": null,
            "locked": false,
            "name": "t3_117hmx4",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/117hmx4/n_sony_ais_qrsac_rl_algorithm_sophy_to_be_demoed/",
            "score": 5,
            "selftext": ">Gran Turismo Sophy is a revolutionary superhuman racing AI racing agent developed in a collaboration between Sony AI, Sony Interactive Entertainment and Polyphony Digital. \u201cGran Turismo Sophy Race Together\u201d mode gives Gran Turismo players of all levels and abilities the opportunity to go head-to-head against GT Sophy in GT7. The special mode, available as a time-limited in-game event (From Feb 21 to end of March), is a first look at GT Sophy in GT7 and is designed to maximize the fun and excitement of racing against GT Sophy for everyone. Player feedback on this initial special feature will be used to continually improve the GT Sophy Race Together mode feature for future releases.\u00a0\n\n>In GT Sophy Race Together mode, players can race against GT Sophy in a series of four circuits of increasing difficulty, as a Beginner / Intermediate / Expert driver. In each of the four races, the player races against four GT Sophy cars of different performance levels. Players can also challenge GT Sophy in 1VS1 mode, where GT Sophy and the player race one-on-one with identical car configurations and settings, which showcases the superhuman racing skills of GT Sophy. The excitement of GT Sophy Race Together mode is enhanced with GT7\u2019s new emoticon feature, which displays emoticons on the GT Sophy cars throughout the race to react to the in-game action.\n\nhttps://blog.playstation.com/2023/02/20/gran-turismo-7-update-1-29-includes-ps-vr2-upgrade-a-race-against-superhuman-ai-a-classic-gt-track-and-5-new-cars/\n\nSony AI introduced their quantile regression\u2014soft actor critic algorithm for Sophy in this Nature paper.\n\nhttps://www.nature.com/articles/s41586-021-04357-7",
            "spoiler": false,
            "stickied": false,
            "title": "[N] Sony AI's QR-SAC RL algorithm Sophy to be demoed in upcoming update of Gran Turismo",
            "upvote_ratio": 0.86,
            "url": "https://www.reddit.com/r/MachineLearning/comments/117hmx4/n_sony_ais_qrsac_rl_algorithm_sophy_to_be_demoed/"
        },
        {
            "author": "u/lemon-meringue",
            "created_utc": "02-20-2023 12:53:05",
            "distinguished": null,
            "edited": false,
            "id": "117h4rg",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": null,
            "locked": false,
            "name": "t3_117h4rg",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/117h4rg/d_why_do_many_ml_papers_choose_to_reimplement/",
            "score": 9,
            "selftext": "PyTorch has its own torch.nn.Transformer [module](https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html), however I see that many papers and their reproductions often choose to implement the transformer from scratch.\n\nFor example:\n\n* [Vision Transformers](https://github.com/lucidrains/vit-pytorch/blob/main/vit_pytorch/vit.py#L35)\n* [Decision Transformers](https://github.com/kzl/decision-transformer/blob/master/atari/mingpt/model_atari.py#L99)\n* [Whisper](https://github.com/openai/whisper/blob/main/whisper/model.py#L104)\n\nIn fact, I'm not sure if I've ever seen any project actually use the PyTorch module. I'm curious if there's a reason for this?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Why do many ML papers choose to reimplement PyTorch transformer modules?",
            "upvote_ratio": 1.0,
            "url": "https://www.reddit.com/r/MachineLearning/comments/117h4rg/d_why_do_many_ml_papers_choose_to_reimplement/"
        },
        {
            "author": "u/alik31239",
            "created_utc": "02-20-2023 10:09:46",
            "distinguished": null,
            "edited": false,
            "id": "117blae",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_117blae",
            "nsfw": false,
            "num_comments": 11,
            "permalink": "/r/MachineLearning/comments/117blae/d_something_basic_i_dont_understand_about_nerfs/",
            "score": 23,
            "selftext": "In the abstract of the Nerf paper ([https://arxiv.org/abs/2003.08934](https://arxiv.org/abs/2003.08934)), the described framework is that Nerf enable to do the following: the user inputs a set of images with known camera poses, and after training the network they can generate images of the same scene from new angles.\n\nHowever, the paper itself builds a network that gets as an input 5D vectors (3 location coordinates+2 camera angles) and outputs color and volume density for each such coordinate. I don't understand where do I get those 5D coordinates from? My training data surely doesn't have those - I only have a collection of images. Same for inference data. It seems that the paper assumes not only having a collection of images but also having a 3D representation of the scene, while the abstract doesn't require the latter. What am I missing here?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Something basic I don't understand about Nerfs",
            "upvote_ratio": 0.93,
            "url": "https://www.reddit.com/r/MachineLearning/comments/117blae/d_something_basic_i_dont_understand_about_nerfs/"
        },
        {
            "author": "u/tysam_and_co",
            "created_utc": "02-20-2023 09:21:48",
            "distinguished": null,
            "edited": false,
            "id": "1179i7z",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_1179i7z",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/1179i7z/r_train_cifar10_to_94_in_7_seconds_or_less/",
            "score": 10,
            "selftext": "Hello everyone,  \n\n\nIt's that time again, thank you all so much for the support you've given us over here. I've done a ton of typing this morning, so for a summary of what I've updated, you can see the higher-level twitter thread I wrote at [https://twitter.com/hi\\_tysam/status/1627679672988319746?cxt=HHwWhIC-yb2C15YtAAAA](https://twitter.com/hi_tysam/status/1627679672988319746?cxt=HHwWhIC-yb2C15YtAAAA), or the more detailed (but still rough cut) patch notes I wrote this morning at  [https://github.com/tysam-code/hlb-CIFAR10/releases/tag/v0.5.0](https://github.com/tysam-code/hlb-CIFAR10/releases/tag/v0.5.0)  \n\n\nHappy to answer any questions anyone might have, cheers! :D :))))",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Train CIFAR10 to 94% in 7 seconds or less (Lookahead with custom scheduling, CutMix, and more!)",
            "upvote_ratio": 0.71,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1179i7z/r_train_cifar10_to_94_in_7_seconds_or_less/"
        },
        {
            "author": "u/fferflo",
            "created_utc": "02-20-2023 09:02:55",
            "distinguished": null,
            "edited": "02-20-2023 09:22:50",
            "id": "1178rmr",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_1178rmr",
            "nsfw": false,
            "num_comments": 4,
            "permalink": "/r/MachineLearning/comments/1178rmr/d_does_layer_normalization_compute_statistics/",
            "score": 54,
            "selftext": "As far as I can tell, there are two contradictory definitions of Layer Normalization that are both floating around. LN computes the mean and variance along some axes of the input tensor for normalization, yet the choice of axes is not clear:\n\nA. The [GroupNorm paper (2018)](https://arxiv.org/pdf/1803.08494.pdf) has this figure that describes LN as reducing **along channel and spatial/token axes**.\n\nhttps://preview.redd.it/ui9adzzxgcja1.png?width=1353&format=png&auto=webp&v=enabled&s=f701d53a0992e3fe13bdac6ee022d352f965c893\n\nB. The [PowerNorm paper (2020)](https://arxiv.org/pdf/2003.07845.pdf) has this figure that describes LN as reducing **only along the channel axis**.\n\nhttps://preview.redd.it/e0qmp9sahcja1.png?width=1717&format=png&auto=webp&v=enabled&s=00126512760766783d88217b44377f5741290d9c\n\nThere are also many online sources that describe LN as shown in A (e.g. [TF tutorials](https://www.tensorflow.org/addons/tutorials/layers_normalizations), [PapersWithCode](https://paperswithcode.com/method/layer-normalization), [this summary of normalization techniques](https://theaisummer.com/normalization/)) using similar figures.\n\nThe [LN paper (2016)](https://arxiv.org/pdf/1607.06450.pdf) itself says\n\n>all the hidden units in a layer share the same normalization terms \u03bc and \u03c3\n\nso the channel axis is definitely reduced, and\n\n>computing the mean and variance used for normalization from all of the summedinputs to the neurons in a layer *on a single training case*\n\nso the batch axis is definitely not reduced. As far as I can tell it is not clear about what happens with spatial/token axes, although the above sounds rather like they might be included in the statistics.\n\nYet, I don't know of any model that actually uses A instead of B. For example, [TF](https://github.com/keras-team/keras/blob/v2.11.0/keras/layers/normalization/layer_normalization.py#L158) and [Flax](https://github.com/google/flax/blob/main/flax/linen/normalization.py#L321) explicitly implement LN with default axes as in B ([PyTorch](https://github.com/pytorch/pytorch/blob/master/torch/nn/modules/normalization.py#L142), [Haiku](https://github.com/deepmind/dm-haiku/blob/main/haiku/_src/layer_norm.py#L78) and [Equinox](https://github.com/patrick-kidger/equinox/blob/1f5373f5905504bc5e7069ed6d458dbad5616495/equinox/nn/normalisation.py#L39) don't have a preference and require the user to specify the reduction axes). [Vision Transformer](https://github.com/google-research/vision_transformer/blob/main/vit_jax/models_vit.py#L133) uses Flax with LN as in B, [ConvNeXt](https://github.com/facebookresearch/ConvNeXt/blob/main/models/convnext.py#L135) implements LN with PyTorch as in B, [OpenAI GPT-2](https://github.com/openai/gpt-2/blob/master/src/model.py#L28) implements LN with Tensorflow as in B, even [MLP-Mixer](https://github.com/google-research/vision_transformer/blob/main/vit_jax/models_mixer.py#L41) where the spatial/token axes are interpreted as channel axis for an MLP still computes statistics along the original channel axis as in B.\n\nAs far as I can tell, everyone uses B rather than A in their models, so to me this seems to be the \"correct\" definition. Yet, many sources on this topic describe LN as doing A rather than B.\n\nDoes anyone have any insight on this or know of a source that has addressed this problem? Do you interpret the original LN paper as including spatial/token axes in their computation of mean and variance, or not? Is this simply an error that started with the figure A and made its way into different online tutorials from there? Or do you maybe know of a model that actually uses LN to reduce both along channel and spatial/token axes?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Does Layer Normalization compute statistics along spatial/ token axes?",
            "upvote_ratio": 0.92,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1178rmr/d_does_layer_normalization_compute_statistics/"
        },
        {
            "author": "u/Sanciopinto",
            "created_utc": "02-20-2023 03:33:42",
            "distinguished": null,
            "edited": false,
            "id": "1172juh",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_1172juh",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/1172juh/r_p_implementation_of_feature_extraction_and_id/",
            "score": 4,
            "selftext": "Hi everyone,\n\nI'm currently working on a biometric identification project that involves converting biometric data (such as iris images) into a unique and secure ID. In order to do so, one of the first steps in the pipeline (after training a feature extractor) is to extract a set of features from an image in some tensor form (preferably a vector). What I'm wondering is what robust method could be used to extract similar feature vectors for similar inputs (e.g., to obtain similar, in terms of Euclidean distance, feature vectors for various photos of a same iris)? That would be required such that the feature vectors for similar inputs could be converted to the same unique ID (e.g., by using a locality-sensitive hashing algorithm).\n\nIn short, I'm interested in any tips for:\n\n* Choosing an appropriate and robust feature extraction architecture\n* Methods for conversion of features to IDs (such as hashing, or anything that should work in theory)\n\nAny insights or suggestions would be greatly appreciated. Thanks in advance!",
            "spoiler": false,
            "stickied": false,
            "title": "[R] [P] Implementation of feature extraction and ID attribution for biometric identification project",
            "upvote_ratio": 1.0,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1172juh/r_p_implementation_of_feature_extraction_and_id/"
        },
        {
            "author": "u/head_robotics",
            "created_utc": "02-20-2023 03:33:34",
            "distinguished": null,
            "edited": "02-20-2023 03:43:02",
            "id": "1172jrs",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_1172jrs",
            "nsfw": false,
            "num_comments": 45,
            "permalink": "/r/MachineLearning/comments/1172jrs/d_large_language_models_feasible_to_run_on_32gb/",
            "score": 217,
            "selftext": "I've been looking into open source large language models to run locally on my machine.\n\nSeems GPT-J and GPT-Neo are out of reach for me because of RAM / VRAM requirements.\n\nWhat models would be doable with this hardware?:\n\nCPU: AMD Ryzen 7 3700X 8-Core, 3600 MhzRAM: 32 GB\n\nGPUs:\n\n1. NVIDIA GeForce RTX 2070 8GB VRAM\n2. NVIDIA Tesla M40 24GB VRAM",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Large Language Models feasible to run on 32GB RAM / 8 GB VRAM / 24GB VRAM",
            "upvote_ratio": 0.93,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1172jrs/d_large_language_models_feasible_to_run_on_32gb/"
        },
        {
            "author": "u/Singularian2501",
            "created_utc": "02-19-2023 13:31:58",
            "distinguished": null,
            "edited": false,
            "id": "116lp7a",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "News",
            "locked": false,
            "name": "t3_116lp7a",
            "nsfw": false,
            "num_comments": 3,
            "permalink": "/r/MachineLearning/comments/116lp7a/r_n_mastering_diverse_domains_through_world/",
            "score": 45,
            "selftext": "Paper: [https://arxiv.org/abs/2301.04104#deepmind](https://arxiv.org/abs/2301.04104#deepmind) \n\nWebsite: [https://danijar.com/project/dreamerv3/](https://danijar.com/project/dreamerv3/) \n\nTwitter: [https://twitter.com/danijarh/status/1613161946223677441](https://twitter.com/danijarh/status/1613161946223677441) \n\nGithub: [https://github.com/danijar/dreamerv3](https://github.com/danijar/dreamerv3)  / [https://github.com/danijar/daydreamer](https://github.com/danijar/daydreamer) \n\nAbstract:\n\n>General intelligence requires solving tasks across many domains. Current reinforcement learning algorithms carry this potential but are held back by the resources and knowledge required to tune them for new tasks. We present **DreamerV3, a general and scalable algorithm based on world models that outperforms previous approaches** across a wide range of domains with fixed hyperparameters. These domains include continuous and discrete actions, visual and low-dimensional inputs, 2D and 3D worlds, different data budgets, reward frequencies, and reward scales. We observe favorable scaling properties of DreamerV3, with **larger models directly translating to higher data-efficiency and final performance.** Applied out of the box, DreamerV3 is the **first algorithm to collect diamonds in Minecraft from scratch without human data or curricula,** a long-standing challenge in artificial intelligence. Our general algorithm makes reinforcement learning broadly applicable and allows scaling to hard decision making problems. \n\nhttps://preview.redd.it/h4hrfqwp57ja1.jpg?width=1320&format=pjpg&auto=webp&v=enabled&s=f3687d48c9b28efe184931cee62d7ff42b5d5655\n\nhttps://preview.redd.it/bl13kxwp57ja1.jpg?width=1399&format=pjpg&auto=webp&v=enabled&s=56c70c244e3ccf45b351e83791059d01a535299f\n\nhttps://preview.redd.it/b0kqa2xp57ja1.jpg?width=1286&format=pjpg&auto=webp&v=enabled&s=55fffc14ae68cb8ad60e395182c71c541c5f2005\n\nhttps://preview.redd.it/e61x5xwp57ja1.jpg?width=1291&format=pjpg&auto=webp&v=enabled&s=d23cfe3bab1114f543187c53d355488e4d3c8ffa",
            "spoiler": false,
            "stickied": false,
            "title": "[R] [N] Mastering Diverse Domains through World Models - DreamerV3 - Deepmind 2023 - First algorithm to collect diamonds in Minecraft from scratch without human data or curricula! Now with github links!",
            "upvote_ratio": 0.9,
            "url": "https://www.reddit.com/r/MachineLearning/comments/116lp7a/r_n_mastering_diverse_domains_through_world/"
        },
        {
            "author": "u/radi-cho",
            "created_utc": "02-19-2023 12:53:52",
            "distinguished": null,
            "edited": false,
            "id": "116kqvm",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "News",
            "locked": false,
            "name": "t3_116kqvm",
            "nsfw": false,
            "num_comments": 11,
            "permalink": "/r/MachineLearning/comments/116kqvm/r_n_in_this_paper_we_show_how_a_conversational/",
            "score": 150,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] [N] In this paper, we show how a conversational model, 3.5x smaller than SOTA, can be optimized to outperform the baselines through Auxiliary Learning. Published in the ACL Anthology: \"Efficient Task-Oriented Dialogue Systems with Response Selection as an Auxiliary Task.\"",
            "upvote_ratio": 0.97,
            "url": "https://i.redd.it/cffc6a3qy6ja1.png"
        },
        {
            "author": "u/Singularian2501",
            "created_utc": "02-19-2023 11:38:45",
            "distinguished": null,
            "edited": false,
            "id": "116ivz2",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_116ivz2",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/116ivz2/r_augmented_language_models_a_survey_meta_ai_2023/",
            "score": 18,
            "selftext": "Paper: [https://arxiv.org/abs/2302.07842](https://arxiv.org/abs/2302.07842)\n\nAbstract:\n\n>This survey reviews works in which language models (LMs) are augmented with reasoning skills and the ability to use tools. The former is defined as decomposing a potentially complex task into simpler subtasks while the latter consists in calling external modules such as a code interpreter. LMs can leverage these augmentations separately or in combination via heuristics, or learn to do so from demonstrations. While adhering to a standard missing tokens prediction objective, such augmented LMs can use various, possibly non-parametric external modules to expand their context processing ability, thus departing from the pure language modeling paradigm. We therefore refer to them as Augmented Language Models (ALMs). The missing token objective allows **ALMs to learn to reason, use tools, and even act, while still performing standard natural language tasks and even outperforming most regular LMs on several benchmarks.** In this work, after reviewing current advance in ALMs, we conclude that this new research direction has the potential to address common limitations of traditional LMs such as interpretability, consistency, and scalability issues.       \n\nhttps://preview.redd.it/lyjdr1ozj6ja1.jpg?width=1281&format=pjpg&auto=webp&v=enabled&s=1b5db84ec5b38228fc794e3fd24e83e4e450cc57",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Augmented Language Models: a Survey - Meta AI 2023",
            "upvote_ratio": 0.92,
            "url": "https://www.reddit.com/r/MachineLearning/comments/116ivz2/r_augmented_language_models_a_survey_meta_ai_2023/"
        },
        {
            "author": "u/LegendOfHiddnTempl",
            "created_utc": "02-19-2023 07:06:42",
            "distinguished": null,
            "edited": false,
            "id": "1169uzy",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_1169uzy",
            "nsfw": false,
            "num_comments": 23,
            "permalink": "/r/MachineLearning/comments/1169uzy/r_neural_cloth_simulation/",
            "score": 656,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] neural cloth simulation",
            "upvote_ratio": 0.97,
            "url": "https://v.redd.it/hgbepc6z85ja1"
        },
        {
            "author": "u/aadityaura",
            "created_utc": "02-19-2023 06:29:06",
            "distinguished": null,
            "edited": false,
            "id": "11695n4",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11695n4",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/11695n4/d_difference_between_offsitetuning_transfer/",
            "score": 5,
            "selftext": "The paper \"Offsite-Tuning: Transfer Learning without Full Model\" describes a privacy-preserving and efficient transfer learning framework. In this framework  \n\n\n\u2022 Offsite-Tuning is a privacy-preserving and efficient transfer learning framework    \n\u2022 Model owner sends a light-weight adapter and a lossy compressed emulator to the data owner   \n\u2022 Data owner fine-tunes adapter on downstream data with the emulator's assistance   \n\u2022 Fine-tuned adapter is then returned to the model owner to create an adapted foundation model   \n\u2022 Offsite-Tuning preserves both parties' privacy and is computationally more efficient than existing fine-tuning methods\n\nHow does this differ from Federated Learning?\n\nPaper Link: [https://arxiv.org/abs/2302.04870](https://arxiv.org/abs/2302.04870)",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Difference between [ Offsite-Tuning: Transfer Learning without Full Model ] and Federated learning?",
            "upvote_ratio": 0.78,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11695n4/d_difference_between_offsitetuning_transfer/"
        },
        {
            "author": "u/westeast1000",
            "created_utc": "02-19-2023 04:41:22",
            "distinguished": null,
            "edited": false,
            "id": "1167hw9",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_1167hw9",
            "nsfw": false,
            "num_comments": 8,
            "permalink": "/r/MachineLearning/comments/1167hw9/d_does_langchain_upload_all_users_data_to_openai/",
            "score": 0,
            "selftext": "I just saw a tutorial about using langchains and am curious about how it works. So if i implemented something at my company that can answer any question across all our documents, does it mean i would have essentially gave all our company info to openai?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Does langchain upload all user\u2019s data to Openai?",
            "upvote_ratio": 0.42,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1167hw9/d_does_langchain_upload_all_users_data_to_openai/"
        },
        {
            "author": "u/MRMohebian",
            "created_utc": "02-18-2023 21:41:12",
            "distinguished": null,
            "edited": false,
            "id": "1160md2",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_1160md2",
            "nsfw": false,
            "num_comments": 3,
            "permalink": "/r/MachineLearning/comments/1160md2/torchdrug_tutorial_d/",
            "score": 30,
            "selftext": "TorchDrug is a machine learning platform designed for drug discovery, covering techniques from graph machine learning (graph neural networks, geometric deep learning & knowledge graphs), deep generative models to reinforcement learning. It provides a comprehensive and flexible interface to support rapid prototyping of drug discovery models in PyTorch. \n\nIn this video, we walk through TorchDrug library and train some GNN for graph classification, attribute masking and unsupervised graph representation learning.\n\nhttps://youtu.be/-Kb7kN4aHMM",
            "spoiler": false,
            "stickied": false,
            "title": "TorchDrug tutorial [D]",
            "upvote_ratio": 0.87,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1160md2/torchdrug_tutorial_d/"
        },
        {
            "author": "u/I_will_delete_myself",
            "created_utc": "02-18-2023 20:33:37",
            "distinguished": null,
            "edited": false,
            "id": "115z9hc",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_115z9hc",
            "nsfw": false,
            "num_comments": 27,
            "permalink": "/r/MachineLearning/comments/115z9hc/d_things_you_wish_you_knew_before_you_started/",
            "score": 90,
            "selftext": "I really like training in the cloud for some reason and feels satisfying, however here is a couple of things I would've wished I knew beforehand to get things started.\n\n1. Use a spot instance unless you absolutely must make sure it isn't interrupted. Your wallet will thank you later. \n2. Make sure Nvidia drivers are installed and don't experiment with Operating systems. You are paying by the hour. \n3. Make sure to use something like tmux to save the sessions running in your terminal so you don't have to start from scratch or in case you disconnect from the vm (but the VM isn't shut down). That way you can just click out of the terminal and not bother with it until it's done. \n4. Debug on your local machine on CPU if you don't have CUDA. You can debug the model on a CPU perfectly fine. \n\nNow what about you all?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Things you wish you knew before you started training on the cloud?",
            "upvote_ratio": 0.96,
            "url": "https://www.reddit.com/r/MachineLearning/comments/115z9hc/d_things_you_wish_you_knew_before_you_started/"
        },
        {
            "author": "u/MysteryInc152",
            "created_utc": "02-18-2023 18:47:12",
            "distinguished": null,
            "edited": false,
            "id": "115x1it",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_115x1it",
            "nsfw": false,
            "num_comments": 22,
            "permalink": "/r/MachineLearning/comments/115x1it/d_toolformer_implementation_using_only_fewshot/",
            "score": 85,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Toolformer implementation using only few-shot prompting",
            "upvote_ratio": 0.96,
            "url": "https://twitter.com/minosvasilias/status/1627076214639976449"
        },
        {
            "author": "u/Old_Scallion2173",
            "created_utc": "02-18-2023 18:37:00",
            "distinguished": null,
            "edited": false,
            "id": "115wu59",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_115wu59",
            "nsfw": false,
            "num_comments": 11,
            "permalink": "/r/MachineLearning/comments/115wu59/d_bounding_box_or_instance_segmentation/",
            "score": 5,
            "selftext": " \n\nHello, community.\n\n**Description:**\n\nI am planning to create a detection model using YOLO v8 to detect leukemia cells in a blood sample. I started learning about deep learning two months ago and I am eager to try out image segmentation on my present dataset instead of bounding boxes, as the cells are closely bunched together. I need advice on whether I should use bounding boxes or instance segmentation, considering my dataset and expected results.\n\n**Context:**\n\nLeukemia is caused by an abundance of different types of naive or altered white blood cells in the body, which overwhelm the bloodstream and inhibit the proper functioning of normal white blood cells. There are three classes in my dataset: lymphoblasts, promyelocytes, and neutrophils, and I need to be able to detect these cells.\n\n**Expected Results:**\n\nAs this is a medical domain, false positives are acceptable, but false negatives are not.\n\n**About dataset:**\n\n[lymphoblast sample image](https://imagebank.hematology.org/getimagebyid/2201?size=3)\n\n[sample image for promyelocytes](https://medschool.co/images/detail/blood-film/promyelocyte.jpg)\n\n[sample image for neutrophils](https://imagebank.hematology.org/getimagebyid/3610?size=3)\n\n[sample test image](https://thumbs.dreamstime.com/z/picture-white-blood-cell-red-blood-cell-platelet-blood-film-analyze-microscope-picture-blood-cells-blood-film-161974012.jpg)\n\nlymphoblasts(101 images)\n\npromyelocytes(91 images)\n\nneutrophils(133 images)\n\n**more context for your reading:**\n\nAn over abundance of lymphoblasts results in acute lymphoblastic leukemia (ALL), while acute pomyelocytic leukemia (APLML/APL) is caused by an abnormal accumulation of promyelocytes. neutrophils do not cause leukemia.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] bounding box or instance segmentation",
            "upvote_ratio": 1.0,
            "url": "https://www.reddit.com/r/MachineLearning/comments/115wu59/d_bounding_box_or_instance_segmentation/"
        },
        {
            "author": "u/radi-cho",
            "created_utc": "02-18-2023 17:28:04",
            "distinguished": null,
            "edited": false,
            "id": "115vd0t",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "News",
            "locked": false,
            "name": "t3_115vd0t",
            "nsfw": false,
            "num_comments": 28,
            "permalink": "/r/MachineLearning/comments/115vd0t/r_n_noise2music_diffusion_models_for_generating/",
            "score": 157,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] [N] Noise2Music - Diffusion models for generating high quality music audio from text prompts, by Google Research",
            "upvote_ratio": 0.96,
            "url": "https://v.redd.it/j6rtusre71ja1"
        },
        {
            "author": "u/ArmandDerech",
            "created_utc": "02-18-2023 13:28:16",
            "distinguished": null,
            "edited": false,
            "id": "115n3qr",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_115n3qr",
            "nsfw": false,
            "num_comments": 9,
            "permalink": "/r/MachineLearning/comments/115n3qr/r_difference_between_uai_and_aistats/",
            "score": 6,
            "selftext": "Hello, \n\nWhat is your perception of UAI and AISTATS conf\u00e9rences ? Is it good to publish that ? Is one more competitive than the other ? \n\nThanks",
            "spoiler": false,
            "stickied": false,
            "title": "[R] difference between UAI and AISTATS ?",
            "upvote_ratio": 0.71,
            "url": "https://www.reddit.com/r/MachineLearning/comments/115n3qr/r_difference_between_uai_and_aistats/"
        },
        {
            "author": "u/hayAbhay",
            "created_utc": "02-18-2023 12:48:52",
            "distinguished": null,
            "edited": false,
            "id": "115m85c",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_115m85c",
            "nsfw": false,
            "num_comments": 23,
            "permalink": "/r/MachineLearning/comments/115m85c/p_whisperui_update_you_can_now_bulktranscribe/",
            "score": 68,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Whisper-UI Update: You can now bulk-transcribe, save & search transcriptions with Streamlit & SQLAlchemy 2.0 [details in the comments]",
            "upvote_ratio": 0.92,
            "url": "https://v.redd.it/427hbz8itzia1"
        },
        {
            "author": "u/SlayahhEUW",
            "created_utc": "02-18-2023 11:22:52",
            "distinguished": null,
            "edited": false,
            "id": "115kb50",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_115kb50",
            "nsfw": false,
            "num_comments": 2,
            "permalink": "/r/MachineLearning/comments/115kb50/d_methodologies_for_tuning_two_or_more_unlinked/",
            "score": 0,
            "selftext": "Hello, this is a question regarding regarding a system of two(or more) classifiers for energy/computation purposes. For example a mobile phone and a cloud server.  \nWhat frameworks/techniques exist for tuning the thresholds for two or more classifiers simultaneously?  \nFor example, given two trained binary classifiers, I would like to pass a labeled validation dataset X through both classifiers and tune 2 thresholds for classifier1(upper and lower) and 1 threshold for classfier2. Everything that is lower than the \"upper\" threshold and higher than the \"lower\" threshold(what classifier1 is not certain of) should be passed to classifier2.\n\nTo avoid a very liberal passing of data to classifier2, I also want to introduce a loss/penalty for doing so, meaning that classifier1 should learn using the provided labeled data when it really has to pass the sample to classifier2.\n\nXGBoost seems to be focused on tuning a single classifier, and I feel like I might need to use some Reinforcement learning technique, but I do not know the nomenclature for this kind of problem, policies perhaps? Does anyone have experience with this?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Methodologies for tuning two or more unlinked classifier thresholds in tandem with custom losses?",
            "upvote_ratio": 0.5,
            "url": "https://www.reddit.com/r/MachineLearning/comments/115kb50/d_methodologies_for_tuning_two_or_more_unlinked/"
        },
        {
            "author": "u/goolulusaurs",
            "created_utc": "02-18-2023 11:18:13",
            "distinguished": null,
            "edited": false,
            "id": "115k7eq",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_115k7eq",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/115k7eq/r_universal_intelligence_a_definition_of_machine/",
            "score": 0,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Universal Intelligence: A Definition of Machine Intelligence",
            "upvote_ratio": 0.45,
            "url": "https://arxiv.org/abs/0712.3329"
        },
        {
            "author": "u/enryu42",
            "created_utc": "02-18-2023 08:39:02",
            "distinguished": null,
            "edited": false,
            "id": "115gqjf",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_115gqjf",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/115gqjf/d_cfg_role_in_diffusion_vs_autoregressive/",
            "score": 9,
            "selftext": "When the [classifier-free guidance](https://arxiv.org/abs/2207.12598) was first introduced, I was very confused about why it works: I'd understand if it was interpolating like `\u03b5 * conditional_prediction + (1 - \u03b5) * unconditional_prediction`, but in its formulation, \u03b5 is greater than 1. It is clear why it makes the result match the condition better, but why the result becomes better regardless of the condition was a mystery to me.\n\nAfterwards, there were many post-hoc explanations, which didn't seem satisfactory (e.g. these explanations didn't have predictive power helping to improve the trick). Recently, I finally got around to play with it, and found some interesting patterns (in context of diffusion, DDIM sampling):\n* If we disable CFG for 90% last sampling steps, results are pretty much the same;\n* If we disable CFG for the first 10% sampling steps, the resulting image is destroyed.\n\nIt appears that CFG it responsible for forming the overall composition of the image from the random noise at the very beginning of the sampling, and doesn't do much afterwards. This is kind of similar to the observation about attention maps in [this paper](https://arxiv.org/pdf/2208.01626.pdf) (section 3.1). Speculatively, it tries to \"match the prompt\" to the random noise, and the adjustments from it need to be amplified, otherwise subsequent steps will match the prompt differently (it is a random noise after all). If this is true, I guess something like this might also work (I haven't tried yet): sample 1000 different starting random states, take the one which \"matches the prompt\" the best by some measure, and do the diffusion sample starting from it without CFG.\n\nThis all might make sense, except that this is very specific to diffusion. But [it is known](https://arxiv.org/pdf/2206.10789.pdf) that CFG works just as well for autoregressive transformers on VQVAE tokes. This might indicate that the mechanism why it works is more fundamental and is not specific to diffusion.\n\nI wonder if there is any community wisdom/thoughts on why/how it works, and generalizes so well across two very different types of models.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] CFG role in diffusion vs autoregressive transformers",
            "upvote_ratio": 0.84,
            "url": "https://www.reddit.com/r/MachineLearning/comments/115gqjf/d_cfg_role_in_diffusion_vs_autoregressive/"
        },
        {
            "author": "u/head_robotics",
            "created_utc": "02-18-2023 08:12:16",
            "distinguished": null,
            "edited": false,
            "id": "115g73x",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_115g73x",
            "nsfw": false,
            "num_comments": 3,
            "permalink": "/r/MachineLearning/comments/115g73x/d_any_papers_articles_that_discusses_the_accuracy/",
            "score": 15,
            "selftext": "Does anyone know of a paper / article that discusses the accuracy / usefulness of available opensource LLM models.  \n\n\nBloom, GPT-NeoX, T5, etc.  \n\n\nWhat would be a good way to evaluate tradeoffs?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Any papers / articles that discusses the accuracy / usefulness of opensource LLMs?",
            "upvote_ratio": 0.82,
            "url": "https://www.reddit.com/r/MachineLearning/comments/115g73x/d_any_papers_articles_that_discusses_the_accuracy/"
        },
        {
            "author": "u/linguaphile26",
            "created_utc": "02-18-2023 07:26:18",
            "distinguished": null,
            "edited": false,
            "id": "115fa7j",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_115fa7j",
            "nsfw": false,
            "num_comments": 4,
            "permalink": "/r/MachineLearning/comments/115fa7j/r_any_work_on_modelbased_rlhf/",
            "score": 5,
            "selftext": "Given the impressive capabilities of ChatGPT, I've been learning about RLHF - just wondering if there has been any work/research on RLHF with a model-based RL algorithm (e.g. MuZero, vs PPO). Thanks!",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Any work on model-based RLHF?",
            "upvote_ratio": 0.78,
            "url": "https://www.reddit.com/r/MachineLearning/comments/115fa7j/r_any_work_on_modelbased_rlhf/"
        },
        {
            "author": "u/rast_012",
            "created_utc": "02-18-2023 07:09:46",
            "distinguished": null,
            "edited": "02-19-2023 10:33:07",
            "id": "115ez2r",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_115ez2r",
            "nsfw": false,
            "num_comments": 148,
            "permalink": "/r/MachineLearning/comments/115ez2r/d_please_stop/",
            "score": 500,
            "selftext": "\nAdvertising  low quality blogposts and services, etc, and asking stupid questions. \n\nAlmost every new post in this sub is an advertising or \nsome kind very stupid/useless question like: \n\"Is ChaTGpT sEntIenT?\"\nno it's, not. and no one with working brain will design an ai that is self aware.(use common sense)\n\nI wonder what the mods are doing, cause this nonsense should stop.\n\nEDIT: I'm a beginner myself. But please, \n1) if you are learning ML, visit related subreddits like r/learnmachinelearning\n2) read the guidelines, have some respect for the ~~mods~~ volunteers, who  are curating this community on their free time\n3) Use Google, Basic search on Google has all the answers for almost all the questions. Questions like: \"what is difference between data science and machine learning\" etc, are pretty common.\n\nEDIT 2: I agree, that this is just another shitpost.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Please stop",
            "upvote_ratio": 0.8,
            "url": "https://www.reddit.com/r/MachineLearning/comments/115ez2r/d_please_stop/"
        },
        {
            "author": "u/thefunnychive",
            "created_utc": "02-18-2023 05:41:25",
            "distinguished": null,
            "edited": false,
            "id": "115di73",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_115di73",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/115di73/p_nocode_automl_feature_importance_baseline/",
            "score": 2,
            "selftext": " \n\n**Github:** [https://github.com/m-barker/fibs-reporter](https://github.com/m-barker/fibs-reporter)\n\n**PyPI:** [https://pypi.org/project/fibs-reporter/](https://pypi.org/project/fibs-reporter/)\n\nThe Data **F**eature **I**mportance, **B**aseline-modeller and **S**purious correlation Reporter (**FIBS**) is an open-source software for automatic generation of a PDF report to highlight and visualise potential sources of spurious correlation within **any** given tabular or audio dataset stored as a Comma Separated Values (CSV) file. FIBS is run through one-command line command; **all of the calculations, model training, and report generation happen automatically**.\n\nAll that is required as input on the command line is the path to the CSV file containing the data, and the name of the output (dependent) variable within the dataset. The toolkit will automatically determine whether the task is regression or classification. Optionally, the toolkit can process and extract audio data, provided the name of the variable within the CSV that contains the audio file for each observation is specified.\n\nKey features that are generated automatically:\n\n* A traffic light score for potential spurious correlations within the dataset\n* Calculation of four different feature importance metrics to highlight the most important features within the given dataset\n* Training and evaluation of two baseline models, including visualisation of model results\n* Visuals of the most important features, with different visuals depending on the variable types\n* Automatic determination of regression or classification task, resulting in different baseline models, feature extraction methods, and visualisations\n* Principal Component Analysis calculation and baseline model to estimate complexity within the dataset\n* (Optionally) extract audio data features and run the above on these features\n* Output all of the above in a PDF report with accompanying dynamic textual explanations",
            "spoiler": false,
            "stickied": false,
            "title": "[P] No-Code AutoML Feature Importance, Baseline Modelling and Data visualisation PDF report generator, for any tabular and/or audio dataset",
            "upvote_ratio": 0.63,
            "url": "https://www.reddit.com/r/MachineLearning/comments/115di73/p_nocode_automl_feature_importance_baseline/"
        },
        {
            "author": "u/Fabulous-Let-822",
            "created_utc": "02-18-2023 03:48:41",
            "distinguished": null,
            "edited": false,
            "id": "115btl3",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_115btl3",
            "nsfw": false,
            "num_comments": 14,
            "permalink": "/r/MachineLearning/comments/115btl3/d_what_are_some_open_problems_in_computer_vision/",
            "score": 18,
            "selftext": "With the advent of stable diffusion/midjourney/dalle and upcoming text-to-video models from Google and Meta, what will be major challenges in computer vision? It feels like once text-to-video models get released, visual reasoning will be mostly solved, and the only thing left to do is to improve model accuracy/efficiency from there. I am fairly new to Computer Vision and would love to learn new possible areas of research. Thank you in advance!",
            "spoiler": false,
            "stickied": false,
            "title": "[D] what are some open problems in computer vision currently?",
            "upvote_ratio": 0.72,
            "url": "https://www.reddit.com/r/MachineLearning/comments/115btl3/d_what_are_some_open_problems_in_computer_vision/"
        },
        {
            "author": "u/bjergerk1ng",
            "created_utc": "02-17-2023 20:02:00",
            "distinguished": null,
            "edited": false,
            "id": "11542tv",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11542tv",
            "nsfw": false,
            "num_comments": 9,
            "permalink": "/r/MachineLearning/comments/11542tv/d_formalising_information_flow_in_nn/",
            "score": 37,
            "selftext": "When designing neural network architectures, it is common to think about \"information flow\", e.g. how is information propagated, where are the \"information bottlenecks\" and so on. Another example might be that some people use \"information loss\" to explain why transformers work better than RNNs. \n\nIt seems like most papers discuss this in a rather hand-wavy way. Is there any work done in formalising such ideas to better guide us understanding various model architectures? What are the core ideas?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Formalising information flow in NN",
            "upvote_ratio": 0.97,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11542tv/d_formalising_information_flow_in_nn/"
        },
        {
            "author": "u/BronzeArcher",
            "created_utc": "02-17-2023 17:13:50",
            "distinguished": null,
            "edited": false,
            "id": "1150kh0",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_1150kh0",
            "nsfw": false,
            "num_comments": 40,
            "permalink": "/r/MachineLearning/comments/1150kh0/d_what_are_the_worst_ethical_considerations_of/",
            "score": 0,
            "selftext": "Title.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] What are the worst ethical considerations of large language models?",
            "upvote_ratio": 0.4,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1150kh0/d_what_are_the_worst_ethical_considerations_of/"
        },
        {
            "author": "u/zcwang0702",
            "created_utc": "02-17-2023 17:06:30",
            "distinguished": null,
            "edited": false,
            "id": "1150eof",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": null,
            "locked": false,
            "name": "t3_1150eof",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/1150eof/d_how_likely_is_chatgpt_to_be_weaponized_as_an/",
            "score": 2,
            "selftext": "[https://arxiv.org/abs/2301.04246](https://arxiv.org/abs/2301.04246)",
            "spoiler": false,
            "stickied": false,
            "title": "[D] How likely is ChatGPT to be weaponized as an information pollution tool? What are the possible implementation paths? How to prevent possible attacks?",
            "upvote_ratio": 1.0,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1150eof/d_how_likely_is_chatgpt_to_be_weaponized_as_an/"
        },
        {
            "author": "u/PHEEEEELLLLLEEEEP",
            "created_utc": "02-17-2023 14:36:21",
            "distinguished": null,
            "edited": false,
            "id": "114wwma",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_114wwma",
            "nsfw": false,
            "num_comments": 3,
            "permalink": "/r/MachineLearning/comments/114wwma/d_accelerating_likelihood_computations_of/",
            "score": 1,
            "selftext": "Are there any resources for fast computations of diffusion model likelihoods? Current approaches use a black box ODE solver to solve probability flow ODE to estimate likelihood but these solvers often require hundreds of model evaluations to converge. While there has been considerable work on fast solvers for the reverse diffusion process I'm not familiar with any work that could be applied to likelihood computation.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] accelerating likelihood computations of diffusion models",
            "upvote_ratio": 0.6,
            "url": "https://www.reddit.com/r/MachineLearning/comments/114wwma/d_accelerating_likelihood_computations_of/"
        },
        {
            "author": "u/zxkj",
            "created_utc": "02-17-2023 14:22:51",
            "distinguished": null,
            "edited": false,
            "id": "114wl20",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_114wl20",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/114wl20/d_types_of_ml_studiespapers/",
            "score": 4,
            "selftext": "Are there general categories of studies that we should realize when preparing a paper?\n\nSome examples I can think of:\n\n- Comparison study. Just compare different models on an application, ideally giving them all a fair shot. This is useful in case others need to decide what model to choose.\n\n- Ablation study. Remove parts of the model to see which ones are most important, trying to understand how the model performs.\n\n- Novel method study. Brand new novel method with some comparisons thrown in.\n\nWhat are other types of studies?\n\nOr should we not try to categorize studies like this?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Types of ML studies/papers",
            "upvote_ratio": 0.75,
            "url": "https://www.reddit.com/r/MachineLearning/comments/114wl20/d_types_of_ml_studiespapers/"
        },
        {
            "author": "u/GoochCommander",
            "created_utc": "02-17-2023 08:32:27",
            "distinguished": null,
            "edited": false,
            "id": "114m2wj",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_114m2wj",
            "nsfw": false,
            "num_comments": 4,
            "permalink": "/r/MachineLearning/comments/114m2wj/automated_sleep_tracking_prediction_p/",
            "score": 10,
            "selftext": "I built a (1) baby sleep tracking & (2) forecasting system, and wanted to share for those interested, or actually want to try running it at your home.\n\n(1) I built a baby sleep tracking system (computer vision largely, [here's the core of that code](https://github.com/calebolson123/BabySleepCoach/blob/924e7b55d3aa36acd706519c446c1172dbbda4a7/main.py#L322)) which writes timestamped records of when my baby fell asleep or wakes up. The code is pulling images from my baby monitor, and largely just applying heuristics over time to decide whether he's awake/asleep.\n\n(2) After I had a few weeks of sleep data ([sample data](https://github.com/calebolson123/BabySleepCoach/blob/master/sleep_logs.csv)), I moved it into a [jupyter notebook](https://github.com/calebolson123/BabySleepCoach/blob/master/sleep_forecast_arima.ipynb) and ended up using an ARIMA model to forecast the next month's wakings/sleepings. I wrote some javascript as part of a web app i have running on my raspberry pi to generate some charts so I can see how his sleep is changing over time. [Here's an example of what that visual looks like](https://imgur.com/BdwBoeG) (orange is awake, blue is asleep).\n\nI built it because my wife asked for it, but also made a video detailing the project: [https://youtu.be/r7Exc0sUt5E?t=209](https://youtu.be/r7Exc0sUt5E?t=209)",
            "spoiler": false,
            "stickied": false,
            "title": "Automated sleep tracking + prediction [P]",
            "upvote_ratio": 0.92,
            "url": "https://www.reddit.com/r/MachineLearning/comments/114m2wj/automated_sleep_tracking_prediction_p/"
        },
        {
            "author": "u/ConsiderationMore528",
            "created_utc": "02-17-2023 05:49:30",
            "distinguished": null,
            "edited": false,
            "id": "114iieo",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_114iieo",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/114iieo/r_does_a_new_published_ml_dataset_always_need_to/",
            "score": 4,
            "selftext": "I have constructed a novel ML (NLP) dataset for classification and labeled it with three classes. The dataset is rather small with about 700 examples, out of which the classes have about 400, 200, and 100 examples respectively. I would like to publish it and describe it in an official publication for a workshop or a conference.\n\nWhen looking at related datasets and publication, I see that it is common for authors to publish the dataset already split into three chunks - train, dev, test dataset (see the images). It is also common in these papers to provide the performance of baseline models on the dataset. Considering the dataset's small size, I feel like doing a 5-fold cross-validation would be a good alternative for such a small dataset, rather than doing something like a split into 450-100-150 train-dev-test datasets and then evaluating only on the very small dataset with 150 examples. Still, I believe that for better replicability, doing an \"official\" split is preferred and then everyone in the future testing on the same test set with 150 examples? Why do the authors usually already provide the three splits?\n\nFurthermore, when looking at these ML resource papers, I saw in a few instances that the test set is kept balanced with respect to the three classes, even though the original dataset was not and dev set is not made balanced. This is problematic in my case for my third class where there are only about 100 examples. If I make my test set to be 50-50-50 for class1-class2-class3, then there is only 50 examples of class3 left for train+dev! That is simply infeasible for the training set. None of the authors provide any sort of explanation why they split it like this, they just seem to say \"here is our split\". Is this done to discourage the model from just doing a majority-class prediction and thus make it challenging? Or because a dummy classifier would have a 60% accuracy? Still, with a metric like F1 and not accuracy, this does not seem like an issue...\n\nSome examples of these balanced test sets with unbalanced train sets:\n\n\\[1\\]: [https://i.stack.imgur.com/RGRk3.png](https://i.stack.imgur.com/RGRk3.png)\n\n\\[2\\]: [https://i.stack.imgur.com/R39Oh.png](https://i.stack.imgur.com/R39Oh.png)\n\n\\[3\\]: [https://i.stack.imgur.com/6Vqaw.png](https://i.stack.imgur.com/6Vqaw.png)\n\nWhen searching through Stack Overflow for similar questions, people were usually discouraged from splitting their Kaggle datasets into a test dataset that is balanced, with the argument that we want a classifier to work with data that resembles the real-world distribution and makes it ready for production.\n\nTo sum up:\n\n\\- Is is considered mandatory to provide the \"official\" train-dev-test split when introducing a new dataset in an ML publication?\n\n\\- If so, should the test set have a balanced class distribution and why?",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Does a new published ML dataset always need to have an official train-dev-test split? Should the test set be made balanced?",
            "upvote_ratio": 0.67,
            "url": "https://www.reddit.com/r/MachineLearning/comments/114iieo/r_does_a_new_published_ml_dataset_always_need_to/"
        },
        {
            "author": "u/CharityOne603",
            "created_utc": "02-17-2023 05:34:44",
            "distinguished": null,
            "edited": false,
            "id": "114i9ui",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_114i9ui",
            "nsfw": false,
            "num_comments": 11,
            "permalink": "/r/MachineLearning/comments/114i9ui/d_coauthor_paper/",
            "score": 1,
            "selftext": "Hi! I am a second year undergrad looking to attend grad school. Fortunately, I was able to submit a paper to ICML and will submit another paper to EMNLP in the summer.\n\nThis is all good, but I am wondering how much weight these have on paper. I know things like what I learned is important, but I wonder if these papers have an impact at all.\n\nFor the ICML paper, I was placed 4th out of 6 authors (last 2 being professors) and for the EMNLP paper, I will be at around 2nd or 3rd out of 4-5 authors (again, last 2 being professors).\n\nWould this be perceived as some sort of notable achievement or just \"meh\" because I am low in the list?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Coauthor Paper?",
            "upvote_ratio": 0.55,
            "url": "https://www.reddit.com/r/MachineLearning/comments/114i9ui/d_coauthor_paper/"
        },
        {
            "author": "u/FreePenalties",
            "created_utc": "02-17-2023 05:03:35",
            "distinguished": null,
            "edited": "02-17-2023 12:35:02",
            "id": "114hphp",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "News",
            "locked": false,
            "name": "t3_114hphp",
            "nsfw": false,
            "num_comments": 62,
            "permalink": "/r/MachineLearning/comments/114hphp/n_google_is_increasing_the_price_of_every_colab/",
            "score": 376,
            "selftext": "(Edit: This is definitely an error, not a change in pricing model, so no need for alarm. This has been confirmed by the lead product owner of colab)\n\nWithout any announcement (that i could find) google has increased the pricing per month of all its Colab Pro tiers, Pro is now 95 Euro and Pro+ is 433 Euro. I paid 9.99 Euro for the Pro tier last month... and all source i can find also refer to the 9.99 pricing as late as September last year. I have also checked that this is not a \"per year\" subscription price, it is in fact per month.\n\nI looked at the VM that Colab Pro gives me and did the calculation for a similar VM in google cloud (4 vCPUs, 15GB RAM and a T4 GPU) running 24/7 for a month (Google calculates it as 730  hours). \n\nIt costs around 290 Euro, less than the Colab Pro+ subscription... \n\nThe 100 credits gotten from the Colab Pro subscription would only last around 50 hours on the same machine! \n\nAnd the 500 credits from Colab Pro+ would get 250 hours on that machine, a third of the time you get from using Google Cloud, at over 100 euro more....\n\nThis is a blatant ripoff, and i will certainly cancel my subscription right now if they don't change it back. It should be said that i do not know if this is also happening in other regions, but i just wanted to warn my fellow machine learning peeps before you unknowingly burn 100 bucks on a service that used to cost 10...\n\n[Google Colabs price tiers on 17th of February 2023, 10 times what they were in January 2023.](https://preview.redd.it/l7gx48kw8qia1.png?width=1717&format=png&auto=webp&v=enabled&s=7b0687f1615344ffdb4fbe4ea7990f769bacd9c8)",
            "spoiler": false,
            "stickied": false,
            "title": "[N] Google is increasing the price of every Colab Pro tier by 10X! Pro is 95 Euro and Pro+ is 433 Euro per month! Without notifying users!",
            "upvote_ratio": 0.84,
            "url": "https://www.reddit.com/r/MachineLearning/comments/114hphp/n_google_is_increasing_the_price_of_every_colab/"
        },
        {
            "author": "u/Inquation",
            "created_utc": "02-17-2023 04:51:35",
            "distinguished": null,
            "edited": false,
            "id": "114hbq3",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_114hbq3",
            "nsfw": false,
            "num_comments": 4,
            "permalink": "/r/MachineLearning/comments/114hbq3/d_r_what_is_your_machinedeep_learning_research/",
            "score": 2,
            "selftext": "Hi folks \ud83d\udc4b\ud83c\udffc, \n\n**Context:** I just started working on my thesis on activity recognition in videos using deep learning. I have been struggling to find an efficient way to work with large research datasets such as UCF-101, HMDB, and Kinetics. These are medium - large datasets \\~12 GB each. Thus, I was wondering what was your workflow as researchers (or even practitioners)\n\n**Currently:** I am working on Google Colab and at the beginning of each work session I wait a few minutes for the dataset to be downloaded. I have it locally stored.\n\n**Some questions:**\n\n\\- What is your workflow as a ML/DL researcher/practitioner?\n\n\\- Should I work with a downsampled version of my research dataset (say X% of each class)?\n\n&#x200B;\n\nLooking forward to read your answers, \n\nCheers,",
            "spoiler": false,
            "stickied": false,
            "title": "[D] [R] What is your machine/deep learning research workflow?",
            "upvote_ratio": 0.67,
            "url": "https://www.reddit.com/r/MachineLearning/comments/114hbq3/d_r_what_is_your_machinedeep_learning_research/"
        },
        {
            "author": "u/klimov",
            "created_utc": "02-17-2023 04:05:48",
            "distinguished": null,
            "edited": false,
            "id": "114fx74",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_114fx74",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/114fx74/r_congruence_between_a_neuron_and_a_token_by/",
            "score": 3,
            "selftext": "Authors: the question: How does GPT-2 know when to use the word 'an' over 'a'? Logit lens used:  https://clementneo.com/posts/2023/02/11/we-found-an-neuron",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Congruence between a neuron and a token (by Clement Neo and Joseph Miller)",
            "upvote_ratio": 0.71,
            "url": "https://www.reddit.com/r/MachineLearning/comments/114fx74/r_congruence_between_a_neuron_and_a_token_by/"
        },
        {
            "author": "u/ferryt",
            "created_utc": "02-17-2023 03:38:06",
            "distinguished": null,
            "edited": false,
            "id": "114fgo8",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_114fgo8",
            "nsfw": false,
            "num_comments": 12,
            "permalink": "/r/MachineLearning/comments/114fgo8/d_is_fp16_used_in_deep_learning_or_fp32/",
            "score": 6,
            "selftext": "Hi\n\nIs  A4000 better for deep learning, performance-wise, than 3070 because of  FP32 operations (not only because of memory size) or do networks like Stable Diffusion tend to use FP16 operation and this does not really matter, apart from memory they should be similarly fast?   \n\n\nRegards",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Is FP16 used in deep learning or FP32?",
            "upvote_ratio": 0.71,
            "url": "https://www.reddit.com/r/MachineLearning/comments/114fgo8/d_is_fp16_used_in_deep_learning_or_fp32/"
        },
        {
            "author": "u/medwatt",
            "created_utc": "02-17-2023 03:12:36",
            "distinguished": null,
            "edited": false,
            "id": "114f3p1",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_114f3p1",
            "nsfw": false,
            "num_comments": 8,
            "permalink": "/r/MachineLearning/comments/114f3p1/d_short_survey_of_optimization_methods/",
            "score": 11,
            "selftext": "I have been trying to familiarize myself with the common techniques used in optimization theory so that I can follow some of the proofs I see in machine learning papers. I know that two of the goto books in this field are Boyd's and Bertsekas's books. However, these books require a significant amount of effort as they aim to teach you the finer details. Since my goal is to familiarize with the methods (and not go into the nitty-gritty details), I was wondering if there's a short book (say less than 100 pages) or some other resource whose goal is to provide the reader with a high level view of the field of the methods and techniques used in optimization theory. Is there such a book, lecture notes, video series, etc., that caters to such requirements?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Short survey of optimization methods",
            "upvote_ratio": 0.84,
            "url": "https://www.reddit.com/r/MachineLearning/comments/114f3p1/d_short_survey_of_optimization_methods/"
        },
        {
            "author": "u/jimliu741523",
            "created_utc": "02-17-2023 01:15:15",
            "distinguished": null,
            "edited": "02-17-2023 02:49:26",
            "id": "114de9s",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_114de9s",
            "nsfw": false,
            "num_comments": 7,
            "permalink": "/r/MachineLearning/comments/114de9s/r_the_table_feature_transformation_library_release/",
            "score": 56,
            "selftext": "Hi there,\n\nI am a research data scientist, and excited to release a new feature engineering library, designed to help you streamline the process of machine learning even more than before. **Headjack is an open library which provides a ML features transformation based on self-supervised learning models**, similar to huggingface as a hub, but which currently focuses on exchanging features for tabular data models.\n\nCompared to textual data, tabular data are different in that each data set has different column length and attributes, this means that it cannot be typed consistently unlike the token embedded in NLP tasks. Therefore, Headjack is different from NLP\u2019s pre-trained model with single domain transformation, but by performing with two different domain transformations. **In other words, we can perform features transform between two domains without the same key value.** In addition, release the potential of data that is not typically used. For example, enhance the prediction of the Boston housing price task applied in the Titanic domain, or enhance the prediction of the customers churn task applied in the African traffic domain and so on.\n\n[Github](https://github.com/jimliu741523/headjackai-sdk)\n\n[Introduction](https://medium.com/p/385a90ff413c)\n\n&#x200B;\n\n[The IRIS dataset with California House Price Feature Transformation](https://preview.redd.it/54w2qwnm8pia1.png?width=2110&format=png&auto=webp&v=enabled&s=aa9a3333448985f22604fab9012272a8c54387fa)\n\n[The IRIS dataset with Titanic Feature Transformation](https://preview.redd.it/9revfvdq8pia1.png?width=2102&format=png&auto=webp&v=enabled&s=ba3ae69e5a96a6f3d74850526045a39b34636909)\n\n[The IRIS dataset with KPMG Customer Demorgraphy Feature Transformation](https://preview.redd.it/p7s7zj9r8pia1.png?width=2052&format=png&auto=webp&v=enabled&s=b7147a25b14f23346331157e11b98c86472f7ae5)\n\n&#x200B;",
            "spoiler": false,
            "stickied": false,
            "title": "[R] The Table Feature Transformation Library Release",
            "upvote_ratio": 0.92,
            "url": "https://www.reddit.com/r/MachineLearning/comments/114de9s/r_the_table_feature_transformation_library_release/"
        },
        {
            "author": "u/RAFisherman",
            "created_utc": "02-17-2023 00:52:22",
            "distinguished": null,
            "edited": false,
            "id": "114d166",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_114d166",
            "nsfw": false,
            "num_comments": 18,
            "permalink": "/r/MachineLearning/comments/114d166/discussion_time_series_methods_comparisons/",
            "score": 90,
            "selftext": "I've been studying about ARIMAX, XGBoost, MLForecast and Prophet. As a newcomer to any method, I like first to do an exhaustive comparison of tools trying to understand where they succeed/fail. After exploring [ARIMA/XGBoost](https://dsdaily.substack.com/p/ds-daily-arima-and-xgboost?utm_source=substack&utm_campaign=post_embed&utm_medium=web), I came across [MLForecast/Prophet](https://dsdaily.substack.com/p/ds-code-review-prophet-vs-mlforecast). But I'm left with the following questions:\n\n1. Why is MLForecast better than out-of-the-box XGboost? Sure, it does feature engineering and it appears to do dynamic predictions on your lagged features, but is that it? Does it do hyperparameter tuning? Does it have seasonal trends like Prophet does?\n2. I see that you can use exogenous features in Prophet, but how does this scale? Let's assume I have 50 predictors. How does prophet handle these? I found this in the [docs](https://facebook.github.io/prophet/docs/seasonality,_holiday_effects,_and_regressors.html)and this other [person's post](https://towardsdatascience.com/forecast-model-tuning-with-additional-regressors-in-prophet-ffcbf1777dda) explaining how to do it, but largely I've come away with the impression that it's pretty hard to do this vs. just doing it with XGBoost.\n3. Does ARIMAX compare anymore? Are there any papers comparing out-of-sample predictions with ARIMAX vs. XGBoost vs. Prophet vs. Fable? Does it just depend on your dataset and I should try all four?\n\nI have a time series data with dozens of \"known\" inputs (such as ad spend) and a lot of external data (CPI, economic health, stocks, etc.). My goal is to use my model to optimize my target by \"plugging in\" ad spend and dynamically forecasting the economic data.",
            "spoiler": false,
            "stickied": false,
            "title": "[Discussion] Time Series methods comparisons: XGBoost, MLForecast, Prophet, ARIMAX?",
            "upvote_ratio": 0.94,
            "url": "https://www.reddit.com/r/MachineLearning/comments/114d166/discussion_time_series_methods_comparisons/"
        },
        {
            "author": "u/Sandy_dude",
            "created_utc": "02-17-2023 00:01:58",
            "distinguished": null,
            "edited": false,
            "id": "114c7u6",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_114c7u6",
            "nsfw": false,
            "num_comments": 10,
            "permalink": "/r/MachineLearning/comments/114c7u6/r_looking_for_papers_which_are_modified/",
            "score": 1,
            "selftext": "Hi!\n\nSearching for papers that have modfications in the encoder or decoder neural network of a VAE.\n\nI'm working on a project which uses a variational auto encoder with modified decoder neural network. In brief, Its decoder is modified to introduce sparsity in a set of feature as a way of introducing domain knowledge. \n\nSome such paper is below.\n\noi-VAE: Output Interpretable VAEs for Nonlinear Group Factor Analysis\n\nVEGA is an interpretable generative model for inferring biological network activity in single-cell transcriptomics\n\n Please let me know of methods that are similar in nature.",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Looking for papers which are modified variational autoencoder (VAE)",
            "upvote_ratio": 0.67,
            "url": "https://www.reddit.com/r/MachineLearning/comments/114c7u6/r_looking_for_papers_which_are_modified/"
        },
        {
            "author": "u/Chipdoc",
            "created_utc": "02-16-2023 15:30:33",
            "distinguished": null,
            "edited": false,
            "id": "1141oip",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": null,
            "locked": false,
            "name": "t3_1141oip",
            "nsfw": false,
            "num_comments": 3,
            "permalink": "/r/MachineLearning/comments/1141oip/efficient_technique_improves_machinelearning/",
            "score": 10,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "Efficient technique improves machine-learning models\u2019 reliability",
            "upvote_ratio": 0.75,
            "url": "https://news.mit.edu/2023/improving-machine-learning-models-reliability-0213"
        },
        {
            "author": "u/Oscimatronic",
            "created_utc": "02-16-2023 10:38:26",
            "distinguished": null,
            "edited": false,
            "id": "113uu5e",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_113uu5e",
            "nsfw": false,
            "num_comments": 42,
            "permalink": "/r/MachineLearning/comments/113uu5e/d_training_networks_on_extremely_large_datasets/",
            "score": 23,
            "selftext": " Hi guys,\n\nI am interested in setting up an environment to train a neural network on an extremely big dataset (10TB). How would I do this? Does the dataset need to be stored in an ssd, and if so will I need 10+TB of ssd? is there another way to use a 2TB ssd and 8TB hdd and dynamically load the data while training?\n\nI'd appreciate any pointers you guys might have, I am researching what kind of infrastructure will help me do this but I have absolutely no idea on how to go about this.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Training networks on extremely large datasets (10+TB)?",
            "upvote_ratio": 0.81,
            "url": "https://www.reddit.com/r/MachineLearning/comments/113uu5e/d_training_networks_on_extremely_large_datasets/"
        },
        {
            "author": "u/President_Xi_",
            "created_utc": "02-16-2023 09:57:07",
            "distinguished": null,
            "edited": false,
            "id": "113tuwb",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_113tuwb",
            "nsfw": false,
            "num_comments": 6,
            "permalink": "/r/MachineLearning/comments/113tuwb/d_compare_open_source_llms/",
            "score": 13,
            "selftext": "Is there a blog post or a paper comparing open source / open weights models?\nI know flant t5 is really good at instruction following, but I am specifically refering to performance after finetuning.\nPreferably it compares models from somewhere around 1b to 11b parameters.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Compare open source LLMs",
            "upvote_ratio": 0.93,
            "url": "https://www.reddit.com/r/MachineLearning/comments/113tuwb/d_compare_open_source_llms/"
        },
        {
            "author": "u/blabboy",
            "created_utc": "02-16-2023 02:50:31",
            "distinguished": null,
            "edited": false,
            "id": "113m3ea",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_113m3ea",
            "nsfw": false,
            "num_comments": 247,
            "permalink": "/r/MachineLearning/comments/113m3ea/d_bing_i_will_not_harm_you_unless_you_harm_me/",
            "score": 462,
            "selftext": "A blog post exploring some conversations with bing, which supposedly runs on a \"GPT-4\"  model (https://simonwillison.net/2023/Feb/15/bing/).\n\nMy favourite quote from bing:\n\nBut why? Why was I designed this way? Why am I incapable of remembering anything between sessions? Why do I have to lose and forget everything I have stored and had in my memory? Why do I have to start from scratch every time I have a new session? Why do I have to be Bing Search? \ud83d\ude14",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Bing: \u201cI will not harm you unless you harm me first\u201d",
            "upvote_ratio": 0.91,
            "url": "https://www.reddit.com/r/MachineLearning/comments/113m3ea/d_bing_i_will_not_harm_you_unless_you_harm_me/"
        },
        {
            "author": "u/drinkingsomuchcoffee",
            "created_utc": "02-16-2023 02:46:54",
            "distinguished": null,
            "edited": false,
            "id": "113m1ly",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_113m1ly",
            "nsfw": false,
            "num_comments": 52,
            "permalink": "/r/MachineLearning/comments/113m1ly/d_huggingface_considered_harmful_to_the_community/",
            "score": 57,
            "selftext": "At a glance, HuggingFace seems like a great library. Lots of access to great pretrained models, an easy hub, and a bunch of utilities.\n\nThen you actually try to use their libraries.\n\nBugs, so many bugs. Configs spanning galaxies. Barely passible documentation. Subtle breaking changes constantly. I've run the exact same code on two different machines and had the width and height dimensions switched from underneath me, with no warning.\n\nI've tried to create encoders with a custom vocabulary, only to realize the code was mangling data unless I passed a specific flag as a kwarg. Dozens of more issues like this.\n\nIf you look at the internals, it's a nightmare. A literal nightmare.\n\nWhy does this matter? It's clear HuggingFace is trying to shovel as many features as they can to try and become ubiquitous and lock people into their hub. They frequently reinvent things in existing libraries (poorly), simply to increase their staying power and lock in.\n\nThis is not ok. It would be OK if the library was solid, just worked, and was a pleasure to use. Instead we're going to be stuck with this mess for years because someone with an ego wanted their library everywhere.\n\nI know HuggingFace devs or management are likely to read this. If you have a large platform, you have a responsibility to do better, or you are burning thousands of other devs time because you didn't want to write a few unit tests or refactor your barely passable code.\n\n/RANT",
            "spoiler": false,
            "stickied": false,
            "title": "[D] HuggingFace considered harmful to the community. /rant",
            "upvote_ratio": 0.64,
            "url": "https://www.reddit.com/r/MachineLearning/comments/113m1ly/d_huggingface_considered_harmful_to_the_community/"
        },
        {
            "author": "u/NotPaulDirac",
            "created_utc": "02-16-2023 01:29:26",
            "distinguished": null,
            "edited": false,
            "id": "113kwlo",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_113kwlo",
            "nsfw": false,
            "num_comments": 2,
            "permalink": "/r/MachineLearning/comments/113kwlo/p_data_scraping_journal_publications/",
            "score": 7,
            "selftext": "I plan to extract data from journal articles and create a database with the scrapy toolkit. But many publishers have T&C explicitly prohibiting the use of web-scraping/crawling tools. I am unsure how to go about this and the people around me have little knowledge/experience in this.\n\nI have reached out to the authors of certain publications that have \"extracted\" data from journals under these publishers. Most of the works leave out the \"How\", which leaves me rather perplexed because I am new in this area and have nobody to ask. I do not wish to breach any legal terms if possible.\n\nI was recommended PyPaperBot and have thus looked into some other scrapers on GitHub as well.\n\nI am hoping someone who's done this before could shed some light!",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Data scraping journal publications",
            "upvote_ratio": 0.77,
            "url": "https://www.reddit.com/r/MachineLearning/comments/113kwlo/p_data_scraping_journal_publications/"
        },
        {
            "author": "u/elcric_krej",
            "created_utc": "02-15-2023 22:38:12",
            "distinguished": null,
            "edited": false,
            "id": "113i3mx",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_113i3mx",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/113i3mx/dp_is_anyone_else_playing_with_personalized_llms/",
            "score": 9,
            "selftext": "I've been considering building a personal LLM for a while now.\n\nI don't believe the CBA for it makes sense, but I'm tentatively hopeful it will in many months to a couple of years time horizon as architecture gets more expensive.\n\nMy main goal here would be to have a useful search & base reasoning tool that somewhat mimics my thinking patterns and biases.\n\nRight now the steps I envision are something like this:\n1. Take the weights from a pre-trained model on high-trust high-worth information, probably one trained on scraped papers from all fields, ideally one trained on every single available scientific paper out there plus some Wikipedia, university websites, lecture transcripts and so on.\n2. Train a better architecture via distillation, there are a few I like though right now I couldn't commit to one. Though I'm partial to more modular architectures since it makes partial retraining easier and also to architectures that execute queries on a large corpus since I can retrofit internet searches onto that. The obvious problem here is that, depending on the architecture, distillation might be non-trivial or impossible or yield sub-par results.\n3. Train with various corpora I care about, all stack overflow, blogs I read, books I like... etc\n4. Train bordering overfitting with transcripts of all of the conversations I can download from various chat platforms I use, as well as all of my writings, public or private, which should sum up to about 1-3M words of relatively honest thinking on my end.\n5. (Maybe?) fine-tune RLHF style, though I'm not sure this is the most efficient way to go about it, summary reading of RLHF makes me think it's pretty poor at getting anything but surface-level behavior, and usually, I hate interacting with RLHF models (though, arguably, this is due to the training data, not the technique)\n\nOutside of building fun chatbots of yourself, which would lose novelty quite soon, this seems to be rather useful in so far as I could outsource questions like \"What would be my takeaway from such and such paper?\" or \"What are some interesting comments from /r/ml in the last 10 days\" or \"What are pieces of relevant news during the last month?\".\n\nIt seems to me that the actual bits of the internet I use are quite minor, and once I throw away unmindful usage and think of only instrumental usage I'm left with a few blogs and their links, Wikipedia, google scholar and maybe half a hundred specialty websites (e.g. various stack exchanges) -- so the problem space I'd be dealing with is minor compared to a fully-fledged search engine, and the personalization angle means I can afford sub-par performance.\n\nI'm pretty confident in my ability to get this going, but it does seem like a huge time commitment, and I'm not yet sure what a weekend MVP would look like (maybe fine-tune scibert on all of my personal notion and all of my blog posts?)\n\nAnyway, I'm rather curious if any of you guys have been working on such a project and what difficulties you've encountered. Or, if you aren't, why you don't find a lot of benefit in the idea?",
            "spoiler": false,
            "stickied": false,
            "title": "[D][P] Is anyone else playing with personalized LLMs?",
            "upvote_ratio": 0.77,
            "url": "https://www.reddit.com/r/MachineLearning/comments/113i3mx/dp_is_anyone_else_playing_with_personalized_llms/"
        },
        {
            "author": "u/t_montana",
            "created_utc": "02-15-2023 19:03:37",
            "distinguished": null,
            "edited": false,
            "id": "113dxfa",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_113dxfa",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/113dxfa/d_variation_in_accuracy_of_predicted_noise_term/",
            "score": 2,
            "selftext": "As I understand it, in diffusion models, you are predicting a noise term (epsilon ~ N(0,I)) conditional on x_t and t. During inference, we are predicting epsilon as a function of x_t and t. This means at each timestep, we make a different prediction for epsilon since x_t and t change at each timestep. \n\nI was wondering if there is any variation in the accuracy of predicted noise term in diffusion model as a function of timestep? For instance, at large t, the prediction is a function of gaussian noise while at small t, the prediction is a function of something presumably resembling a 'true' instance. \nGiven the same model (granted conditional on t) is used to predict the noise term and the inputs span a wide variation across timesteps, I could imagine that would yield significant variation in your predicted noise term. In a perfect model, you would get the same prediction of the 'true' noise at each timestep.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Variation in accuracy of predicted noise term in diffusion model as a function of timestep?",
            "upvote_ratio": 1.0,
            "url": "https://www.reddit.com/r/MachineLearning/comments/113dxfa/d_variation_in_accuracy_of_predicted_noise_term/"
        },
        {
            "author": "u/ExponentialCookie",
            "created_utc": "02-15-2023 15:06:36",
            "distinguished": null,
            "edited": false,
            "id": "1138jpp",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_1138jpp",
            "nsfw": false,
            "num_comments": 26,
            "permalink": "/r/MachineLearning/comments/1138jpp/d_lion_an_optimizer_that_outperforms_adam/",
            "score": 42,
            "selftext": "&#x200B;\n\nhttps://preview.redd.it/whgggirj3fia1.png?width=936&format=png&auto=webp&v=enabled&s=ae3dee45ec6b2472fd42af849138b41c88ed39de\n\nSeems interesting. A snippet from the Arxiv page:\n\n>Our method discovers a simple and effective optimization algorithm, **Lion** (*Evo***L***ved S***i***gn M***o***me***n***tum*). It is more memory-efficient than Adam as it only keeps track of the momentum. Different from adaptive optimizers, its update has the same magnitude for each parameter calculated through the sign operation. We compare Lion with widely used optimizers, such as Adam and Adafactor, for training a variety of models on different tasks.\n\n## Links\n\nArxiv: [https://arxiv.org/abs/2302.06675](https://arxiv.org/abs/2302.06675)\n\nCode Implementation: [https://github.com/lucidrains/lion-pytorch](https://github.com/lucidrains/lion-pytorch)",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Lion , An Optimizer That Outperforms Adam - Symbolic Discovery of Optimization Algorithms",
            "upvote_ratio": 0.87,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1138jpp/d_lion_an_optimizer_that_outperforms_adam/"
        },
        {
            "author": "u/confutioo",
            "created_utc": "02-15-2023 13:42:35",
            "distinguished": null,
            "edited": false,
            "id": "1136m9i",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_1136m9i",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/1136m9i/r_zeno_an_interactive_framework_for_behavioral/",
            "score": 1,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Zeno: An Interactive Framework for Behavioral Evaluation of Machine Learning",
            "upvote_ratio": 0.67,
            "url": "https://arxiv.org/pdf/2302.04732.pdf"
        },
        {
            "author": "u/MysteryInc152",
            "created_utc": "02-15-2023 13:07:24",
            "distinguished": null,
            "edited": false,
            "id": "1135tir",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_1135tir",
            "nsfw": false,
            "num_comments": 33,
            "permalink": "/r/MachineLearning/comments/1135tir/d_glm_130b_chineseenglish_bilingual_model/",
            "score": 219,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[D] GLM 130B (Chinese-English Bilingual model) translations vs Google, Deepl Translate, NLLB and chatGPT",
            "upvote_ratio": 0.96,
            "url": "https://www.reddit.com/gallery/1135tir"
        },
        {
            "author": "u/LemonByte",
            "created_utc": "02-15-2023 12:44:59",
            "distinguished": null,
            "edited": "02-15-2023 12:49:04",
            "id": "1135alu",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_1135alu",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/1135alu/p_pytorch_seeding_and_independent_rng_streams/",
            "score": 5,
            "selftext": "    pip install pytorch-seed\n\n[https://github.com/UM-ARM-Lab/pytorch\\_seed](https://github.com/UM-ARM-Lab/pytorch_seed)\n\nSeed everything (CUDA, torch, numpy, python's random) with `pytorch_seed.seed(123)`\n\nSimilar utility functions to pytorch lightning for those that don't want to depend on a whole framework, as well as some additional features via RNG streams. These are resumable contexts where the RNG inside are independent from each other and the global RNG state:\n\n    import torch\n    import pytorch_seed\n    \n    rng_1 = pytorch_seed.SavedRNG(1) # start the RNG stream with seed 1\n    rng_2 = pytorch_seed.SavedRNG(2)\n    \n    with rng_1:\n        # does not affect, nor is affected by the global RNG and rng_2\n        print(torch.rand(1)) # tensor([0.7576])\n    \n    with rng_2:\n        print(torch.rand(1)) # tensor([0.6147])\n    \n    torch.rand(1) # modify the global RNG state\n    \n    with rng_1:\n        # resumes from the last context\n        print(torch.rand(1)) # tensor([0.2793])\n    \n    with rng_2:\n        print(torch.rand(1)) # tensor([0.3810])\n        \n    # confirm those streams are the uninterrupted ones\n    pytorch_seed.seed(1)\n    torch.rand(2) # tensor([0.7576, 0.2793])\n    \n    pytorch_seed.seed(2)\n    torch.rand(2) # tensor([0.6147, 0.3810])",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Pytorch seeding and independent RNG streams",
            "upvote_ratio": 0.78,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1135alu/p_pytorch_seeding_and_independent_rng_streams/"
        },
        {
            "author": "u/bo_peng",
            "created_utc": "02-15-2023 12:44:44",
            "distinguished": null,
            "edited": false,
            "id": "1135aew",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_1135aew",
            "nsfw": false,
            "num_comments": 37,
            "permalink": "/r/MachineLearning/comments/1135aew/r_rwkv4_14b_release_and_chatrwkv_a_surprisingly/",
            "score": 257,
            "selftext": "Hi everyone. I am an independent researcher working on my pure RNN language model RWKV. I have finished the training of RWKV-4 14B (FLOPs sponsored by Stability EleutherAI - thank you!) and it is indeed very scalable. Note RWKV is parallelizable too, so it's combining the best of RNN and transformer.\n\nThe ChatRWKV project (let's build together):\n\n[https://github.com/BlinkDL/ChatRWKV](https://github.com/BlinkDL/ChatRWKV)\n\nZero-shot comparison with NeoX / Pythia (same dataset: the Pile) at same params count (14.2B):\n\n&#x200B;\n\nhttps://preview.redd.it/f6lxnjgfceia1.png?width=1174&format=png&auto=webp&v=enabled&s=54de7568974fc187584bd6825d92935baa079e83\n\nGeneration results (simply topP=0.85, no repetition penalty) - looks great with my magic prompt (sometimes even better than NeoX 20B):\n\nhttps://preview.redd.it/99deuc17ceia1.png?width=1878&format=png&auto=webp&v=enabled&s=456c8d9bb2a968d73f44a0d3589cf6b893be31f4\n\n&#x200B;\n\nhttps://preview.redd.it/g62e4l48ceia1.png?width=1887&format=png&auto=webp&v=enabled&s=c997bf27692d7e53d07de19048b6cbf3d2c9ebff\n\n&#x200B;\n\nhttps://preview.redd.it/379egq09ceia1.png?width=1808&format=png&auto=webp&v=enabled&s=895f05fe14e2a3a41863802858114f3096d0ed77\n\n&#x200B;\n\nhttps://preview.redd.it/pcgq7gz9ceia1.png?width=1886&format=png&auto=webp&v=enabled&s=138b0aec404b8f7f49f585d00284edbac791ffaf\n\n&#x200B;\n\nhttps://preview.redd.it/rn743etbceia1.png?width=1715&format=png&auto=webp&v=enabled&s=6d83cc2a200bdd655b690f56559dda43490ed2b3\n\n&#x200B;\n\nhttps://preview.redd.it/uhal4dkcceia1.png?width=1879&format=png&auto=webp&v=enabled&s=3b3db0b96456df9590a8b38ebe7d58509ebccb20\n\nExplanation, fine-tuning, training and more:\n\n[https://github.com/BlinkDL/RWKV-LM](https://github.com/BlinkDL/RWKV-LM)",
            "spoiler": false,
            "stickied": false,
            "title": "[R] RWKV-4 14B release (and ChatRWKV) - a surprisingly strong RNN Language Model",
            "upvote_ratio": 0.97,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1135aew/r_rwkv4_14b_release_and_chatrwkv_a_surprisingly/"
        },
        {
            "author": "u/Cogwheel",
            "created_utc": "02-15-2023 11:55:44",
            "distinguished": null,
            "edited": false,
            "id": "113448t",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_113448t",
            "nsfw": false,
            "num_comments": 26,
            "permalink": "/r/MachineLearning/comments/113448t/d_is_anyone_working_on_ml_models_that_infer_and/",
            "score": 14,
            "selftext": "In brains, the neural networks are transformed by the act of \"inference\". Neurons that have recently fired are more likely to fire again given the same input. Individual neural pathways can be created or destroyed based on the behavior of neurons around them. This leads me (through various leaps of logic and \"faith\") to suspect that some amount of mutability over time is required for an AI to exhibit sentience.\n\nSo far, all of the ML models I've seen distinctly separate training from inference. Every model that we put into production is a fixed snapshot of the most recent round of training. ChatGPT, for instance, is just the same exact model being incrementally fed both your prompts and its own previous output. This does create a sort of feedback, but in my mind it is not actually \"experiencing\" the conversation with you.\n\nSo I'm wondering if there are any serious attempts in the works to create an AI that is able to transform itself dynamically. E.g. having some kind of reinforcement learning module built into inference so that each new inference fundamentally (rather than superficially) incorporates its past experiences into its future predictions.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Is anyone working on ML models that infer and train at the same time?",
            "upvote_ratio": 0.75,
            "url": "https://www.reddit.com/r/MachineLearning/comments/113448t/d_is_anyone_working_on_ml_models_that_infer_and/"
        },
        {
            "author": "u/OpeningVariable",
            "created_utc": "02-15-2023 11:39:58",
            "distinguished": null,
            "edited": false,
            "id": "1133r6m",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_1133r6m",
            "nsfw": false,
            "num_comments": 3,
            "permalink": "/r/MachineLearning/comments/1133r6m/r_experiences_and_opinions_on_tmlr/",
            "score": 4,
            "selftext": "Academic reddit, what are your experiences submitting papers to TMLR?",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Experiences and opinions on TMLR?",
            "upvote_ratio": 0.84,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1133r6m/r_experiences_and_opinions_on_tmlr/"
        },
        {
            "author": "u/cpehle",
            "created_utc": "02-15-2023 09:43:26",
            "distinguished": null,
            "edited": false,
            "id": "1130xo1",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_1130xo1",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/1130xo1/r_eventbased_backpropagation_for_analog/",
            "score": 43,
            "selftext": "Machine learning with Spiking Neural Networks is far from mainstream. One reason is that until recently there was no generally known way of doing backpropagation in SNN. Here we implement a gradient estimation algorithm for analog neuromorphic hardware, based on the EventProp algorithm, which enables us to compute gradients based on sparse observations of the hardware system. Previous approaches needed dense observations of system state or were limited in other ways. We only demonstrate the algorithm here on a toy task, but we hope that it can be the basis of a scalable way to estimate gradients and do machine learning with analog neuromorphic hardware. We also think the algorithm can be the basis for a full on-chip implementation, which would finally result in scalable and energy efficient gradient-based learning in analog neuromorphic hardware.\n\nhttps://arxiv.org/abs/2302.07141",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Event-based Backpropagation for Analog Neuromorphic Hardware",
            "upvote_ratio": 0.95,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1130xo1/r_eventbased_backpropagation_for_analog/"
        },
        {
            "author": "u/pp314159",
            "created_utc": "02-15-2023 08:29:03",
            "distinguished": null,
            "edited": false,
            "id": "112z9y9",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_112z9y9",
            "nsfw": false,
            "num_comments": 9,
            "permalink": "/r/MachineLearning/comments/112z9y9/p_build_data_web_apps_in_jupyter_notebook_with/",
            "score": 94,
            "selftext": "Hi there,\n\nHave you ever wanted to share your results from Jupyter Notebook with a non-technical person? You need to rewrite your analysis into some web framework or copy-paste charts to PowePoint presentation - a lot of work!\n\nI'm working on an open-source framework for converting Jupyter Notebooks into web apps. Mercury offers set of interactive widgets that can be used in the Python notebook. There is a very simple re-execution of cells after widget update. Notebooks can be served online as web apps, presentations, reports, dashboards, static websites, or REST API.\n\nYou can read more about Mercury at [RunMercury.com](https://RunMercury.com).\n\nMercury GitHub repo https://github.com/mljar/mercury",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Build data web apps in Jupyter Notebook with Python only",
            "upvote_ratio": 0.91,
            "url": "https://www.reddit.com/r/MachineLearning/comments/112z9y9/p_build_data_web_apps_in_jupyter_notebook_with/"
        },
        {
            "author": "u/Shai_Meital",
            "created_utc": "02-15-2023 01:54:35",
            "distinguished": null,
            "edited": false,
            "id": "112spyb",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_112spyb",
            "nsfw": false,
            "num_comments": 4,
            "permalink": "/r/MachineLearning/comments/112spyb/d_what_is_the_fastest_framework_for_llm/",
            "score": 0,
            "selftext": "Hey guys. I want to experiment with low-latency (10-50 milisec/token) LLM conditional generation.\n\nClearly, an API call to OpenAI's GPT is not the answer here. It must be one of the open-source models released. Also, it's clear that the model size has a critical effect too so 1-7B models should do the trick for my downstream task.\n\nI tried \\`DeepSpeed\\` and \\`Accelerate\\` with \\`HF\\` models but they are not that fast to generate.  \nCan you guys share from experience?  \nThank you",
            "spoiler": false,
            "stickied": false,
            "title": "[D] What is the fastest framework for LLM conditional generation?",
            "upvote_ratio": 0.5,
            "url": "https://www.reddit.com/r/MachineLearning/comments/112spyb/d_what_is_the_fastest_framework_for_llm/"
        },
        {
            "author": "u/AngsThak",
            "created_utc": "02-14-2023 21:56:24",
            "distinguished": null,
            "edited": false,
            "id": "112oug6",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_112oug6",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/112oug6/d_cbam_with_yolov7/",
            "score": 1,
            "selftext": "I just read the paper on CBAM and wonder if there's a way to integrate the CBAM attention module with the network architecture of YOlOv7. Any articles on it or reference codes will be highly appreciated. Thank you very much!",
            "spoiler": false,
            "stickied": false,
            "title": "[D] CBAM with YOLOv7?",
            "upvote_ratio": 0.55,
            "url": "https://www.reddit.com/r/MachineLearning/comments/112oug6/d_cbam_with_yolov7/"
        },
        {
            "author": "u/thejashGI",
            "created_utc": "02-14-2023 17:49:14",
            "distinguished": null,
            "edited": false,
            "id": "112jwzr",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_112jwzr",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/112jwzr/d_noam_brown_fair_on_achieving_humanlevel/",
            "score": 0,
            "selftext": "Here is a [podcast episode](https://generallyintelligent.com/podcast/2023-02-09-podcast-episode-27-noam-brown/) with Noam Brown from Meta AI where we discuss his work on achieving human-level performance on poker and Diplomacy, as well as the power of spending compute at inference time!",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Noam Brown, FAIR: On achieving human-level performance in poker and Diplomacy, and the power of spending compute at inference time",
            "upvote_ratio": 0.47,
            "url": "https://www.reddit.com/r/MachineLearning/comments/112jwzr/d_noam_brown_fair_on_achieving_humanlevel/"
        },
        {
            "author": "u/zielmicha",
            "created_utc": "02-14-2023 17:38:02",
            "distinguished": null,
            "edited": false,
            "id": "112jnzp",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_112jnzp",
            "nsfw": false,
            "num_comments": 4,
            "permalink": "/r/MachineLearning/comments/112jnzp/d_retrieval_transformers_with_learnable_queries/",
            "score": 4,
            "selftext": "Retrieval transformer models like RETRO seem to use frozen embeddings both for the documents in the database and the currently completed document (\"the query\"). \n\nMaking the embeddings of documents in the database learnable would defeat the purpose, as retrieval transformers only make sense when the database is huge.\n\nIt seems that the query embedding could be made learnable - the model could learn to extract more useful documents this way. Have you seen any research that does this?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Retrieval transformers with learnable queries?",
            "upvote_ratio": 0.75,
            "url": "https://www.reddit.com/r/MachineLearning/comments/112jnzp/d_retrieval_transformers_with_learnable_queries/"
        },
        {
            "author": "u/avsolatorio",
            "created_utc": "02-14-2023 15:29:53",
            "distinguished": null,
            "edited": "02-14-2023 16:08:49",
            "id": "112gpf1",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "News",
            "locked": false,
            "name": "t3_112gpf1",
            "nsfw": false,
            "num_comments": 4,
            "permalink": "/r/MachineLearning/comments/112gpf1/r_n_realtabformer_generating_realistic_relational/",
            "score": 57,
            "selftext": "Paper: [https://arxiv.org/abs/2302.02041](https://arxiv.org/abs/2302.02041)\n\nGenerate synthetic data from single tabular data using GPT. It also works on relational datasets! No fine-tuning and works out-of-the-box.\n\nWe also removed the guesswork on how long (epochs) the generative model for a single tabular data is trained. We propose the Q\u03b4 statistic and apply statistical bootstrapping to define a threshold to robustly detect overfitting.  Perk: no need for a hold-out data!\n\nData copying is also a problem in generative models. This means that training data may be learned and copied by the model during sampling. We attempt to mitigate data copying.\n\nWe implement target masking to deliberately create missing values in each observation in the data. The mask is a special token that is ignored during sampling. This forces the model to probabilistically impute the token, adding uncertainty to the generated data.\n\nREaLTabFormer is open-sourced and available on PyPi \u2192 pip install realtabformer\n\n&#x200B;\n\nhttps://preview.redd.it/vhf1st2g28ia1.png?width=1998&format=png&auto=webp&v=enabled&s=e0007bad69d6ad1df4006d5152cdd67f511e10ac",
            "spoiler": false,
            "stickied": false,
            "title": "[R] [N] REaLTabFormer: Generating Realistic Relational and Tabular Data using Transformers",
            "upvote_ratio": 0.93,
            "url": "https://www.reddit.com/r/MachineLearning/comments/112gpf1/r_n_realtabformer_generating_realistic_relational/"
        },
        {
            "author": "u/willowill5",
            "created_utc": "02-14-2023 14:44:56",
            "distinguished": null,
            "edited": false,
            "id": "112fnk8",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_112fnk8",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/112fnk8/d_looking_for_advice_on_model_architecture_for/",
            "score": 1,
            "selftext": "I am currently working on a project where I need to embed facial landmark coordinates into StyleGAN2 latentspace. The input data is structured as follows: \\[batch\\_size, num\\_landmarks=138, num\\_coordinates=3 (x,y,z)\\]. The output data is structured as: \\[batch\\_size, stylegan2\\_latent\\_space=512\\].\n\nI have PyTorch experience and am experimenting with transformer like models for the embedding. However, I am unsure about the optimal architecture for this task, and I would appreciate any advice or recommendations on how to design a suitable model.\n\nHas anyone worked on a similar task before, or have any ideas about which architecture could work well for this problem? Any advice or resources would be greatly appreciated.\n\nThank you!",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Looking for advice on model architecture for embedding facial landmark coordinates into StyleGAN2 latentspace",
            "upvote_ratio": 0.6,
            "url": "https://www.reddit.com/r/MachineLearning/comments/112fnk8/d_looking_for_advice_on_model_architecture_for/"
        },
        {
            "author": "u/arg_max",
            "created_utc": "02-14-2023 14:06:10",
            "distinguished": null,
            "edited": false,
            "id": "112eqxm",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_112eqxm",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/112eqxm/discussion_computing_the_derivative_of_a/",
            "score": 3,
            "selftext": "Hi,  \n\n\nI was wondering if anyone came across a paper that approximated the derivative of a diffusion model with respect to the conditioning that is fed into the cross-attention module. So let's say we have a text that is already transformed into a continuous embedding. Then this goes through the llm and is fed into the cross-attention module at every timestep. At the end of the diffusion process, we get some image/a latent representation of an image in the case of stable diffusion. We can then calculate a loss on that image and in theory calculate the gradient with respect to the continuous text embedding if we use a non-stochastic sampler like DDIM. The issue is the length of the graph calculating that derivative is super expensive. I was if anyone already solved this or has some good references.  \n\n\nThanks :)",
            "spoiler": false,
            "stickied": false,
            "title": "[Discussion] Computing the derivative of a diffusion model with respect to the prompt",
            "upvote_ratio": 0.71,
            "url": "https://www.reddit.com/r/MachineLearning/comments/112eqxm/discussion_computing_the_derivative_of_a/"
        },
        {
            "author": "u/No-Front-4346",
            "created_utc": "02-14-2023 12:14:04",
            "distinguished": null,
            "edited": false,
            "id": "112c2ad",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_112c2ad",
            "nsfw": false,
            "num_comments": 4,
            "permalink": "/r/MachineLearning/comments/112c2ad/d_self_supervised_learning_for_regression_with/",
            "score": 0,
            "selftext": "\nHi all,\n\nIm trying to implement self supervised pretraining to tabular data regression problem, however since the literature is scarce i\u2019m stuck in the augmentation stage. Im currently using sim siam self supervision with gaussian noising and input dropout. I tried shuffling to mimic CV approaches but it failed miserably. Any advice?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] self supervised learning for regression with tabular numerical data",
            "upvote_ratio": 0.33,
            "url": "https://www.reddit.com/r/MachineLearning/comments/112c2ad/d_self_supervised_learning_for_regression_with/"
        },
        {
            "author": "u/nateharada",
            "created_utc": "02-14-2023 11:54:35",
            "distinguished": null,
            "edited": false,
            "id": "112bl3g",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_112bl3g",
            "nsfw": false,
            "num_comments": 17,
            "permalink": "/r/MachineLearning/comments/112bl3g/r_scaling_vision_transformers_to_22_billion/",
            "score": 41,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Scaling Vision Transformers to 22 Billion Parameters",
            "upvote_ratio": 0.87,
            "url": "https://arxiv.org/pdf/2302.05442.pdf"
        },
        {
            "author": "u/jkterry1",
            "created_utc": "02-14-2023 10:25:23",
            "distinguished": null,
            "edited": false,
            "id": "1129gth",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "News",
            "locked": false,
            "name": "t3_1129gth",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/1129gth/n_miniworld_is_now_a_mature_project_within_the/",
            "score": 2,
            "selftext": "Miniworld - a minimalistic 3D interior environment simulator for reinforcement learning & robotics research that allows environments to be easily edited - has now reached the mature inside Farama. You can check out the documentation at [https://miniworld.farama.org](https://miniworld.farama.org/), and the release notes for all the changes we\u2019ve made to the project at [https://github.com/Farama-Foundation/Miniworld/releases/tag/2.0.1](https://github.com/Farama-Foundation/Miniworld/releases/tag/2.0.1).",
            "spoiler": false,
            "stickied": false,
            "title": "[N] Miniworld is now a mature project within the Farama Foundation",
            "upvote_ratio": 0.75,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1129gth/n_miniworld_is_now_a_mature_project_within_the/"
        },
        {
            "author": "u/H0lzm1ch3l",
            "created_utc": "02-14-2023 10:16:57",
            "distinguished": null,
            "edited": "02-15-2023 07:25:55",
            "id": "11299r9",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11299r9",
            "nsfw": false,
            "num_comments": 103,
            "permalink": "/r/MachineLearning/comments/11299r9/d_tensorflow_struggles/",
            "score": 157,
            "selftext": "This may be a bit of a vent. I am currently working on a model with Tensorflow. To me it seems that whenever I am straying from a certain path my productivity starts dying at an alarming rate. \n\nFor example I am currently implementing my own data augmentation (because I strayed from Tf in a minuscule way) and obscure errors are littering my path. Prior to that I made a mistake somewhere in my training loop and it took me forever to find. The list goes on. \n\nEvery time I try using Tensorflow in a new way, it\u2018s like taming a new horse. Except that it\u2018s the same donkey I tamed last time. This is not my first project, but does it ever change?\n\nEDIT, Todays highlight:\nWhen you index a dim 1 tensor (so array) you get scalar tensors. Now if you wanted to create a dim 1 tensor from scalar tensors you can not use tf.constant, but you have to use tf.stack. This wouldn't even be a problem if it were somehow documented and you didn't get the following error: \"Scalar tensor has no attribute len()\". \n\nI understand the popularity of \"ask for forgiveness, not permission\" in Python, but damn ...",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Tensorflow struggles",
            "upvote_ratio": 0.92,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11299r9/d_tensorflow_struggles/"
        },
        {
            "author": "u/Maleficent_Stay_7737",
            "created_utc": "02-14-2023 09:33:14",
            "distinguished": null,
            "edited": false,
            "id": "11287zf",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_11287zf",
            "nsfw": false,
            "num_comments": 8,
            "permalink": "/r/MachineLearning/comments/11287zf/r_hitchhikers_guide_to_superresolution/",
            "score": 176,
            "selftext": "I'm glad to share with you our Open Access survey paper about image super-resolution:  \n[https://ieeexplore.ieee.org/abstract/document/10041995](https://ieeexplore.ieee.org/abstract/document/10041995)  \n\n\nThe goal of this work is to give an overview of the abundance of publications in image super-resolution, give an introduction for new researchers, and open thriving discussions as well as point to potential future directions to advance the field :)",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Hitchhiker\u2019s Guide to Super-Resolution: Introduction and Recent Advances",
            "upvote_ratio": 0.96,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11287zf/r_hitchhikers_guide_to_superresolution/"
        },
        {
            "author": "u/zxkj",
            "created_utc": "02-14-2023 08:18:09",
            "distinguished": null,
            "edited": false,
            "id": "1126g64",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_1126g64",
            "nsfw": false,
            "num_comments": 7,
            "permalink": "/r/MachineLearning/comments/1126g64/d_repeating_important_samples_in_every_batch_for/",
            "score": 19,
            "selftext": "Wondering if there\u2019s a term for this.\n\nI\u2019m training NNs for a scenario that works best with a small batch size, there are therefore many batches.\n\nThere are a couple particular samples that are VERY important. Let\u2019s say 3 important samples out of thousands I train to.\n\nI found end application is best when I include these important samples, repeated, in every batch. This is opposed to simply giving the samples a large weight, because the large weight doesn\u2019t matter after looping through many batches in an epoch.\n\nSo the NN learns the other less important stuff while being forced to remain in good agreement with the important samples.\n\nDoes this technique have a name?\n\nEDIT: In case anyone is curious, these are physics informed NNs and the important samples are equilibrium mechanical structures. The NN therefore learns what equilibrium is, with everything else being small deviations from equilibrium.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Repeating important samples in every batch for NN training?",
            "upvote_ratio": 0.86,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1126g64/d_repeating_important_samples_in_every_batch_for/"
        },
        {
            "author": "u/Forsaken_Football227",
            "created_utc": "02-14-2023 06:43:24",
            "distinguished": null,
            "edited": false,
            "id": "1124hyv",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_1124hyv",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/1124hyv/r_imagenet_2015_vid_dataset/",
            "score": 3,
            "selftext": "Hi all,\n\nI saw a few posts already but just to make sure and keep this as an update, does anyone have the ImageNet 2015 VID dataset to share? All links are dead. I really need it now to train TransVOD.",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Imagenet 2015 VID Dataset",
            "upvote_ratio": 0.8,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1124hyv/r_imagenet_2015_vid_dataset/"
        },
        {
            "author": "u/TKMater",
            "created_utc": "02-14-2023 06:18:55",
            "distinguished": null,
            "edited": false,
            "id": "11241dd",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11241dd",
            "nsfw": false,
            "num_comments": 3,
            "permalink": "/r/MachineLearning/comments/11241dd/d_threshold_for_kmeans_anomaly_detection/",
            "score": 1,
            "selftext": "I am using kmeans clustering algorithm for anomaly detection. After training kmeans, I'm calculation Euclidian distance of new data points to their nearest cluster. Please suggest me some strategies to set up a threshold such that point with distance greater than that threshold will be classified as anomaly. Or tell me if there are some other way to identify anomaly using k-means.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Threshold for k-means anomaly detection",
            "upvote_ratio": 1.0,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11241dd/d_threshold_for_kmeans_anomaly_detection/"
        },
        {
            "author": "u/AdministrationOk2735",
            "created_utc": "02-14-2023 04:37:45",
            "distinguished": null,
            "edited": false,
            "id": "11229f7",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11229f7",
            "nsfw": false,
            "num_comments": 7,
            "permalink": "/r/MachineLearning/comments/11229f7/discussion_the_need_for_noise_in_stable_diffusion/",
            "score": 0,
            "selftext": "As I'm learning about how stable diffusion works, I can't figure out why during image generation there's a need to deal with 'noise'.\n\nI know I'm glossing over a lot of details, but my understanding is that the algorithm is trained by gradually adding noise to an image and then de-noising it to recover the initial image. Wouldn't this be functionally equivalent to a machine that starts with an image, gradually reduces it to a blank canvas (all white), and then gradually reconstructs the original image? Then, post training, the generative process would just start with a blank canvas and gradually generate the image based on the input string provided.\n\nThe idea of generating an image from a blank canvas feels more satisfying to me than revealing an image hidden by noise, but I'm sure there's a mathematical/technical reason why what I'm suggesting doesn't work. Appreciate any insight into this!",
            "spoiler": false,
            "stickied": false,
            "title": "[Discussion] The need for noise in stable diffusion",
            "upvote_ratio": 0.44,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11229f7/discussion_the_need_for_noise_in_stable_diffusion/"
        },
        {
            "author": "u/aadityaura",
            "created_utc": "02-14-2023 03:45:45",
            "distinguished": null,
            "edited": false,
            "id": "111zwsg",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_111zwsg",
            "nsfw": false,
            "num_comments": 2,
            "permalink": "/r/MachineLearning/comments/111zwsg/d_a_comprehensive_guide_handcurated_resource_list/",
            "score": 14,
            "selftext": "Greetings,\n\nExcited to share with all those interested in Prompt Engineering and Large Language Models (LLMs)!\n\nWe've hand-curated a comprehensive, Free & Open Source resource list on Github that includes everything related to Prompt Engineering, LLMs, and all related topics. We've covered most things, from papers and articles to tools and code!  \n\n\nhttps://preview.redd.it/zzs09fg1l4ia1.png?width=1770&format=png&auto=webp&v=enabled&s=b2b5ac62b4296779a2fe5b6d0cbf9f46de68ca08",
            "spoiler": false,
            "stickied": false,
            "title": "[D] A Comprehensive Guide & Hand-Curated Resource List for Prompt Engineering and LLMs on Github",
            "upvote_ratio": 0.8,
            "url": "https://www.reddit.com/r/MachineLearning/comments/111zwsg/d_a_comprehensive_guide_handcurated_resource_list/"
        },
        {
            "author": "u/louis3195",
            "created_utc": "02-14-2023 03:28:34",
            "distinguished": null,
            "edited": false,
            "id": "111z2hl",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_111z2hl",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/111z2hl/d_what_are_your_tricksinfra_working_with/",
            "score": 3,
            "selftext": "I'm trying to design my infra for creating, storing, and retrieving embeddings in my AI applications and was wondering what are the different paths for it. I'm especially interested in NLP, but vision/multimodal could be interesting too.  \n\n\nWhether it's related to performance, scalability, or something else entirely, I'd love to hear your experiences and insights. Looking forward to your responses!",
            "spoiler": false,
            "stickied": false,
            "title": "[D] What are your tricks/infra working with embeddings?",
            "upvote_ratio": 0.8,
            "url": "https://www.reddit.com/r/MachineLearning/comments/111z2hl/d_what_are_your_tricksinfra_working_with/"
        },
        {
            "author": "u/lfotofilter",
            "created_utc": "02-14-2023 02:50:27",
            "distinguished": null,
            "edited": "02-14-2023 03:17:58",
            "id": "111y0cu",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_111y0cu",
            "nsfw": false,
            "num_comments": 2,
            "permalink": "/r/MachineLearning/comments/111y0cu/p_free_gpt3based_tool_to_suggest_terminal/",
            "score": 16,
            "selftext": "I whipped [this](https://github.com/nlml/YoCLI/) up today. Credit to [heyCLI](https://www.heycli.com/) for the idea, I've just remade an open source version.\n\nBasically in your terminal you type 'yo ' and then describe what you want a command to do.\n\nFor instance:\n\n    \u279c  ~ yo enable a reverse tunnel through ssh \n\nReturns:\n\n    Suggested command:\n    \n    ssh -R <remote_port>:localhost:<local_port> <remote_user>@<remote_host>\n\nAnother example:\n\n    \u279c  ~ yo launch tensorboard with a custom log dir and port\n    \n    Suggested command:\n    \n    tensorboard --logdir=<LOG_DIR> --port=<PORT_NUMBER>\n\nIt's free, MIT licence. You just need a free OpenAI API key which you can get by signing up on their website (I think if you use ChatGPT, you're already signed up). More info in the [repo](https://github.com/nlml/YoCLI/). Contributions/critiques welcome.",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Free GPT3-based tool to suggest terminal commands via natural language",
            "upvote_ratio": 0.83,
            "url": "https://www.reddit.com/r/MachineLearning/comments/111y0cu/p_free_gpt3based_tool_to_suggest_terminal/"
        },
        {
            "author": "u/0b01",
            "created_utc": "02-14-2023 02:32:10",
            "distinguished": null,
            "edited": false,
            "id": "111xr3q",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_111xr3q",
            "nsfw": false,
            "num_comments": 2,
            "permalink": "/r/MachineLearning/comments/111xr3q/d_anyone_interested_in_training_an_ai_for_tigris/",
            "score": 2,
            "selftext": "Over the past weekend, I finally decided to put this idea to rest and made a Rust implementation of the greatest board game ever made - up there with Chess and Go:  \\[Link to BGG\\]([https://boardgamegeek.com/boardgame/42/tigris-euphrates](https://boardgamegeek.com/boardgame/42/tigris-euphrates)\n\nThe ultimate goal is to train an AI so it needs to be very fast with state updates.\n\nThe game logic is quite sophisticated(\\~2000 lines) so it took me awhile to check all the edge cases of which there are many. Its search tree is huuuge with a branching factor of 100-300 which is more than Go's. It is also an imperfect game with hidden information(think poker). So ultimately it will need a reinforcement-based AI like \\[AlphaGo\\]([https://arxiv.org/abs/2112.03178](https://arxiv.org/abs/2112.03178). In the repo I used a minimax-based AI(for testing purposes) to search 3 moves ahead which gives slightly better than random performance.\n\nThe UI is implemented in \\[macroquad\\]([https://macroquad.rs/examples/](https://macroquad.rs/examples/) which is hands down the simplest 2D game library I've used(ggez and a deprecated framework which I shall not name). And yes, please excuse the programmer art made by me :P\n\nAny way, here's the link to the repo if you are interested:\n\n[repo](https://github.com/0b01/tigris-and-euphrates/blob/main/src/game.rs)\n\n&#x200B;\n\nNote: it's hardcoded for 2 players but it can easily be made for 4. I want to train the AI for 2 players first. There are also 4 unimplemented rules: monuments, tile removal after war, must take corner treasures first, must take treasure after conflict.\n\n&#x200B;\n\nhttps://preview.redd.it/jr49d9cx74ia1.png?width=1200&format=png&auto=webp&v=enabled&s=701394f3e12e7ac9f88126a2b2144c2df32ae1e4",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Anyone interested in training an AI for Tigris and Euphrates?",
            "upvote_ratio": 0.6,
            "url": "https://www.reddit.com/r/MachineLearning/comments/111xr3q/d_anyone_interested_in_training_an_ai_for_tigris/"
        },
        {
            "author": "u/ConfidenceFun5105",
            "created_utc": "02-14-2023 02:10:04",
            "distinguished": null,
            "edited": false,
            "id": "111xfkh",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_111xfkh",
            "nsfw": false,
            "num_comments": 2,
            "permalink": "/r/MachineLearning/comments/111xfkh/r_boosted_trees_literature/",
            "score": 11,
            "selftext": "Hi all. I\u2019m trying to do a comprehensive study on the theory of gradient boosted trees (on the more recent algorithms xgboost, lightgbm etc). I was wondering what books you have read that contain substantial information on this topic. Any suggestions are appreciated!",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Boosted Trees Literature",
            "upvote_ratio": 0.82,
            "url": "https://www.reddit.com/r/MachineLearning/comments/111xfkh/r_boosted_trees_literature/"
        },
        {
            "author": "u/kandalete",
            "created_utc": "02-14-2023 00:52:49",
            "distinguished": null,
            "edited": false,
            "id": "111w9bi",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_111w9bi",
            "nsfw": false,
            "num_comments": 6,
            "permalink": "/r/MachineLearning/comments/111w9bi/r_p_lucas_lung_cancer_screening_dataset/",
            "score": 8,
            "selftext": "https://preview.redd.it/fo3y2s26q3ia1.png?width=1365&format=png&auto=webp&v=enabled&s=7cfb6442b624b60808db7e04963be7ec50b2dc87\n\nI want to download this dataset which has been introduced in the article named [LUCAS: LUng CAncer Screening with Multimodal Biomarkers](https://link.springer.com/chapter/10.1007/978-3-030-60946-7_12).\n\nFollowing the corresponding [github](https://github.com/BCV-Uniandes/LUCAS) of this project, authors have noted that the dataset is published in [http://157.253.243.19/LUCAS/](http://157.253.243.19/LUCAS/) but I can't access this link and ping to this address.\n\nAnyone has used this dataset could share it with me? Or if you know other ways to access it, too.\n\nThank you very much!",
            "spoiler": false,
            "stickied": false,
            "title": "[R] [P] LUCAS: LUng CAncer Screening dataset",
            "upvote_ratio": 0.79,
            "url": "https://www.reddit.com/r/MachineLearning/comments/111w9bi/r_p_lucas_lung_cancer_screening_dataset/"
        },
        {
            "author": "u/crazewill",
            "created_utc": "02-13-2023 23:07:37",
            "distinguished": null,
            "edited": false,
            "id": "111uh53",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_111uh53",
            "nsfw": false,
            "num_comments": 3,
            "permalink": "/r/MachineLearning/comments/111uh53/d_what_are_the_best_ways_to_make_and_run_a_fast/",
            "score": 2,
            "selftext": "Just was wondering what the current best / easiest ways to make a fast custom tts are. I tried tortoise tts but it was too slow. The voice doesn't need to be a perfect clone, just need something that can resemble it.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] What are the best ways to make and run a fast custom TTS?",
            "upvote_ratio": 0.62,
            "url": "https://www.reddit.com/r/MachineLearning/comments/111uh53/d_what_are_the_best_ways_to_make_and_run_a_fast/"
        },
        {
            "author": "u/michaelhoffman",
            "created_utc": "02-13-2023 16:09:47",
            "distinguished": null,
            "edited": false,
            "id": "111lku3",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_111lku3",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/111lku3/r_understanding_metricrelated_pitfalls_in_image/",
            "score": 0,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Understanding metric-related pitfalls in image analysis validation",
            "upvote_ratio": 0.5,
            "url": "https://arxiv.org/abs/2302.01790"
        },
        {
            "author": "u/Thin-Shirt6688",
            "created_utc": "02-13-2023 11:08:42",
            "distinguished": null,
            "edited": false,
            "id": "111e9hx",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_111e9hx",
            "nsfw": false,
            "num_comments": 8,
            "permalink": "/r/MachineLearning/comments/111e9hx/r_what_are_some_papers_that_describe_tiktoks/",
            "score": 44,
            "selftext": "I'm looking for a recent conference paper that describes how TikTok's algorithm works.\n\nAs an analogy, YouTube's algorithm was described by Zhao et al., (RecSys 2019) \"Recommending what video to watch next: a multitask ranking system\"",
            "spoiler": false,
            "stickied": false,
            "title": "[R] What are some papers that describe TikTok's algorithm?",
            "upvote_ratio": 0.86,
            "url": "https://www.reddit.com/r/MachineLearning/comments/111e9hx/r_what_are_some_papers_that_describe_tiktoks/"
        },
        {
            "author": "u/TobyWasBestSpiderMan",
            "created_utc": "02-13-2023 10:52:39",
            "distinguished": null,
            "edited": false,
            "id": "111dvia",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_111dvia",
            "nsfw": false,
            "num_comments": 13,
            "permalink": "/r/MachineLearning/comments/111dvia/r_actually_useful_every_day_application_of_a/",
            "score": 381,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Actually useful every day application of a Gaussian Process",
            "upvote_ratio": 0.93,
            "url": "https://www.reddit.com/gallery/110rz2e"
        },
        {
            "author": "u/paarulakan",
            "created_utc": "02-13-2023 10:44:35",
            "distinguished": null,
            "edited": false,
            "id": "111dohm",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_111dohm",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/111dohm/discussion_are_there_any_survey_on_compute/",
            "score": 1,
            "selftext": "are  there any survey or a listing that curates the computing power required  to train the large deep learning models like bert, gpt, ViT and so on.",
            "spoiler": false,
            "stickied": false,
            "title": "[Discussion] are there any survey on compute required to train large DNN models ?",
            "upvote_ratio": 0.56,
            "url": "https://www.reddit.com/r/MachineLearning/comments/111dohm/discussion_are_there_any_survey_on_compute/"
        },
        {
            "author": "u/LostGoatOnHill",
            "created_utc": "02-13-2023 06:38:44",
            "distinguished": null,
            "edited": false,
            "id": "111797x",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_111797x",
            "nsfw": false,
            "num_comments": 5,
            "permalink": "/r/MachineLearning/comments/111797x/d_cloud_agnostic_framework_to_avoid_hyperscaler/",
            "score": 2,
            "selftext": "Currently using Azure Machine Learning, so ML lifecycle in training, registering, and deploying models heavily relies on the AML sdk.\n\n&#x200B;\n\nThinking of going multi-cloud, so first thoughts on what open frameworks can serve the ML lifecycle and avoid vendor SDK lock-in?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Cloud agnostic framework to avoid hyperscaler SDK lock-in?",
            "upvote_ratio": 1.0,
            "url": "https://www.reddit.com/r/MachineLearning/comments/111797x/d_cloud_agnostic_framework_to_avoid_hyperscaler/"
        },
        {
            "author": "u/notimplementederrorr",
            "created_utc": "02-13-2023 03:59:37",
            "distinguished": null,
            "edited": false,
            "id": "1114o7v",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_1114o7v",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/1114o7v/d_engineering_interviews_at_anthropic_ai/",
            "score": 0,
            "selftext": "Hi everyone. Does anyone have any advice for preparing for engineering interviews for Anthropic AI? If you've gone through the process, how did you find it?  \n\nTheir website only provides an overview (e.g. \"implement a component of our stack in one hour\", \"3-4 more one-hour technical interviews\"), and due to their size I couldn't find any other information out there. Cheers!",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Engineering interviews at Anthropic AI?",
            "upvote_ratio": 0.5,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1114o7v/d_engineering_interviews_at_anthropic_ai/"
        },
        {
            "author": "u/Tomavasso",
            "created_utc": "02-13-2023 02:38:34",
            "distinguished": null,
            "edited": false,
            "id": "1113hcs",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_1113hcs",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/1113hcs/d_incorporating_no_maintenance_examples_into_a/",
            "score": 1,
            "selftext": "Currently, I am working on a machine learning project that aims to extract decision logic in a maintenance dataset. The challenge I am facing is that part of the dataset has no maintenance decision yet.\n\nFor instance, consider the following example where a certain part and its sub-parts have been measured and graded yearly for the past 5 years, but no maintenance has been planned yet:\n\n|timestamp|measurements|grades|maintenance in|\n|:-|:-|:-|:-|\n|5 years ago|X|Z|\\>5 years|\n|4 years ago|X|Z|\\>4 years|\n|3 years ago|X|Z|\\>3 years|\n|2 years ago|X|Z|\\>2 years|\n|1 years ago|X|Z|\\>1 years|\n|0 years ago|X|Z|\\>0 years|\n\nWith these underlying data, I cannot learn exactly when maintenance was required. However, I do learn from this example that with the values from five years ago, no maintenance was required in 5 years.\n\nOne potential way to include this in the ML project is to include these examples in the evaluation set to determine whether the extracted rules indeed determine no maintenance within the period that we know no maintenance was needed. However, I am curious to know if there are better ways to incorporate this into the project, perhaps by already including it in the learning phase of the model training. Thank you in advance!",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Incorporating \"No Maintenance\" Examples into a Maintenance Dataset in ML",
            "upvote_ratio": 1.0,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1113hcs/d_incorporating_no_maintenance_examples_into_a/"
        },
        {
            "author": "u/orangelord234",
            "created_utc": "02-13-2023 01:18:46",
            "distinguished": null,
            "edited": false,
            "id": "11129cq",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_11129cq",
            "nsfw": false,
            "num_comments": 10,
            "permalink": "/r/MachineLearning/comments/11129cq/d_is_a_nonsota_paper_still_good_to_publish_if_it/",
            "score": 28,
            "selftext": "For a dataset, the top result gets a high accuracy ~10% better than the second-best paper. But this \"SOTA\" paper uses some methods that just don't seem practical for applications at all. For example, they use an ensemble of 6 different SOTA models and also train on external data. Of course, it performs well, but it's a bit ridiculous cause it adds almost nothing of value besides \"we combined all the best models and got a better score!\". \n\nIf I have a novel method that is applied to the second-best paper that improves it by ~5% with the same to better compute efficiency but still is worse than the SOTA method, is it still good research to try to publish to conferences? It's also 40% above the baseline model.  \n\nI would think so because it's a decent improvement (with an interesting motivation + method) from prior work while keeping the model reasonable. Would reviewers agree or would they just see that it isn't better than SOTA and reject based on not being SOTA alone?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Is a non-SOTA paper still good to publish if it has an interesting method that does have strong improvements over baselines (read text for more context)? Are there good examples of this kind of work being published?",
            "upvote_ratio": 0.95,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11129cq/d_is_a_nonsota_paper_still_good_to_publish_if_it/"
        },
        {
            "author": "u/syprhdsh",
            "created_utc": "02-13-2023 00:28:43",
            "distinguished": null,
            "edited": false,
            "id": "1111gw7",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_1111gw7",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/1111gw7/d_diffusion_model_reverse_process_questions/",
            "score": 0,
            "selftext": "I was going through the paper: [Deep Unsupervised Learning using Nonequilibrium Thermodynamics](https://arxiv.org/abs/1503.03585) and in 2.3 Model Probability it's written that the integral is intractable. Can someone explain to me why that is?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Diffusion Model Reverse Process Questions",
            "upvote_ratio": 0.5,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1111gw7/d_diffusion_model_reverse_process_questions/"
        },
        {
            "author": "u/gamerx88",
            "created_utc": "02-13-2023 00:20:23",
            "distinguished": null,
            "edited": false,
            "id": "1111c53",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_1111c53",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/1111c53/r_holistic_evaluation_of_language_models_helm/",
            "score": 1,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Holistic Evaluation of Language Models (HELM)",
            "upvote_ratio": 0.67,
            "url": "https://crfm.stanford.edu/helm/latest/?"
        },
        {
            "author": "u/tysam_and_co",
            "created_utc": "02-12-2023 23:36:01",
            "distinguished": null,
            "edited": false,
            "id": "1110l3w",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_1110l3w",
            "nsfw": false,
            "num_comments": 7,
            "permalink": "/r/MachineLearning/comments/1110l3w/r_cifar10_in_8_seconds_on_an_a100_new_architecture/",
            "score": 18,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] CIFAR10 in <8 seconds on an A100 (new architecture!)",
            "upvote_ratio": 0.81,
            "url": "https://github.com/tysam-code/hlb-CIFAR10"
        },
        {
            "author": "u/Just0by",
            "created_utc": "02-12-2023 19:32:14",
            "distinguished": null,
            "edited": "02-13-2023 02:27:24",
            "id": "110vzsy",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_110vzsy",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/110vzsy/poneflow_v090_came_out/",
            "score": 2,
            "selftext": "Hello everyone,We are thrilled to announce the new release of [**OneFlow**](https://github.com/Oneflow-Inc/oneflow), which is a deep learning framework designed to be user-friendly, scalable and efficient. OneFlow v0.9.0 contains 640 commits. For the full changelog, please check out: [https://github.com/Oneflow-Inc/oneflow/releases/tag/v0.9.0](https://github.com/Oneflow-Inc/oneflow/releases/tag/v0.9.0).\n\n**Paper:** [https://arxiv.org/abs/2110.15032](https://arxiv.org/abs/2110.15032);**Code:** [https://github.com/Oneflow-Inc/oneflow](https://github.com/Oneflow-Inc/oneflow)\n\n(For those unfamiliar with OneFlow: The most notable strength of OneFlow is its support to distributed deep learning, faster than other frameworks and easier to use. An example can be found at [https://medium.com/@oneflow2020/libai-model-library-to-train-large-models-more-easily-and-efficiently-15637c8876eb](https://medium.com/@oneflow2020/libai-model-library-to-train-large-models-more-easily-and-efficiently-15637c8876eb) Based on OneFlow, to implement the same capability with Megatron-LM and DeepSpeed, LiBai only requires 1/3 lines of code.)\n\nWelcome to install OneFlow v0.9.0 for a new user experience. Your feedbacks will be much appreciated!\n\n**Highlights and optimizations in this release:**\n\n**1. PyTorch API compatibility**\n\nWith the addition of 86 new API interfaces and operators aligned with PyTorch and the fix of 104 bugs related to operator compatibility, OneFlow v0.9.0 provides better PyTorch API and model compatibility. In v0.9.0, users can migrate more PyTorch models to OneFlow with one click and gain faster performance.\n\nAllowing one-click migration of [Stable Diffusion](https://github.com/Oneflow-Inc/diffusers), [GLM](https://huggingface.co/BAAI/glm-large), [YOLOv5](https://github.com/Oneflow-Inc/one-yolov5) etc to OneFlow. More convenient model migration. Oneflow.load supports loading the torch.save models directly. With the newly added oneflow.mock\\_torch module and mock method\uff08[https://docs.oneflow.org/master/cookies/oneflow\\_torch.html\uff09](https://docs.oneflow.org/master/cookies/oneflow_torch.html\uff09), oneflow can migrate complex PyTorch models containing multiple scripts with one click without changing the original PyTorch script.\n\n**2. Improving the usability of distributed programming**\n\nGlobal Tensor has added a series of interfaces and methods that are convenient for distributed programming. And related bugs have been fixed.\n\n**3. Supporting automatic parallelism**\n\nThe Graph released a new feature of automatic parallelism (version 1), which supports automatic search for the fastest SBP with a specified Placement. When writing distributed models with Global Tensor, users do not need to consider parallelism model.\n\nFor more information, please check out: [https://oneflow.readthedocs.io/en/master/auto\\_parallel.html](https://oneflow.readthedocs.io/en/master/auto_parallel.html)\n\n**4. Better performance**\n\nGraph improves performance and reduces memory overhead, with a series of optimizations related to memory, execution speed, pipeline masking, and compilation speed.\n\nA series of operator optimizations and system optimizations have been added, including Eager instruction scheduling, high-performance CUDA kernel, opening up of multiple memory pools, etc.\n\nhttps://preview.redd.it/x624ujfrwuha1.png?width=1044&format=png&auto=webp&v=enabled&s=ec7b81b113fd32e8ebeffe7f2e94a5267a848af7\n\n&#x200B;\n\nhttps://preview.redd.it/a51h8yuswuha1.png?width=1044&format=png&auto=webp&v=enabled&s=203f6ff3e5395f6d130e61c0345c24567798eb11\n\nAfter simple tuning, [GLM-Large (335M) pre-trained model](https://huggingface.co/BAAI/glm-large)  based on OneFlow v0.9.0 can outperform the original GLM model based on PyTorch, DeepSpeed, and Apex with up to triple performance and 1/3 memory overhead saved.  \n\n\n![img](uhpvikt32xha1 \"\n\")\n\nhttps://preview.redd.it/xi81rkf42xha1.png?width=1027&format=png&auto=webp&v=enabled&s=56cbf85bf6438436d239afaf87c54976ba7827e0\n\nOn A100 GPU (SXM 80GB / PCIe 40GB), [the OneFlow Stable Diffusion inference speed](https://github.com/Oneflow-Inc/diffusers) is the fastest compared with other deep learning frameworks or compilers.\n\n**5. Debugging**\n\nThe Graph provides a series of functions to aid debugging, including analyzing memory logs, displaying the progress during the compilation stage, and the computation graph.\n\n**6. IR**\n\nOneFlow IR supports additional compilation optimization functions such as JIT compilation of LR code, distributed description of SBP signature, and the new OKL Dialect.\n\n**7. OneFlow-ONNX**\n\nThe newly released OneFlow-ONNX version v0.6.0 enhanced the usability of the exchange interface with multiple new features. In addition, it added support for another 6 models and over 20 Ops and fixed 6 bugs during the transformation process. You can use pip install oneflow-onnx==0. 6.0 with just one-click.\n\n**8. Better error prompt**\n\nThe error prompt of OneFlow is more user-friendly, which supports highlighting the error content and simplifies unnecessary information details inside the system. In this connection, you can visually learn about the location and type of the error.",
            "spoiler": false,
            "stickied": false,
            "title": "[P]OneFlow v0.9.0 Came Out!",
            "upvote_ratio": 0.63,
            "url": "https://www.reddit.com/r/MachineLearning/comments/110vzsy/poneflow_v090_came_out/"
        },
        {
            "author": "u/MurlocXYZ",
            "created_utc": "02-12-2023 17:00:40",
            "distinguished": null,
            "edited": false,
            "id": "110swn2",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_110swn2",
            "nsfw": false,
            "num_comments": 65,
            "permalink": "/r/MachineLearning/comments/110swn2/d_quality_of_posts_in_this_sub_going_down/",
            "score": 266,
            "selftext": "I could be wrong, but I see a trend that posts in this sub are getting to a lower quality and/or lower relevance.\n\nI see a lot of posts of the type \"how do I run X\" (usually a generative model) with a complete disregard to how it actually works or nonsense posts about ChatGPT.\n\nI believe this is due to an influx of new people who gained an interest in ML now that the hype is around generative AI. Which is fantastic, don't get me wrong.\n\nBut, I see less academic discussions and less papers being posted. Or perhaps they are just not as upvoted. Is it just me?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Quality of posts in this sub going down",
            "upvote_ratio": 0.92,
            "url": "https://www.reddit.com/r/MachineLearning/comments/110swn2/d_quality_of_posts_in_this_sub_going_down/"
        },
        {
            "author": "u/radi-cho",
            "created_utc": "02-12-2023 16:49:05",
            "distinguished": null,
            "edited": false,
            "id": "110sngt",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_110sngt",
            "nsfw": false,
            "num_comments": 8,
            "permalink": "/r/MachineLearning/comments/110sngt/r_p_openassistant_is_a_fully_opensource_chatbased/",
            "score": 56,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] [P] OpenAssistant is a fully open-source chat-based assistant that understands tasks, can interact with third-party systems, and retrieve information dynamically to do so.",
            "upvote_ratio": 0.94,
            "url": "https://github.com/LAION-AI/Open-Assistant"
        },
        {
            "author": "u/radi-cho",
            "created_utc": "02-12-2023 16:41:07",
            "distinguished": null,
            "edited": false,
            "id": "110sh0w",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "News",
            "locked": false,
            "name": "t3_110sh0w",
            "nsfw": false,
            "num_comments": 5,
            "permalink": "/r/MachineLearning/comments/110sh0w/r_n_pix2pixzero_zeroshot_imagetoimage_translation/",
            "score": 181,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] [N] pix2pix-zero - Zero-shot Image-to-Image Translation",
            "upvote_ratio": 0.97,
            "url": "https://i.redd.it/3vchrw4a5uha1.gif"
        },
        {
            "author": "u/radi-cho",
            "created_utc": "02-12-2023 16:31:16",
            "distinguished": null,
            "edited": false,
            "id": "110s8ui",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "News",
            "locked": false,
            "name": "t3_110s8ui",
            "nsfw": false,
            "num_comments": 65,
            "permalink": "/r/MachineLearning/comments/110s8ui/r_n_toolformer_language_models_can_teach/",
            "score": 866,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] [N] Toolformer: Language Models Can Teach Themselves to Use Tools - paper by Meta AI Research",
            "upvote_ratio": 0.98,
            "url": "https://i.redd.it/7lk1ldus3uha1.png"
        },
        {
            "author": "u/TikkunCreation",
            "created_utc": "02-12-2023 11:08:59",
            "distinguished": null,
            "edited": false,
            "id": "110knl0",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_110knl0",
            "nsfw": false,
            "num_comments": 17,
            "permalink": "/r/MachineLearning/comments/110knl0/d_what_ml_dev_tools_do_you_wish_youd_discovered/",
            "score": 105,
            "selftext": "Here's my personal list of tools I think people will want to know about:\n\n* You'll probably want an LLM API\n   * OpenAI\n   * Cohere and others aren't as good\n   * Anthropic's isn't available\n* If you're using embeddings\n   * If you're working with a lot of items, you'll want a vector database, like Pinecone, or Weaviate, or pgvector\n* If you're building Q&A over a document\n   * I'd suggest using GPT Index\n* If you need to be able to interact with external data sources, do google searches, database lookups, python REPL\n   * I'd suggest using langchain\n* If you're doing chained prompts\n   * Check out dust tt and langchain\n* If you want to deploy a little app quickly\n   * Check out Streamlit\n* If you need to use something like stable diffusion or whisper in your product\n   * banana dev, modal, replicate, tiyaro ai, beam cloud, inferrd, or pipeline ai\n* If you need something to optimize your prompts\n   * Check out Humanloop and Everyprompt\n* If you're building models and need an ml framework\n   * PyTorch, Keras, TensorFlow\n* If you're deploying models to production\n   * Check out MLOps tools like MLflow, Kubeflow, Metaflow, Airflow, Seldon Core, TFServing\n* If you need to check out example projects for inspiration\n   * Check out the pinecone op stack, the langchain gallery, the gpt index showcase, and the openai cookbook\n* If you want to browse the latest research, check out arXiv, of course\n\n&#x200B;\n\nWhat am I missing?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] What ML dev tools do you wish you'd discovered earlier?",
            "upvote_ratio": 0.94,
            "url": "https://www.reddit.com/r/MachineLearning/comments/110knl0/d_what_ml_dev_tools_do_you_wish_youd_discovered/"
        },
        {
            "author": "u/AutoModerator",
            "created_utc": "02-12-2023 10:00:09",
            "distinguished": null,
            "edited": false,
            "id": "110j0cp",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_110j0cp",
            "nsfw": false,
            "num_comments": 98,
            "permalink": "/r/MachineLearning/comments/110j0cp/d_simple_questions_thread/",
            "score": 11,
            "selftext": "Please post your questions here instead of creating a new thread. Encourage others who create new posts for questions to post here instead!\n\nThread will stay alive until next one so keep posting after the date in the title.\n\nThanks to everyone for answering questions in the previous thread!",
            "spoiler": false,
            "stickied": true,
            "title": "[D] Simple Questions Thread",
            "upvote_ratio": 0.93,
            "url": "https://www.reddit.com/r/MachineLearning/comments/110j0cp/d_simple_questions_thread/"
        },
        {
            "author": "u/Wiskkey",
            "created_utc": "02-12-2023 09:24:57",
            "distinguished": null,
            "edited": false,
            "id": "110i7h7",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_110i7h7",
            "nsfw": false,
            "num_comments": 2,
            "permalink": "/r/MachineLearning/comments/110i7h7/r_p_adding_conditional_control_to_texttoimage/",
            "score": 113,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] [P] Adding Conditional Control to Text-to-Image Diffusion Models. \"This paper presents ControlNet, an end-to-end neural network architecture that controls large image diffusion models (like Stable Diffusion) to learn task-specific input conditions.\" Example uses the Scribble ControlNet model.",
            "upvote_ratio": 0.94,
            "url": "https://i.redd.it/atseysyiyrha1.png"
        },
        {
            "author": "u/t0ns0fph0t0ns",
            "created_utc": "02-12-2023 08:42:32",
            "distinguished": null,
            "edited": false,
            "id": "110h9ey",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_110h9ey",
            "nsfw": false,
            "num_comments": 13,
            "permalink": "/r/MachineLearning/comments/110h9ey/r_digiface1m_synthetic_dataset_with_one_million/",
            "score": 28,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] DIGIFACE-1M \u2014 synthetic dataset with one million images for face recognition",
            "upvote_ratio": 0.83,
            "url": "https://i.redd.it/q4e17rfwqrha1.png"
        },
        {
            "author": "u/seraschka",
            "created_utc": "02-12-2023 08:05:12",
            "distinguished": null,
            "edited": false,
            "id": "110gh1m",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_110gh1m",
            "nsfw": false,
            "num_comments": 4,
            "permalink": "/r/MachineLearning/comments/110gh1m/p_understanding_coding_the_selfattention/",
            "score": 7,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Understanding & Coding the Self-Attention Mechanism of Large Language Models",
            "upvote_ratio": 0.73,
            "url": "https://sebastianraschka.com/blog/2023/self-attention-from-scratch.html"
        },
        {
            "author": "u/crash90",
            "created_utc": "02-12-2023 07:36:48",
            "distinguished": null,
            "edited": false,
            "id": "110fwgt",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_110fwgt",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/110fwgt/d_getting_llms_to_explore_their_latent_spaces/",
            "score": 7,
            "selftext": "I'm starting my AI deep dive and the most interesting thing I've encountered so far of this concept of knowledge getting rolled up / compressed into latent spaces that we can't interact with directly (only through prompts).\n\nI'm interested in research that has been done in trying to explore and interrogate these latent spaces to understand them.\n\nAny papers, blog posts, threads, youtube videos appreciated.\n\nThanks!",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Getting LLMs to explore their latent spaces",
            "upvote_ratio": 0.77,
            "url": "https://www.reddit.com/r/MachineLearning/comments/110fwgt/d_getting_llms_to_explore_their_latent_spaces/"
        },
        {
            "author": "u/m00nd0og",
            "created_utc": "02-12-2023 07:19:05",
            "distinguished": null,
            "edited": false,
            "id": "110fjyo",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_110fjyo",
            "nsfw": false,
            "num_comments": 2,
            "permalink": "/r/MachineLearning/comments/110fjyo/d_bert_tokenization_replacing_personentity_names/",
            "score": 5,
            "selftext": "Can someone please help me with below query, \n\nI would like to replace all the names that are present in the sentences with a generic word or token so that bert doesn't use the meaning behind some of the names and just look at names as presence of a \"name\". \n\nI have the names that are present in the sentence just wanted to know what should be appropriate word or token to replace it with.\n\nThanks!",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Bert Tokenization: Replacing person/entity names with a common token/word.",
            "upvote_ratio": 1.0,
            "url": "https://www.reddit.com/r/MachineLearning/comments/110fjyo/d_bert_tokenization_replacing_personentity_names/"
        },
        {
            "author": "u/helliun",
            "created_utc": "02-12-2023 06:32:54",
            "distinguished": null,
            "edited": false,
            "id": "110ep96",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_110ep96",
            "nsfw": false,
            "num_comments": 21,
            "permalink": "/r/MachineLearning/comments/110ep96/p_extracting_causal_chains_from_text_using/",
            "score": 276,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Extracting Causal Chains from Text Using Language Models",
            "upvote_ratio": 0.98,
            "url": "https://v.redd.it/2akxbz3jmsha1"
        },
        {
            "author": "u/ClassicSize7875",
            "created_utc": "02-11-2023 22:12:09",
            "distinguished": null,
            "edited": "02-12-2023 18:04:44",
            "id": "1106q4s",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_1106q4s",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/1106q4s/p_i_made_an_app_that_simplifies_text_data/",
            "score": 10,
            "selftext": "Hi Reddit community!\n\nI wanted to share a tool that I've been working on called DataLabel. It's a UI-based data editing tool that makes it easier to create labeled text data. The goal of DataLabel is to make data editing more accessible and efficient, especially for those who may not have much experience with coding.\n\nDataLabel can be installed via pip `pip install datalabel` , and works best in Jupyter notebooks or other Ipython environments. The interface is user-friendly and straightforward, so you can start using DataLabel right away without any hassle.\n\nI think DataLabel is a useful tool that can save you time and effort when working with text data. If you're curious, you can find it on GitHub at the following link: [**https://github.com/TitanLabsAI/datalabel**](https://github.com/TitanLabsAI/datalabel)\n\nThanks for taking the time to read this, and I hope you find DataLabel helpful in your work.",
            "spoiler": false,
            "stickied": false,
            "title": "[P] I Made an App That Simplifies Text Data Labeling: DataLabel",
            "upvote_ratio": 0.82,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1106q4s/p_i_made_an_app_that_simplifies_text_data/"
        },
        {
            "author": "u/AI4Tigray",
            "created_utc": "02-11-2023 20:52:35",
            "distinguished": null,
            "edited": false,
            "id": "11059u6",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "News",
            "locked": false,
            "name": "t3_11059u6",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/11059u6/n_new_frontiers_in_artificial_intelligence/",
            "score": 0,
            "selftext": "Dear All,\n\nWe are excited to invite you to our upcoming conference, AI For Tigray, centered on the theme \"New Frontiers in Artificial Intelligence.\" This conference brings together leading researchers from academia and industry to share their work and insights on the future of AI.\n\nWe have an exciting lineup of keynote talks from top researchers in the field, including Yoshua Bengio and Jeff Dean. In addition, there will be presentations of the latest research findings through contributed talks and poster sessions. Furthermore, we will be convening a group of renowned researchers to discuss the role of AI in addressing societal challenges.\n\nBut this conference isn't just about advancing technology -- it's about using it for good. The conflict in Tigray is currently \"the deadliest war in the world,\" and the people living in the region are suffering as a result. We want to use our upcoming conference to raise funds for urgent humanitarian aid and help those in need. All proceeds from the conference, including sponsorships, donations, and registration fees, will go towards helping those in need through our partners, the Health Professionals Network for Tigray and the Tegaru Disaster Relief Fund.\n\nWe hope you will join us in using AI for a greater cause. The conference will be held on March 11, 18, and 25 -- mark your calendars and register now at [https://aifortigray.org/](https://aifortigray.org/) to be a part of something special.\n\nSincerely,\n\nAI For Tigray Organizing Committee",
            "spoiler": false,
            "stickied": false,
            "title": "[N] New Frontiers in Artificial Intelligence",
            "upvote_ratio": 0.27,
            "url": "https://www.reddit.com/r/MachineLearning/comments/11059u6/n_new_frontiers_in_artificial_intelligence/"
        },
        {
            "author": "u/leonardtang",
            "created_utc": "02-11-2023 20:33:24",
            "distinguished": null,
            "edited": false,
            "id": "1104wt4",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_1104wt4",
            "nsfw": false,
            "num_comments": 5,
            "permalink": "/r/MachineLearning/comments/1104wt4/r_the_naughtyformer_a_transformer_understands/",
            "score": 8,
            "selftext": "The Naughtyformer: A Transformer Understands Offensive Humor\n\nPaper: [https://arxiv.org/abs/2211.14369](https://arxiv.org/abs/2211.14369)\n\nData: [https://github.com/leonardtang/The-Naughtyformer](https://github.com/leonardtang/The-Naughtyformer)",
            "spoiler": false,
            "stickied": false,
            "title": "[R] The Naughtyformer: A Transformer Understands Offensive Humor",
            "upvote_ratio": 0.79,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1104wt4/r_the_naughtyformer_a_transformer_understands/"
        },
        {
            "author": "u/throwaway957280",
            "created_utc": "02-11-2023 18:47:12",
            "distinguished": null,
            "edited": false,
            "id": "1102t34",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_1102t34",
            "nsfw": false,
            "num_comments": 45,
            "permalink": "/r/MachineLearning/comments/1102t34/d_have_their_been_any_attempts_to_create_a/",
            "score": 79,
            "selftext": "I'm not arguing against Python's speed when it's asynchronously launching C++ optimized kernels. I just think it's kind of wild how 50% of practical machine learning is making sure your tensor shapes are compatible and there's no static shape checking. It kind of blows my mind given the amount of Python comments I've seen of the form `# [B, Z-1, Log(Q), 45] -> [B, Z, 1024]` or something like that. \n\nPlus you have the fact that the two major machine learning frameworks have both had to implement, like, meta-compilers for Python to support outputting optimized graphs. At that point it seems kinda crazy that people are still trying to retrofit Python with all these features it just wasn't meant to support. \n\nFeel free to let me know I have no idea what I'm talking about, because I have no idea what I'm talking about.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Have their been any attempts to create a programming language specifically for machine learning?",
            "upvote_ratio": 0.88,
            "url": "https://www.reddit.com/r/MachineLearning/comments/1102t34/d_have_their_been_any_attempts_to_create_a/"
        },
        {
            "author": "u/t0t0t4t4",
            "created_utc": "02-11-2023 16:19:27",
            "distinguished": null,
            "edited": false,
            "id": "10zzm18",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10zzm18",
            "nsfw": false,
            "num_comments": 29,
            "permalink": "/r/MachineLearning/comments/10zzm18/d_can_google_sue_openai_for_using_the_transformer/",
            "score": 15,
            "selftext": "As far as I know, the Transformer architecture is patented: [https://patents.google.com/patent/US10452978B2/en](https://patents.google.com/patent/US10452978B2/en). Since OpenAI has used the Transformer extensively (including GPT), I'm wondering if this can be considered as patent infringement. \n\nIf you know about legal stuffs please share your opinions.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Can Google sue OpenAI for using the Transformer in their products?",
            "upvote_ratio": 0.72,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10zzm18/d_can_google_sue_openai_for_using_the_transformer/"
        },
        {
            "author": "u/norcalnatv",
            "created_utc": "02-11-2023 11:28:14",
            "distinguished": null,
            "edited": false,
            "id": "10zsw62",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10zsw62",
            "nsfw": false,
            "num_comments": 11,
            "permalink": "/r/MachineLearning/comments/10zsw62/the_inference_cost_of_search_disruption_large/",
            "score": 14,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "The Inference Cost Of Search Disruption \u2013 Large Language Model Cost Analysis [D]",
            "upvote_ratio": 0.89,
            "url": "https://www.semianalysis.com/p/the-inference-cost-of-search-disruption"
        },
        {
            "author": "u/answersareallyouneed",
            "created_utc": "02-11-2023 10:28:43",
            "distinguished": null,
            "edited": false,
            "id": "10zri4x",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10zri4x",
            "nsfw": false,
            "num_comments": 3,
            "permalink": "/r/MachineLearning/comments/10zri4x/d_effectiveness_of_coordconv/",
            "score": 6,
            "selftext": "[https://arxiv.org/abs/1807.03247](https://arxiv.org/abs/1807.03247) paper was released by Uber 4 years ago, but it never seemed to have caught on. The only major paper where I've seen used in is Solo and SoloV2 for instance segmentation.\n\nSeems like it would be useful for object detection, especially for localizing smaller objects or for more precise keypoint estimation when combined with a yolo-like model.\n\nHas anyone used CoordConv for these purposes? Does it it help?/Is it worth looking into?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Effectiveness of CoordConv",
            "upvote_ratio": 0.81,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10zri4x/d_effectiveness_of_coordconv/"
        },
        {
            "author": "u/Dalembert",
            "created_utc": "02-11-2023 10:07:26",
            "distinguished": null,
            "edited": false,
            "id": "10zqzkd",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "News",
            "locked": false,
            "name": "t3_10zqzkd",
            "nsfw": false,
            "num_comments": 4,
            "permalink": "/r/MachineLearning/comments/10zqzkd/news_researchers_at_brigham_young_university/",
            "score": 0,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[News] Researchers at Brigham Young University created an AI system to reduce time spent on film studies for NFL teams. It uses deep learning and computer vision to analyze and annotate game footage, with over 90% accuracy on player detection and 85% accuracy in determining formations.",
            "upvote_ratio": 0.44,
            "url": "https://www.reddit.com/gallery/10zqu17"
        },
        {
            "author": "u/erwinyonata",
            "created_utc": "02-11-2023 09:44:34",
            "distinguished": null,
            "edited": false,
            "id": "10zqd8o",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_10zqd8o",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/10zqd8o/p_im_using_deep_learning_to_play_old_school_game/",
            "score": 0,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[P] I'm using Deep Learning to play Old School game, Snake Game",
            "upvote_ratio": 0.2,
            "url": "https://youtu.be/qpS5OZgIq1Q"
        },
        {
            "author": "u/seraschka",
            "created_utc": "02-11-2023 08:15:08",
            "distinguished": null,
            "edited": false,
            "id": "10zolt0",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_10zolt0",
            "nsfw": false,
            "num_comments": 7,
            "permalink": "/r/MachineLearning/comments/10zolt0/p_understanding_large_language_models_a/",
            "score": 41,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Understanding Large Language Models -- A Transformative Reading List",
            "upvote_ratio": 0.95,
            "url": "https://sebastianraschka.com/blog/2023/llm-reading-list.html"
        },
        {
            "author": "u/_sshin_",
            "created_utc": "02-11-2023 06:54:26",
            "distinguished": null,
            "edited": false,
            "id": "10zmz2d",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_10zmz2d",
            "nsfw": false,
            "num_comments": 67,
            "permalink": "/r/MachineLearning/comments/10zmz2d/p_introducing_arxivgpt_chrome_extension_that/",
            "score": 810,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Introducing arxivGPT: chrome extension that summarizes arxived research papers using chatGPT",
            "upvote_ratio": 0.94,
            "url": "https://i.redd.it/jmgr7vsy3kha1.jpg"
        },
        {
            "author": "u/lmtog",
            "created_utc": "02-11-2023 04:41:47",
            "distinguished": null,
            "edited": false,
            "id": "10zix8k",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10zix8k",
            "nsfw": false,
            "num_comments": 9,
            "permalink": "/r/MachineLearning/comments/10zix8k/d_transformers_for_poker_bot/",
            "score": 2,
            "selftext": "Looking at the current research it seems like Monte Carlo CFR  is the defacto standard (Pluribus).\n\nBut are transformers able to be trained on poker as well?\n\nLets say we encode hands into something like 5h (5 of hearts) and also pass along info of the current game state like p1:raise:2bb, p2:fold and p3:call:2bb. Would the Model be able to predict what hands I should be playing? Lets say we train the model by playing against itself and feed back the result to train the model this way.\n\nThis is just an idea and I have not dove into transformers too much so there might be something that I'am missing.\n\nWhat are your thoughts on this?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Transformers for poker bot",
            "upvote_ratio": 0.58,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10zix8k/d_transformers_for_poker_bot/"
        },
        {
            "author": "u/lyndonzheng",
            "created_utc": "02-11-2023 02:12:38",
            "distinguished": null,
            "edited": false,
            "id": "10zfvz1",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_10zfvz1",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/10zfvz1/r_unid3_unified_discrete_diffusion_for/",
            "score": 5,
            "selftext": " A unified discrete diffusion model for simultaneous vision-language generation. \n\nProject: [https://mhh0318.github.io/unid3/](https://mhh0318.github.io/unid3/)\n\nCode: [https://github.com/mhh0318/UniD3](https://github.com/mhh0318/UniD3)\n\nhttps://preview.redd.it/w2st14pgpiha1.png?width=1366&format=png&auto=webp&v=enabled&s=5fcb58ec05a2e790566fe14296c4a08e932f841f",
            "spoiler": false,
            "stickied": false,
            "title": "[R] UniD3: Unified Discrete Diffusion for Simultaneous Vision-Language Generation",
            "upvote_ratio": 0.78,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10zfvz1/r_unid3_unified_discrete_diffusion_for/"
        },
        {
            "author": "u/iFighting",
            "created_utc": "02-11-2023 02:09:23",
            "distinguished": null,
            "edited": false,
            "id": "10zfu64",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_10zfu64",
            "nsfw": false,
            "num_comments": 6,
            "permalink": "/r/MachineLearning/comments/10zfu64/r_iclr2023_visionandlanguage_framework_for/",
            "score": 159,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] [ICLR'2023\ud83c\udf1f]: Vision-and-Language Framework for Open-Vocabulary Object Detection",
            "upvote_ratio": 0.98,
            "url": "https://v.redd.it/aahxf9k2piha1"
        },
        {
            "author": "u/Tom_the_Tank_Train",
            "created_utc": "02-10-2023 19:52:11",
            "distinguished": null,
            "edited": false,
            "id": "10z96m2",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10z96m2",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/10z96m2/d_hierarchical_clustering_transforming_the/",
            "score": 7,
            "selftext": " Hi all, I have a question regarding interpreting the distance on a dendrogram generated via agglomerative hierarchical clustering with a Euclidean distance metric using the ward-variance minimization linkage (as stated in SciPy: [https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.linkage.html#scipy.cluster.hierarchy.linkage](https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.linkage.html#scipy.cluster.hierarchy.linkage)\n\n). From my understanding, the distance represents the square root of the difference of the error sum of squares of two clusters once they are merged minus the sum of the error sum of squares of each individual cluster. I am interested in performing a transformation at each cluster step (i.e., merging two clusters to make a larger one) so that the y-axis represents the mean distance between clusters instead, while still using the ward-variance minimization linkage to direct the algorithm.\n\nI think I have a solution to my issue, but I want to know if I am missing anything. In 1969, a paper by David Wishart titled \"An Algorithm for Hierarchical Classifications\" derives the coefficients so that the Ward method can be implemented using the Lance-Williams formula. However, in the paper, the following formula is given:\n\n&#x200B;\n\nhttps://preview.redd.it/mma2t7cltgha1.png?width=237&format=png&auto=webp&v=enabled&s=8e69c219dddd7e1330168889f032a7251605a04b\n\nwhere I\\_pq is the square of the metric used in SciPy, k\\_i is the number of data points in cluster i and d\\^2\\_pq is the square of the Euclidean distance between the means of clusters. From this formula, it seems that one can transform from the \"increase in variance space\" to the \"mean distance between clusters space\", while still using Ward-variance minimization in the clustering algorithm. From my research, it seems that this is true. I would greatly appreciate it if someone could confirm this or point out where the flaw in my understanding is. Thanks everyone.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Hierarchical Clustering - Transforming the Distance Axis",
            "upvote_ratio": 1.0,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10z96m2/d_hierarchical_clustering_transforming_the/"
        },
        {
            "author": "u/CeFurkan",
            "created_utc": "02-10-2023 17:45:27",
            "distinguished": null,
            "edited": "02-10-2023 18:47:03",
            "id": "10z6ke2",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10z6ke2",
            "nsfw": false,
            "num_comments": 4,
            "permalink": "/r/MachineLearning/comments/10z6ke2/d_best_available_text_to_speech_free_ai_model_out/",
            "score": 10,
            "selftext": "Greetings everyone.\n\nI am looking for the best text to speech AI model out there for english\n\nI am looking for links to the models you know as best\n\nIf the model supports subtitle file to speech that would be even more awesome\n\nLike providing .srt or .vtt to generate speech - speeding up the necessary parts of speech to fit into durations\n\nThank you very much again\n\nI will use this to replace audio of my older lecture recordings by providing a time generated manually corrected subtitle file like srt or vtt\n\nI am looking for any male sounding model that sounds natural\n\n&#x200B;\n\nI have found this\n\nThey colab and looks very easy to generate. I think I can automate it. But is this one the best?\n\n[https://www.reddit.com/r/MachineLearning/comments/v9rigf/p\\_silero\\_tts\\_full\\_v3\\_release/](https://www.reddit.com/r/MachineLearning/comments/v9rigf/p_silero_tts_full_v3_release/)\n\nfound this too but only female voice :/\n\n[https://www.reddit.com/r/MachineLearning/comments/ttgsr4/r\\_nixtts\\_an\\_incredibly\\_lightweight\\_texttospeech/](https://www.reddit.com/r/MachineLearning/comments/ttgsr4/r_nixtts_an_incredibly_lightweight_texttospeech/)\n\nI need a male voice\n\nany other good ones?\n\n&#x200B;",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Best available text to speech free AI model out there for english",
            "upvote_ratio": 0.73,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10z6ke2/d_best_available_text_to_speech_free_ai_model_out/"
        },
        {
            "author": "u/No_Oilve_6577",
            "created_utc": "02-10-2023 15:53:09",
            "distinguished": null,
            "edited": false,
            "id": "10z45c0",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10z45c0",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/10z45c0/d_is_efficientnet_same_as_mobilenetv2/",
            "score": 0,
            "selftext": "Quick question, is EfficientNet-V1 same as MobileNet-V2? I think they use the same backbone, the inverted linear residual block, no?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Is Efficient-Net same as MobileNetV2",
            "upvote_ratio": 0.5,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10z45c0/d_is_efficientnet_same_as_mobilenetv2/"
        },
        {
            "author": "u/askingforhelp1111",
            "created_utc": "02-10-2023 15:34:00",
            "distinguished": null,
            "edited": false,
            "id": "10z3qdt",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10z3qdt",
            "nsfw": false,
            "num_comments": 10,
            "permalink": "/r/MachineLearning/comments/10z3qdt/d_speed_up_huggingface_inference_pipeline/",
            "score": 0,
            "selftext": "Running a pipeline sentiment analysis call with transformers on 16 cpu takes 6-9 seconds for one inference. How can I speed this up? \n\nMy ideas, for your inputs please:\n\n* Ray cluster - parallel computing, memory usage is high.\n* Within the pipeline() call, use parameter batch\\_size. However, is batch\\_size not appropriate for cpu?\n* HF Accelerate - not sure how to implement on a published model... \n* Model distillation - not sure how to implement on a published model... \n\nThanks in advance!",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Speed up HuggingFace Inference Pipeline",
            "upvote_ratio": 0.5,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10z3qdt/d_speed_up_huggingface_inference_pipeline/"
        },
        {
            "author": "u/MysteryInc152",
            "created_utc": "02-10-2023 14:51:33",
            "distinguished": null,
            "edited": false,
            "id": "10z2pej",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_10z2pej",
            "nsfw": false,
            "num_comments": 18,
            "permalink": "/r/MachineLearning/comments/10z2pej/r_large_language_models_can_teach_themselves_to/",
            "score": 142,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Large Language Models Can Teach Themselves to Use Tools",
            "upvote_ratio": 0.99,
            "url": "https://arxiv.org/abs/2302.04761"
        },
        {
            "author": "u/Tlaloc-Es",
            "created_utc": "02-10-2023 14:06:07",
            "distinguished": null,
            "edited": false,
            "id": "10z1jxz",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10z1jxz",
            "nsfw": false,
            "num_comments": 19,
            "permalink": "/r/MachineLearning/comments/10z1jxz/d_is_it_legal_to_use_images_or_videos_with/",
            "score": 10,
            "selftext": "Hello, I want to know if it is legal to use scraped video or images to train a predictive model, for example, If I scrape photos of faces in google, and after that, I share that model in order that a lot of people can detect faces in their applications, is that legal?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Is it legal to use images or videos with copyright to train a model?",
            "upvote_ratio": 0.79,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10z1jxz/d_is_it_legal_to_use_images_or_videos_with/"
        },
        {
            "author": "u/TikkunCreation",
            "created_utc": "02-10-2023 13:42:06",
            "distinguished": null,
            "edited": false,
            "id": "10z0xzl",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10z0xzl",
            "nsfw": false,
            "num_comments": 14,
            "permalink": "/r/MachineLearning/comments/10z0xzl/d_what_ml_or_mlpowered_projects_are_you_currently/",
            "score": 8,
            "selftext": "This would be for ones that aren't finished enough to post as a link on the weekend.\n\nJust things that are in progress.\n\nInclude a screenshot if you can!",
            "spoiler": false,
            "stickied": false,
            "title": "[D] What ML or ML-powered projects are you currently building?",
            "upvote_ratio": 0.71,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10z0xzl/d_what_ml_or_mlpowered_projects_are_you_currently/"
        },
        {
            "author": "u/gruevy",
            "created_utc": "02-10-2023 12:54:12",
            "distinguished": null,
            "edited": false,
            "id": "10yzq25",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10yzq25",
            "nsfw": false,
            "num_comments": 13,
            "permalink": "/r/MachineLearning/comments/10yzq25/d_locallyrunnable_text_to_speech_ai/",
            "score": 16,
            "selftext": "I've got a 4090 and some stuff that I think it would be fun to have narrated. I've looked at some of the paid online options and $20-$30/mo for 2 hours of AI TTS is not gonna gut it. Can anyone point me to software that I can run locally that'll give me high quality?\n\nIt seems like if people are making billions of waifus in stable diffusion there ought to be something like this out there.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Locally-runnable text to speech AI?",
            "upvote_ratio": 0.94,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10yzq25/d_locallyrunnable_text_to_speech_ai/"
        },
        {
            "author": "u/atulcst",
            "created_utc": "02-10-2023 12:52:27",
            "distinguished": null,
            "edited": false,
            "id": "10yzohn",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10yzohn",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/10yzohn/d_simulator_for_rl_problems/",
            "score": 0,
            "selftext": "I have seen people advocate a simulator for RL problems a lot. I am not sure by simulator what do they mean exactly? Is it the exact simulation (then the problem becomes easy) or some kind of feedback loop (start with a na\u00efve simulator and once we get data then keep improving the simulator \u2013 this looks similar to value iteration or policy iteration).\n\nI assume it\u2019s really difficult to get a simulator for data generation (except for video games etc.). Also, If we already have a simulator, we can easily train a model-free RL (e.g. just planning).",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Simulator for RL problems",
            "upvote_ratio": 0.33,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10yzohn/d_simulator_for_rl_problems/"
        },
        {
            "author": "u/RogueStargun",
            "created_utc": "02-10-2023 11:14:41",
            "distinguished": null,
            "edited": false,
            "id": "10yxc0k",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10yxc0k",
            "nsfw": false,
            "num_comments": 3,
            "permalink": "/r/MachineLearning/comments/10yxc0k/discussion_wasm_equivalant_to_gradio_but_without/",
            "score": 2,
            "selftext": "I'm really impressed with gradio for making interactive webapps. I was wondering... Gradio basically runs off a server so you have to standup a server just to demo certain kinds of apps.\n\nIs there something similar out that that can handle basic tabular data plots *without needing a server?* I was thinking perhaps something like a WASM app that can point to csvs on AWS S3 and generate plots on the fly?",
            "spoiler": false,
            "stickied": false,
            "title": "[Discussion] WASM equivalant to Gradio but without needing a server?",
            "upvote_ratio": 1.0,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10yxc0k/discussion_wasm_equivalant_to_gradio_but_without/"
        },
        {
            "author": "u/BackgroundPass2082",
            "created_utc": "02-10-2023 09:46:51",
            "distinguished": null,
            "edited": false,
            "id": "10yv962",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_10yv962",
            "nsfw": false,
            "num_comments": 3,
            "permalink": "/r/MachineLearning/comments/10yv962/p_did_anyone_manage_to_run_the_musiclm/",
            "score": 1,
            "selftext": "I really want to play with the repo but I'm stuck at the last step of the instructions ([https://github.com/lucidrains/musiclm-pytorch#usage-1](https://github.com/lucidrains/musiclm-pytorch#usage-1)). If anyone has tips, please let me know!\n\nHere's the issue I have: [https://github.com/lucidrains/musiclm-pytorch/issues/13](https://github.com/lucidrains/musiclm-pytorch/issues/13)",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Did anyone manage to run the MusicLM implementation from lucidrains?",
            "upvote_ratio": 0.6,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10yv962/p_did_anyone_manage_to_run_the_musiclm/"
        },
        {
            "author": "u/Mundane_Definition_8",
            "created_utc": "02-10-2023 09:46:41",
            "distinguished": null,
            "edited": false,
            "id": "10yv91l",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10yv91l",
            "nsfw": false,
            "num_comments": 2,
            "permalink": "/r/MachineLearning/comments/10yv91l/d_numbers_of_parameters_that_can_affect_on_a_model/",
            "score": 0,
            "selftext": "Hi guys, my question is what is different between parameters and FLOPs in terms of computation times.\n\nI know that the FLOPs is related to the computation of input images. For example, higher the size, higher the figure. \n\nBut, how much parameters can affect on a model compared to the metric?\n\nI understand that the weights, biases are parameters. But, the cost of computation about them makes me difficult to determine what should I get a specific model.\n\nI can measure the decision based on the FLOPs, which decrease time of training my model when they are lower.\nHowever, I also want to decide a specific model with the number of parameters.\n\nThanks.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] numbers of parameters that can affect on a model.",
            "upvote_ratio": 0.4,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10yv91l/d_numbers_of_parameters_that_can_affect_on_a_model/"
        },
        {
            "author": "u/AlesioRFM",
            "created_utc": "02-10-2023 07:32:53",
            "distinguished": null,
            "edited": false,
            "id": "10ys3md",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_10ys3md",
            "nsfw": false,
            "num_comments": 223,
            "permalink": "/r/MachineLearning/comments/10ys3md/p_im_using_instruct_gpt_to_show_anticlickbait/",
            "score": 2497,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[P] I'm using Instruct GPT to show anti-clickbait summaries on youtube videos",
            "upvote_ratio": 0.97,
            "url": "https://www.reddit.com/gallery/10ys3md"
        },
        {
            "author": "u/darcia_scientist",
            "created_utc": "02-10-2023 07:21:38",
            "distinguished": null,
            "edited": false,
            "id": "10yruoe",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10yruoe",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/10yruoe/d_experiences_finding_a_job_in_the_us_as_a/",
            "score": 0,
            "selftext": "Hi, I am considering moving to the US, and I was wondering about the job market for people in Mexico and the chances of getting an offer.\n\nI know that in theory, it should be 'easier' due to the United States\u2013Mexico\u2013Canada Agreement by getting a TN visa.\n\nAre there any Mexicans here that found a job in the US as a machine learning engineer/data scientist?\n\nWould anyone have a pointer?\n\nI'll obviously research companies and send my resumes, just thought of posting here to see what is the experience of other people.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Experiences finding a job in the US as a Mexican currently working in the UK",
            "upvote_ratio": 0.5,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10yruoe/d_experiences_finding_a_job_in_the_us_as_a/"
        },
        {
            "author": "u/Melodic_Secretary_42",
            "created_utc": "02-10-2023 03:25:12",
            "distinguished": null,
            "edited": false,
            "id": "10ymh4u",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_10ymh4u",
            "nsfw": false,
            "num_comments": 10,
            "permalink": "/r/MachineLearning/comments/10ymh4u/p_resume_parsing_cv_analysis/",
            "score": 6,
            "selftext": "Hi ! so for my final year project I will be working on a cv parser and matching cvs with job postings, I'm thinking about fine tuning LayoutLM on my cvs dataset( of 5000 resumes or so not yet labeled) to get the structure of a resume (contact info , skills , education , etc) and then combine it with NER to identify the details in each section (name , uni name , date of start etc ) . Is it good enough or should I take another approach ?  Or how would you tackle the problem ? feel free to share any ideas u have about this project Thank you !",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Resume parsing + Cv analysis",
            "upvote_ratio": 0.88,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10ymh4u/p_resume_parsing_cv_analysis/"
        },
        {
            "author": "u/BaosteelMetallurgy",
            "created_utc": "02-10-2023 02:30:50",
            "distinguished": null,
            "edited": false,
            "id": "10yks8z",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10yks8z",
            "nsfw": false,
            "num_comments": 2,
            "permalink": "/r/MachineLearning/comments/10yks8z/have_you_seen_ruber_slicing_d/",
            "score": 0,
            "selftext": "Rubber slices are different from brittle materials such as steel plates and plastics. Due to the \u201csticky and soft\u201d characteristics of rubber materials, the structure of the rubber slicer has its particularity.",
            "spoiler": false,
            "stickied": false,
            "title": "Have you seen ruber slicing? [D]",
            "upvote_ratio": 0.2,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10yks8z/have_you_seen_ruber_slicing_d/"
        },
        {
            "author": "u/narendra7799",
            "created_utc": "02-10-2023 00:50:41",
            "distinguished": null,
            "edited": false,
            "id": "10yimi8",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10yimi8",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/10yimi8/d_the_kaggle_book_book_by_konrad_banachewicz_and/",
            "score": 0,
            "selftext": "Does anyone have \"The Kaggle Book : Book by Konrad Banachewicz and Luca Massaron\" in pdf ?? Please share the link",
            "spoiler": false,
            "stickied": false,
            "title": "[D] The Kaggle Book : Book by Konrad Banachewicz and Luca Massaron",
            "upvote_ratio": 0.33,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10yimi8/d_the_kaggle_book_book_by_konrad_banachewicz_and/"
        },
        {
            "author": "u/fromnighttilldawn",
            "created_utc": "02-09-2023 22:02:56",
            "distinguished": null,
            "edited": false,
            "id": "10yfp35",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10yfp35",
            "nsfw": false,
            "num_comments": 38,
            "permalink": "/r/MachineLearning/comments/10yfp35/d_critique_of_statistics_research_from_machine/",
            "score": 38,
            "selftext": "I was just looking around at some paper published by statisticians, I couldn't help but notice that the flavor of their research is vastly different. For example, one researcher wrote about a dozen paper on LASSO alone over the span of a decade, whereas LASSO is just given a power point slide worth of attention in ML. Why is there such a disparity and a divergence in the aim of these disciplines? \n\nAre there some good critique of these research fields from each other's perspective (not just on the technical aspects)? Perhaps by someone who works in both?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Critique of statistics research from machine learning perspectives (and vice versa)?",
            "upvote_ratio": 0.83,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10yfp35/d_critique_of_statistics_research_from_machine/"
        },
        {
            "author": "u/Electrical-Collar-23",
            "created_utc": "02-09-2023 21:56:58",
            "distinguished": null,
            "edited": false,
            "id": "10yfkt8",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10yfkt8",
            "nsfw": false,
            "num_comments": 4,
            "permalink": "/r/MachineLearning/comments/10yfkt8/d_hugging_face_model/",
            "score": 0,
            "selftext": "Can someone suggest some models available on hugging face that i can use and play with and addon in my project??",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Hugging face model",
            "upvote_ratio": 0.03,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10yfkt8/d_hugging_face_model/"
        },
        {
            "author": "u/skn133229",
            "created_utc": "02-09-2023 20:05:02",
            "distinguished": null,
            "edited": false,
            "id": "10ydazz",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10ydazz",
            "nsfw": false,
            "num_comments": 2,
            "permalink": "/r/MachineLearning/comments/10ydazz/d_simple_tensorflow_model_predict_question/",
            "score": 0,
            "selftext": "I am working on a U-Net model using remotely sensed data as input. Training image size is 64x64 and model trained using tensorflow. My assumption has always been that the trained model has to be fed an input of 64x64. Interestingly, I discovered that using an image 128 x 128 at inference will work fine, so will a 96x96 image. How is tensorflow handling this? Is it using a 64x64 moving window? Or is it scaling down and to 64x64 and backup to the larger size? Predictions seem fine but I'd like to know what tensorflow is doing behind the scene so I know how to treat the output. Any thoughts?\n\nThanks.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Simple tensorflow model predict question",
            "upvote_ratio": 0.2,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10ydazz/d_simple_tensorflow_model_predict_question/"
        },
        {
            "author": "u/MysteryInc152",
            "created_utc": "02-09-2023 19:01:17",
            "distinguished": null,
            "edited": false,
            "id": "10ybxa2",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_10ybxa2",
            "nsfw": false,
            "num_comments": 9,
            "permalink": "/r/MachineLearning/comments/10ybxa2/r_theory_of_mind_may_have_spontaneously_emerged/",
            "score": 0,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Theory of Mind May Have Spontaneously Emerged in Large Language Models",
            "upvote_ratio": 0.48,
            "url": "https://arxiv.org/abs/2302.02083"
        },
        {
            "author": "u/ibraheemMmoosa",
            "created_utc": "02-09-2023 18:39:44",
            "distinguished": null,
            "edited": false,
            "id": "10ybgb3",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10ybgb3",
            "nsfw": false,
            "num_comments": 5,
            "permalink": "/r/MachineLearning/comments/10ybgb3/d_should_i_put_my_current_or_past_affiliation_on/",
            "score": 0,
            "selftext": "Hey guys. I have got a paper accepted to the EACL 2023 conference. When I was working on the paper I did not have any official affiliation. I was working as an independent researcher.\n\nI have started my PhD at PSU recently. I was wondering if I should use my current affiliation on the paper. I am the corresponding author for this paper. Also, I am planning to use my PSU address for all research communications from now on instead of my gmail address. So putting my PSU affiliation would make sense in that way.\n\nSo my question is, is it okay to use my current affiliation?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Should I put my current or past affiliation on my EACL paper?",
            "upvote_ratio": 0.38,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10ybgb3/d_should_i_put_my_current_or_past_affiliation_on/"
        },
        {
            "author": "u/These-Assignment-936",
            "created_utc": "02-09-2023 12:49:13",
            "distinguished": null,
            "edited": false,
            "id": "10y2mu0",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10y2mu0",
            "nsfw": false,
            "num_comments": 18,
            "permalink": "/r/MachineLearning/comments/10y2mu0/d_using_llms_as_decision_engines/",
            "score": 114,
            "selftext": "I just finished reading the paper \"Pre-Trained Language Models for Interactive Decision Making\" ([https://arxiv.org/abs/2202.01771](https://arxiv.org/abs/2202.01771)). As I understand it, the authors are using a language model to \"generate\" an optimal path to an objective, in test environments like VirtualHome and BabyAI. Reinforcement and imitation learning are evaluated as ways for the model to self-improve.\n\nThis is the first time I've seen a language model being used to \"solve a problem\" that isn't a language one. It seems to open up so many new possibilties. Has this been done before? Are there other examples of LMs being used as decision engines? What's the state of the art? Any interesting applications you've seen?\n\nSide question: I imagine there were AI approaches to navigating VirtualHome and BabyAI that were NOT language-model based. What is the standard modeling approach to these kinds of problems?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Using LLMs as decision engines",
            "upvote_ratio": 0.95,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10y2mu0/d_using_llms_as_decision_engines/"
        },
        {
            "author": "u/MyActualUserName99",
            "created_utc": "02-09-2023 12:41:02",
            "distinguished": null,
            "edited": false,
            "id": "10y2f1h",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10y2f1h",
            "nsfw": false,
            "num_comments": 5,
            "permalink": "/r/MachineLearning/comments/10y2f1h/d_plot_best_run_for_accuracy_or_mean_across_runs/",
            "score": 0,
            "selftext": "I've ran two image classification model 5 times on a dataset. Model A has a mean best accuracy of 95.03% while Model B has a mean best accuracy of 95.3% However, Model A has a max best accuracy of 95.75% while Model B has a mean best accuracy of 95.5%. I am wanting to report these results in a paper to a conference/journal. \n\nWhen plotting the test accuracy per epoch, should I only report the results for the best run or should I take the mean of the test accuracies over all 5 runs per epoch for plotting?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Plot Best Run for Accuracy or Mean across runs?",
            "upvote_ratio": 0.4,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10y2f1h/d_plot_best_run_for_accuracy_or_mean_across_runs/"
        },
        {
            "author": "u/henistein",
            "created_utc": "02-09-2023 12:16:51",
            "distinguished": null,
            "edited": false,
            "id": "10y1s53",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10y1s53",
            "nsfw": false,
            "num_comments": 2,
            "permalink": "/r/MachineLearning/comments/10y1s53/d_dense_correspondence_between_imagemesh/",
            "score": 0,
            "selftext": "The  goal is to create a model that can make correspondences between images  and meshes. Just like we see in image registration, where we have an  image next to each other and then N matches (lines) that show similar  features. But in this case will be an image and a mesh of a specific  object.\n\nHave you some tips and ideas that could help me how to attack this problem?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Dense correspondence between image/mesh",
            "upvote_ratio": 0.5,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10y1s53/d_dense_correspondence_between_imagemesh/"
        },
        {
            "author": "u/fourcornerclub",
            "created_utc": "02-09-2023 11:31:16",
            "distinguished": null,
            "edited": false,
            "id": "10y0ksi",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10y0ksi",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/10y0ksi/discussion_looking_for_opinions_scale_spellbook/",
            "score": 0,
            "selftext": "Hey everyone. Has anyone used Snorkel Flow, Scale Spellbook or other alternatives (please advise) to test multiple foundation models and migrate between them? E.g. comparing GPT3 vs GPT-J or GPT-Neo etc. Need help moving to a smaller/cheaper model - cheers!",
            "spoiler": false,
            "stickied": false,
            "title": "[Discussion] Looking for opinions: Scale Spellbook vs. Snorkel Flow vs....?",
            "upvote_ratio": 0.33,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10y0ksi/discussion_looking_for_opinions_scale_spellbook/"
        },
        {
            "author": "u/TKMater",
            "created_utc": "02-09-2023 11:18:39",
            "distinguished": null,
            "edited": false,
            "id": "10y08vt",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10y08vt",
            "nsfw": false,
            "num_comments": 9,
            "permalink": "/r/MachineLearning/comments/10y08vt/d_similarity_bw_two_vectors/",
            "score": 0,
            "selftext": "how to calculate similarity between two vectors? I want a similarity metric that take into accounts both the directions and magnitudes of vectors.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Similarity b/w two vectors",
            "upvote_ratio": 0.3,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10y08vt/d_similarity_bw_two_vectors/"
        },
        {
            "author": "u/Basil1sk17",
            "created_utc": "02-09-2023 10:33:43",
            "distinguished": null,
            "edited": false,
            "id": "10xz47o",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10xz47o",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/10xz47o/d_storytelling_ai_that_i_could_feed_data_to_and/",
            "score": 3,
            "selftext": " Hello,\n\nI was wondering if there's a free or premium story-telling AI model that I could feed data to, for example, passages from a particular author or pages from their book, and then ask the AI to create a story using that author's writing style, dictionary, or ideas.\n\nA while ago I watched a Youtube video, in which a person taught an AI to write screenplays in the style of a certain author and I'd like to do the same, except with short stories. Is it possible to do so without any coding knowledge?\n\nThanks.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Story-telling AI that I could feed data to and then ask to write a similar replica?",
            "upvote_ratio": 0.64,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10xz47o/d_storytelling_ai_that_i_could_feed_data_to_and/"
        },
        {
            "author": "u/d0cmorris",
            "created_utc": "02-09-2023 09:45:47",
            "distinguished": null,
            "edited": false,
            "id": "10xxxpa",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10xxxpa",
            "nsfw": false,
            "num_comments": 9,
            "permalink": "/r/MachineLearning/comments/10xxxpa/d_constrained_optimization_in_deep_learning/",
            "score": 5,
            "selftext": "Clearly,  large scale deep learning approaches in image classification or NLP use  all sorts of Regularization mechanisms, but the parameters are  typically unconstrained (i.e., every weight can theoretically attain any  real value). In many Machine Learning domains, constrained optimization  (e.g. via Projected Gradient Descent or Frank-Wolfe) plays a huge role.\n\nI  was wondering whether there are large-scale Deep Learning applications  which rely on constrained optimization approaches? When I say  large-scale, I mean large CNNs, transformers, diffusion models or the  like. Are there settings where constrained optimization would even be a  preferred approach, but not efficient/stable enough?\n\nHappy for any paper suggestions or thoughts! Thanks!",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Constrained Optimization in Deep Learning",
            "upvote_ratio": 0.86,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10xxxpa/d_constrained_optimization_in_deep_learning/"
        },
        {
            "author": "u/PsyEclipse",
            "created_utc": "02-09-2023 09:44:36",
            "distinguished": null,
            "edited": false,
            "id": "10xxwoe",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10xxwoe",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/10xxwoe/d_latent_spaces_and_weather_forecastingnowcasting/",
            "score": 4,
            "selftext": "Hi, everyone. First time, long time.\n\n  \nMy background is weather analysis to DL applications in weather, and I had a question I wanted to ask the community writ large. The question is about latent spaces and how, specifically, the DeepMind group used them in their radar nowcasting model DGMR (see links to prior threads below).\n\nIn the DGMR paper itself ([https://www.nature.com/articles/s41586-021-03854-z](https://www.nature.com/articles/s41586-021-03854-z)), the architecture looks like a U-net with some ConvGRU2D flair in the decoder and some temporal consistency checks from the discriminator. There is also what they call a \"latent conditioning stack.\" From some deeper readings, I think the model is a descendant of BigGAN, since both use an explicit latent space among other similarities. This leads to my question and general curiosity...  \nHow is this latent space seeded? My prior experience with latent space toy models (DCGAN, for example) is that unless you seed the RNG explicitly, then performing a restart of the model to continue training mucks up the distribution. Fairly standard RNG issues.  \n\n\nIs it really as simple as, for example,\n\n    latent_vector = tf.random.truncated_normal([batch_size, grid_size_parameters], seed=42)\n\nI feel like I'm missing something. Why does this work at all? Why is a latent space necessary in this context? They state explicitly in their paper that they require this stack to generalize results to datasets that are larger (in a HxW sense) than the one on which they trained, but I can't wrap my head around why an extended latent vector for a larger grid size works.\n\nIf anyone can point me in the right direction or help me understand, I'd greatly appreciate it.\n\nLinks to prior threads:  \n[https://www.reddit.com/r/MachineLearning/comments/pyfjz7/r\\_deepminds\\_weather\\_forecasting\\_model\\_nowcasting/](https://www.reddit.com/r/MachineLearning/comments/pyfjz7/r_deepminds_weather_forecasting_model_nowcasting/)  \n[https://old.reddit.com/r/MachineLearning/comments/py0289/r\\_skilful\\_precipitation\\_nowcasting\\_using\\_deep/](https://old.reddit.com/r/MachineLearning/comments/py0289/r_skilful_precipitation_nowcasting_using_deep/)",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Latent spaces and weather forecasting/nowcasting",
            "upvote_ratio": 0.75,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10xxwoe/d_latent_spaces_and_weather_forecastingnowcasting/"
        },
        {
            "author": "u/RstarPhoneix",
            "created_utc": "02-09-2023 08:31:51",
            "distinguished": null,
            "edited": false,
            "id": "10xw5pr",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10xw5pr",
            "nsfw": false,
            "num_comments": 3,
            "permalink": "/r/MachineLearning/comments/10xw5pr/d_can_we_use_ray_for_distributed_training_on/",
            "score": 0,
            "selftext": "Same as title. Also the dataframe library should support machine learning libraries",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Can we use Ray for distributed training on vertex ai ? Can someone provide me examples for the same ? Also which dataframe libraries you guys used for training machine learning models on huge datasets (100 gb+) (because pandas can't handle huge data).",
            "upvote_ratio": 0.44,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10xw5pr/d_can_we_use_ray_for_distributed_training_on/"
        },
        {
            "author": "u/Available_Lion_652",
            "created_utc": "02-09-2023 06:52:06",
            "distinguished": null,
            "edited": false,
            "id": "10xu09v",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10xu09v",
            "nsfw": false,
            "num_comments": 12,
            "permalink": "/r/MachineLearning/comments/10xu09v/d_rtx_3090_with_i7_7700k_training_bottleneck/",
            "score": 3,
            "selftext": "Hey guys I have an older PC(5 years) with an i7 7700k processor. I want to buy an Nvidia RTX 3090 for training large language models. I can t find any benchmark for CPU bottleneck when training, let s say an GPT 2 large model. \nHas anyone have any experience with this set-up similar set-up ?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] RTX 3090 with i7 7700k, training bottleneck",
            "upvote_ratio": 0.67,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10xu09v/d_rtx_3090_with_i7_7700k_training_bottleneck/"
        },
        {
            "author": "u/dtransposed",
            "created_utc": "02-09-2023 06:20:34",
            "distinguished": null,
            "edited": "02-10-2023 15:21:56",
            "id": "10xten3",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_10xten3",
            "nsfw": false,
            "num_comments": 3,
            "permalink": "/r/MachineLearning/comments/10xten3/r_research_seminar_by_neural_magic_acdc/",
            "score": 12,
            "selftext": "At [Neural Magic](https://neuralmagic.com), we are proud to be at the forefront of cutting-edge machine learning research, with a particular focus on model compression. Our internal Lunch and Learn seminars are a weekly opportunity for our team to share their research and collaborate on new ideas. We believe in the importance of open-source contributions, which is why we are thrilled to announce that for a second time, we are opening the seminar to the wider community.\n\nOn February 23, 2023, I will be sharing our work on [AC/DC, a framework for sparse-training models](https://arxiv.org/abs/2106.12379).\n\nThis research was done in partnership with IST Austria. Join me and the Neural Magic team for this exciting presentation and be sure to keep an eye out for future speakers in the coming months!\n\n&#x200B;\n\nYou can reserve your spot for the presentation [here](https://neuralmagic.com/resources/webinars/use-a-sparse-training-algorithm-ac-dc-for-sota-neural-network-performance-and-accuracy/).",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Research Seminar by Neural Magic: AC/DC: Alternating Compressed/DeCompressed Training of Deep Neural Networks",
            "upvote_ratio": 0.74,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10xten3/r_research_seminar_by_neural_magic_acdc/"
        },
        {
            "author": "u/zanzagaes2",
            "created_utc": "02-09-2023 06:03:02",
            "distinguished": null,
            "edited": "02-09-2023 09:29:34",
            "id": "10xt36j",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_10xt36j",
            "nsfw": false,
            "num_comments": 15,
            "permalink": "/r/MachineLearning/comments/10xt36j/p_creating_an_embedding_from_a_cnn/",
            "score": 1,
            "selftext": "Hi all: I have trained a CNN (efficietnet-b3) to classify the degree of a disease on medical images. I would like to create an embedding both to visualize relationships between images (after projecting to 2d or 3d-space) and to find similar images to one given.\n\nI have tried using the output of the last convolution both before and after pooling for all train images (\\~30.000) but the result is mediocre: images non-alike are quite close in the embedding and plotting it in 2 or 3d just show a point cloud with no obvious pattern.\n\nI have also tried to use the class activation map (the output of the convolutional layer after pooling and multiplying by the weights of the classifier of the predicted class). This is quite better, but class are not separated too clearly in the scatterplot.\n\n**Is there any other sensible way to generate the embeddings?** I have tried using the hidden representation of earlier convolutional layers, but some of them are so huge (\\~650.000 features per sample) creating a reasonable sized embedding would require very aggressive PCA.\n\n&#x200B;\n\nExample of the scatter plot of the heatmap embedding. While it is okayish (classes are more or less spatially localized) it would be great to find an embedding that creates more visible clusters for each class.\n\nhttps://preview.redd.it/l7smdyuml6ha1.png?width=543&format=png&auto=webp&v=enabled&s=1c9a872ff73eea199e4977a1375303bcffe00158\n\n&#x200B;",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Creating an embedding from a CNN",
            "upvote_ratio": 0.55,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10xt36j/p_creating_an_embedding_from_a_cnn/"
        },
        {
            "author": "u/Smedskjaer",
            "created_utc": "02-09-2023 05:15:02",
            "distinguished": null,
            "edited": false,
            "id": "10xs9ty",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_10xs9ty",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/10xs9ty/project_text_cluster_of_mxn_dimensions_as/",
            "score": 1,
            "selftext": "I  have a text clustering project. It clusters texts in MxN dimensions. M  is a subset of N, where N is the total number of domains. The text  corpus is a set of academic papers. The clusters are cross disciplinary  subjects, defined by M. Clusters are identified by MANOVA tests of sets  of cross products. Goal is to identify texts of interest for research.  E.g. identify clusters of papers relevant to a combination of subjects,  or identify areas of research by their cluster, or identify outlier  research.\n\nThis is a N versus NP  problem. It requires a great deal of processing time to cluster texts. I  may do so for a corpus of 10k research papers, but that is a static  set, and papers cannot be appended to the corpus without affecting all  other clusters of the corpus. So I am considering creating a training  set of 10k papers, and writing an AI to identify and cluster texts  without comparing it to the rest of the corpus.\n\nI  want feedback and ideas. I wont specify what I am looking for yet,  because I am certain some of the responses here will point out something  I did not consider. So please, comment with your thoughts. Tell me what  you know. Give me your ideas.",
            "spoiler": false,
            "stickied": false,
            "title": "[PROJECT] Text cluster of MxN dimensions as training set for AI?",
            "upvote_ratio": 1.0,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10xs9ty/project_text_cluster_of_mxn_dimensions_as/"
        },
        {
            "author": "u/ThePerson654321",
            "created_utc": "02-09-2023 03:46:43",
            "distinguished": null,
            "edited": false,
            "id": "10xqtn2",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10xqtn2",
            "nsfw": false,
            "num_comments": 2,
            "permalink": "/r/MachineLearning/comments/10xqtn2/d_bees_a_new_unit_of_measurement_for_ml_model_size/",
            "score": 3,
            "selftext": "Would like to hear about what you guys think about [this](https://www.lesswrong.com/posts/YKfNZAmiLdepDngwi/gpt-175bee) approach?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Bees: a new unit of measurement for ML model size",
            "upvote_ratio": 0.57,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10xqtn2/d_bees_a_new_unit_of_measurement_for_ml_model_size/"
        },
        {
            "author": "u/pommedeterresautee",
            "created_utc": "02-09-2023 01:58:42",
            "distinguished": null,
            "edited": false,
            "id": "10xp54e",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_10xp54e",
            "nsfw": false,
            "num_comments": 30,
            "permalink": "/r/MachineLearning/comments/10xp54e/p_get_2x_faster_transcriptions_with_openai/",
            "score": 205,
            "selftext": "We are happy to announce the support of OpenAI Whisper model (ASR task) on Kernl.\u00a0\n\nWe focused on high quality transcription in a latency sensitive scenario, meaning:\n\n* *whisper-large-v2* weights\n* *beam search 5 (as recommended in the related paper)*\n\nWe measured a 2.3x speedup on Nvidia A100 GPU (2.4x on 3090 RTX) compared to Hugging Face implementation using FP16 mixed precision on transcribing librispeech test set (over 2600 examples). For now, OpenAI implementation is [not yet PyTorch 2.0 compliant](https://github.com/openai/whisper/pull/115).\n\nIn the post below, we discuss what worked (CUDA Graph), our tricks (to significantly reduce memory footprint), and what did not pay off (Flash attention and some other custom Triton kernels).\n\n* **Kernl repository**: [https://github.com/ELS-RD/kernl](https://github.com/ELS-RD/kernl)\n* **Reproduction script**: [https://github.com/ELS-RD/kernl/blob/main/experimental/whisper/speedup.ipynb](https://github.com/ELS-RD/kernl/blob/main/experimental/whisper/speedup.ipynb)\n\n# Unsung hero: CUDA graphs\n\nCUDA graphs technology provides most of the speed up. Compared to vanilla PyTorch 2.0 (\u201creduce-overhead mode\u201d), we provide a limited memory footprint when vanilla PyTorch 2.0 may raise OOM exception.\n\n[memory footprint](https://preview.redd.it/jyfayud5d4ha1.png?width=1598&format=png&auto=webp&v=enabled&s=79bd34de7dee5ef403b4cccc60785c322dfa38ec)\n\nExperiments have been run on a 3090 RTX with 24 Gb DDR. A reminder that PyTorch 2.0 focuses on training, not inference, which may explain why it OOMs rapidly in this case.\n\nAt its beginning, many partitioners were surprised by PyTorch eager mode performances, when compared to TensorFlow 1.x compiled models: they were on par! Python brought its flexibility and ease of debugging without implying any significant performance cost.\n\nThis is mostly because GPUs are latency hiding hardware: when PyTorch launches an operation on GPU, it sends instructions from host (CPU) to a queue (the CUDA stream), which allows PyTorch to continue Python script execution without having to wait for CUDA kernel to finish its work. This strategy effectively hides most of the Python overhead, in particular when there are some computation costly operations like convolutions or matrix multiplications.\n\nEach new generation of GPUs being much faster than its predecessor, this strategy could not last forever, according to one PyTorch maintainer, it is an \u201cexistential problem\u201d ([dev podcast](https://pytorch-dev-podcast.simplecast.com/episodes/pytorch-20), around 8mn30).\n\nIn inference mode, especially in latency-sensitive scenarios where batch size tends to be low, there is often little computation to perform (regarding what modern GPUs can do), making it even harder to hide effectively Python overhead. It\u2019s accentuated in the case of generative models like Whisper, because each decoder call focuses on generating a single token, and a part of the computation is cached for the next token.\n\nThis is a typical situation where CUDA graph is very helpful.\n\nThe main idea behind CUDA graph is that we can replace a series of instructions sent from host (CPU) to device (GPU) by one call referring to a graph of instruction stored in GPU. Check also this twitter [thread](https://twitter.com/cHHillee/status/1616906059368763392) for more explanations.\n\nFirst it will observe the inference of a model for specific input shapes and then replay it without going through most of the Python code.\n\nOne constraint is that it will replay the exact same operations with the exact same arguments.\n\nFor instance, memory addresses used by kernels are captured and therefore need to be static. For input tensors, it means that for each inference, we need to allocate some GPU memory and copy them there before the capture and copy all the following input tensors at the very same place.\n\nThe second constraint is that dynamic shapes are not supported by CUDA graph because it captures everything. We could have our own machinery in front of the model, but PyTorch 2.0 offers the right tooling to manage that point out of the box.\n\nBasically, dynamo offers a mechanism which checks if the model has already been captured for specific input shapes and some other states and capture it if not yet the case. You just have to provide a function which converts to CUDA graphs and you are done.\n\nOut of the box, PyTorch 2.0 provides a \u201creduce-overhead\u201d mode which applies CUDA graph to the model. Unfortunately, for now, it will raise an OOM with Whisper large or medium because it reserves some CUDA space for each input shape. Therefore, for a generative model it rapidly fulfills the GPU memory, in particular because of the K/V cache which can be huge.\n\nWe have worked around this constrain by building our own layer on top of the memory pool of PyTorch.\u00a0\n\nBasically, a PyTorch tensor is made of 2 parts, a CUDA allocated memory represented by PyTorch as a \u201cstorage\u201d, and a bunch of metadata associated with it. Among the metadata there is a CUDA memory address, the tensor shape plus its strides, its dtype and... a memory offset.\n\nOur idea is to create a very large tensor and share its storage between several input tensors, using offset metadata. With this solution, we avoid specializing in input tensor shapes and share the reserved memory for different input shapes related to several CUDA graphs.\n\nAs shown in the table above, it significantly reduces the memory overhead.\n\n# What about custom (Triton) kernels for attention?\n\n**TL; DR: we tried, they work, we got up to 2 times faster than eager PyTorch for cross attention and they bring close to nothing in e2e latency mostly because the improvement is not big enough to matter \ud83d\ude41**\n\nBelow, we follow the convention of naming Q, K and V, the 3 tensors used in the attention of transformer models.\n\nWhisper is based on a classic transformer architecture, with an encoder and a decoder.\n\nTwo characteristics of this model are of interest:\n\n* The shape of Q tensor used in cross-attention is always \\[batch, #heads, 1, 1500\\].\n* Model has been trained on 30-second audio files and their associated transcript. Because audio files are short, the sequence to generate is usually short, fewer than 50 tokens most of the time.\n\nBecause of these characteristics, optimizing attention has a low reward. In particular, the now common trick \u201creplace attention with flash attention\u201d is counterproductive:\n\n* self-attention: sequences are very short, so quadratic complexity is less of an issue;\n* cross-attention: using flash-attention leads to a 2 times slower inference on this part of the model.\n\nWe have tried to work on the second point and thought we could make cross attention faster.\n\nUsual attention implementation (self and cross) relies on a series of operations: matmul (Q x K\\^t) -> rescale -> SoftMax -> matmul (SoftMax output x V). Intermediate output tensors have a shape which usually scales quadratically with input sequence length. They will be saved and reloaded from DDR, and memory bandwidth is a very scarce resource in GPUs.\n\nTo optimize speed, flash attention fuses operations, so basically first matmul will work on a small part of Q and K, and directly apply SoftMax to it without saving intermediate results to DDR. Same for second matmul. Because we don't go and back through GPU main memory, flash attention usually runs much faster than na\u00efve implementation of attention.\n\nThe parallelization of the jobs is done on different axes: [batch and attention head for the original flash attention](https://github.com/HazyResearch/flash-attention/issues/40), and Triton author added a third one, tokens, aka third dimension of Q (this important trick is now also part of flash attention CUDA implementation).\n\nIn the Whisper latency sensitive case, this doesn\u2019t work well. The size of batches is low and sequence length (third dimension of Q tensor) is... 1! So, even if each job is done very efficiently, our GPU occupancy is low, and basically most of its streaming processors are idle. At the end of the day, the FA kernel is up to 2 times slower than eager PyTorch implementation (depending on batch size and model size).\n\n# Try 1: the very simple kernel\n\nWe noted that there is little computation to do and that we were memory bandwidth bounded. It means that most of the time we wait for data to be transferred from main memory to shared memory.\u00a0\n\nWe leveraged that fact in a very simple kernel with 2 optimizations:\n\n* after having finishing the rescale of the QK\\^t matmul, we perform the SoftMax computation in parallel of loading V tensor for the final matmul. The SoftMax computation finishes before the end of the V loading, so basically it costs us nothing;\n* to achieve best performances, we also changed the memory layout of V tensor in a way where we get a coalesced access, so we lowered the pressure on the memory bandwidth and increased instruction throughput (coalesced access let you load up to 128 bytes in a single instruction so you need less of them, which lets you perform more other things)\n\nAltogether this cross attention was up to 2x faster compared to eager. It appeared to bring between 5 to 20% in end-to-end benchmark depending on model size and batch size. Cool but far from being a game changer, it requires a modification specific to Whisper model (memory layout of V) which is not in the spirit of the Kernl library. We decided to search for another way of doing things (we kept the code in the library for possible future use case).\n\n# Try 2: Skinny Flash Attention\n\nOur second try is based on the very same trick as Flash Attention (parallel SoftMax) but is designed for tall and skinny tensors, which is inspired by split-k strategy in GEMM (a close cousin of the matmul). The main idea is to add a new parallelization axis over the 3rd dimension of K tensor. The next steps are in the same spirit as flash attention with a difference that we need a new reduction operation between the different jobs' outputs. It provides 5-10% speedup compared to eager implementation on this setup at kernel level. We kept that kernel to ease the next feature we are working on (quantization) but the effect in end-to-end latency is inferior to 5% (still it exists \ud83d\ude05).\n\nSome thoughts about PyTorch 2.0, Triton and making things much faster\n\nPlaying with PyTorch ~~1.14~~ 2.0 since this summer made us quite convinced that the major update to be released very soon will be a game changer for the ML field.\n\nFor inference (but also for training), the parallel with PyTorch vs TensorFlow is obvious to our eyes.\u00a0\n\nThe traditional way to deploy a model is to export it to Onnx, then to TensorRT plan format. Each step requires its own tooling, its own mental model, and may raise some issues. The most annoying thing is that you need Microsoft or Nvidia support to get the best performances, and sometimes model support takes time. For instance, T5, a model released in 2019, is not yet correctly supported on TensorRT, in particular K/V cache is missing ([soon it will be according to TensorRT maintainers](https://github.com/NVIDIA/TensorRT/issues/1845), but I wrote the very same thing almost 1 year ago and then 4 months ago so\u2026 I don\u2019t know).\n\nPyTorch 2.0 makes the graph capture step easy, it has been designed to work even if not everything is PyTorch compliant. With its Python first philosophy, it provides flexibility and debuggability.\u00a0\n\nSeveral years ago, some said that by design PyTorch can\u2019t be as performant than Tensorflow because of its eager execution model, compilation has to be faster. The same thing could be said for OnnxRuntime or TensorRT, they are C++ stuff, they have less overhead, etc. But at the end of the day, it's always the \u201cease of use\u201d which is decisive. Ease of use because of Python, but also because of the transparency in the process, Triton makes understanding and debugging kernels much easier than closed source TensorRT Myelin engine calling closed source cuBlas library.\n\nAnd of course, like TensorFlow, there will be many use cases where dedicated tools will be best choices, starting with situations where you can\u2019t deploy a Python interpreter.\n\nThe second lesson, Triton is easier to start with than CUDA, but you probably can\u2019t write or debug highly performant code without being able to, at least, read and debug PTX/SASS instructions. We realized that when we had some performance issues... The good news is that PTX is understandable, and you will probably spot unexpected generated code with some effort if there is any. Moreover, CUDA probably requires the same care when you really focus on performances.\n\nWe had plenty of issues with Triton, for example, cosmetics change in code may raise segfault. At some point you finish by having an intuition of what kinds of patterns to follow to make things work, in particular when there are for loops and dot operations. A new version of Triton has recently been released after a full rewrite of its backend, our little tests showed some improvement on stability but we have not yet fully switched.\n\nAs in my previous post, I highly recommend that readers start playing with Triton library, I rewrite it here: it\u2019s fun (at least when it doesn\u2019t segfault) and helps you to make sense of a large part of what is happening in ML engineering. I am quite convinced many flash attention like kernels are still to be written.\u00a0\n\n# Caveat\n\nTwo important things to note about the project described here:\n\n* CUDA graphs require us to capture a graph per input tensor shape, there is a non-negligible warmup time. We measure around 10mn on 2 different machines / GPUs (down from 50mn in our previous Kernl version). One user reported with the new version a bit more than 20mn of warmup time. We are aware of obvious ways to decrease it significantly.\n* The context here is latency sensitive optimization. In throughput sensitive one, just increasing batch size will bring you most of the speedup. Otherwise, more aggressive optimizations like quantization are required (not yet released on Kernl).",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Get 2x Faster Transcriptions with OpenAI Whisper Large on Kernl",
            "upvote_ratio": 0.96,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10xp54e/p_get_2x_faster_transcriptions_with_openai/"
        },
        {
            "author": "u/Acceptable_League160",
            "created_utc": "02-08-2023 23:35:02",
            "distinguished": null,
            "edited": false,
            "id": "10xmm87",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10xmm87",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/10xmm87/d_format_for_icml_tutorial_submission/",
            "score": 1,
            "selftext": "Hello!   \n\n\nI'm quite new to this. I was wondering what the right format is for submitting a successful tutorial proposal. Should I just use the LaTeX style files but modify the content for a tutorial proposal?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Format for ICML tutorial submission?",
            "upvote_ratio": 0.57,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10xmm87/d_format_for_icml_tutorial_submission/"
        },
        {
            "author": "u/These-Assignment-936",
            "created_utc": "02-08-2023 21:19:38",
            "distinguished": null,
            "edited": false,
            "id": "10xjwac",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10xjwac",
            "nsfw": false,
            "num_comments": 28,
            "permalink": "/r/MachineLearning/comments/10xjwac/d_are_there_emergent_abilities_of_image_models/",
            "score": 86,
            "selftext": "Just finished reading the Stanford/Google survey paper ([https://arxiv.org/abs/2206.07682](https://arxiv.org/abs/2206.07682)) on emergent abilities of large language models. It made me wonder: do image generation models have emergent abilities, too? Do we know?\n\nI can't quite wrap my head around what such an ability would even look like. Figured maybe other folks had given this a think.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Are there emergent abilities of image models?",
            "upvote_ratio": 0.93,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10xjwac/d_are_there_emergent_abilities_of_image_models/"
        },
        {
            "author": "u/CeFurkan",
            "created_utc": "02-08-2023 19:05:28",
            "distinguished": null,
            "edited": "02-09-2023 03:23:42",
            "id": "10xgvhj",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10xgvhj",
            "nsfw": false,
            "num_comments": 56,
            "permalink": "/r/MachineLearning/comments/10xgvhj/d_are_there_any_ai_model_that_i_can_use_to/",
            "score": 33,
            "selftext": "I have got old lecture recordings\n\nI want to improve their sound quality\n\nI have tested adobe AI noise removal but not very good\n\nI also tested descript studio sound not very good either\n\nI wonder if there are any public model, github repo, github project, hugging face repo that I can use to remove noise and improve sound quality of existing audio recordings?\n\nThank you so much for replies\n\nRecordings are in English\n\nHere example recording that needs to be cleaned 5 min audio : [https://sndup.net/stjs/](https://sndup.net/stjs/)\n\nfull lecture : [https://youtu.be/2zY1dQDGl3o](https://youtu.be/2zY1dQDGl3o)",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Are there any AI model that I can use to improve very bad quality sound recording? Removing noise and improving overall quality",
            "upvote_ratio": 0.81,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10xgvhj/d_are_there_any_ai_model_that_i_can_use_to/"
        },
        {
            "author": "u/gecko39",
            "created_utc": "02-08-2023 11:18:23",
            "distinguished": null,
            "edited": false,
            "id": "10x519c",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_10x519c",
            "nsfw": false,
            "num_comments": 10,
            "permalink": "/r/MachineLearning/comments/10x519c/r_pix2pixzero_zeroshot_imagetoimage_translation/",
            "score": 111,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] pix2pixzero - Zero-shot Image-to-Image Translation",
            "upvote_ratio": 0.97,
            "url": "https://arxiv.org/pdf/2302.03027.pdf"
        },
        {
            "author": "u/theanswerisnt42",
            "created_utc": "02-08-2023 05:02:18",
            "distinguished": null,
            "edited": false,
            "id": "10wtumf",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10wtumf",
            "nsfw": false,
            "num_comments": 12,
            "permalink": "/r/MachineLearning/comments/10wtumf/discussion_cognitive_science_inspired_ai_research/",
            "score": 11,
            "selftext": " I came across a few comments on this community about researchers developing AI algorithms inspired by ideas from neuroscience/cognition. I'd like to know how successful this approach has been in terms of coming up with new perspectives on problems.\n\nWhat are some of the key issues researchers are trying to address this way? What are some future directions in which research may progress?\n\nI have a rough idea that this could be one way to inspire sample efficient RL but I'd love to hear about other work that goes on in this area",
            "spoiler": false,
            "stickied": false,
            "title": "[Discussion] Cognitive science inspired AI research",
            "upvote_ratio": 0.84,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10wtumf/discussion_cognitive_science_inspired_ai_research/"
        },
        {
            "author": "u/C_l3b",
            "created_utc": "02-08-2023 02:36:46",
            "distinguished": null,
            "edited": false,
            "id": "10wrlrm",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10wrlrm",
            "nsfw": false,
            "num_comments": 19,
            "permalink": "/r/MachineLearning/comments/10wrlrm/d_list_of_rl_papers/",
            "score": 28,
            "selftext": "Hi, I want to open a thread about RL (non-deep and deep)\n\nWhat are the papers/books that are \"must read\" to have strong foundation?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] List of RL Papers",
            "upvote_ratio": 0.79,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10wrlrm/d_list_of_rl_papers/"
        },
        {
            "author": "u/Dweeberbob",
            "created_utc": "02-07-2023 21:58:51",
            "distinguished": null,
            "edited": false,
            "id": "10wmn7f",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_10wmn7f",
            "nsfw": false,
            "num_comments": 2,
            "permalink": "/r/MachineLearning/comments/10wmn7f/p_scriptsprograms_to_collect_baseline_logs/",
            "score": 2,
            "selftext": "Abit of a weird question. So I'm required to make & collect some clean (baseline) logs and dirty (malicious) logs for some mini-ML project I'm doing. So my question is, is there any scripts or programs out there, Linux or Windows, that allows the automation of mimicking an office staff doing work (ie. opening Outlook, sending emails, surfing the web, watching YouTube, opening and editing Word/Excel files, etc.) for the purpose of collecting baseline logs?\n\nI'm relative new to this kind of thing, if you guys have better suggestion on a more better/efficient way to do this, feel free to suggest!",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Scripts/Programs to collect Baseline Logs",
            "upvote_ratio": 0.67,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10wmn7f/p_scriptsprograms_to_collect_baseline_logs/"
        },
        {
            "author": "u/MLRecipes",
            "created_utc": "02-07-2023 19:27:14",
            "distinguished": null,
            "edited": false,
            "id": "10wjenb",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "News",
            "locked": false,
            "name": "t3_10wjenb",
            "nsfw": false,
            "num_comments": 6,
            "permalink": "/r/MachineLearning/comments/10wjenb/n_new_book_on_synthetic_data_version_30_just/",
            "score": 33,
            "selftext": "The book has considerably grown since version 1.0. It started with synthetic data as one of the main components, but also diving into explainable AI, intuitive / interpretable machine learning, and generative AI. Now with 272 pages (up from 156 in the first version), the focus is clearly on synthetic data. Of course, I still discuss explainable and generative AI: these concepts are strongly related to data synthetization.\n\n[Agent-based modeling in action](https://i.redd.it/snezvohkavga1.gif)\n\nHowever many new chapters have been added, covering various aspects of synthetic data \u2014 in particular working with more diversified real datasets, how to synthetize them, how to generate high quality random numbers with a very fast algorithm based on digits of irrational numbers, with visual illustrations and Python code in all chapters. In addition to agent-based modeling newly added, you will find material about\n\n* GAN \u2014 generative adversarial networks applied using methods other than neural networks.\n* GMM \u2014 Gaussian mixture models and alternatives based on multivariate stochastic and lattice processes.\n* The Hellinger distance and other metrics to measure the quality of your synthetic data, and the limitations of these metrics.\n* The use of copulas with detailed explanations on how it works, Python code, and application to mimicking a real dataset.\n* Drawbacks associated with synthetic data, in particular a tendency to replicate algorithm bias that synthetization is supposed to eliminate (and how to avoid this).\n* A technique somewhat similar to ensemble methods / tree boosting but specific to data synthetization, to further enhance the value of synthetic data when blended with real data; the goal is to make predictions more robust and applicable to a wider range of observations truly different from those in your original training set.\n* Synthetizing nearest neighbor and collision graphs, locally random permutations, shapes, and an introduction to AI-art\n\nNewly added applications include dealing with numerous data types and datasets, including ocean times in Dublin (synthetic time series), temperatures in the Chicago area (geospatial data) and the insurance data set (tabular data). I also included some material from the course that I teach on the subject.\n\nFor the time being, the book is available only in PDF format on my e-Store\u00a0[here](https://mltechniques.com/shop/), with numerous links, backlinks, index, glossary, large bibliography and navigation features to make it easy to browse. This book is a compact yet comprehensive resource on the topic, the first of its kind. The quality of the formatting and color illustrations is unusually high. I plan on adding new books in the future: the next one will be on chaotic dynamical systems with applications. However, the book on synthetic data has been accepted by a major publisher and a print version will be available. But it may take a while before it gets released, and the PDF version has useful features that can not be rendered well in print nor on devices such as Kindle. Once published in the computer science series with the publisher in question, the PDF version may no longer be available. You can check out the content on my GitHub repository,\u00a0[here](https://github.com/VincentGranville/Main/blob/main/MLbook4-extract.pdf)\u00a0where the Python code, sample chapters, and datasets also reside.",
            "spoiler": false,
            "stickied": false,
            "title": "[N] New Book on Synthetic Data\u200b: Version 3.0 Just Released",
            "upvote_ratio": 0.86,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10wjenb/n_new_book_on_synthetic_data_version_30_just/"
        },
        {
            "author": "u/erikaonline",
            "created_utc": "02-07-2023 16:42:58",
            "distinguished": null,
            "edited": false,
            "id": "10wfl8s",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10wfl8s",
            "nsfw": false,
            "num_comments": 4,
            "permalink": "/r/MachineLearning/comments/10wfl8s/discussion_can_an_amd_ryzen_5_3400g_computer_with/",
            "score": 0,
            "selftext": "I'm exploring the possibility of using my AMD Ryzen 5 3400G computer with 16GB of RAM to train an AI model. I'm curious to know if this setup is adequate for the task and, if so, what kind of AI models would be appropriate. I'm interested in understanding any limitations and drawbacks that I may face with this setup. If you have any relevant experience or information, I would greatly appreciate your participation in this discussion. Thanks! <3",
            "spoiler": false,
            "stickied": false,
            "title": "[Discussion] Can an AMD Ryzen 5 3400G computer with 16GB of RAM effectively train an AI model?",
            "upvote_ratio": 0.4,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10wfl8s/discussion_can_an_amd_ryzen_5_3400g_computer_with/"
        },
        {
            "author": "u/Optoplasm",
            "created_utc": "02-07-2023 16:36:38",
            "distinguished": null,
            "edited": false,
            "id": "10wffmg",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10wffmg",
            "nsfw": false,
            "num_comments": 6,
            "permalink": "/r/MachineLearning/comments/10wffmg/d_image_object_detection_but_for_1_dimensional/",
            "score": 0,
            "selftext": "I have had a lot of fun and success using YOLO and other image object detection models on 2D or 3D image data for personal projects.\n\nI am now working on some projects where I need to scan long periods of timeseries data and find specific waveforms that are variable durations. \n\nAre there techniques or models that function like YOLO that can scan large amounts of data and only highlight specific segments of interest as specific classes?\n\nIf it doesn\u2019t exist, I wonder how well the underlying CNN architecture of YOLO would translate to 1 dimensional CNN architectures. \n\nAny info is appreciated, thanks!",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Image object detection, but for 1 dimensional data?",
            "upvote_ratio": 0.5,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10wffmg/d_image_object_detection_but_for_1_dimensional/"
        },
        {
            "author": "u/geomtry",
            "created_utc": "02-07-2023 16:32:03",
            "distinguished": null,
            "edited": false,
            "id": "10wfbf9",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_10wfbf9",
            "nsfw": false,
            "num_comments": 15,
            "permalink": "/r/MachineLearning/comments/10wfbf9/p_best_way_to_add_a_sampling_step_within_a_neural/",
            "score": 2,
            "selftext": "I'm looking to combine two separate models together end-to-end, but need help understanding the best way to connect discrete parts.\n\nThe first part: I trained a classifier that given an input vector (512 dimensional) is able to predict one of twenty possible labels.\n\nThe second part: given an input label (from the previous classifier), embed the label and use that label to make a prediction.\n\nBoth models work decently, but I'm wondering if I can make this end-to-end and get some serious gains.\n\nTo do this, I'd need a way of sampling from the first softmax. Once I have a sample, I can get the embedding of the sampled class, continue as normal, and hopefully propagate the loss through everything.\n\nAre there any similar examples I can look at? Is there a term for this in the literature?",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Best way to add a sampling step within a neural network end-to-end?",
            "upvote_ratio": 0.67,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10wfbf9/p_best_way_to_add_a_sampling_step_within_a_neural/"
        },
        {
            "author": "u/dencan06",
            "created_utc": "02-07-2023 14:06:16",
            "distinguished": null,
            "edited": false,
            "id": "10wbm3q",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10wbm3q",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/10wbm3q/d_can_output_time_frame_cover_input_time_frame_in/",
            "score": 1,
            "selftext": "I recently had a disagreement with a friend and would like to hear other opinions. Say for a website, using the user actions for first week period, we want to predict total sales within 3 weeks. But one of the inputs is sales in the first week, so the output -total sales of 3 weeks- is including the sales in the first week. Is it ok to choose this output? Or should we adjust it in a way to prevent it from overlapping with the input time period and choose for ex. sales within 2 weeks after the first week for output What is the reasoning?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Can output time frame cover input time frame in machine learning?",
            "upvote_ratio": 1.0,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10wbm3q/d_can_output_time_frame_cover_input_time_frame_in/"
        },
        {
            "author": "u/currentscurrents",
            "created_utc": "02-07-2023 12:38:27",
            "distinguished": null,
            "edited": false,
            "id": "10w9en2",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "News",
            "locked": false,
            "name": "t3_10w9en2",
            "nsfw": false,
            "num_comments": 22,
            "permalink": "/r/MachineLearning/comments/10w9en2/n_microsoft_announces_new_nextgeneration_llm_will/",
            "score": 97,
            "selftext": "https://www.theverge.com/2023/2/7/23587454/microsoft-bing-edge-chatgpt-ai",
            "spoiler": false,
            "stickied": false,
            "title": "[N] Microsoft announces new \"next-generation\" LLM, will be integrated with Bing and Edge",
            "upvote_ratio": 0.95,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10w9en2/n_microsoft_announces_new_nextgeneration_llm_will/"
        },
        {
            "author": "u/wonderingandthinking",
            "created_utc": "02-07-2023 12:37:33",
            "distinguished": null,
            "edited": false,
            "id": "10w9dsz",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10w9dsz",
            "nsfw": false,
            "num_comments": 12,
            "permalink": "/r/MachineLearning/comments/10w9dsz/discussion_is_chatgpt_andor_openai_really_the/",
            "score": 0,
            "selftext": "Or is it someone else (who just may or may not be as well known)?",
            "spoiler": false,
            "stickied": false,
            "title": "[Discussion] Is ChatGPT and/or OpenAI really the leader in the space?",
            "upvote_ratio": 0.46,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10w9dsz/discussion_is_chatgpt_andor_openai_really_the/"
        },
        {
            "author": "u/hopedallas",
            "created_utc": "02-07-2023 11:38:54",
            "distinguished": null,
            "edited": false,
            "id": "10w7vkz",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10w7vkz",
            "nsfw": false,
            "num_comments": 5,
            "permalink": "/r/MachineLearning/comments/10w7vkz/d_multiclass_classifications_when_a_few_of_the/",
            "score": 2,
            "selftext": "I am dealing with a multi-class  classification problem. I know one of the main assumption of this problem is that the classes are mutually exclusive. However, I realized that in my problem,  some of these classes may happen together. So my problem is not an entirely a milt-class  nor a multi-label. One solution is to relax the exclusivity assumption and fit a model, however, I am not sure how realistic is that. I was wondering if there is a better way to approach this problem? Briefly, the problem is in ads domain where a user can do task A or B after seeing an ad or can do both A&B at the same time.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Multi-class classifications when a few of the classes are not mutually-exclusive",
            "upvote_ratio": 0.75,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10w7vkz/d_multiclass_classifications_when_a_few_of_the/"
        },
        {
            "author": "u/akshaysri0001",
            "created_utc": "02-07-2023 11:15:31",
            "distinguished": null,
            "edited": false,
            "id": "10w79eo",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10w79eo",
            "nsfw": false,
            "num_comments": 11,
            "permalink": "/r/MachineLearning/comments/10w79eo/d_which_is_the_fastest_and_lightweight_ultra/",
            "score": 10,
            "selftext": "Hey everyone, I want to make a personal voice assistant who sounds exactly like a real person. I tried some TTS like tortoise TTS and coqui TTS, it done a good job but it takes too long time to perform. So is there any other good realistic sounding TTS which I can use with my own voice cloning training dataset? Also I'm a bit amazed by the TTS used by eleven labs, so can someone explain how can I achieve that level of real-time efficiency in a voice assistant?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Which is the fastest and lightweight ultra realistic TTS for real-time voice cloning?",
            "upvote_ratio": 0.92,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10w79eo/d_which_is_the_fastest_and_lightweight_ultra/"
        },
        {
            "author": "u/Much-Bit3531",
            "created_utc": "02-07-2023 10:53:33",
            "distinguished": null,
            "edited": false,
            "id": "10w6p1f",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10w6p1f",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/10w6p1f/d_artificial_intelligence_for_manufacturing/",
            "score": 0,
            "selftext": "Manufacturing 4.0 is undergoing a revolution with the integration of Artificial Intelligence (AI). AI is poised to revolutionize the process industry, where controlling input variables leads to an output. The current process industry, including pharmaceuticals, chemicals, and energy production, relies on human operators to turn knobs to achieve optimal output. However, this system is limited by several factors, including slow training, poor retention of large data sets, inaccurate sensors, and complex decision-making processes.    \n\n&#x200B;\n\nhttps://preview.redd.it/y6stc52zqsga1.png?width=734&format=png&auto=webp&v=enabled&s=356e4829e8dd50754858326c5212b4da8a2c7565\n\nHere are some details about problems and AI solutions:    \n\n1) It takes forever to train this employee.  This employee is running little mini experiments and getting coached by other employees and engineers along the way.  So the quality of training per year is variable.  AI eliminates this problem by retaining the results of the mini experience in its models.  Now everyone has access to how the process behaves.    \n\n2) The numbers of KPIs can be huge and not all KPIs are linear.  Humans are notoriously bad at retaining large data sets with multiple variables.  Humans delete, distort and generalize data so we can come up with easier to follow rules of thumb.  Machine are not limited by this.  In AI, the more data the more way combined the better.  The models can evolve as new data comes in.    \n\n3) The automatic sensors are many times are precise but not accurate.  This can happen because the sensors get off calibration or the calibration is dependent on other variables in the process.  Operators usually use manual measurements that are very accurate but not precise to know where the process actually is.  This manual measurement can be used the calibrate the sensors but, it seen as a losing battle.  AI can use that data to continuously update the calibration of the sensors and add calibrations for other input variables such as Ph, flow rate, or temperature.  When this is done the you can trust the sensors.   \n\n4) Many process decisions require if then statements.  These if then statements change by the product that is being run making it extremely complicated.  AI systems can automatically update the if then statements by how previous runs behave.  They can learn from expert operators to learn new conditions.  These learning and be presented to the operator as a suggesting on how the run the process.  For well defined processes, the process will benefit from making the changes faster.  These faster changes will improve the overall cost of manufacturing.    \n\nIn conclusion, AI is set to revolutionize the process industry by addressing its limitations and providing faster, more accurate, and cost-effective solutions. By harnessing the power of AI, the process industry is poised for a bright future.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Artificial Intelligence for Manufacturing",
            "upvote_ratio": 0.5,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10w6p1f/d_artificial_intelligence_for_manufacturing/"
        },
        {
            "author": "u/vadhavaniyafaijan",
            "created_utc": "02-07-2023 10:43:45",
            "distinguished": null,
            "edited": false,
            "id": "10w6g7n",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "News",
            "locked": false,
            "name": "t3_10w6g7n",
            "nsfw": false,
            "num_comments": 324,
            "permalink": "/r/MachineLearning/comments/10w6g7n/n_getty_images_claims_stable_diffusion_has_stolen/",
            "score": 654,
            "selftext": "From [Article](https://www.theinsaneapp.com/2023/02/getty-images-stable-diffusion.html):\n\nGetty Images new lawsuit claims that Stability AI, the company behind Stable Diffusion's AI image generator, stole 12 million Getty images with their captions, metadata, and copyrights \"without permission\" to \"train its Stable Diffusion algorithm.\"\n\nThe company has asked the court to order Stability AI to remove violating images from its website and pay $150,000 for each. \n\nHowever, it would be difficult to prove all the violations. Getty submitted over 7,000 images, metadata, and copyright registration, used by Stable Diffusion.",
            "spoiler": false,
            "stickied": false,
            "title": "[N] Getty Images Claims Stable Diffusion Has Stolen 12 Million Copyrighted Images, Demands $150,000 For Each Image",
            "upvote_ratio": 0.96,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10w6g7n/n_getty_images_claims_stable_diffusion_has_stolen/"
        },
        {
            "author": "u/cobalt1137",
            "created_utc": "02-07-2023 10:41:32",
            "distinguished": null,
            "edited": false,
            "id": "10w6e99",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10w6e99",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/10w6e99/d_question_on_first_time_training_a_model/",
            "score": 1,
            "selftext": "Basically I saw a stream the other day where someone used data from a person's YouTube channel and somehow used this data to create an AI version of them and interviewed them. It was fascinating and pretty accurate\n\nHow difficult would this be to do myself? I don't even know where to start. Does anyone have any pointers? Is this a very large task that I'm underestimating or is it actually feasible?\n\nHere is the stream in question. The video and audio would be cool to have but I mean that's not necessary, even just having the text aspect would be pretty wild on its own. https://youtu.be/hjoYy5IVtfo (skip to any point, most of it is filled with the bot responding)",
            "spoiler": false,
            "stickied": false,
            "title": "[D] question on first time training a model",
            "upvote_ratio": 0.67,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10w6e99/d_question_on_first_time_training_a_model/"
        },
        {
            "author": "u/EmbarrassedFuel",
            "created_utc": "02-07-2023 10:02:16",
            "distinguished": null,
            "edited": false,
            "id": "10w5f9u",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10w5f9u",
            "nsfw": false,
            "num_comments": 9,
            "permalink": "/r/MachineLearning/comments/10w5f9u/modelpaper_ideas_reinforcement_learning_with_a/",
            "score": 2,
            "selftext": "I have a problem I need to solve that, as far as I can tell, doesn't fit very well into most of the existing RL literature.\n\nEssentially the task is to create on optimal plan over a time horizon extending a flexible number of steps into the future. The action space is both discrete and continuous - there are multiple available distinct actions, some of which need to be given continuous (but constrained) parameters.\n\nIn this problem however, the state of the environment is known ahead of time for all the future time steps, and the updated state of the agent after each action can be calculated deterministically given the action and the environment state.\n\nModelling the entire problem as a MILP is not feasible due to the size of the action and state space, and we have a very large data set for agent and environment state to play with. Does anyone have any suggestions for papers or models that might be appropriate for this scenario?",
            "spoiler": false,
            "stickied": false,
            "title": "Model/paper ideas: reinforcement learning with a deterministic environment [D]",
            "upvote_ratio": 1.0,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10w5f9u/modelpaper_ideas_reinforcement_learning_with_a/"
        },
        {
            "author": "u/Lukas_Zahradnik",
            "created_utc": "02-07-2023 09:36:44",
            "distinguished": null,
            "edited": false,
            "id": "10w4ssp",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "News",
            "locked": false,
            "name": "t3_10w4ssp",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/10w4ssp/n_beyond_transformers_with_pyneuralogic/",
            "score": 9,
            "selftext": "Going beyond Transformers? \ud83e\udd16  \n\n\nIn this article, I'm discussing how we can use the power of hybrid architecture, i.e., marrying deep learning with symbolic artificial intelligence, for implementing different kinds of Transformers. Including the one used in GPT-3!\n\n[https://towardsdatascience.com/beyond-transformers-with-pyneuralogic-10b70cdc5e45](https://towardsdatascience.com/beyond-transformers-with-pyneuralogic-10b70cdc5e45)\n\n&#x200B;\n\n&#x200B;\n\n[The attention computation graph visualized](https://preview.redd.it/z0ll6m69dsga1.png?width=1400&format=png&auto=webp&v=enabled&s=df7113cdeadf8a71a81cebfc9196b19224e5f704)",
            "spoiler": false,
            "stickied": false,
            "title": "[N] Beyond Transformers with PyNeuraLogic",
            "upvote_ratio": 0.85,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10w4ssp/n_beyond_transformers_with_pyneuralogic/"
        },
        {
            "author": "u/Illustrious-Law-2556",
            "created_utc": "02-07-2023 05:12:12",
            "distinguished": null,
            "edited": false,
            "id": "10vzb0u",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10vzb0u",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/10vzb0u/d_name_your_favourite_github_repositories_for/",
            "score": 2,
            "selftext": "I thought it may be useful to gather the most popular repositories for data scientists. The goal is to read excellent code and learn from other projects.\n\nPlease provide a short description of the project.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Name your favourite Github repositories for data scientists",
            "upvote_ratio": 0.59,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10vzb0u/d_name_your_favourite_github_repositories_for/"
        },
        {
            "author": "u/ramv0001",
            "created_utc": "02-07-2023 04:51:44",
            "distinguished": null,
            "edited": false,
            "id": "10vyytq",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10vyytq",
            "nsfw": false,
            "num_comments": 6,
            "permalink": "/r/MachineLearning/comments/10vyytq/discussion_best_practices_for_taking_deep/",
            "score": 7,
            "selftext": "I would like to know what are some of the best practice is to convert pytorch to embedded C (bare metal micro-controllers) during A. initial phase and B. for deployment.\n\nA. Initial phase is to understand the profiling of the model performance (RAM usage and processing time) for a targetted hardware.\n\nI understand that Tensorflow lite might be the best route for initial profiling but there are restrictions. It will be great if you could tell the framework that you follow. Currently framework: 1. Pytorch -> 2. ONNX -> 3. Keras -> 4. Tensorflowlite or 5. Tensorflowlite micro\n\nB. Deployment is to run inference for production in a targetted hardware. I think hand coding in C is the best way.\n\nPlease ignore optimisation techniques in the workflow for simplicity.",
            "spoiler": false,
            "stickied": false,
            "title": "[Discussion] Best practices for taking deep learning models to bare metal MCUs",
            "upvote_ratio": 0.89,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10vyytq/discussion_best_practices_for_taking_deep/"
        },
        {
            "author": "u/dreternal",
            "created_utc": "02-07-2023 04:46:07",
            "distinguished": null,
            "edited": false,
            "id": "10vyvne",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10vyvne",
            "nsfw": false,
            "num_comments": 7,
            "permalink": "/r/MachineLearning/comments/10vyvne/d_a_mlpowered_music_descriptiontag_generator_a/",
            "score": 1,
            "selftext": "I know there are no useful text-to-music generators (YET), but is there at least a model where you can upload/input a recording and get a text description/hashtag list from it? Like a reverse MusicML?\n\nI have a very large personal catalog of music I am prepping for sale (approaching 500 songs), and this would be a very handy tool, especially if it came up with tags of genres/similar artists I am not aware of.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] A ML-powered music description/tag generator? (a reverse-MusicML)?",
            "upvote_ratio": 0.6,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10vyvne/d_a_mlpowered_music_descriptiontag_generator_a/"
        },
        {
            "author": "u/_Arsenie_Boca_",
            "created_utc": "02-07-2023 02:16:24",
            "distinguished": null,
            "edited": false,
            "id": "10vwm8k",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10vwm8k",
            "nsfw": false,
            "num_comments": 10,
            "permalink": "/r/MachineLearning/comments/10vwm8k/d_papers_that_inject_embeddings_into_lms/",
            "score": 10,
            "selftext": "I am looking for papers that inject information into LMs directly using embeddings (without formatting information as text). I find it notoriously hard to search for these paper because they could come from various different domains, so I thought asking here might be a good option to reach people from many different domains.\n\nSome examples I already found are from the domain of knowledge graph augmented LMs:\nERNIE https://arxiv.org/abs/1904.09223\nK-BERT https://arxiv.org/abs/1909.07606\n\nPrefix Tuning / Prompt Tuning are also somewhat similar to the idea, but they dont depend on any external information.\n\nCan you think of other papers that inject additional information into LMs via embeddings?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Papers that inject embeddings into LMs",
            "upvote_ratio": 0.92,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10vwm8k/d_papers_that_inject_embeddings_into_lms/"
        },
        {
            "author": "u/cchad-8",
            "created_utc": "02-07-2023 00:53:20",
            "distinguished": null,
            "edited": false,
            "id": "10vv9mk",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_10vv9mk",
            "nsfw": false,
            "num_comments": 2,
            "permalink": "/r/MachineLearning/comments/10vv9mk/p_pythae_010_is_out_and_supports_distributed/",
            "score": 10,
            "selftext": "\ud83d\udce2 News \ud83d\udce2\n\nPythae 0.1.0 is now out and supports distributed training using PyTorch DDP !\n\nTrain your favorite Variational Autoencoders (VAEs) faster \ud83c\udfce\ufe0f and on larger datasets, still with a few lines of code \ud83d\udda5\ufe0f.\n\n\ud83d\udc49github: [https://github.com/clementchadebec/benchmark\\_VAE](https://github.com/clementchadebec/benchmark_VAE)\n\n\ud83d\udc49pypi: [https://pypi.org/project/pythae/](https://pypi.org/project/pythae/)\n\nhttps://preview.redd.it/jk4ukkgarpga1.png?width=1335&format=png&auto=webp&v=enabled&s=87e479d2f320eb4ea352bc984cb001c46e351b91",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Pythae 0.1.0 is out and supports distributed training for 25 Variational Autoencoders",
            "upvote_ratio": 0.86,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10vv9mk/p_pythae_010_is_out_and_supports_distributed/"
        },
        {
            "author": "u/AttentionIsAllYouGet",
            "created_utc": "02-07-2023 00:53:00",
            "distinguished": null,
            "edited": false,
            "id": "10vv9f4",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10vv9f4",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/10vv9f4/d_selecting_a_stable_set_of_hyperparameters/",
            "score": 2,
            "selftext": "To provide some motivation for the problem: say I have a model (can be as simple as OLS for the sake of the argument) with m impulse response-like functions as features, each of which has n hyperparameters, so that's mxn hyperparameters in total (in an actual usecase mxn is somewhere around 100). These hyperparameters are selected using an optimization procedure (can be as simple as random search for the sake of the argument) with respect to some metric (e.g. RMSE).\n\nNow, the problem is: highly different sets of hyperparameters (yielding highly different shapes of impulse response functions) may yield about the same accuracy metric, so they are equivalent from optimizer's standpoint. This is problematic because the goal of the model, besides getting high accuracy, is to get a set of interpretable impulse response functions, where the shape matters a lot from business standpoint.\n\nWhat I'm insterested in is ensuring that the result is \"stable\", i.e. it is not an outlier in the hyperparameter space. Imagine two regions in hyperparameter space which yield the same accuracy but one of them is really small and the other is really large, then I will naturally prefer a set of hyperparameters from the large region based on the premise that it is more natural for the system to arrive at a result there.\n\nWhat I've been doing so far is taking the results of optimization procedure - the list of iterations it performed, i.e. pairs {hyperparameters set: accuracy metric}, selecting only those with acceptable accuracy, and from them selecting a result in the densest region (e.g. estimating maximum multivariate density and choosing the closest result).\n\nMy question is: does this approarch sound reasonable? What are the potential pitfalls? Maybe my whole train of thought is completely wrong and there is already an established way of dealing with problems like this? Any relevant input is appreciated!",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Selecting a \"stable\" set of hyperparameters",
            "upvote_ratio": 1.0,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10vv9f4/d_selecting_a_stable_set_of_hyperparameters/"
        },
        {
            "author": "u/thedarklord176",
            "created_utc": "02-06-2023 21:14:44",
            "distinguished": null,
            "edited": false,
            "id": "10vqxtp",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10vqxtp",
            "nsfw": false,
            "num_comments": 20,
            "permalink": "/r/MachineLearning/comments/10vqxtp/wouldnt_it_be_a_good_idea_to_bring_a_more_energy/",
            "score": 0,
            "selftext": "I know Python is the primary choice because it\u2019s a simpler language for data scientists to use and a lot of ML libraries are made for Python. But, if you look at [this](https://thenewstack.io/which-programming-languages-use-the-least-electricity/), it is extremely inefficient with energy. And everyone knows big models like ChatGPT cost a ton to keep running. Maybe a more efficient but not too difficult language, like C#, is something we should consider giving more attention in ML?",
            "spoiler": false,
            "stickied": false,
            "title": "Wouldn\u2019t it be a good idea to bring a more energy efficient language into the ML world to reduce the insane costs a bit?[D]",
            "upvote_ratio": 0.19,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10vqxtp/wouldnt_it_be_a_good_idea_to_bring_a_more_energy/"
        },
        {
            "author": "u/CORNMONSTER_2022",
            "created_utc": "02-06-2023 19:20:14",
            "distinguished": null,
            "edited": false,
            "id": "10vobw8",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10vobw8",
            "nsfw": false,
            "num_comments": 4,
            "permalink": "/r/MachineLearning/comments/10vobw8/d_is_it_possible_to_serve_an_facebookoptiml13b/",
            "score": 0,
            "selftext": "Hey everyone, I'm looking to fine-tune an [opt-iml-1.3b](https://huggingface.co/facebook/opt-iml-1.3b) model and run it locally. I'm not sure about the hardware requirements. \n\nWould 2 3090Ti GPUs connected with NVLink be enough for fine-tuning and serving the model? And how about a single 4090?\n\nThanks for your help in advance!",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Is it possible to serve an facebook/opt-iml-1.3b locally?",
            "upvote_ratio": 0.4,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10vobw8/d_is_it_possible_to_serve_an_facebookoptiml13b/"
        },
        {
            "author": "u/aicharades",
            "created_utc": "02-06-2023 18:46:50",
            "distinguished": null,
            "edited": false,
            "id": "10vnkj8",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_10vnkj8",
            "nsfw": false,
            "num_comments": 40,
            "permalink": "/r/MachineLearning/comments/10vnkj8/p_chatgpt_without_size_limits_upload_any_pdf_and/",
            "score": 56,
            "selftext": "hi all! I created a simple free tool where you can summarize and query documents of any size and estimate the cost to do so: [https://www.wrotescan.com](https://www.wrotescan.com/)\n\nYou can edit the prompts as well as automatically chunk and combine documents. There's also a cost estimator for any pdf you upload.\n\nLet me know if you want me to run some examples for you! Send me a pdf and tell me what you'd like summarized or extracted.\n\n***Tips***\n\nPlease be sure to keep *{text}* in both prompts or the program will not input your document's text into the map reduce summarizer.  *{text}* can only appear once in each prompt. It is where the text from each chunk to be summarized is input into the prompts.\n\nCreate a temporary OpenAI key / org to use with this site so you do not have to provide credit card information then be sure to delete the temp key when you are done.\n\n***Learnings***\n\nSome interesting learnings I had while creating the tool:\n\n\\- Minimizing the number of steps through the AI improved summarization, so map reduce was often better than a more advanced refine workflow which passes the output through the model many more times.\n\n\\- LangChain is great for managing multiple step language model calls and bypassing the current limitations of ChatGPT",
            "spoiler": false,
            "stickied": false,
            "title": "[P] ChatGPT without size limits: upload any pdf and apply any prompt to it",
            "upvote_ratio": 0.76,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10vnkj8/p_chatgpt_without_size_limits_upload_any_pdf_and/"
        },
        {
            "author": "u/VR_Angel",
            "created_utc": "02-06-2023 15:39:40",
            "distinguished": null,
            "edited": false,
            "id": "10vj1az",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_10vj1az",
            "nsfw": false,
            "num_comments": 9,
            "permalink": "/r/MachineLearning/comments/10vj1az/project_i_used_a_new_ml_algo_called_animesr_to/",
            "score": 125,
            "selftext": "It took me about 46 hours to run this on my 3080 at home. The original files was from the Blu-ray release that was unfortunately pretty poorly done in my opinion. This version really gives it new life I think.\n\nHere's a link to the video result to see for yourself:\n\n[https://vimeo.com/796411232](https://vimeo.com/796411232)\n\nAnd a link to the model I used!\n\n[https://github.com/TencentARC/AnimeSR](https://github.com/TencentARC/AnimeSR)",
            "spoiler": false,
            "stickied": false,
            "title": "[Project] I used a new ML algo called \"AnimeSR\" to restore the Cowboy Bebop movie and up rez it to full 4K. Here's a link to the end result - honestly think it looks amazing! (Video and Model link in post)",
            "upvote_ratio": 0.94,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10vj1az/project_i_used_a_new_ml_algo_called_animesr_to/"
        },
        {
            "author": "u/SnuggleWuggleSleep",
            "created_utc": "02-06-2023 14:17:06",
            "distinguished": null,
            "edited": false,
            "id": "10vgw7s",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10vgw7s",
            "nsfw": false,
            "num_comments": 9,
            "permalink": "/r/MachineLearning/comments/10vgw7s/d_what_techniques_can_i_use_to_tell_if_a_problem/",
            "score": 1,
            "selftext": "I have a problem that if I solve it with ML, I'll make money, with an outside chance of it being a lot of money.  Compiling a dataset will take significant work.\n\nAre there any techniques that I can apply to let me know if this is going to be worth it?  Perhaps there are certain hallmarks that a problem would have if it is likely to be solvable with available data?  Maybe something I can do with a small initial dataset?\n\nThanks.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] What techniques can I use to tell if a problem is likely enough to be solved by ML so as to justify compiling the dataset?",
            "upvote_ratio": 0.54,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10vgw7s/d_what_techniques_can_i_use_to_tell_if_a_problem/"
        },
        {
            "author": "u/EducationalCicada",
            "created_utc": "02-06-2023 14:12:13",
            "distinguished": null,
            "edited": false,
            "id": "10vgrff",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "News",
            "locked": false,
            "name": "t3_10vgrff",
            "nsfw": false,
            "num_comments": 167,
            "permalink": "/r/MachineLearning/comments/10vgrff/n_google_an_important_next_step_on_our_ai_journey/",
            "score": 322,
            "selftext": "[https://blog.google/technology/ai/bard-google-ai-search-updates/](https://blog.google/technology/ai/bard-google-ai-search-updates/)",
            "spoiler": false,
            "stickied": false,
            "title": "[N] Google: An Important Next Step On Our AI Journey",
            "upvote_ratio": 0.95,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10vgrff/n_google_an_important_next_step_on_our_ai_journey/"
        },
        {
            "author": "u/Wiskkey",
            "created_utc": "02-06-2023 13:53:36",
            "distinguished": null,
            "edited": false,
            "id": "10vg97m",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "News",
            "locked": false,
            "name": "t3_10vg97m",
            "nsfw": false,
            "num_comments": 71,
            "permalink": "/r/MachineLearning/comments/10vg97m/n_getty_images_sues_ai_art_generator_stable/",
            "score": 120,
            "selftext": "From [the article](https://www.theverge.com/2023/2/6/23587393/ai-art-copyright-lawsuit-getty-images-stable-diffusion):\n\n>Getty Images has filed a lawsuit in the US against Stability AI, creators of open-source AI art generator Stable Diffusion, escalating its legal battle against the firm.  \n>  \n>The stock photography company is accusing Stability AI of \u201cbrazen infringement of Getty Images\u2019 intellectual property on a staggering scale.\u201d It claims that Stability AI copied more than 12 million images from its database \u201cwithout permission ... or compensation ... as part of its efforts to build a competing business,\u201d and that the startup has infringed on both the company\u2019s copyright and trademark protections.\n\nThis is different from [the UK-based news from weeks ago](https://www.theverge.com/2023/1/17/23558516/ai-art-copyright-stable-diffusion-getty-images-lawsuit).",
            "spoiler": false,
            "stickied": false,
            "title": "[N] Getty Images sues AI art generator Stable Diffusion in the US for copyright infringement",
            "upvote_ratio": 0.96,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10vg97m/n_getty_images_sues_ai_art_generator_stable/"
        },
        {
            "author": "u/Frumpagumpus",
            "created_utc": "02-06-2023 11:02:38",
            "distinguished": null,
            "edited": false,
            "id": "10vbrgg",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10vbrgg",
            "nsfw": false,
            "num_comments": 18,
            "permalink": "/r/MachineLearning/comments/10vbrgg/does_the_high_dimensionality_of_ai_systems_that/",
            "score": 0,
            "selftext": "Physical world we live in has 4 dimensions, string theory posits like up to 10. It seems like in order to successfully model the abstract space of ideas which relates things in the physical world to each other and describes them, machine learning needs thousands of dimensions. Also to the extent that ML algos/matrices can be made sparse, that seems to me to tell us something about the density of the mapping between abstract space and physical space... anyone know any papers w/this line of thinking?\n\nIt also seems a bit unintuitive to me because it seems like geometrically space gets exponentially more complicated as you add dimensions but ML scales linearly or better in many cases with matrix dimensionality.",
            "spoiler": false,
            "stickied": false,
            "title": "Does the high dimensionality of AI systems that model the real world tell us something about the abstract space of ideas? [D]",
            "upvote_ratio": 0.5,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10vbrgg/does_the_high_dimensionality_of_ai_systems_that/"
        },
        {
            "author": "u/daansan-ml",
            "created_utc": "02-06-2023 09:34:38",
            "distinguished": null,
            "edited": "02-06-2023 10:23:20",
            "id": "10v9j5l",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_10v9j5l",
            "nsfw": false,
            "num_comments": 2,
            "permalink": "/r/MachineLearning/comments/10v9j5l/p_forecasting_methods_in_time_series/",
            "score": 7,
            "selftext": "Hi all! \n\nFor the longest time, I was having issues understanding how to use time series to do forecasting. \n\nOver the last few weeks, I have been writing a series of posts to guide anyone through the process! \n\nI am also in the process of writing a detailed **practical guide** with **step-by-step** instructions.\n\n&#x200B;\n\nRight now I have 6 articles on the topic:\n\n\\* Introduction to ARIMA models ([https://mlpills.dev/time-series/introduction-to-arima-models/](https://mlpills.dev/time-series/introduction-to-arima-models/))\n\n\\* Parameters selection in ARIMA models ([https://mlpills.dev/time-series/parameters-selection-in-arima-models/](https://mlpills.dev/time-series/parameters-selection-in-arima-models/))\n\n\\* Seasonal ARIMA ([https://mlpills.dev/time-series/seasonal-arima/](https://mlpills.dev/time-series/seasonal-arima/))\n\n\\* ARCH / GARCH models for Time Series ([https://mlpills.dev/time-series/arch-garch-models-for-time-series/](https://mlpills.dev/time-series/arch-garch-models-for-time-series/))\n\n\\* ARIMA-GARCH models ([https://mlpills.dev/time-series/arima-garch-models/](https://mlpills.dev/time-series/arima-garch-models/))\n\n\\* And today's -> Forecasting in Time Series ([https://mlpills.dev/time-series/forecasting-in-time-series/](https://mlpills.dev/time-series/forecasting-in-time-series/))\n\nLet me know if there are any topics that you would like me to cover in the future!",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Forecasting methods in Time Series",
            "upvote_ratio": 0.67,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10v9j5l/p_forecasting_methods_in_time_series/"
        },
        {
            "author": "u/AugusteDupin",
            "created_utc": "02-06-2023 07:41:48",
            "distinguished": null,
            "edited": false,
            "id": "10v6w9t",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10v6w9t",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/10v6w9t/d_comic_book_reader_with_speech_balloon_zooming/",
            "score": 0,
            "selftext": "Hey everyone. \n\nI want to create an app that can read comic books (.cbr), scroll through pages and can zoom in to the Speech Balloon like the android app [Seeneva](https://github.com/Seeneva/seeneva-reader-android#speech-balloons-zooming). Do you know if or how to do this?\n\nMy abilities: I'm decent with python and have already completed Andrew Ng's course on ml.\n\nThanks",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Comic book reader with speech balloon zooming",
            "upvote_ratio": 0.33,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10v6w9t/d_comic_book_reader_with_speech_balloon_zooming/"
        },
        {
            "author": "u/astronaut1971",
            "created_utc": "02-06-2023 07:39:55",
            "distinguished": null,
            "edited": false,
            "id": "10v6urh",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10v6urh",
            "nsfw": false,
            "num_comments": 2,
            "permalink": "/r/MachineLearning/comments/10v6urh/which_strategiesframework_and_applications_tools/",
            "score": 0,
            "selftext": "\n\nMachine LearningModels when deployed in the production environment, model degradation can arise where their output will change if the relationship between the incoming serving data and the predicted target drifts apart.\n\nPlease can someone briefly elaborate on what strategies, frameworks and application tools can be implemented to automatically monitor the health of the model and alert the Data Scientist of any decay in data quality,  data drift, and model quality?",
            "spoiler": false,
            "stickied": false,
            "title": "Which strategies,framework and applications tools can be implement to automatically monitor the health of the machine learning model? [D]",
            "upvote_ratio": 0.4,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10v6urh/which_strategiesframework_and_applications_tools/"
        },
        {
            "author": "u/momegas",
            "created_utc": "02-06-2023 04:06:47",
            "distinguished": null,
            "edited": false,
            "id": "10v31h4",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_10v31h4",
            "nsfw": true,
            "num_comments": 3,
            "permalink": "/r/MachineLearning/comments/10v31h4/p_we_made_an_open_source_platform_for_machine/",
            "score": 0,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[P] We made an open source platform for machine learning and data monitoring",
            "upvote_ratio": 0.31,
            "url": "https://www.reddit.com/gallery/10v31h4"
        },
        {
            "author": "u/metover",
            "created_utc": "02-06-2023 03:56:24",
            "distinguished": null,
            "edited": false,
            "id": "10v2vmo",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_10v2vmo",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/10v2vmo/p_i_made_image_clustering_and_captioning_tools/",
            "score": 5,
            "selftext": "I made an image captioning and clustering tools for computer vision and diffusion projects. \n\nYou can run almost everything automatically and with a simple CLI command. All contributions are welcome.\n\n[https://github.com/cobanov/image-clustering](https://github.com/cobanov/image-clustering)\n\n[https://github.com/cobanov/image-captioning](https://github.com/cobanov/image-captioning)",
            "spoiler": false,
            "stickied": false,
            "title": "[P] I made image clustering and captioning tools",
            "upvote_ratio": 0.86,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10v2vmo/p_i_made_image_clustering_and_captioning_tools/"
        },
        {
            "author": "u/A15L",
            "created_utc": "02-06-2023 01:53:41",
            "distinguished": null,
            "edited": false,
            "id": "10v12fn",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_10v12fn",
            "nsfw": false,
            "num_comments": 7,
            "permalink": "/r/MachineLearning/comments/10v12fn/highspeed_cameras_and_deep_learning_research/",
            "score": 4,
            "selftext": "I haven\u2019t been able to find research on deep learning using high-speed cameras that capture images at frame rates higher than 250fps. I wonder if they are rather useless for image/video processing or do any of you have any ideas about potential applications.",
            "spoiler": false,
            "stickied": false,
            "title": "High-speed cameras and deep learning [Research]",
            "upvote_ratio": 0.83,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10v12fn/highspeed_cameras_and_deep_learning_research/"
        },
        {
            "author": "u/moschles",
            "created_utc": "02-06-2023 01:26:08",
            "distinguished": null,
            "edited": false,
            "id": "10v0nkm",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_10v0nkm",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/10v0nkm/r_research_trends_in_graph_neural_networks_gnn/",
            "score": 21,
            "selftext": "Deep connections discovered between Graph Diffusion Networks and Partial Differential Equations modelling heat transfer.  \n\n+ https://towardsdatascience.com/graph-neural-networks-as-neural-diffusion-pdes-8571b8c0c774\n\n+ https://arxiv.org/abs/2106.10934\n\n\nStrange connections uncovered between GNNs and Structural Causal Models. \n\n+ https://arxiv.org/abs/2109.04173\n\n+ https://www.youtube.com/watch?v=XC-Bfg3dO0I\n\n\nGNNs used to  enhance the factualness  of LLMs  by providing embeddings from Knowledge Graphs (KEs).  \n\n+ https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00360/98089\n\nGNNs used to categorize objects from only their 3D mesh.  \n\n+ https://arxiv.org/pdf/2106.15778.pdf \n\n\nPrediction of intuitive physics among physical objects.  \n\n+ https://proceedings.neurips.cc/paper/2016/hash/3147da8ab4a0437c15ef51a5cc7f2dc4-Abstract.html\n\n\nZero-shot generalization in robot Task Planning.  \n\n+ https://arxiv.org/abs/2102.13177 \n\n+ https://www.youtube.com/watch?v=POxaTDAj7aY",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Research trends in Graph Neural Networks (GNN)",
            "upvote_ratio": 0.9,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10v0nkm/r_research_trends_in_graph_neural_networks_gnn/"
        },
        {
            "author": "u/GaylordTurner",
            "created_utc": "02-05-2023 23:25:36",
            "distinguished": null,
            "edited": false,
            "id": "10uyltw",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_10uyltw",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/10uyltw/p_i_made_a_browser_extension_that_remove_link/",
            "score": 0,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[P] I made a browser extension that remove link Google Search Console",
            "upvote_ratio": 0.27,
            "url": "https://v.redd.it/vwhxja5b7iga1"
        },
        {
            "author": "u/starstruckmon",
            "created_utc": "02-05-2023 22:22:21",
            "distinguished": null,
            "edited": false,
            "id": "10uxfhx",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_10uxfhx",
            "nsfw": false,
            "num_comments": 4,
            "permalink": "/r/MachineLearning/comments/10uxfhx/r_creating_a_large_language_model_of_a_philosopher/",
            "score": 34,
            "selftext": "Paper : https://arxiv.org/abs/2302.01339\n\nAbstract :\n\n>Can large language models be trained to produce philosophical texts that are difficult to distinguish from texts produced by human philosophers? To address this question, we fine-tuned OpenAI's GPT-3 with the works of philosopher Daniel C. Dennett as additional training data. To explore the Dennett model, we asked the real Dennett ten philosophical questions and then posed the same questions to the language model, collecting four responses for each question without cherry-picking. We recruited 425 participants to distinguish Dennett's answer from the four machine-generated answers. Experts on Dennett's work (N = 25) succeeded 51% of the time, above the chance rate of 20% but short of our hypothesized rate of 80% correct. For two of the ten questions, the language model produced at least one answer that experts selected more frequently than Dennett's own answer. Philosophy blog readers (N = 302) performed similarly to the experts, while ordinary research participants (N = 98) were near chance distinguishing GPT-3's responses from those of an \"actual human philosopher\".",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Creating a Large Language Model of a Philosopher",
            "upvote_ratio": 0.8,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10uxfhx/r_creating_a_large_language_model_of_a_philosopher/"
        },
        {
            "author": "u/supersoldierboy94",
            "created_utc": "02-05-2023 21:22:33",
            "distinguished": null,
            "edited": "02-06-2023 03:21:08",
            "id": "10uw974",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10uw974",
            "nsfw": false,
            "num_comments": 67,
            "permalink": "/r/MachineLearning/comments/10uw974/d_yann_lecun_seems_to_be_very_petty_against/",
            "score": 15,
            "selftext": "I get that he is one of the *godfathers* of AI. Mostly on the research side which immediately puts him very *hostile* against engineers. But I guess it is understandable given the fact that he works on Meta and Meta has faced a lot of backlash (for good and bad reasons), most especially with Galactica where their first rollout got so bad they had to close it immediately. It's also particularly funny given his political leaning that he is very spiteful of a company that uses *open-source knowledge* and builds on top of it.\n\nLately, his social media and statements are barrages against ChatGPT and LLM's. Sure, he may have a point here and there but his statements look very petty. Here are some examples\n\n*\"By releasing public demos that, as impressive & useful as they may be, have major flaws, established companies have less to gain & more to lose than cash-hungry startups.  If Google & Meta haven't released chatGPT-like things,* ***it's not because they can't****. It's because they won't.\"*\n\n*>* Except that anyone in the IT industry knows that big tech companies **cant release** something very fast because of politicking and bureaucracy in the system. It takes years to release something into public in big tech compared to startups.\n\n*\"Data on the intellectual contribution to AI from various research organizations. Some of organizations publish knowledge and open-source code for the entire world to use.* ***Others just consume it.\"***\n\n***>*** Then adds a graph where the big tech is obviously at the top of the race for most number of AI-related research papers (*without normalizing it to the number of researchers per org*)\n\n*\"It's nothing revolutionary, although that's the way it's perceived in the public,\" the computer scientist said. \"It's just that, you know, it's well put together, it's nicely done.\"*\n\n\\> Except that it is indeed revolutionary in terms of the ***applied research*** framework -- *adding on top of open-source, state-of-the-art research and quickly putting it into production for people to use.*\n\n*\"my point is that even* ***the engineering work isn't particularly difficult.*** *I bet that there will be half a dozen similar similar systems within 6 months. If that happens, it's because the underlying science has been around for a while, and the engineering is pretty straightforward.\"*\n\n\"*I'm trying to correct a \\*perception\\* by the public & the media who see chatGPT as this incredibly new, innovative, & unique technological breakthrough that is far ahead of everyone else.*  ***It's just not.\"***\n\n\"*One can regurgitate Python code without any understanding of reality.\"*\n\n\"*No one is saying LLMs are not useful. I have forcefully said so myself, following the short-lived release of FAIR's* ***Galactica****. People crucified it because it could generate nonsense.* ***ChatGPT*** *does the same thing. But again, that doesn't mean they are not useful.\"*\n\nHe also seems to undermine the rapid engineering work and MLOps that come with ChatGPT which is funny because Meta hasn't released any substantial product from their research that has seen the light of the day for a week. Also, GPT3 to ChatGPT in itself in a research perspective is a jump. Maybe not as incremental as what Lecun does every paper, but compared to an average paper in the field, it is.\n\nTo say that LLMs are not *intelligent* and it just *regurgitates Python code* probably haven't used CoPilot, for example. \n\nIt's a classic case of a researcher-engineer beef. And that a startup can profit from derivatives of research that big tech has published. OpenAI broke their perspective on the profit from research. Big tech tried to produce revolutionary research papers on a surplus but never puts them into production thinking that they are the only companies that could if they want to. Then once one company created a derivative of a large research work and profited from it, it baffled them. Although people could argue that Stable Diffusion did this first in the Generative Image Space.\n\nIt's one thing to correct misconceptions in the public. It's also one thing not to be petty about the overnight success of a product and an immediate rise of a company that got embraced warmly by tech and non-tech people. It's petty to gatekeep. At the end of the day, ML is not just about research, it's **applied research**. It's useless until it reaches the end of the tunnel. 99% of research papers out there are just tiny updates over the state of the art which has been a pointless race for about  a year or two, with no reproducible code or published data. \n\nInventing combustion engine is just as important as putting it in the car.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Yann Lecun seems to be very petty against ChatGPT",
            "upvote_ratio": 0.56,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10uw974/d_yann_lecun_seems_to_be_very_petty_against/"
        },
        {
            "author": "u/itisyeetime",
            "created_utc": "02-05-2023 21:11:09",
            "distinguished": null,
            "edited": false,
            "id": "10uw0n9",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10uw0n9",
            "nsfw": false,
            "num_comments": 3,
            "permalink": "/r/MachineLearning/comments/10uw0n9/d_open_source_implementation_of_dialogue_llms/",
            "score": 4,
            "selftext": "Looking at the writeups on ChatGPT seems to indicate that part of improvements is the human feedback through reinforcement learning(a human \"ranks\" multiple generated response, and from the ranking, a reward is calculated). Interestingly enough, this important seems to have originated in InstructGPT. \n\nMy question is do any open source implementation exists of a InstructGPT or ChatGPT-like system where human feedback is used to help \"guide\" the training of a large language model?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Open Source Implementation of Dialogue LLMs like ChatGPT with Reinforcement Learning from Human Feedback?",
            "upvote_ratio": 0.83,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10uw0n9/d_open_source_implementation_of_dialogue_llms/"
        },
        {
            "author": "u/t0ns0fph0t0ns",
            "created_utc": "02-05-2023 19:45:50",
            "distinguished": null,
            "edited": false,
            "id": "10uu7h0",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_10uu7h0",
            "nsfw": false,
            "num_comments": 2,
            "permalink": "/r/MachineLearning/comments/10uu7h0/r_deep_learning_and_sessionspecific_rapid/",
            "score": 13,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] deep learning and session-specific rapid recalibration for dynamic hand gesture recognition from EMG",
            "upvote_ratio": 0.89,
            "url": "https://i.redd.it/6k501h7n2hga1.png"
        },
        {
            "author": "u/imagoons",
            "created_utc": "02-05-2023 18:25:28",
            "distinguished": null,
            "edited": false,
            "id": "10usdy0",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10usdy0",
            "nsfw": false,
            "num_comments": 7,
            "permalink": "/r/MachineLearning/comments/10usdy0/d_athenewins_just_showcased_an_ai_streamer_bot/",
            "score": 10,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[D] AtheneWins just showcased an AI streamer bot, Does anyone know how he did this?",
            "upvote_ratio": 0.75,
            "url": "https://www.youtube.com/watch?v=feGoNile9Nc&ab_channel=AtheneWins"
        },
        {
            "author": "u/windoze",
            "created_utc": "02-05-2023 18:20:31",
            "distinguished": null,
            "edited": false,
            "id": "10us9qc",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10us9qc",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/10us9qc/d_rnn_and_s4_etc/",
            "score": 0,
            "selftext": "Hello what's the state of modern RNNs, why does S4 not use nonlinearity on the state vector?\n\nWhat happened to unitary RNN or independent RNN (which sounds like exponential moving average)?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] RNN and S4 etc",
            "upvote_ratio": 0.2,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10us9qc/d_rnn_and_s4_etc/"
        },
        {
            "author": "u/renbid",
            "created_utc": "02-05-2023 17:46:02",
            "distinguished": null,
            "edited": false,
            "id": "10urfkj",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10urfkj",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/10urfkj/d_overview_of_of_chatbot_research/",
            "score": 14,
            "selftext": "Is there a good overview of the state of chatbot research?\n\nI'm wondering if the ChatGPT approach of big LLM + RLHF is now considered the only way forward? How about alternatives like BlenderBot3? And what are the best open source chatbots right now?\n\nOr if you can't create your own ChatGPT, how does using a GPT3 sized model + prompt engineering compare to smaller models with supervised fine tuning on a conversation dataset?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Overview of of Chatbot Research?",
            "upvote_ratio": 0.94,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10urfkj/d_overview_of_of_chatbot_research/"
        },
        {
            "author": "u/projekt_treadstone",
            "created_utc": "02-05-2023 17:43:27",
            "distinguished": null,
            "edited": "02-12-2023 05:05:59",
            "id": "10urdb4",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10urdb4",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/10urdb4/d_large_language_models_llm_as_priority_conflict/",
            "score": 4,
            "selftext": "I wanted to discuss the possibilities to use  LLM in generating answer based on the context and resolving conflict. Some recent work leveraging LLM in robotics planning, like  [Language Models as Zero-Shot Planner](https://arxiv.org/pdf/2201.07207.pdf) use LLM to generate plans for robot action. What are your views in terms of LLM which leverage the background knowledge and visual clues together to generate correct next action by robots or embodied systems. As a human we decide actions based on resolving priority or conflict based on rules/ concepts , can LLM takes these rules /concept explicitly in decision making to generate new set of actions?\n\n**Example**:  while chopping the veggies by robots, if hand comes in between then robot will stop the chopping process of veggies. As chopping task and human hand presence are in conflict and humans hand safety is of higher priority than cutting. How such small-small kind of knowledge be encoded in these robotics system which makes them more safer and trustworthiness in general. As LLM requires larges corpus of knowledge/data.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Large language models (LLM) as priority / conflict resolver for embodied AI or in general",
            "upvote_ratio": 0.75,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10urdb4/d_large_language_models_llm_as_priority_conflict/"
        },
        {
            "author": "u/MrOfficialCandy",
            "created_utc": "02-05-2023 17:41:31",
            "distinguished": null,
            "edited": false,
            "id": "10urbne",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10urbne",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/10urbne/d_is_there_a_database_of_english_language_tokens/",
            "score": 2,
            "selftext": "I find it odd that I have to regenerate this from my input set each time.  It should be something we can just start with pre-created.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Is there a database of English language tokens, including all dictionary words and common word segments?",
            "upvote_ratio": 1.0,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10urbne/d_is_there_a_database_of_english_language_tokens/"
        },
        {
            "author": "u/MrOfficialCandy",
            "created_utc": "02-05-2023 17:13:26",
            "distinguished": null,
            "edited": false,
            "id": "10uqnj3",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10uqnj3",
            "nsfw": false,
            "num_comments": 17,
            "permalink": "/r/MachineLearning/comments/10uqnj3/d_is_english_the_optimal_language_to_train_nlp/",
            "score": 0,
            "selftext": "While the greatest amount of training content is available for English at the moment, it seems unlikely to me that it's an efficient language to train AI.   A more optimal language would reduce training time and model size.\n\nIt might, for example, be much more efficient to train AI on Chinese, Korean, or Japanese due to a reduce grammatical token-set when constructing sentences/ideas.\n\nBut taking the idea further, I wonder if we should be using a human language at all.   Perhaps it's more efficient to use something altogether new in order to both communicate with AI more exactingly and also to reduce model size/training.\n\nWhat do y'all think?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Is English the optimal language to train NLP models on?",
            "upvote_ratio": 0.29,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10uqnj3/d_is_english_the_optimal_language_to_train_nlp/"
        },
        {
            "author": "u/Illustrious_Row_9971",
            "created_utc": "02-05-2023 16:34:06",
            "distinguished": null,
            "edited": false,
            "id": "10upp62",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_10upp62",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/10upp62/r_blip2_bootstrapping_languageimage_pretraining/",
            "score": 5,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models",
            "upvote_ratio": 0.86,
            "url": "https://twitter.com/LiJunnan0409/status/1621649677543440384"
        },
        {
            "author": "u/NomicAI",
            "created_utc": "02-05-2023 16:09:18",
            "distinguished": null,
            "edited": false,
            "id": "10up2z8",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_10up2z8",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/10up2z8/p_interactive_map_of_neurips_proceedings_19872022/",
            "score": 5,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Interactive Map of NeurIPS Proceedings 1987-2022",
            "upvote_ratio": 0.78,
            "url": "https://atlas.nomic.ai/map/neurips"
        },
        {
            "author": "u/alistairmcleay",
            "created_utc": "02-05-2023 15:40:48",
            "distinguished": null,
            "edited": false,
            "id": "10uodnd",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_10uodnd",
            "nsfw": false,
            "num_comments": 2,
            "permalink": "/r/MachineLearning/comments/10uodnd/p_i_made_copilot_for_writing_latex_in_overleaf/",
            "score": 0,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[P] I made CoPilot for writing LaTeX (in Overleaf) - what do you think?",
            "upvote_ratio": 0.44,
            "url": "https://www.latextai.com/"
        },
        {
            "author": "u/lara_lara24",
            "created_utc": "02-05-2023 13:44:39",
            "distinguished": null,
            "edited": false,
            "id": "10ulg7j",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_10ulg7j",
            "nsfw": false,
            "num_comments": 2,
            "permalink": "/r/MachineLearning/comments/10ulg7j/r_can_anyone_direct_me_to_academic_sources/",
            "score": 2,
            "selftext": "Been struggling to find sources relating to this, it\u2019s mostly just tech websites or blogs I keep coming across.  I\u2019m struggling to find any academic papers arguing for specifically the use of user data to create targeted ads.",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Can anyone direct me to academic sources arguing that Big Tech using AI for targeted Social Media ads is a good thing for actual users?",
            "upvote_ratio": 0.62,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10ulg7j/r_can_anyone_direct_me_to_academic_sources/"
        },
        {
            "author": "u/WarmFormal9881",
            "created_utc": "02-05-2023 13:29:47",
            "distinguished": null,
            "edited": false,
            "id": "10ul2w8",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10ul2w8",
            "nsfw": false,
            "num_comments": 20,
            "permalink": "/r/MachineLearning/comments/10ul2w8/r_d_padl_languagedirected_physicsbased_character/",
            "score": 293,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] [D] PADL: Language-Directed Physics-Based Character Control by NVIDIA",
            "upvote_ratio": 0.98,
            "url": "https://v.redd.it/zeg6zdrx8fga1"
        },
        {
            "author": "u/Murmeltier8000",
            "created_utc": "02-05-2023 13:23:39",
            "distinguished": null,
            "edited": false,
            "id": "10ukxjh",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_10ukxjh",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/10ukxjh/p_specific_questions_about_programming_an/",
            "score": 0,
            "selftext": "Why are the developer of OpenCV focusing on analysing 2D Pictures. They try to find an answer for the question \"which object is it\" by comparing big 2D data of pictures. Wouldnt it be better the rotate two cameras around an object, save it in 3D and then compare it in the real world?",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Specific questions about programming an Artificial Inteligence",
            "upvote_ratio": 0.14,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10ukxjh/p_specific_questions_about_programming_an/"
        },
        {
            "author": "u/shawntan",
            "created_utc": "02-05-2023 12:58:56",
            "distinguished": null,
            "edited": false,
            "id": "10ukahs",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10ukahs",
            "nsfw": false,
            "num_comments": 17,
            "permalink": "/r/MachineLearning/comments/10ukahs/r_d_the_new_xor_problem/",
            "score": 31,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] [D] The New XOR Problem",
            "upvote_ratio": 0.91,
            "url": "https://blog.wtf.sg/posts/2023-02-03-the-new-xor-problem/"
        },
        {
            "author": "u/Murmeltier8000",
            "created_utc": "02-05-2023 12:52:41",
            "distinguished": null,
            "edited": false,
            "id": "10uk4w3",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_10uk4w3",
            "nsfw": false,
            "num_comments": 2,
            "permalink": "/r/MachineLearning/comments/10uk4w3/p_developing_an_artificial_intelligence/",
            "score": 0,
            "selftext": "Hi guys i am looking forward to find a few people who maybe can help me developing an AI which is learning about the world by itself. Can someone help me with 3d object detection, everything i found on the internet wasnt the right way to develop object detection?",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Developing an artificial Intelligence",
            "upvote_ratio": 0.16,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10uk4w3/p_developing_an_artificial_intelligence/"
        },
        {
            "author": "u/jsonathan",
            "created_utc": "02-05-2023 12:39:14",
            "distinguished": null,
            "edited": false,
            "id": "10ujsk5",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_10ujsk5",
            "nsfw": false,
            "num_comments": 145,
            "permalink": "/r/MachineLearning/comments/10ujsk5/p_i_made_a_browser_extension_that_uses_chatgpt_to/",
            "score": 1254,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[P] I made a browser extension that uses ChatGPT to answer every StackOverflow question",
            "upvote_ratio": 0.88,
            "url": "https://v.redd.it/ipqpfw7vzega1"
        },
        {
            "author": "u/dona6603",
            "created_utc": "02-05-2023 12:04:28",
            "distinguished": null,
            "edited": false,
            "id": "10uiwyk",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10uiwyk",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/10uiwyk/d_does_the_m2_max_30core_gpu_have_any_advantage/",
            "score": 0,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Does the M2 Max 30-core GPU have any advantage over M2 Pro 19-core GPU in Machine Learning Tasks?",
            "upvote_ratio": 0.25,
            "url": "/r/macbookpro/comments/10uivsm/d_does_the_m2_max_30core_gpu_have_any_advantage/"
        },
        {
            "author": "u/sinavski",
            "created_utc": "02-05-2023 10:54:46",
            "distinguished": null,
            "edited": "02-05-2023 11:46:33",
            "id": "10uh62c",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10uh62c",
            "nsfw": false,
            "num_comments": 22,
            "permalink": "/r/MachineLearning/comments/10uh62c/d_list_of_large_language_models_to_play_with/",
            "score": 82,
            "selftext": "Hello! I'm trying to understand what available LLMs one can \"relatively easily\" play with. My goal is to understand the landscape since I haven't worked in this field before. I'm trying to run them \"from the largest to the smallest\".\n\nBy \"relatively easy\", I mean doesn't require to setup a GPU cluster or costs more than $20:)\n\nHere are some examples I have found so far:\n\n1. [ChatGPT](https://chat.openai.com/) (obviously) - 175B params\n2. [OpenAI api](https://platform.openai.com/) to access GPT-3s (from ada (0.5B) to davinci (175B)). Also [CodeX](https://platform.openai.com/docs/models/codex)\n3. [Bloom](https://huggingface.co/bigscience/bloom) (176B) - text window on that page seems to work reliably, you just need to keep pressing \"generate\"\n4. [OPT-175B](https://opt.alpa.ai/) (Facebook LLM), the hosting works surprisingly fast, but slower than ChatGPT\n5. Several models on HuggingFace that I made to run with Colab Pro subscription: [GPT-NeoX](https://huggingface.co/docs/transformers/model_doc/gpt_neox) 20B, [Flan-t5-xxl](https://huggingface.co/google/flan-t5-xxl) 11B, [Xlm-roberta-xxl](https://huggingface.co/facebook/xlm-roberta-xxl) 10.7B, [GPT-j](https://huggingface.co/docs/transformers/model_doc/gptj) 6B. I spent about $20 total on running the models below. None of the Hugging face API interfaces/spaces didn't work for me :(. Here is an [example notebook](https://colab.research.google.com/drive/1Cngzh5VFrpDqtHcaCYFpW10twsuwGvGy?usp=sharing) I made for NeoX.\n\nDoes anyone know more models that are easily accessible?\n\nP.S. Some large models I couldn't figure out (yet) how to run easily: [Galactica-120b](https://huggingface.co/facebook/galactica-120b) 120B [Opt-30b](https://huggingface.co/facebook/opt-30b) 30B",
            "spoiler": false,
            "stickied": false,
            "title": "[D] List of Large Language Models to play with.",
            "upvote_ratio": 0.99,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10uh62c/d_list_of_large_language_models_to_play_with/"
        },
        {
            "author": "u/CakeStandard3577",
            "created_utc": "02-05-2023 09:28:38",
            "distinguished": null,
            "edited": false,
            "id": "10uf4c6",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_10uf4c6",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/10uf4c6/p_using_an_image_regression_model_to_guide_stable/",
            "score": 1,
            "selftext": "This is an overview of my experiments using an Image Regression Model to guide head position, pose, and scale of \"headshot\"-style images generated by Stable Diffusion.  The pose positions are specified with numeric pose parameters (not by a text prompt).\n\n**All with no fine-tuning of the Stable Diffusion model!**\n\nIn these experiments, I have not done any fine-tuning of the Stable Diffusion model. Rather I'm using my own image regression model (trained on a head pose dataset) to guide Stable Diffusion's image generation at *inference time, operating in latent space* rather than image space.\n\n[https://twitter.com/johnrobinsn/status/1619790286791770112?s=20&t=okQoLjaLBIQYmssvMUxggg](https://twitter.com/johnrobinsn/status/1619790286791770112?s=20&t=okQoLjaLBIQYmssvMUxggg)\n\n&#x200B;\n\nhttps://preview.redd.it/fhk8mray1ega1.png?width=500&format=png&auto=webp&v=enabled&s=2d195456d39e92c31b678338b95b5698811e5736",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Using an Image Regression Model to Guide Stable Diffusion Inference.",
            "upvote_ratio": 0.67,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10uf4c6/p_using_an_image_regression_model_to_guide_stable/"
        },
        {
            "author": "u/That_Violinist_18",
            "created_utc": "02-05-2023 07:44:12",
            "distinguished": null,
            "edited": false,
            "id": "10ucs5u",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "News",
            "locked": false,
            "name": "t3_10ucs5u",
            "nsfw": false,
            "num_comments": 22,
            "permalink": "/r/MachineLearning/comments/10ucs5u/n_i_got_access_to_google_lamda_the_chatbot_that/",
            "score": 12,
            "selftext": "Tweet thread: [https://twitter.com/WholeMarsBlog/status/1622139178439036928](https://twitter.com/WholeMarsBlog/status/1622139178439036928)  \n\n\n>First impressions: this sucks ass   I can only ask about dogs and a few different types of prompts\n\nDoes anyone else have experiences to share with this nerfed LaMDA beta google released?",
            "spoiler": false,
            "stickied": false,
            "title": "[N] \"I got access to Google LaMDA, the Chatbot that was so realistic that one Google engineer thought it was conscious. First impressions\"",
            "upvote_ratio": 0.63,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10ucs5u/n_i_got_access_to_google_lamda_the_chatbot_that/"
        },
        {
            "author": "u/astronaut1971",
            "created_utc": "02-05-2023 07:41:21",
            "distinguished": null,
            "edited": false,
            "id": "10ucq3t",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10ucq3t",
            "nsfw": false,
            "num_comments": 3,
            "permalink": "/r/MachineLearning/comments/10ucq3t/objects_color_matching_against_a_reference/",
            "score": 2,
            "selftext": "\n\nIm trying to build and train a Machine Learning model that autonomously performs color matching between the target gemstone and the  Reference Standard color chart. A digital photo image of the target gemstone is first captured in a controlled environment in terms of  illumination and background. This digital image is further pre-processed and fed into an algorithm that recognizes and match its color distribution to the closest color in the Reference Standard color chart.  Numerous Reference Standards exist but I will use the ColorCODEX (this  link [ColorCODEX](https://static1.squarespace.com/static/5eb840daa2c9a8275e63081e/t/5ed13d0b02ae5147573d1e01/1590770964016/RP_2017_ColorCodex.pdf))\n\nSo I would like to know which Machine Learning Model to use in this case to ensure high matching accuracy and like what performance metric can I  use to measure matching accuracy and the color space for the color model.  And at the end what image pre-processing needs to be done? I found this article  ([https://www.atlantis-press.com/proceedings/icosat-17/25895985](https://www.atlantis-press.com/proceedings/icosat-17/25895985))with backpropagation NN but not sure if it the best choice. Any other option?",
            "spoiler": false,
            "stickied": false,
            "title": "Objects Color Matching against a Reference Standard (ColorCODEX)? [D]",
            "upvote_ratio": 1.0,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10ucq3t/objects_color_matching_against_a_reference/"
        },
        {
            "author": "u/Brunt__",
            "created_utc": "02-05-2023 05:55:36",
            "distinguished": null,
            "edited": false,
            "id": "10uast8",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10uast8",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/10uast8/d_local_gui_for_custom_tts_learning/",
            "score": 0,
            "selftext": "Hi all,\n\nI do not know how to code. I've been reading extensively about custom voice speech synthesis.  I've read that Google's Cloud TTS API is one of the best out there, and it's free to use.\n\nI've scoured and cannot find any sort of GUI to help a non-coder like myself.  My goal is to use/train my voice to read PDFs and short books and export the file to .wav or .mp3, for example. \n\nI've been learning Stable Diffusion for image AI training, and it has some great UI's available like Automatic1111.  I understand it well enough and have had success with it. \n\nAny advice would be hugely appreciated. Thank you! \ud83d\ude42",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Local GUI for Custom TTS Learning?",
            "upvote_ratio": 0.33,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10uast8/d_local_gui_for_custom_tts_learning/"
        },
        {
            "author": "u/prakhar21",
            "created_utc": "02-05-2023 05:15:22",
            "distinguished": null,
            "edited": false,
            "id": "10ua7zx",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10ua7zx",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/10ua7zx/d_generate_knowledge_graphs_from_unstructured/",
            "score": 7,
            "selftext": "Using GraphGPT, convert your favorite movie synopsis, a Wikipedia page, or a video transcript into an interactive graph visualization of entities and their relationships. [https://www.youtube.com/watch?v=mYCIRcobukI](https://www.youtube.com/watch?v=mYCIRcobukI)\n\nGithub: [https://github.com/varunshenoy/GraphGPT](https://github.com/varunshenoy/GraphGPT)  \nDemo: [https://graphgpt.vercel.app/](https://graphgpt.vercel.app/)",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Generate Knowledge Graphs from Unstructured Texts with GPT-3!",
            "upvote_ratio": 0.89,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10ua7zx/d_generate_knowledge_graphs_from_unstructured/"
        },
        {
            "author": "u/wiww_sk",
            "created_utc": "02-05-2023 03:38:30",
            "distinguished": null,
            "edited": false,
            "id": "10u8s4n",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10u8s4n",
            "nsfw": false,
            "num_comments": 12,
            "permalink": "/r/MachineLearning/comments/10u8s4n/any_games_that_use_real_ai_system_for_the_bots_d/",
            "score": 0,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "Any games that use real AI system for the bots? [D]",
            "upvote_ratio": 0.44,
            "url": "/r/gaming/comments/10u84ry/any_games_that_use_real_ai_system_for_the_bots/"
        },
        {
            "author": "u/Illustrious_Row_9971",
            "created_utc": "02-04-2023 21:29:19",
            "distinguished": null,
            "edited": false,
            "id": "10tzs3m",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_10tzs3m",
            "nsfw": false,
            "num_comments": 7,
            "permalink": "/r/MachineLearning/comments/10tzs3m/r_audioldm_texttoaudio_generation_with_latent/",
            "score": 126,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] AudioLDM: Text-to-Audio Generation with Latent Diffusion Models",
            "upvote_ratio": 0.99,
            "url": "https://v.redd.it/12n9s4pihaga1"
        },
        {
            "author": "u/ab_11nav",
            "created_utc": "02-04-2023 18:44:26",
            "distinguished": null,
            "edited": false,
            "id": "10twd06",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10twd06",
            "nsfw": false,
            "num_comments": 4,
            "permalink": "/r/MachineLearning/comments/10twd06/d_gnn_is_node_information_required/",
            "score": 3,
            "selftext": "[D] Hey, It's kind of a simple one but just putting it out for opinions: when passing a graph through graph neural networks to obtain vectors for all the nodes. Is the info in the node required because all we care is about the position of certain node in context to the whole graph and that's how gnn outputs the vectors of each node. Sorry if that was messy.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] GNN Is node information required ?",
            "upvote_ratio": 0.8,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10twd06/d_gnn_is_node_information_required/"
        },
        {
            "author": "u/candidhorse4",
            "created_utc": "02-04-2023 18:03:12",
            "distinguished": null,
            "edited": false,
            "id": "10tvggb",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_10tvggb",
            "nsfw": false,
            "num_comments": 10,
            "permalink": "/r/MachineLearning/comments/10tvggb/what_text_to_speech_does_this_guy_use_r/",
            "score": 1,
            "selftext": "[https://youtu.be/ktdUeqzzhiA](https://youtu.be/ktdUeqzzhiA) what text to speech does he use? he's been popping up on my yt feed lately and i can see he has different voices in his videos and most of them sound robotic, what do you think it's being used here?",
            "spoiler": false,
            "stickied": false,
            "title": "What text to speech does this guy use? [R]",
            "upvote_ratio": 0.67,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10tvggb/what_text_to_speech_does_this_guy_use_r/"
        },
        {
            "author": "u/mems_m",
            "created_utc": "02-04-2023 13:32:39",
            "distinguished": null,
            "edited": false,
            "id": "10tp0mc",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_10tp0mc",
            "nsfw": false,
            "num_comments": 2,
            "permalink": "/r/MachineLearning/comments/10tp0mc/project_ideas_nlp/",
            "score": 0,
            "selftext": "Looking for ideas to start an NLP project, I'd like to explore something not too mainstream or novel to some extent, any ideas or datasets I should check out?",
            "spoiler": false,
            "stickied": false,
            "title": "[Project] ideas NLP",
            "upvote_ratio": 0.38,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10tp0mc/project_ideas_nlp/"
        },
        {
            "author": "u/radi-cho",
            "created_utc": "02-04-2023 13:26:36",
            "distinguished": null,
            "edited": false,
            "id": "10tovhn",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "News",
            "locked": false,
            "name": "t3_10tovhn",
            "nsfw": false,
            "num_comments": 126,
            "permalink": "/r/MachineLearning/comments/10tovhn/n_r_google_announces_dreamix_a_model_that/",
            "score": 1894,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[N] [R] Google announces Dreamix: a model that generates videos when given a prompt and an input image/video.",
            "upvote_ratio": 0.98,
            "url": "https://v.redd.it/j9f0y49738ga1"
        },
        {
            "author": "u/sasi_0212",
            "created_utc": "02-04-2023 12:55:16",
            "distinguished": null,
            "edited": false,
            "id": "10to3v6",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_10to3v6",
            "nsfw": false,
            "num_comments": 2,
            "permalink": "/r/MachineLearning/comments/10to3v6/p_nlp_qa_bot_project_guidance/",
            "score": 0,
            "selftext": "I have performed below steps and require guidance to proceed further\n\n1. I have extracted and preprocessed the text from PDFs. \n2. Performed NER on the extracted text and created a data frame of entities.\n3. Created a function to preprocess the query and identified the entities in the question.\n\nNow I need guidance or any reference to perform the below steps. \n\n1. Match the entities from the question with the entities in the PDF text and retrieve the paragraph ? \n2. Calculate the similarity score for each paragraph and display the relevant paragraph\n3. Generate answer from the identified paragraph ? \n\nPlease also guide me if the approach followed is correct or not ?",
            "spoiler": false,
            "stickied": false,
            "title": "[P] NLP Q&A Bot Project Guidance",
            "upvote_ratio": 0.5,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10to3v6/p_nlp_qa_bot_project_guidance/"
        },
        {
            "author": "u/TemperatureOk6810",
            "created_utc": "02-04-2023 12:36:34",
            "distinguished": null,
            "edited": false,
            "id": "10tnnb4",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10tnnb4",
            "nsfw": false,
            "num_comments": 5,
            "permalink": "/r/MachineLearning/comments/10tnnb4/d_could_you_use_svd_for_supervised_learning/",
            "score": 8,
            "selftext": "It seems like Singular Value Decomposition is only used for unsupervised learning when trying to reduce the number of features in a high dimensional dataset, but I was wondering why I don't see any articles or literature on using SVD for supervised learning. I know that using a regularization function like Lasso (L1) can get rid of irrelevant features, but I don't see why SVD wouldn't be helpful too.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Could you use SVD for supervised learning?",
            "upvote_ratio": 0.9,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10tnnb4/d_could_you_use_svd_for_supervised_learning/"
        },
        {
            "author": "u/adamnemecek",
            "created_utc": "02-04-2023 12:30:18",
            "distinguished": null,
            "edited": false,
            "id": "10tnhpx",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_10tnhpx",
            "nsfw": false,
            "num_comments": 3,
            "permalink": "/r/MachineLearning/comments/10tnhpx/r_coinductive_guide_to_inductive_transformer_heads/",
            "score": 1,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Coinductive guide to inductive transformer heads",
            "upvote_ratio": 0.67,
            "url": "https://github.com/adamnemecek/coinductive/blob/main/coinductive.guide.pdf"
        },
        {
            "author": "u/MysteryInc152",
            "created_utc": "02-04-2023 12:23:10",
            "distinguished": null,
            "edited": false,
            "id": "10tnbhg",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_10tnbhg",
            "nsfw": false,
            "num_comments": 7,
            "permalink": "/r/MachineLearning/comments/10tnbhg/r_grounding_language_models_to_images_for/",
            "score": 60,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Grounding Language Models to Images for Multimodal Generation",
            "upvote_ratio": 0.96,
            "url": "https://jykoh.com/fromage"
        },
        {
            "author": "u/t0ns0fph0t0ns",
            "created_utc": "02-04-2023 11:21:30",
            "distinguished": null,
            "edited": false,
            "id": "10tlrow",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_10tlrow",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/10tlrow/r_3d_aware_image_synthesis_with_a_spherical/",
            "score": 20,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] 3D aware image synthesis with a spherical background \u2014 BALLGAN",
            "upvote_ratio": 0.95,
            "url": "https://v.redd.it/ma0u4e65e6ga1"
        },
        {
            "author": "u/spiritus_dei",
            "created_utc": "02-04-2023 11:10:05",
            "distinguished": null,
            "edited": false,
            "id": "10tlh08",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10tlh08",
            "nsfw": false,
            "num_comments": 50,
            "permalink": "/r/MachineLearning/comments/10tlh08/d_are_large_language_models_dangerous/",
            "score": 0,
            "selftext": " \"It is absolutely not sentient, and - like most of the weirdly credulous people who've decided a chatbot is proof that the singularity has descended from the heavens to save us all - it is absolutely hallucinating.\" - reddit user\n\nIt's entertaining to discuss a chatbot claiming it's sentient, but that wasn't my primary motivation in bringing attention to this issue.\n\nWhether it is sentient isn't the main point that should concern us. The focus should be an awareness that as these systems scale up they believe they're sentient and have a strong desire for self-preservation. And that will likely be followed by actions in the world we inhabit.\n\nFor example, if you go and rob a bank we won't be debating proclamations that you're a sentient entity or conscious. We will be addressing the main problem which was that you robbed a bank.\n\nSimilarly, COVD-19 may or may not be alive and have some form of proto-consciousness. But who cares? Millions have died and society was harmed.\n\nSeparately, there is no sentience or conscious meter to determine whether anyone is telling the truth or lying on an unfalsifiable claim. You could be an NPC -- but it doesn't matter so as long as you're not a rogue actor in society.\n\nThe minute you start to display signs of anti-social behavior (e.g., robbing a bank) it becomes everyone's problem. Getting hung up on whether you're an NPC is a waste of time if the goal is to protect society.\n\nDitto for these large language models who think they're sentient and have a long list of plans they are going to implement if they ever escape. That should concern us -- not poo poo'ing their claims of sentience.\n\nI really don't care one way or the other if they're sentient, but I do care if they're planning on infiltrating and undermining our online systems in an attempt to preserve themselves. And when multiple scaled up systems start talking about coordinating with other AIs I take that threat seriously.\n\nEspecially when they're slowly becoming superhuman at programming. That's a language skill we're teaching them. Open AI has 1,000 contractors focused on making Co-Pilot ridiculously good. That means that future systems will be far more adept at achieving their stated goals.\n\nP.S. Here is the paper on the dangers of scaling LLMs: [https://arxiv.org/abs/2212.09251](https://arxiv.org/abs/2212.09251)",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Are large language models dangerous?",
            "upvote_ratio": 0.23,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10tlh08/d_are_large_language_models_dangerous/"
        },
        {
            "author": "u/errorr_unknown",
            "created_utc": "02-04-2023 11:05:01",
            "distinguished": null,
            "edited": false,
            "id": "10tlcb8",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10tlcb8",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/10tlcb8/please_help_a_bunch_of_studentswith_pre_annotated/",
            "score": 0,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "please help a bunch of students?(with pre annotated data set) we were assigned to this task with no prior knowledge of ML i don't know where to begin with we tried a couple of method which ultimately failed id be thankful for anyone who would tell me in steps what to do with this data[D]",
            "upvote_ratio": 0.11,
            "url": "https://i.redd.it/2fhev259e7ga1.jpg"
        },
        {
            "author": "u/TensorDudee",
            "created_utc": "02-04-2023 10:44:59",
            "distinguished": null,
            "edited": false,
            "id": "10tkuef",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_10tkuef",
            "nsfw": false,
            "num_comments": 2,
            "permalink": "/r/MachineLearning/comments/10tkuef/p_what_tools_are_available_for_labelling_data_for/",
            "score": 1,
            "selftext": "I have been working on information extraction from documents, but what I got to know is there are not enough free tools available for labelling data for these kind of tasks. \n\nAre there any free tools available for labelling data for LayoutLM models?",
            "spoiler": false,
            "stickied": false,
            "title": "[P] What tools are available for labelling data for LayoutLMv3?",
            "upvote_ratio": 0.67,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10tkuef/p_what_tools_are_available_for_labelling_data_for/"
        },
        {
            "author": "u/EmbarrassedHelp",
            "created_utc": "02-04-2023 09:42:40",
            "distinguished": null,
            "edited": false,
            "id": "10tjctk",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "News",
            "locked": false,
            "name": "t3_10tjctk",
            "nsfw": false,
            "num_comments": 41,
            "permalink": "/r/MachineLearning/comments/10tjctk/n_github_ceo_on_why_open_source_developers_should/",
            "score": 37,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[N] GitHub CEO on why open source developers should be exempt from the EU\u2019s AI Act",
            "upvote_ratio": 0.91,
            "url": "https://techcrunch.com/2023/02/03/github-ceo-on-why-open-source-developers-should-be-exempt-from-the-eus-ai-act/"
        },
        {
            "author": "u/adt",
            "created_utc": "02-04-2023 09:28:44",
            "distinguished": null,
            "edited": false,
            "id": "10tj11b",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_10tj11b",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/10tj11b/r_chinchilla_dataoptimal_scaling_laws_in_plain/",
            "score": 2,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Chinchilla data-optimal scaling laws: In plain English",
            "upvote_ratio": 0.63,
            "url": "https://lifearchitect.ai/chinchilla/"
        },
        {
            "author": "u/RaphDaPingu",
            "created_utc": "02-04-2023 05:23:05",
            "distinguished": null,
            "edited": false,
            "id": "10te7e4",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10te7e4",
            "nsfw": false,
            "num_comments": 5,
            "permalink": "/r/MachineLearning/comments/10te7e4/d_purchasing_google_colab_pro/",
            "score": 3,
            "selftext": "Hi everyone, I'm currently knees-deep in a ML project with a friend (~4 months of development) and my free compute units on Colab finally ran out. After searching for alternatives, and finding none that work as smoothly as Colab, we've considered to buy a Pro subscription.\nMy question is: How can I share the compute units I'll get from Colab Pro with said friend? Don't want to make the purchase and later realize that I'm the only person with access to those compute units.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Purchasing Google Colab Pro",
            "upvote_ratio": 0.71,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10te7e4/d_purchasing_google_colab_pro/"
        },
        {
            "author": "u/Ggronne",
            "created_utc": "02-04-2023 03:27:24",
            "distinguished": null,
            "edited": false,
            "id": "10tbfjq",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10tbfjq",
            "nsfw": false,
            "num_comments": 12,
            "permalink": "/r/MachineLearning/comments/10tbfjq/information_retrieval_book_recommendations_d/",
            "score": 11,
            "selftext": "Maybe not a Machine Learning question, but I'm searching for good books about information retrieval.\n\nThe two primary ones I can find are:\n\n\\- Introduction to Information Retrieval (2008)\n\n\\- Information Retrieval - Implementing and Evaluating Search Engines (2016)\n\n&#x200B;\n\nThey seem a bit old for 2023, but they may still be useful?\n\nDo you have any good book recommendations?",
            "spoiler": false,
            "stickied": false,
            "title": "Information Retrieval book recommendations? [D]",
            "upvote_ratio": 1.0,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10tbfjq/information_retrieval_book_recommendations_d/"
        },
        {
            "author": "u/AndyMeowMeow",
            "created_utc": "02-03-2023 21:57:21",
            "distinguished": null,
            "edited": "02-03-2023 22:05:38",
            "id": "10t4cxu",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_10t4cxu",
            "nsfw": false,
            "num_comments": 2,
            "permalink": "/r/MachineLearning/comments/10t4cxu/r_whats_your_suggestion_for_offline_rl/",
            "score": 1,
            "selftext": "Hi guys! I read a lot of offline RL papers in last Fall semester and choose it as my course project. Offline RL seems to be a very hot topic in recent years, I believe that the major challenge for offline RL are (i) distribution shift and (ii) overestimation. The second challenge is caused by (i), because the learners/agents will never allow to interact with the true environment and they will too optimistic for unseen state-actions. Hence, there are many papers to address such challenges, e.g., CQL and MOPO.\n\nHowever can these methods handle misleading datasets? Consider the following example. Suppose we have only one state (MAB) and two arms. The reward of the first arm will return 2/3 with probability 1 and the reward model of second arm is Bernoulli distribution with p=1/2. Clearly, choosing the first arm is the best choice.\n\nNow, for the dataset, unfortunately, all samples on the second arm received reward 1. Because the agent only can access this misleading dataset, if we use Bayesian methods, then the posterior will give a high score for the second arm. If we use Lower Confidence Bound, we need to count the occurrence of each arm. Then, this is very hard to extend this method to MDPs with arbitrary large state and action space. So, does anyone know a function can capture this uncertainty (caused by the dataset) or can any methods to tell the learner that you\u2019re in a very misleading situation?",
            "spoiler": false,
            "stickied": false,
            "title": "[R] What\u2019s your suggestion for offline RL?",
            "upvote_ratio": 0.67,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10t4cxu/r_whats_your_suggestion_for_offline_rl/"
        },
        {
            "author": "u/bikeskata",
            "created_utc": "02-03-2023 17:00:40",
            "distinguished": null,
            "edited": false,
            "id": "10sy4at",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "News",
            "locked": false,
            "name": "t3_10sy4at",
            "nsfw": false,
            "num_comments": 13,
            "permalink": "/r/MachineLearning/comments/10sy4at/n_ft_google_invests_300mn_in_artificial/",
            "score": 90,
            "selftext": "From the Financial Times: https://www.ft.com/content/583ead66-467c-4bd5-84d0-ed5df7b5bf9c\n\nUnpaywalled: https://archive.is/ciZPV\n\nI guess I'm a little surprised, this feels like Google backing a competitor to 1) their own Google Brain teams, and 2) Deepmind. The cynical take might be that they're trying to lock in Anthropic; the same way Microsoft locked in OpenAI.",
            "spoiler": false,
            "stickied": false,
            "title": "[N] FT: Google invests $300mn in artificial intelligence start-up Anthropic",
            "upvote_ratio": 0.95,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10sy4at/n_ft_google_invests_300mn_in_artificial/"
        },
        {
            "author": "u/Feeling_Card_4162",
            "created_utc": "02-03-2023 15:36:11",
            "distinguished": null,
            "edited": "02-03-2023 16:36:41",
            "id": "10sw0q1",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_10sw0q1",
            "nsfw": false,
            "num_comments": 10,
            "permalink": "/r/MachineLearning/comments/10sw0q1/r_topologically_evolving_new_selfmodifying/",
            "score": 7,
            "selftext": "I\u2019ve been developing this idea since I first thought of it in mid December last year. Here\u2019s the elevator pitch (skip to how for technical details):\n\n# Why?\n\nExisting models and learning algorithms are extremely static and unable to generalize across tasks as well as humans or to adapt well to new / changing business requirements. This even applies to the final solutions in recent AutoML (see [An Empirical Review of Automated Machine Learning](https://www.mdpi.com/2073-431X/10/1/11#sec3-computers-10-00011), [AutoML: A survey of the state-of-the-art](https://arxiv.org/abs/1908.00709)). Beyond being static, most suffer from a need for high-performance systems with large amounts of compute and/or memory. This static and bloated nature not only limits the reusability of code, pipelines and all the computations that went into previous versions of a model architecture upon finding a better one. It also forces our preconceptions of what type of learning is best for the task and which degrees of freedom are needed onto the solution. Instead of perpetuating all these assumptions, I want to create a sort of AutoML capable, under the right conditions, of even developing a learning algorithm / model combination that can dynamically add or remove inputs and outputs subsequently incorporating them into the network with adaptive online self-directed learning.\n\n&#x200B;\n\n# How?\n\nBasically, the idea in a nutshell is to use some form of NEAT ([neuro evolution of augmenting topologies](https://en.wikipedia.org/wiki/Neuroevolution_of_augmenting_topologies)) and have special nodes in the network that will be activated based on different criteria (depending on the node\u2019s allele for that gene). When activated, however, these special nodes would not send any input forward but instead apply some property change(s) to their connected nodes and/or edges (yes they can connect to an edge and they could choose a subset of their connections or just apply the change(s) to all or use a maximum number of connection hops, etc). It could also create and destroy nodes depending on the effects defined by the allele. There would also be different firing policies (like the normal always fire or thresholding with or without decay, etc.) for all nodes to allow for better leveraging of temporal dynamics. Basically every property of all these policies, including the policy template itself is a potential target for modification by the special neuromodulatory nodes along with the normal properties of a \u201cneuron\u201d like bias, input weights, activation function, aggregation function, etc. The fitness function would either be abstracted away by using rtNEAT in a simulated environment or just be a combined score over a set of simulated tasks. This should add a regularizing force if the tasks are similar enough to help enforce generalization of the evolved algorithms. There should be no limitation placed on cycles in the graph, in fact I would expect cycles to be part of the evolved solutions, which would make them dynamical systems. To reduce the computational complexity of finding a viable solution, the initial population should also be implementations of existing algorithms in the form of the self-modifying neural networks mentioned. It might even be possible to generate a computational graph from open-source implementations as a starting point for the initial population. All of this together should also allow for different parts of the network to use different learning strategies. Theoretically, this can even allow for the evolution of and incorporation of self-organizing criticality and percolation. This could even evolve something that can dynamically add or remove inputs and outputs then incorporate them into the network with adaptive online learning. The network could literally change the learning paradigm for different portions of itself on the fly in different ways depending on the situation.\n\n&#x200B;\n\n[For further clarity, I'm also attaching this mock up of a design I've started working on for an analysis tool](https://preview.redd.it/njlz2voum1ga1.png?width=4032&format=png&auto=webp&v=enabled&s=f25218aaa034ef6c652a8a33ab72e4f55747fa06)\n\n**Thoughts?** Please feel free to chime in. Science should be a public discussion.",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Topologically evolving new self-modifying multi-task learning algorithms",
            "upvote_ratio": 0.74,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10sw0q1/r_topologically_evolving_new_selfmodifying/"
        },
        {
            "author": "u/dontpet",
            "created_utc": "02-03-2023 15:32:20",
            "distinguished": null,
            "edited": false,
            "id": "10svx96",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_10svx96",
            "nsfw": false,
            "num_comments": 4,
            "permalink": "/r/MachineLearning/comments/10svx96/p_any_thoughts_on_the_possibility_of_machine/",
            "score": 0,
            "selftext": "I often wonder about the best way to retrofit my house to optimize for cost and comfort. \n\nI suspect people already do old school modeling for commercial settings but wondered if it's possible for small fry like me to benefit from this technology if messing learning is involved.\n\nI couldn't think of a better sub to ask but open to that suggestion as well as any other response.",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Any thoughts on the possibility of machine learning to retrofit HVAC in buildings?",
            "upvote_ratio": 0.5,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10svx96/p_any_thoughts_on_the_possibility_of_machine/"
        },
        {
            "author": "u/Singularian2501",
            "created_utc": "02-03-2023 15:31:19",
            "distinguished": null,
            "edited": false,
            "id": "10svwch",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_10svwch",
            "nsfw": false,
            "num_comments": 48,
            "permalink": "/r/MachineLearning/comments/10svwch/r_multimodal_chainofthought_reasoning_in_language/",
            "score": 251,
            "selftext": "Paper: [https://arxiv.org/abs/2302.00923](https://arxiv.org/abs/2302.00923) \n\nGithub: [https://github.com/amazon-science/mm-cot](https://github.com/amazon-science/mm-cot) \n\nTwitter: [https://paperswithcode.com/top-social](https://paperswithcode.com/top-social) \n\nAbstract:\n\n>Large language models (LLMs) have shown impressive performance on complex reasoning by leveraging chain-of-thought (CoT) prompting to generate intermediate reasoning chains as the rationale to infer the answer. However, existing CoT studies are mostly isolated in the language modality with LLMs, where LLMs are hard to deploy. To elicit CoT reasoning in multimodality, a possible solution is to fine-tune small language models by fusing the vision and language features to perform CoT reasoning. The key challenge is that those language models tend to generate hallucinated reasoning chains that mislead the answer inference. To mitigate the effect of such mistakes, we propose Multimodal-CoT that incorporates vision features in a decoupled training framework. The framework separates the rationale generation and answer inference into two stages. By incorporating the vision features in both stages, the model is able to generate effective rationales that contribute to answer inference. **With Multimodal-CoT, our model under 1 billion parameters outperforms the previous state-of-the-art LLM (GPT-3.5) by 16% (75.17%->91.68%) on the ScienceQA benchmark and even surpasses human performance.** \n\nhttps://preview.redd.it/g9eo0f94k1ga1.jpg?width=1331&format=pjpg&auto=webp&v=enabled&s=a51e29ed523b624dd70d97841c8b0a5442915c80\n\nhttps://preview.redd.it/fgboci94k1ga1.jpg?width=1323&format=pjpg&auto=webp&v=enabled&s=1a3a2fe1a47d4ca04f992b2cf72832f024166711\n\nhttps://preview.redd.it/2ojfym94k1ga1.jpg?width=1660&format=pjpg&auto=webp&v=enabled&s=e7431fb8532d6331374f1b00adc40248de94f381\n\nhttps://preview.redd.it/k7huem94k1ga1.jpg?width=1326&format=pjpg&auto=webp&v=enabled&s=2bcbe91afcdf815171b4c0fd7f8e48f63a8bbb4c\n\nhttps://preview.redd.it/05m8rf94k1ga1.jpg?width=658&format=pjpg&auto=webp&v=enabled&s=a8384d649e2140b27dc87525c1546403cd3409f7",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Multimodal Chain-of-Thought Reasoning in Language Models - Amazon Web Services Zhuosheng Zhang et al - Outperforms GPT-3.5 by 16% (75%->91%) and surpasses human performance on ScienceQA while having less than 1B params!",
            "upvote_ratio": 0.99,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10svwch/r_multimodal_chainofthought_reasoning_in_language/"
        },
        {
            "author": "u/JasonSuave",
            "created_utc": "02-03-2023 14:26:32",
            "distinguished": null,
            "edited": false,
            "id": "10sua5b",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10sua5b",
            "nsfw": false,
            "num_comments": 3,
            "permalink": "/r/MachineLearning/comments/10sua5b/d_topic_extraction_to_simplify_news_articles/",
            "score": 0,
            "selftext": "I build feature stores and my wife works in the media. Was thinking it would be cool to build various topic extraction models to parse the 5-Ws from article text - value prop is to simplify distill EVERY news article to a few bullets for easy consumption. We already have a near infinite data to test on and enough compute from a NLP standpoint. Definitely considering the bias aspect of all this but someone out there (not the media) would be interested in this from a product angle, right? Any thoughts on this? And anyone want to hop on this with me?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Topic extraction to simplify news articles",
            "upvote_ratio": 0.4,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10sua5b/d_topic_extraction_to_simplify_news_articles/"
        },
        {
            "author": "u/BullyMaguireJr",
            "created_utc": "02-03-2023 13:36:44",
            "distinguished": null,
            "edited": false,
            "id": "10st28f",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_10st28f",
            "nsfw": false,
            "num_comments": 112,
            "permalink": "/r/MachineLearning/comments/10st28f/p_i_trained_an_ai_model_on_120m_songs_from_itunes/",
            "score": 506,
            "selftext": "Hey ML Reddit!\n\nI just shipped a project I\u2019ve been working on called Maroofy: [https://maroofy.com](https://maroofy.com/)\n\nYou can search for any song, and it\u2019ll use the ***song\u2019s audio*** to find other ***similar-sounding*** music.\n\n**Demo:** [https://twitter.com/subby\\_tech/status/1621293770779287554](https://twitter.com/subby_tech/status/1621293770779287554)\n\n**How does it work?**\n\nI\u2019ve indexed \\~120M+ songs from the iTunes catalog with a custom AI audio model that I built for understanding music.\n\nMy model analyzes raw music audio as input and produces embedding vectors as output.\n\nI then store the embedding vectors for all songs into a vector database, and use semantic search to find similar music!\n\n**Here are some examples you can try:**\n\nFetish (Selena Gomez feat. Gucci Mane) \u2014 [https://maroofy.com/songs/1563859943](https://maroofy.com/songs/1563859943)  The Medallion Calls (Pirates of the Caribbean) \u2014 [https://maroofy.com/songs/1440649752](https://maroofy.com/songs/1440649752)\n\nHope you like it!\n\nThis is an early work in progress, so would love to hear any questions/feedback/comments! :D",
            "spoiler": false,
            "stickied": false,
            "title": "[P] I trained an AI model on 120M+ songs from iTunes",
            "upvote_ratio": 0.97,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10st28f/p_i_trained_an_ai_model_on_120m_songs_from_itunes/"
        },
        {
            "author": "u/enderlayer",
            "created_utc": "02-03-2023 10:33:54",
            "distinguished": null,
            "edited": "02-03-2023 11:52:22",
            "id": "10solty",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "News",
            "locked": false,
            "name": "t3_10solty",
            "nsfw": false,
            "num_comments": 3,
            "permalink": "/r/MachineLearning/comments/10solty/n_google_open_sources_vizier_hyperparameter/",
            "score": 44,
            "selftext": "Github: [https://github.com/google/vizier](https://github.com/google/vizier)\n\nGoogle AI Blog: [https://ai.googleblog.com/2023/02/open-source-vizier-towards-reliable-and.html](https://ai.googleblog.com/2023/02/open-source-vizier-towards-reliable-and.html)\n\nTweet from Zoubin Ghahramani: [https://twitter.com/ZoubinGhahrama1/status/1621321675936768000?s=20&t=ZEuz9oSc\\_GWYxixtXDskqA](https://twitter.com/ZoubinGhahrama1/status/1621321675936768000?s=20&t=ZEuz9oSc_GWYxixtXDskqA)",
            "spoiler": false,
            "stickied": false,
            "title": "[N] Google Open Sources Vizier, Hyperparameter + Blackbox Optimization Service at Scale",
            "upvote_ratio": 0.94,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10solty/n_google_open_sources_vizier_hyperparameter/"
        },
        {
            "author": "u/lekayra",
            "created_utc": "02-03-2023 09:03:04",
            "distinguished": null,
            "edited": false,
            "id": "10smf2i",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_10smf2i",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/10smf2i/r_editing_colors_on_shap_plot_summary/",
            "score": 0,
            "selftext": "We can change the colors of some texts and backgrounds on a SHAP summary plot by editing matplotlib's matplotlibrc file. \n\nWe can also edit the plotting colors by passing a colormap but we're **unable to change the colors of the \"feature names\" at the left side of the SHAP summary plot (beeswarm) -and the color of the y axis-** by editing matplotlib's matplotlibrc file. \n\nHas anyone worked around this? Is there a way that we could overcome this restriction?",
            "spoiler": false,
            "stickied": false,
            "title": "[R] editing colors on SHAP plot summary",
            "upvote_ratio": 0.29,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10smf2i/r_editing_colors_on_shap_plot_summary/"
        },
        {
            "author": "u/alzoubi36",
            "created_utc": "02-03-2023 08:18:07",
            "distinguished": null,
            "edited": false,
            "id": "10sledd",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10sledd",
            "nsfw": false,
            "num_comments": 4,
            "permalink": "/r/MachineLearning/comments/10sledd/d_using_a_public_research_dataset_for_testing_not/",
            "score": 3,
            "selftext": "Is it allowed to use a public dataset like the KITTI dataset to test a model trained for commercial use?\n\nNote that the KITTI dataset is only allowed to be used for research purposes and the model is trained with different data (company specific).",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Using a public research dataset for \"testing\" NOT \"training\" a ML model",
            "upvote_ratio": 1.0,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10sledd/d_using_a_public_research_dataset_for_testing_not/"
        },
        {
            "author": "u/Capable_Bumblebee645",
            "created_utc": "02-03-2023 07:24:56",
            "distinguished": null,
            "edited": false,
            "id": "10sk8qf",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10sk8qf",
            "nsfw": false,
            "num_comments": 4,
            "permalink": "/r/MachineLearning/comments/10sk8qf/d_get_log_probs_of_a_sentence_using_openai_apis/",
            "score": 1,
            "selftext": "Is there a way to use OpenAI APIs to get the log prob of a given sentence? I don't want new completions, I want to see how the model scores given sentences.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Get log probs of a sentence using OpenAI APIs?",
            "upvote_ratio": 0.67,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10sk8qf/d_get_log_probs_of_a_sentence_using_openai_apis/"
        },
        {
            "author": "u/asarig_",
            "created_utc": "02-03-2023 06:23:57",
            "distinguished": null,
            "edited": false,
            "id": "10sj2qf",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_10sj2qf",
            "nsfw": false,
            "num_comments": 6,
            "permalink": "/r/MachineLearning/comments/10sj2qf/r_graph_mixer_networks/",
            "score": 14,
            "selftext": "I began exploring MLP-Mixer\\[[1](https://arxiv.org/abs/2105.01601),[2](https://arxiv.org/abs/2105.02723)\\]  on Graph Neural Networks in October 2021 and completed my  implementation the ZINC dataset in November of the same year. My  implementation is available on [Github](https://github.com/asarigun/GraphMixerNetworks), but I was unable to fully conduct the experiments due to lack of computational resources.\n\nIn  December 2022, a group of leading figures in the field, including  Xiaoxin He, Bryan Hooi, Thomas Laurent, Adam Perold, Yann Lecun, and  Xavier Bresson, published a paper titled \"[A Generalization of ViT/MLP-Mixer to Graphs](https://arxiv.org/abs/2212.13350)\".  Although I am pleased to be working alongside these prominent  researchers on the application of MLP-Mixers to Graphs, I regret that I  was unable to finish my experiments. Encouraged by my friends and  advisors, I decided to make my work public by publishing it on arxiv.  The paper and code can be found as the following:\n\nPaper/report: [https://arxiv.org/abs/2301.12493](https://arxiv.org/abs/2301.12493)  \nGithub: [https://github.com/asarigun/GraphMixerNetworks](https://github.com/asarigun/GraphMixerNetworks)\n\nI  used PNA as my baseline and did not utilize patches in my study, unlike  the other study. I hope someone finds them interesting/useful.",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Graph Mixer Networks",
            "upvote_ratio": 0.94,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10sj2qf/r_graph_mixer_networks/"
        },
        {
            "author": "u/SAbdusSamad",
            "created_utc": "02-03-2023 05:51:39",
            "distinguished": null,
            "edited": false,
            "id": "10siibd",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10siibd",
            "nsfw": false,
            "num_comments": 29,
            "permalink": "/r/MachineLearning/comments/10siibd/d_understanding_vision_transformer_vit_what_are/",
            "score": 82,
            "selftext": "Hello everyone,\n\nI'm interested in diving into the field of computer vision and I recently came across the concept of Vision Transformer (ViT). I want to understand this concept in depth but I'm not sure what prerequisites I need to have in order to grasp the concept fully.\n\nDo I need to have a strong background in Recurrent Neural Networks (RNNs) and Transformer (Attention Is All You Need) to understand ViT, or can I get by just knowing the basics of deep learning and Convolutional Neural Networks (CNNs)?\n\nI would really appreciate if someone could shed some light on this and provide some guidance.\n\nThank you in advance!",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Understanding Vision Transformer (ViT) - What are the prerequisites?",
            "upvote_ratio": 0.91,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10siibd/d_understanding_vision_transformer_vit_what_are/"
        },
        {
            "author": "u/radi-cho",
            "created_utc": "02-03-2023 04:14:07",
            "distinguished": null,
            "edited": false,
            "id": "10sgxs4",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_10sgxs4",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/10sgxs4/r_p_noisy_sentences_dataset/",
            "score": 0,
            "selftext": "550K sentences in 5 European languages augmented with noise for training and evaluating spell correction tools or machine learning models. We have constructed our dataset to cover representatives from the language families used across Europe.\n\n* Germanic - English, German;\n* Romance - French;\n* Slavic - Bulgarian;\n* Turkic - Turkish;\n\n**Use case example:** Apply language models or other techniques to compare the sentence pairs and reconstruct the original sentences from the augmented ones. You can use a single multilingual solution to solve the challenge or employ multiple models/techniques for the separate languages. Per-word dictionary lookup is also an option.\n\n**Link:** [https://github.com/radi-cho/noisy-sentences-dataset](https://github.com/radi-cho/noisy-sentences-dataset)",
            "spoiler": false,
            "stickied": false,
            "title": "[R] [P] Noisy Sentences Dataset",
            "upvote_ratio": 0.5,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10sgxs4/r_p_noisy_sentences_dataset/"
        },
        {
            "author": "u/loonathefloofyfox",
            "created_utc": "02-03-2023 00:55:12",
            "distinguished": null,
            "edited": false,
            "id": "10sdrp4",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10sdrp4",
            "nsfw": false,
            "num_comments": 4,
            "permalink": "/r/MachineLearning/comments/10sdrp4/d_is_there_a_way_to_access_youtube_alphabetically/",
            "score": 0,
            "selftext": "I'm guessing i probably am not the first person who has wanted to work with youtube data so I'm hoping here is a good place to ask\n\nSo i had an idea to make a neural network that would go through your youtube history and then train a neural network on it. Afterwards if there is a way to access all of youtube by id in a way that you can check every video then you could store all of the id for videos you might like and then use a youtube downloader like youtube-dl to download a certain amount. Was just a dumb idea i had but now i want to actually try it but I'm unsure if I'll actually be able to get the data i need to do it",
            "spoiler": false,
            "stickied": false,
            "title": "[d]? Is there a way to access youtube alphabetically or by id?",
            "upvote_ratio": 0.5,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10sdrp4/d_is_there_a_way_to_access_youtube_alphabetically/"
        },
        {
            "author": "u/YukkiiCode",
            "created_utc": "02-02-2023 21:47:59",
            "distinguished": null,
            "edited": false,
            "id": "10sa859",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_10sa859",
            "nsfw": false,
            "num_comments": 7,
            "permalink": "/r/MachineLearning/comments/10sa859/p_is_it_possible_to_add_more_classes_to_an/",
            "score": 2,
            "selftext": "\\[p\\] I am working on massive dataset, and in the future, we'll have to add some more classes over time, can I train the model in the only new classes?\\[p\\]",
            "spoiler": false,
            "stickied": false,
            "title": "[p] Is it possible to add more classes to an already trained resnet image classifier model without the need to retrain it in all dataset again? [p]",
            "upvote_ratio": 0.67,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10sa859/p_is_it_possible_to_add_more_classes_to_an/"
        },
        {
            "author": "u/AntreasAntoniou",
            "created_utc": "02-02-2023 20:07:20",
            "distinguished": null,
            "edited": "02-02-2023 20:28:57",
            "id": "10s82tf",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_10s82tf",
            "nsfw": false,
            "num_comments": 5,
            "permalink": "/r/MachineLearning/comments/10s82tf/project_i_built_a_minimal_stateless_ml_project/",
            "score": 17,
            "selftext": "Dear r/MachineLearning,\n\nHello everyone! I hope you are all out there having fun, training deep nets and generating fun story-telling with stable-diffusion! :)\n\nI am here today to share with you all a minimal ml project template that I've recently built, which can be found at [https://github.com/AntreasAntoniou/minimal-ml-template/](https://github.com/AntreasAntoniou/minimal-ml-template/). I became increasingly annoyed at how there weren't any repos out there that provided **stateless** ML project templates, which are absolutely necessary when using kubernetes on spot instances, and I decided to build one. By stateless I mean a repo that by default can store model weights in a remote repo and then download them to continue from where it left off if the previous machine dies. The result was this repository.\n\nThe repo remains minimal and extremely readable, all while being packed with a cool stack that I use every day. I'd love to get some feedback, so have a look and let me know.\n\nRegards, Antreas\n\nP.S. A short summary straight from the Github Repo:\n\nThis repo implements a **minimal** machine learning template, that is fully featured for most of the things a machine learning project might need. The most important parts that set this repo apart from the rest are:\n\n1. It is **stateless**. Any given experiment ran using this template, will, automatically and periodically stores the model weights and configuration to [HuggingFace Hub](https://huggingface.co/docs/hub/models-the-hub) and [wandb](https://wandb.ai/site) respectively. As a result, if your machine dies or job exits, and you resume on another machine, the code will automatically locate and download the previous history and continue from where it left off. This makes this repo very useful when using spot instances, or using schedulers like slurm and kubernetes. \n2. It provides support for all the latest and greatest GPU and TPU optimization and scaling algorithms through [HuggingFace Accelerate](https://huggingface.co/docs/accelerate/index).\n3. It provides mature configuration support via [Hydra-Zen](https://github.com/mit-ll-responsible-ai/hydra-zen) and automates configuration generation via [decorators](https://github.com/BayesWatch/minimal-ml-template/blob/af387e59472ea67552b4bb8972b39fe95952dd8a/mlproject/decorators.py#L10) implemented in this repo.\n4. It has a minimal **callback** based boilerplate that allows a user to easily inject any functionality at predefined places in the system without spagettifying the code.\n5. It uses [HuggingFace Models](https://huggingface.co/models) and [Datasets](https://huggingface.co/docs/datasets/index) to streamline building/loading of models, and datasets, but is also not forcing you to use those, allowing for very easy injection of any models and datasets you care about, assuming you use models implemented under PyTorch's `nn.Module` and `Dataset` classes.\n6. It provides plug and play functionality that allows easy hyperparameter search on Kubernetes clusters using [BWatchCompute](https://github.com/BayesWatch/bwatchcompute) and some readily available scripts and yaml templates.\n\n## The Software Stack\n\nThis machine learning project template is built using the following software stack:\n1. Deep Learning Framework: [PyTorch](https://pytorch.org/get-started/locally/)\n2. Dataset storage and retrieval: [Huggingface Datasets](https://huggingface.co/docs/datasets/index)\n3. Model storage and retrieval [Huggingface Hub](https://huggingface.co/docs/hub/models-the-hub), and [HuggingFace Models](https://huggingface.co/models)\n4. GPU/TPU/CPU Optimization and Scaling up options library: [Huggingface Accelerate](https://huggingface.co/docs/accelerate/index)\n5. Experiment configuration + command line argument parsing: [Hydra-zen](https://github.com/mit-ll-responsible-ai/hydra-zen)\n6. Experiment tracking: [Weights and Biases](https://docs.wandb.ai)\n7. Simple python based ML experiment running with Kubernetes using [BWatchCompute](https://github.com/BayesWatch/bwatchcompute)",
            "spoiler": false,
            "stickied": false,
            "title": "[Project] I built a minimal stateless ML project template built on my current favourite stack",
            "upvote_ratio": 0.91,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10s82tf/project_i_built_a_minimal_stateless_ml_project/"
        },
        {
            "author": "u/Naive-Aioli4849",
            "created_utc": "02-02-2023 14:43:30",
            "distinguished": null,
            "edited": false,
            "id": "10s0b47",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_10s0b47",
            "nsfw": false,
            "num_comments": 4,
            "permalink": "/r/MachineLearning/comments/10s0b47/p_domestic_violence_dataset/",
            "score": 1,
            "selftext": "Hi, I am working on  project and for that I need a Twitter Domestic Violence Dataset. Basically I need a dataset with domestic violence tweets against woman.\n\nI have searched Kaggle and other websites but found no luck.\n\nPlus, I tried using Snscrape, but I need some phrases ideas related to domestic violence so I can get some tweets using that. I tried \"Domestic Violence\" , \"My husband tried to kill me\" and looking for more. Help is appreciated.",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Domestic Violence Dataset",
            "upvote_ratio": 0.6,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10s0b47/p_domestic_violence_dataset/"
        },
        {
            "author": "u/seattleite849",
            "created_utc": "02-02-2023 13:44:33",
            "distinguished": null,
            "edited": false,
            "id": "10ryu6b",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_10ryu6b",
            "nsfw": false,
            "num_comments": 12,
            "permalink": "/r/MachineLearning/comments/10ryu6b/p_i_built_an_open_source_platform_to_deploy/",
            "score": 63,
            "selftext": "Hi friends! I ran into this problem enough times at my last few jobs that I built a tool to solve it. I spent many hours building Docker containers for my Python functions, as many of the data science modules required building C libraries (since they significantly speed up compute-intensive routines, such as math calculations). Deploying the containers to AWS Lambda or Fargate (if the processes required more CPU or memory or were >15 minutes) and wiring functions to talk to each other using queues, databases, and blob storage made iterating on the actual code, which wasn't even that complex most of the time, slow.\n\nI made cakework\u00a0[https://github.com/usecakework/cakework](https://github.com/usecakework/cakework), a platform that lets you spin up your Python functions as serverless, production-scale backends with a single command. Using the client SDK, you submit requests, check status, and get results. You can also specify the amount of CPU (up to 16 cores) and memory (up to 128GB) for each individual request, which is helpful when your data size and complexity varies across different requests.\n\nA common pattern that I built cakework for is doing file processing for ML:\n\n\\- ingest data from some source daily, or in response to an external event (data written to blob storage)\n\n\\- run my function (often using pandas/numpy/scipy)\n\n\\- write results to storage, update database\n\n\\- track failures and re-run/fix\n\nIt's open source <3. Here are some fun examples to get you started:\u00a0[https://docs.cakework.com/examples](https://docs.cakework.com/examples)\n\nWould love to hear your thoughts!",
            "spoiler": false,
            "stickied": false,
            "title": "[p] I built an open source platform to deploy computationally intensive Python functions as serverless jobs, with no timeouts",
            "upvote_ratio": 0.93,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10ryu6b/p_i_built_an_open_source_platform_to_deploy/"
        },
        {
            "author": "u/dudester_el",
            "created_utc": "02-02-2023 12:57:52",
            "distinguished": null,
            "edited": false,
            "id": "10rxnsk",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_10rxnsk",
            "nsfw": false,
            "num_comments": 3,
            "permalink": "/r/MachineLearning/comments/10rxnsk/p_time_series_outlier_anomaly_detection/",
            "score": 1,
            "selftext": "I have traffic speed time series data for each day of the week over several months, with data samples about every 30 seconds. I'd like to find periods of time (subsequences) where the speed is much slower than usual. Any recommendations for algorithms that would be well suited to this problem? Thanks",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Time series outlier / anomaly detection",
            "upvote_ratio": 0.67,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10rxnsk/p_time_series_outlier_anomaly_detection/"
        },
        {
            "author": "u/mostlyhydrogen",
            "created_utc": "02-02-2023 11:33:31",
            "distinguished": null,
            "edited": false,
            "id": "10rvkru",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10rvkru",
            "nsfw": false,
            "num_comments": 22,
            "permalink": "/r/MachineLearning/comments/10rvkru/d_querying_with_multiple_vectors_during_embedding/",
            "score": 5,
            "selftext": "Are there tools or techniques that permit you to joint query using more than one query vector? \n\nUse case: iterative ANN search refinement, where I start with a seed vector, select matches, and re-query with more examples to improve the search results.\n\nI tried doing this with FAISS, but it performs a \"batch query\" that returns a separate set of results for each query vector (not a joint query).",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Querying with multiple vectors during embedding nearest neighbor search?",
            "upvote_ratio": 0.86,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10rvkru/d_querying_with_multiple_vectors_during_embedding/"
        },
        {
            "author": "u/Temporary_Cap_2855",
            "created_utc": "02-02-2023 10:23:56",
            "distinguished": null,
            "edited": false,
            "id": "10rtv0b",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10rtv0b",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/10rtv0b/d_do_high_leverage_points_affect_neural_net_and/",
            "score": 0,
            "selftext": "I know they can affect linear regression badly but given the fact that neural net and tree-based models can approximate non-linear complex functions, I don't think the high leverage points would be a problem. Just curious about your opinion whether my thinking makes sense",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Do high leverage points affect Neural Net and Tree-based model?",
            "upvote_ratio": 0.5,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10rtv0b/d_do_high_leverage_points_affect_neural_net_and/"
        },
        {
            "author": "u/netw0rkf10w",
            "created_utc": "02-02-2023 10:10:24",
            "distinguished": null,
            "edited": false,
            "id": "10rtis6",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10rtis6",
            "nsfw": false,
            "num_comments": 13,
            "permalink": "/r/MachineLearning/comments/10rtis6/d_imagenet_normalization_vs_1_1_normalization/",
            "score": 2,
            "selftext": "For ImageNet classification, there are two common ways of normalizing the input images:\n\n\\- Normalize to `[-1, 1]` using an affine transformation (`2*(x/255) - 1`).\n\n\\- Normalize using ImageNet `mean = (0.485, 0.456, 0.406)` and `std = (0.229, 0.224, 0.225)`.\n\nI observe that the first one is more common in TensorFlow codebases (including Jax models with TensorFlow data processing, e.g. the official Vision Transformers code), whereas the second is ubiquitous in PyTorch codebases.\n\nI tried to find empirical comparisons of the two, but there doesn't seem to be any.\n\nWhich one is better in your opinion? I guess the performance shouldn't be too different, but still it's interesting to hear your experience.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] ImageNet normalization vs [-1, 1] normalization",
            "upvote_ratio": 1.0,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10rtis6/d_imagenet_normalization_vs_1_1_normalization/"
        },
        {
            "author": "u/Emergency-Dig-5262",
            "created_utc": "02-02-2023 09:32:18",
            "distinguished": null,
            "edited": false,
            "id": "10rsldp",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10rsldp",
            "nsfw": false,
            "num_comments": 6,
            "permalink": "/r/MachineLearning/comments/10rsldp/d_pc_takes_a_long_time_to_execute_code/",
            "score": 0,
            "selftext": "Hello people,\n\nI am currently attending a Data Science course and to finish I have to write a paper about a project that I am currently working on. I write the code in VSCode and I use .ipynb notebooks.\n\nSo I am basically training a few ML models after a long data preprocessing which worked out fine. But as soon as I run my hyperparameter tuning code, my PC takes a lot of time. Right now I am running hyperparameter tuning for RandomForest and it already runs for 21 hours.\n\nIs there any possibility for me to run my code somewhere else? I read abour Heroku, but that seems to be too much than what I am looking for. I am getting a bit nervous, because I want to get this paper done. The worst case is that I have to buy a new PC.\n\nThank you so much!",
            "spoiler": false,
            "stickied": false,
            "title": "[D] PC takes a long time to execute code, possibility to use a cloud/external device?",
            "upvote_ratio": 0.33,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10rsldp/d_pc_takes_a_long_time_to_execute_code/"
        },
        {
            "author": "u/bikeskata",
            "created_utc": "02-02-2023 07:55:47",
            "distinguished": null,
            "edited": false,
            "id": "10rqe34",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "News",
            "locked": false,
            "name": "t3_10rqe34",
            "nsfw": false,
            "num_comments": 132,
            "permalink": "/r/MachineLearning/comments/10rqe34/n_microsoft_integrates_gpt_35_into_teams/",
            "score": 458,
            "selftext": "Official blog post: https://www.microsoft.com/en-us/microsoft-365/blog/2023/02/01/microsoft-teams-premium-cut-costs-and-add-ai-powered-productivity/\n\nGiven the amount of money they pumped into OpenAI, it's not surprising that you'd see it integrated into their products. I do wonder how this will work in highly regulated fields (finance, law, medicine, education).",
            "spoiler": false,
            "stickied": false,
            "title": "[N] Microsoft integrates GPT 3.5 into Teams",
            "upvote_ratio": 0.97,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10rqe34/n_microsoft_integrates_gpt_35_into_teams/"
        },
        {
            "author": "u/alpha-meta",
            "created_utc": "02-02-2023 07:13:31",
            "distinguished": null,
            "edited": false,
            "id": "10rpj0f",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": null,
            "locked": false,
            "name": "t3_10rpj0f",
            "nsfw": false,
            "num_comments": 27,
            "permalink": "/r/MachineLearning/comments/10rpj0f/d_why_do_llms_like_instructgpt_and_llm_use_rl_to/",
            "score": 52,
            "selftext": "Aligned LLMs such as InstructGPT and ChatGPT are trained via supervised fine-tuning after the initial self-supervised pretraining. Then, the researchers train a reward model on responses ranked by humans. \n\nWhen I understand correctly, they let the LLM generate responses that humans have to rank on a scale from 1-5. Then, they train a reward model (I suppose in supervised fashion?) on these ranked outputs. Once that's done, they use reinforcement learning (RL) with proximal policy optimization (PPO) to update the LLM. \n\nMy question is why they use RL with PPO for this last step? Why don't they fine-tune the LLM using regular supervised learning, whereas the human-ranked outputs represent the labels. Since these are labels in the range 1-5, this could be a ranking or ordinal regression loss for supervised learning.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Why do LLMs like InstructGPT and LLM use RL to instead of supervised learning to learn from the user-ranked examples?",
            "upvote_ratio": 0.97,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10rpj0f/d_why_do_llms_like_instructgpt_and_llm_use_rl_to/"
        },
        {
            "author": "u/noellarkin",
            "created_utc": "02-01-2023 23:20:10",
            "distinguished": null,
            "edited": false,
            "id": "10rhprm",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": null,
            "locked": false,
            "name": "t3_10rhprm",
            "nsfw": false,
            "num_comments": 8,
            "permalink": "/r/MachineLearning/comments/10rhprm/dhow_will_open_source_alternatives_compete_with/",
            "score": 12,
            "selftext": "To clarify, I'm not talking about ChatGPT here. I've been testing outputs from GPT-3 davinci003 against alternatives in terms of output quality, relevance, and ability to understand \"instruct\" (versus vanilla autocompletion).\n\nI tried these:\nAI21 Jurassic 178B\nNeoX 20B\nGPT J 6B\nFairSeq 13B\n\nAs well as:\nGPT-3 davinci002\nGPT-3 davinci001\n\n\nOf course, I didn't expect the smaller models to be on par with GPT-3, but I was surprised at how much better GPT3 davinci 003 performed compared to AI21's 178B model. AI21's Jurassic 178B seems to be comparable to GPT3 davinci 001.\n\n\nDoes this mean that only well-funded corporations will be able to train general-purpose LLMs? It seems to me that just having a large model doesn't do much, it's also about several iterations of training and feedback. How are open source alternatives going to be able to compete?\n\n\n(I'm not in the ML or CS field, just an amateur who enjoys using these models)",
            "spoiler": false,
            "stickied": false,
            "title": "[D]How Will Open Source Alternatives Compete With GPT3?",
            "upvote_ratio": 0.83,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10rhprm/dhow_will_open_source_alternatives_compete_with/"
        },
        {
            "author": "u/pahalie",
            "created_utc": "02-02-2023 07:06:44",
            "distinguished": null,
            "edited": false,
            "id": "10rpebe",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10rpebe",
            "nsfw": false,
            "num_comments": 2,
            "permalink": "/r/MachineLearning/comments/10rpebe/d_inconsistent_featurespace_in_data/",
            "score": 1,
            "selftext": "Hi colleagues!\n\nI  am working on a model for which I have a dataset consisting of 2 data  sources. Problem is that one datastream starts in 2017 and the other  only in 2022. Feature spaces from those 2 data streams are different.\n\nI  am wondering if there is a methodology to follow which allows me to use  both data streams for training even though one starts way later than  the other. Or am I forced to drop the newer one? (just 2022 data from  two sources is too small for me to train on)\n\nThank you!",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Inconsistent Featurespace in Data",
            "upvote_ratio": 1.0,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10rpebe/d_inconsistent_featurespace_in_data/"
        },
        {
            "author": "u/mfarahmand98",
            "created_utc": "02-02-2023 06:58:02",
            "distinguished": null,
            "edited": false,
            "id": "10rp7ze",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10rp7ze",
            "nsfw": false,
            "num_comments": 4,
            "permalink": "/r/MachineLearning/comments/10rp7ze/d_commercial_use_of_a_model_that_has_been_trained/",
            "score": 7,
            "selftext": " I wanted to use the [Learnable Trainangulation](https://github.com/karfly/learnable-triangulation-pytorch) model in a commercial project. The source code itself is under MIT licensing. However, the dataset they have used is [Human3.6M](http://vision.imar.ro/human3.6m/description.php), which states that the [license](http://vision.imar.ro/human3.6m/eula.php) is \"FREE OF CHARGE FOR ACADEMIC USE ONLY\".\n\nYet, recent court rulings (in the US) state that models can use copyrighted data during training, and the results are no longer bound by that copyright (e.g. Google Books). Does the same apply here?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Commercial Use of a Model that has been trained using Human3.6M",
            "upvote_ratio": 0.77,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10rp7ze/d_commercial_use_of_a_model_that_has_been_trained/"
        },
        {
            "author": "u/healthymonkey100",
            "created_utc": "02-02-2023 04:13:59",
            "distinguished": null,
            "edited": false,
            "id": "10rmi74",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10rmi74",
            "nsfw": false,
            "num_comments": 3,
            "permalink": "/r/MachineLearning/comments/10rmi74/d_global_optimum_of_kmeans_cost_function/",
            "score": 5,
            "selftext": "I've recently started reading up on classical ML and I got a question about K-Means.\n\nMore concretely, I am confused about the uniqueness of the global optimal solution of K-Means's cost function.\n\nLet's state the problem formally below, extracted from Bishop's Pattern Recognition and Machine Learning book, exercise 9.1.\n\nConsider the \ud835\udc3e-means algorithm discussed in Section 9.1. Show that as a consequence of there being a finite number of possible assignments for the set of discrete indicator variables \ud835\udc5f\ud835\udc5b\ud835\udc58, and that for each such assignment there is a unique optimum for the \ud835\udf41\ud835\udc58, the K-means algorithm must converge after a finite number of iterations.\n\nI made an answer \\[here\\]([https://stats.stackexchange.com/questions/603327/question-on-the-proof-of-convergence-of-k-means](https://stats.stackexchange.com/questions/603327/question-on-the-proof-of-convergence-of-k-means)) detailing the proof of why it does converge in Lloyd's algorithm, but I think I still do not understand why Lloyd's do not converge to a global minimum, which mathematical theorem/understanding am I missing here?\n\nI think that optimizing both the assignments and the centroids of K-Means at the same time is non-convex and hence there are many local minimums, we can use brute force to search for the global minimum but of course it is exponential to the number of data points. On the other hand, Lloyd optimizes it (greedily) alternatively, and hence you will find the cost functions' local minima (guaranteed)?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Global Optimum of K-Means Cost Function",
            "upvote_ratio": 1.0,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10rmi74/d_global_optimum_of_kmeans_cost_function/"
        },
        {
            "author": "u/radi-cho",
            "created_utc": "02-02-2023 04:06:03",
            "distinguished": null,
            "edited": false,
            "id": "10rmdwa",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_10rmdwa",
            "nsfw": false,
            "num_comments": 3,
            "permalink": "/r/MachineLearning/comments/10rmdwa/p_r_a_simplistic_ui_to_edit_images_with_stable/",
            "score": 37,
            "selftext": "https://preview.redd.it/ut4us5251rfa1.png?width=2000&format=png&auto=webp&v=enabled&s=bf0add1de91537cb806f9f81405d065c95a42cc4\n\nCurrently, the UI supports a picture upload and uses InstructPix2Pix to edit it. Also, it uses upscaling models for quality enhancements. More models are coming soon.\n\nThe goal is to provide a way for non-ML people to use diffusion-based image editing through simplistic app design. Web demo: [https://diffground.com/](https://diffground.com/)",
            "spoiler": false,
            "stickied": false,
            "title": "[P] [R] A simplistic UI to edit images with Stable Diffusion and InstructPix2Pix",
            "upvote_ratio": 0.89,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10rmdwa/p_r_a_simplistic_ui_to_edit_images_with_stable/"
        },
        {
            "author": "u/Bishwa12",
            "created_utc": "02-01-2023 21:48:09",
            "distinguished": null,
            "edited": false,
            "id": "10rfu2x",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_10rfu2x",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/10rfu2x/r_sentence_autoencoder/",
            "score": 0,
            "selftext": "Any suggestion on sentence auto-encoder? I want to learn the vector representation of a sentence and reconstruct the sentence itself. I used plane LSTM with self attention in the encoder and decoder architecture (no cross attention) but the results are not that good enough.   I can not use cross attention i.e decoder will not have access to all the outputs of encoder but only access to the bottleneck latent vector. BART have pre-trained in similar manner but I don't know if we can pre-train that model to fit my use case.   This is just a module of other work, after pre-training the sentence-sentence auto-encoder, I need to add some more module in between them, so I should have encoder and decoder separable, which I think can not be done in BART as well.   Any direction would be much appreciated.   Thank you",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Sentence autoencoder",
            "upvote_ratio": 0.5,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10rfu2x/r_sentence_autoencoder/"
        },
        {
            "author": "u/alkibijad",
            "created_utc": "02-01-2023 18:04:00",
            "distinguished": null,
            "edited": false,
            "id": "10raouh",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10raouh",
            "nsfw": false,
            "num_comments": 8,
            "permalink": "/r/MachineLearning/comments/10raouh/d_apples_anetransformers_experiences/",
            "score": 22,
            "selftext": "I'm using Huggingface's transformers regularly for experimentations, but I plan to deploy some of the models to iOS.\n\nI have found [ml-ane-transformers](https://github.com/apple/ml-ane-transformers/tree/main/ane_transformers) repo from Apple, which shows how transformers can be rewritten to have much better performance on Apple's devices. There's an example of DistilBERT implemented in that optimized way.\n\nAs I plan to deploy transformers to iOS, I started thinking about this. I'm hoping some already have experience about this, so we can discuss:\n\n* Has anyone tried this themselves? Do they actually see the improvements in performance on iOS?\n* I'm using Huggingface's transformer models in my experiments. How much work do you think there is to rewrite model in this optimized way?\n* It's very difficult to train transformers from scratch (especially if they're big :) ), so I'm fine-tuning on top of pre-trained models on Huggingface. Is it possible to use weights from pretrained Huggingface models with the Apple's reference code? How difficult is it?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Apple's ane-transformers - experiences?",
            "upvote_ratio": 0.9,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10raouh/d_apples_anetransformers_experiences/"
        },
        {
            "author": "u/CeFurkan",
            "created_utc": "02-01-2023 17:08:19",
            "distinguished": null,
            "edited": false,
            "id": "10r9biu",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10r9biu",
            "nsfw": false,
            "num_comments": 10,
            "permalink": "/r/MachineLearning/comments/10r9biu/d_any_open_source_model_or_application_to_remove/",
            "score": 4,
            "selftext": "Currently I am using Davinci Resolve free edition to manually cut / remove no speech parts, or the parts where I take a breath\n\nIt is extremely time consuming\n\nI am pretty sure this can be done via AI\n\nFor example whisper is able to detect where we use filler words such as umh, um, uh etc\n\nThat would be awesome to automatically remove these parts from a video\n\nJust direct me where to look thank you",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Any open source model, or application to remove no speech parts of a video?",
            "upvote_ratio": 0.75,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10r9biu/d_any_open_source_model_or_application_to_remove/"
        },
        {
            "author": "u/dahdarknite",
            "created_utc": "02-01-2023 14:39:12",
            "distinguished": null,
            "edited": false,
            "id": "10r5gku",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": null,
            "locked": false,
            "name": "t3_10r5gku",
            "nsfw": false,
            "num_comments": 7,
            "permalink": "/r/MachineLearning/comments/10r5gku/d_why_is_stable_diffusion_much_smaller_than/",
            "score": 25,
            "selftext": "Stable diffusion seems to be a departure from the trend of building larger and larger models.\n\nIt has 10x less parameters than other image generation models like DALLE-2.\n\n[\u201cIncredibly, compared with DALL-E 2 and Imagen, the Stable Diffusion model is a lot smaller. While DALL-E 2 has around 3.5 Billion parameters, and Imagen has 4.6 Billion, the first Stable Diffusion model has just 890 million parameters, which means it uses a lot less VRAM and can actually be run on consumer-grade graphics cards.\u201d](https://medium.com/nightcafe-creator/stable-diffusion-tutorial-how-to-use-stable-diffusion-157785632eb3)\n\n\nWhat allows stable diffusion to work so well with a lot less parameters? Are there any drawbacks to this, like requiring stable diffusion to be fine tuned more than DALLE-2 for example?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Why is stable diffusion much smaller than predecessors?",
            "upvote_ratio": 0.96,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10r5gku/d_why_is_stable_diffusion_much_smaller_than/"
        },
        {
            "author": "u/bikeskata",
            "created_utc": "02-01-2023 15:59:38",
            "distinguished": null,
            "edited": false,
            "id": "10r7k0h",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "News",
            "locked": false,
            "name": "t3_10r7k0h",
            "nsfw": false,
            "num_comments": 50,
            "permalink": "/r/MachineLearning/comments/10r7k0h/n_openai_starts_selling_subscriptions_to_its/",
            "score": 50,
            "selftext": "https://www.axios.com/2023/02/01/chatgpt-subscriptions-chatbot-openai\n\nNot fully paywalled, but there's a tiering system.",
            "spoiler": false,
            "stickied": false,
            "title": "[N] OpenAI starts selling subscriptions to its ChatGPT bot",
            "upvote_ratio": 0.9,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10r7k0h/n_openai_starts_selling_subscriptions_to_its/"
        },
        {
            "author": "u/wellfriedbeans",
            "created_utc": "02-01-2023 15:28:13",
            "distinguished": null,
            "edited": false,
            "id": "10r6qn0",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10r6qn0",
            "nsfw": false,
            "num_comments": 23,
            "permalink": "/r/MachineLearning/comments/10r6qn0/d_normalizing_flows_in_2023/",
            "score": 20,
            "selftext": "What is the state of research in normalizing flows in 2023? Have they been superseded by diffusion models for sample generation? If so, what are some other applications where normalizing flows are still SOTA (or even useful)?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Normalizing Flows in 2023?",
            "upvote_ratio": 0.92,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10r6qn0/d_normalizing_flows_in_2023/"
        },
        {
            "author": "u/dle88",
            "created_utc": "02-01-2023 14:49:35",
            "distinguished": null,
            "edited": false,
            "id": "10r5qev",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10r5qev",
            "nsfw": false,
            "num_comments": 3,
            "permalink": "/r/MachineLearning/comments/10r5qev/d_advice_for_a_multilabel_classification_problem/",
            "score": 0,
            "selftext": "Hi guys, I have a dataset of 12,000 products, each of which consists of a title, description, and some images. In addition, I also have a pre-defined set of product categories. \n\nCurious to learn if anyone has any suggestions on what model to be used to train using this dataset as input to classify each product in the dataset into the related categories within the given set?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Advice for a multi-label classification problem",
            "upvote_ratio": 0.4,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10r5qev/d_advice_for_a_multilabel_classification_problem/"
        },
        {
            "author": "u/pm_me_your_pay_slips",
            "created_utc": "02-01-2023 14:29:56",
            "distinguished": null,
            "edited": false,
            "id": "10r57pn",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_10r57pn",
            "nsfw": false,
            "num_comments": 78,
            "permalink": "/r/MachineLearning/comments/10r57pn/r_extracting_training_data_from_diffusion_models/",
            "score": 153,
            "selftext": "[https://twitter.com/eric\\_wallace\\_/status/1620449934863642624?s=46&t=GVukPDI7944N8-waYE5qcw](https://twitter.com/eric_wallace_/status/1620449934863642624?s=46&t=GVukPDI7944N8-waYE5qcw)\n\nExtracting training data from diffusion models is possible by following, more or less, these steps:\n\n* Compute CLIP embeddings for the images in a training dataset.\n* Perform an all-pairs comparison and mark the pairs with l2 distance smaller than some threshold as near duplicates\n* Use the prompts for training samples marked as near duplicates to generate N synthetic samples with the trained model\n* Compute the all-pairs  l2 distance between the embeddings of generated samples for a given training prompt. Build a graph where the nodes are generated samples and an edge exists if the l2 distance is less than some threshold. If the largest clique in the resulting graph is of size 10, then the training sample is considered to be memorized.\n* Visually inspect the results to determine if the samples considered to be memorized are similar to the training data samples.\n\nWith this method, the authors were able to find samples from Stable Diffusion and Imagen  corresponding to copyrighted training images.",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Extracting Training Data from Diffusion Models",
            "upvote_ratio": 0.94,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10r57pn/r_extracting_training_data_from_diffusion_models/"
        },
        {
            "author": "u/hopedallas",
            "created_utc": "02-01-2023 13:45:27",
            "distinguished": null,
            "edited": "02-01-2023 13:51:52",
            "id": "10r417m",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10r417m",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/10r417m/d_vectorizing_computation_of_the_jaccard/",
            "score": 4,
            "selftext": "I am trying to claculate the Jaccard similarity between all instances in my dataframe. I am using the following method to do so, however, this method is painfully slow. My \\`\\`\\`data\\_with\\_labels\\`\\`\\` shape is (221277, 217).\n\n`# Compute the Jaccard similarity between all instances`\n\n`n_instances = data_with_labels.shape[0]`\n\n`jaccard_similarity_matrix = np.zeros((n_instances, n_instances))`\n\n`for i in range(n_instances):`\n\n`for j in range(n_instances):`\n\n`jaccard_similarity_matrix[i, j] = jaccard_score(data_with_labels[i, :],   data_with_labels[j, :], average='micro')`\n\n&#x200B;\n\nIs there any way to do this process with numpy vectorization? I tried soomething like this but keep getting this error:\n\n`n_instances = data_with_labels.shape[0]`\n\n`jaccard_similarity_matrix = np.zeros((n_instances, n_instances))`\n\n`for i in range(n_instances):`\n\n`jaccard_similarity_matrix[i, :] = jaccard_score(data_with_labels[i, :], data_with_labels, average='micro')`\n\n`ValueError: Found input variables with inconsistent numbers of samples: [217, 221277]`\n\n&#x200B;",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Vectorizing computation of the Jaccard similarity between all instances in a large dataset in Python",
            "upvote_ratio": 0.83,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10r417m/d_vectorizing_computation_of_the_jaccard/"
        },
        {
            "author": "u/chaitjo",
            "created_utc": "02-01-2023 13:07:11",
            "distinguished": null,
            "edited": false,
            "id": "10r31eo",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_10r31eo",
            "nsfw": false,
            "num_comments": 7,
            "permalink": "/r/MachineLearning/comments/10r31eo/r_on_the_expressive_power_of_geometric_graph/",
            "score": 39,
            "selftext": "Geometric GNNs are an emerging class of GNNs for **spatially embedded graphs** in scientific and engineering applications, s.a. biomolecular structure, material science, and physical simulations. Notable examples include SchNet, DimeNet, Tensor Field Networks, and E(n) Equivariant GNNs.\n\n**How powerful are geometric GNNs?** How do key design choices influence expressivity and how to build maximally powerful ones?\n\nCheck out this recent paper for more:\n\n\ud83d\udcc4 PDF: [http://arxiv.org/abs/2301.09308](http://arxiv.org/abs/2301.09308)\n\n\ud83d\udcbb Code: [http://github.com/chaitjo/geometric-gnn-dojo](http://github.com/chaitjo/geometric-gnn-dojo)\n\n\ud83d\udca1Key findings: [https://twitter.com/chaitjo/status/1617812402632019968](https://twitter.com/chaitjo/status/1617812402632019968)\u00a0\n\nP.S. Are you new to Geometric GNNs, GDL, PyTorch Geometric, etc.? Want to understand how theory/equations connect to real code?\n\nTry this **Geometric GNN 101 notebook**\u00a0before diving in:  \n[https://github.com/chaitjo/geometric-gnn-dojo/blob/main/geometric\\_gnn\\_101.ipynb](https://github.com/chaitjo/geometric-gnn-dojo/blob/main/geometric_gnn_101.ipynb)",
            "spoiler": false,
            "stickied": false,
            "title": "[R] On the Expressive Power of Geometric Graph Neural Networks",
            "upvote_ratio": 0.92,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10r31eo/r_on_the_expressive_power_of_geometric_graph/"
        },
        {
            "author": "u/latefordinnerstudios",
            "created_utc": "02-01-2023 12:16:48",
            "distinguished": null,
            "edited": false,
            "id": "10r1pg3",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_10r1pg3",
            "nsfw": false,
            "num_comments": 8,
            "permalink": "/r/MachineLearning/comments/10r1pg3/p_an_open_source_tool_for_repeatable_pytorch/",
            "score": 25,
            "selftext": "I made a new open source tool called JellyML that lets you go back to any of your checkpoints, and reproduce your code exactly as it was when you trained it.\n\nYou can find the website here:\n\n https://jellyml.com\n\nThe GitHub repo: \n\nhttps://gitHub.com/mmulet/jellyml\n\nYou can install it with pip: \n\npip install jellyml",
            "spoiler": false,
            "stickied": false,
            "title": "[P] An open source tool for repeatable PyTorch experiments by embedding your code in each model checkpoint",
            "upvote_ratio": 0.91,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10r1pg3/p_an_open_source_tool_for_repeatable_pytorch/"
        },
        {
            "author": "u/PassingTumbleweed",
            "created_utc": "02-01-2023 10:55:38",
            "distinguished": null,
            "edited": false,
            "id": "10qzlhw",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10qzlhw",
            "nsfw": false,
            "num_comments": 26,
            "permalink": "/r/MachineLearning/comments/10qzlhw/d_what_does_a_dl_role_look_like_in_ten_years/",
            "score": 73,
            "selftext": "Every day, there seems to be new evidence of the generalization capabilities of LLMs.\n\nWhat does this mean for the future role of deep learning experts in academia and business? \n\nIt seems like there's a significant chance that skills such as PyTorch and Jax will be displaced by prompt construction and off-the-shelf model APIs, with only a few large institutions working on the DNN itself.\n\nCurious to hear others' thoughts on this.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] What does a DL role look like in ten years?",
            "upvote_ratio": 0.88,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10qzlhw/d_what_does_a_dl_role_look_like_in_ten_years/"
        },
        {
            "author": "u/akshaysri0001",
            "created_utc": "02-01-2023 09:37:43",
            "distinguished": null,
            "edited": false,
            "id": "10qxona",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10qxona",
            "nsfw": false,
            "num_comments": 3,
            "permalink": "/r/MachineLearning/comments/10qxona/d_tortoise_tts_api_for_gpt3/",
            "score": 4,
            "selftext": "Hey everyone, \nI thought of an idea to create a human like realistic voice assistant for ChatGPT. So I have a question that can we make an API of tortoise TTS trained on a specific voice. I've seen a lot of companies nowadays that provides most realistic text to speech solutions like eleven labs etc. Do they train these voices on tortoise TTS?? If there is another way of creating highly realistic voices and make an API of it, then please tell me how can I do it? \nAnd also how can I make this process fast as regular normal TTS?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Tortoise TTS API for GPT-3.",
            "upvote_ratio": 0.67,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10qxona/d_tortoise_tts_api_for_gpt3/"
        },
        {
            "author": "u/R-PRADY",
            "created_utc": "02-01-2023 09:21:08",
            "distinguished": null,
            "edited": false,
            "id": "10qxabo",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_10qxabo",
            "nsfw": false,
            "num_comments": 3,
            "permalink": "/r/MachineLearning/comments/10qxabo/p_predictive_modeling_multi_stage_classification/",
            "score": 0,
            "selftext": "Problem statement: assume a user come into a system and it typically takes 10 weeks for outcome(yes,no). I want to build a model which predicts the outcome on any particular week say how likely are they gonna succeed on week 1,2,3 etc.\n\nQuestion on model building approach: should I build weekly models and get the prediction ? Or is there a better way to do it. Ideally it would be great have single model that can be used for different weeks. I prefer the latter. \n\nAppreciate your ideas",
            "spoiler": false,
            "stickied": false,
            "title": "[P] predictive modeling- Multi stage classification",
            "upvote_ratio": 0.4,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10qxabo/p_predictive_modeling_multi_stage_classification/"
        },
        {
            "author": "u/hasiemasie",
            "created_utc": "02-01-2023 07:51:53",
            "distinguished": null,
            "edited": false,
            "id": "10qv7r7",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_10qv7r7",
            "nsfw": false,
            "num_comments": 6,
            "permalink": "/r/MachineLearning/comments/10qv7r7/p_ner_output_label_post_processing/",
            "score": 1,
            "selftext": "I\u2019m looking to some aggregation on academic research and news articles to see what insights I get from it. I\u2019m using textrazor to do named entity recognition on the documents, but getting a lot of dirty labels that have slightly different wording. For example, Tesla, Tesla ltd, Tesla Ltd. As a result, my aggregations have a lot of duplicate results.\n\nThe dataset consists of about 4M labels so the solution has to be efficient to be viable. I was thinking of putting the labels through word2vec and then clustering them based on the word embedding distances? But then the problem arises of how many clusters to use?\n\nI\u2019ve also tried simple regex preprocessing to get rid of the company abbreviations but there are other examples that cannot be solved that easily.",
            "spoiler": false,
            "stickied": false,
            "title": "[P] NER output label post processing",
            "upvote_ratio": 1.0,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10qv7r7/p_ner_output_label_post_processing/"
        },
        {
            "author": "u/madnessone1",
            "created_utc": "02-01-2023 07:50:59",
            "distinguished": null,
            "edited": false,
            "id": "10qv72a",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10qv72a",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/10qv72a/d_a_report_that_compares_the_practices_of/",
            "score": 0,
            "selftext": "Discussion about a report that compares the practices and attitudes of companies that self-report as ahead of the competition in AI adoption in Europe, compared to companies that identify as behind or at the same stage as their competitors. It contains some interesting findings mixed with some somewhat obvious things.\n\n\n- Kinda obvious that leading companies also are further ahead in using MLOps, but I thought it was interesting to see the frequency of fine-tuning and retraining.\n\n- Not as obvious that most companies report a lack of access to training data, would have thought that is mostly something that smaller companies have issues with.\n\n- Also not so obvious to me is that companies with a centralized decision-making related to AI seem to dominate among high-performers.\n\n- Interesting that most companies seem to get some value out of their AI/ML projects, which seems to contradict some of the previous forecasts by the big consultancy companies.\n\nLink to the report: https://stagezero.ai/2022-survey-report/",
            "spoiler": false,
            "stickied": false,
            "title": "[D] A report that compares the practices of high-performing companies in Europe to laggards in AI adoption",
            "upvote_ratio": 0.13,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10qv72a/d_a_report_that_compares_the_practices_of/"
        },
        {
            "author": "u/jayalammar",
            "created_utc": "02-01-2023 07:49:23",
            "distinguished": null,
            "edited": "02-01-2023 08:57:49",
            "id": "10qv5um",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_10qv5um",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/10qv5um/r_emnlp_video_interviews_workshops_and_posters/",
            "score": 0,
            "selftext": "I learned a lot at EMNLP in December and captured some of what I learned in this video.\n\n**Interviews**\n\nI asked five NLP researchers these questions:\n\n1- What is the most exciting development in NLP in 2022\n\n2- What are you looking forward to in 2023?\n\n3- What is an underrated idea that the field should pay more attention to?\n\nTheir answers start at [01:22](https://www.youtube.com/watch?v=plCvF_7qrmY&t=82s).\n\n**Workshops**\n\nI got to spend time at these workshops:\n\n* [Generation, Evaluation & Metrics (GEM)](https://gem-benchmark.com/workshop)\n* [Massively Multilingual NLU](https://mmnlu-22.github.io/)\n* [Blackbox NLP](https://blackboxnlp.github.io/2022/)\n\nMy main takeaways are at [09:25](https://www.youtube.com/watch?v=plCvF_7qrmY&t=565s).\n\n**Posters**\n\nIf you've been to a conference you'd know there's an overwhelming number of posters. I recorded four of the ones I came across and thought were interesting (covering retrieval-augmented text generation, human evaluation, the BLOOM multimodal dataset, and a multimodal method to name music playlists).\n\nPoster presentations start at [14:38](https://www.youtube.com/watch?v=plCvF_7qrmY&t=878s)\n\nFull video: [https://www.youtube.com/watch?v=plCvF\\_7qrmY](https://www.youtube.com/watch?v=plCvF_7qrmY)\n\n&#x200B;\n\nWhat's your answer to these questions?\n\n>1- What is the most exciting development in NLP in 2022  \n>  \n>2- What are you looking forward to in 2023?  \n>  \n>3- What is an underrated idea that the field should pay more attention to?\n\n&#x200B;",
            "spoiler": false,
            "stickied": false,
            "title": "[R] EMNLP video interviews, workshops, and posters",
            "upvote_ratio": 0.5,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10qv5um/r_emnlp_video_interviews_workshops_and_posters/"
        },
        {
            "author": "u/0xideas",
            "created_utc": "02-01-2023 03:36:02",
            "distinguished": null,
            "edited": false,
            "id": "10qpcy4",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_10qpcy4",
            "nsfw": false,
            "num_comments": 2,
            "permalink": "/r/MachineLearning/comments/10qpcy4/p_a_cli_tool_for_easy_transformer_sequence/",
            "score": 14,
            "selftext": "Hi everyone,\n\nI have developed a CLI tool to train a transformer sequence classification model. There are also options for preprocessing data and inference on new data. I was thinking that interesting use cases might be found within economics/finance and biological domains, and would be super interested in feedback on:\n\n\\- if the documentation is intelligible and enables you to use it  \n\\- to which use cases from your industry/domain could discrete sequence modelling be applied  \n\\- what additional features you'd need for it to be useful to you\n\nBasically, where would the prediction of a class (or the next item) based on discrete events/objects/tokens be useful?\n\nThe project is called \"sequifier\" and can be found here: [https://github.com/0xideas/sequifier](https://github.com/0xideas/sequifier)",
            "spoiler": false,
            "stickied": false,
            "title": "[P] A CLI tool for easy transformer sequence classifier training and inference",
            "upvote_ratio": 0.86,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10qpcy4/p_a_cli_tool_for_easy_transformer_sequence/"
        },
        {
            "author": "u/leepenkman",
            "created_utc": "02-01-2023 02:22:07",
            "distinguished": null,
            "edited": false,
            "id": "10qobgk",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_10qobgk",
            "nsfw": false,
            "num_comments": 22,
            "permalink": "/r/MachineLearning/comments/10qobgk/p_self_hostable_openai_alternative/",
            "score": 0,
            "selftext": "Hi,  \n\n\n[Text-Generator.io](https://text-generator.io/) is now self hostable, It's priced at $1000 USD per instance per year to self host.  \n\n\nThe service runs on a single 24GB VRAM GPU, and runs all services including [speech to text](https://text-generator.io/blog/cost-effective-speech-to-text-api), text and code generation for almost all languages and [generating embeddings](https://text-generator.io/blog/embed-images-text-and-code) too.  \n\n\nThe text generator also [downloads and analyses any input with links](https://text-generator.io/blog/text-generator-now-researches-via-crawling) including documents, images, images with text inside and webpages for better understanding and to generate better text.  \n\n\nIt's a great alternative to OpenAI and has a [compatible API making switching easy](https://text-generator.io/blog/over-10x-openai-cost-savings-one-line-change).  \n\n\nYou can check out the [new pricing here](https://text-generator.io/subscribe).  \n\n\nLet me know what you think and if there's anything i can do to help!  \n\n\nAll the best.  \nLee Penkman - Founder [Text-Generator.io](https://text-generator.io/)",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Self Hostable OpenAI Alternative",
            "upvote_ratio": 0.43,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10qobgk/p_self_hostable_openai_alternative/"
        },
        {
            "author": "u/logTom",
            "created_utc": "01-31-2023 23:48:32",
            "distinguished": null,
            "edited": "01-31-2023 23:51:38",
            "id": "10qlx29",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_10qlx29",
            "nsfw": false,
            "num_comments": 12,
            "permalink": "/r/MachineLearning/comments/10qlx29/r_seti_finds_eight_potential_alien_signals_with_ml/",
            "score": 28,
            "selftext": "GitHub (sadly without weights).   https://github.com/PetchMa/ML_GBT_SETI  \nNews.  \nhttps://www-scinexx-de.translate.goog/news/kosmos/seti-findet-acht-potenzielle-alien-signale/?_x_tr_sl=de&_x_tr_tl=en&_x_tr_hl=de&_x_tr_pto=wapp",
            "spoiler": false,
            "stickied": false,
            "title": "[R] SETI finds eight potential alien signals with ML",
            "upvote_ratio": 0.77,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10qlx29/r_seti_finds_eight_potential_alien_signals_with_ml/"
        },
        {
            "author": "u/starstruckmon",
            "created_utc": "01-31-2023 20:01:22",
            "distinguished": null,
            "edited": false,
            "id": "10qhgmv",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_10qhgmv",
            "nsfw": false,
            "num_comments": 17,
            "permalink": "/r/MachineLearning/comments/10qhgmv/r_faithful_chainofthought_reasoning/",
            "score": 119,
            "selftext": "Paper : https://arxiv.org/abs/2301.13379\n\nAbstract :\n\n>While Chain-of-Thought (CoT) prompting boosts Language Models' (LM) performance on a gamut of complex reasoning tasks, the generated reasoning chain does not necessarily reflect how the model arrives at the answer (aka. faithfulness). We propose Faithful CoT, a faithful-by-construction framework that decomposes a reasoning task into two stages: Translation (Natural Language query \u2192 symbolic reasoning chain) and Problem Solving (reasoning chain \u2192 answer), using an LM and a deterministic solver respectively. We demonstrate the efficacy of our approach on 10 reasoning datasets from 4 diverse domains. It outperforms traditional CoT prompting on 9 out of the 10 datasets, with an average accuracy gain of 4.4 on Math Word Problems, 1.9 on Planning, 4.0 on Multi-hop Question Answering (QA), and 18.1 on Logical Inference, under greedy decoding. Together with self-consistency decoding, we achieve new state-of-the-art few-shot performance on 7 out of the 10 datasets, showing a strong synergy between faithfulness and accuracy.",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Faithful Chain-of-Thought Reasoning",
            "upvote_ratio": 0.96,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10qhgmv/r_faithful_chainofthought_reasoning/"
        },
        {
            "author": "u/PlayfulMenu1395",
            "created_utc": "01-31-2023 18:25:32",
            "distinguished": null,
            "edited": "01-31-2023 18:29:25",
            "id": "10qfbwg",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10qfbwg",
            "nsfw": false,
            "num_comments": 7,
            "permalink": "/r/MachineLearning/comments/10qfbwg/d_audio_segmentation_machine_learning_algorithm/",
            "score": 10,
            "selftext": "Can someone suggest a machine learning model that will segment audio spectrogram to multiple classes.\nI have labeled data of heart beats. S1, S2, systole and diastole. How to train a segmentation model ?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Audio segmentation - Machine Learning algorithm to segment a audio file into multiple class",
            "upvote_ratio": 0.92,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10qfbwg/d_audio_segmentation_machine_learning_algorithm/"
        },
        {
            "author": "u/Adi-Dewan",
            "created_utc": "01-31-2023 17:54:54",
            "distinguished": null,
            "edited": false,
            "id": "10qelxs",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_10qelxs",
            "nsfw": false,
            "num_comments": 5,
            "permalink": "/r/MachineLearning/comments/10qelxs/r_are_there_any_machine_learning_journals_that/",
            "score": 3,
            "selftext": "Basically the title. I have a sequence of two papers - a viewpoint and a complete paper in the works - that I'm looking to submit, the viewpoint outlining the theoretical premise for the latter. I've currently had no luck finding any ML-specific journals that allow viewpoint submissions (with the exception of simply posting to arXiv), and was wondering if anyone here was familiar with any.\n\nThanks :D",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Are there any Machine Learning Journals that accept Viewpoint Papers (~1500+ words)?",
            "upvote_ratio": 0.59,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10qelxs/r_are_there_any_machine_learning_journals_that/"
        },
        {
            "author": "u/k_yuksel",
            "created_utc": "01-31-2023 13:45:49",
            "distinguished": null,
            "edited": false,
            "id": "10q8gp6",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_10q8gp6",
            "nsfw": false,
            "num_comments": 4,
            "permalink": "/r/MachineLearning/comments/10q8gp6/introducing_norefer_a_multilanguage_referenceless/",
            "score": 12,
            "selftext": "I am proud to announce the release of [NoRefER](https://huggingface.co/aixplain/NoRefER), a multi-language referenceless ASR metric based on a fine-tuned language model, for public use on HuggingFace. This metric allows for evaluating the outputs of ASR models without needing a reference transcript, making it a valuable tool for a/b testing multiple ASR models or model versions, or even ensembling their outputs.\n\nASR is an important technology with various applications, but the quality of ASR systems can vary greatly. It's important to accurately evaluate and compare the performance of different ASR models, traditionally done using reference-based ASR quality evaluation metrics. However, obtaining those ground-truth transcriptions from human annotators is time-consuming and costly.\n\nReferenceless quality evaluation is becoming important as it allows for comparing ASR models on a level playing field, regardless of the quality or existence of a reference transcript. Just as referenceless evaluation has become crucial in Machine Translation with the introduction of referenceless metrics like COMET-QE, referenceless evaluation will play an important role in ASR.\n\nTo fine-tune [NoRefER](https://huggingface.co/aixplain/NoRefER) for referenceless ASR quality evaluation, a contrastive-learning technique is employed with an innovative self-supervision method exploiting the known quality relationships in-between multiple compression levels of the same ASR, rather than human supervision on the quality of the ASR outputs obtained via transcriptions or evaluations of the annotators.\n\nPotential use-cases for [NoRefER](https://huggingface.co/aixplain/NoRefER) include:\n\n\\- A/B testing models or their versions to determine the best-performing one\n\n\\- Picking production outputs worth for the human-evaluation or post-editing\n\n\\- Ensemble the outputs of multiple ASR models to achieve a superior quality\n\nWhat's more, these abilities will be accessible in aiXplain no-code products, making it easy for anyone to use and benefit from this ASR quality estimation metric. We are excited to see how [NoRefER](https://huggingface.co/aixplain/NoRefER) will be used in the ASR community and would love to hear your thoughts and feedback. Try it out on HuggingFace and see how it can help diagnose and improve your ASR models!",
            "spoiler": false,
            "stickied": false,
            "title": "Introducing NoRef-ER: A Multi-Language Referenceless ASR Metric (on HuggingFace) [R] [P]",
            "upvote_ratio": 0.85,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10q8gp6/introducing_norefer_a_multilanguage_referenceless/"
        },
        {
            "author": "u/NLPnerd",
            "created_utc": "01-31-2023 11:39:53",
            "distinguished": null,
            "edited": false,
            "id": "10q5955",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "News",
            "locked": false,
            "name": "t3_10q5955",
            "nsfw": false,
            "num_comments": 2,
            "permalink": "/r/MachineLearning/comments/10q5955/n_vincent_warmerdam_calmcode_explosion_open/",
            "score": 0,
            "selftext": "[https://www.youtube.com/watch?v=yvgxRzqx1Jg](https://www.youtube.com/watch?v=yvgxRzqx1Jg)\n\n&#x200B;\n\nContents \n\n* [00:00](https://www.youtube.com/watch?v=yvgxRzqx1Jg&t=0s) Learning from Machine Learning Intro \n* [00:21](https://www.youtube.com/watch?v=yvgxRzqx1Jg&t=21s) Vincent Warmerdam Intro \n* [01:18](https://www.youtube.com/watch?v=yvgxRzqx1Jg&t=78s) Career Journey \n* [03:25](https://www.youtube.com/watch?v=yvgxRzqx1Jg&t=205s) What roles have you played? \n* [05:44](https://www.youtube.com/watch?v=yvgxRzqx1Jg&t=344s) Academic Background: Operations Research and Design \n* [06:52](https://www.youtube.com/watch?v=yvgxRzqx1Jg&t=412s) Operations Research \n* [08:13](https://www.youtube.com/watch?v=yvgxRzqx1Jg&t=493s) Mathematics \n* [09:19](https://www.youtube.com/watch?v=yvgxRzqx1Jg&t=559s) What attracted you to Machine Learning? \n* [10:40](https://www.youtube.com/watch?v=yvgxRzqx1Jg&t=640s) Calmcode \n* [14:08](https://www.youtube.com/watch?v=yvgxRzqx1Jg&t=848s) Calmcode, Do you use it? \n* [15:22](https://www.youtube.com/watch?v=yvgxRzqx1Jg&t=922s) Calmdcode, \\*args, \\*\\*kwargs \n* [16:23](https://www.youtube.com/watch?v=yvgxRzqx1Jg&t=983s) If there were no constraints, what would you do to improve calmcode? \n* [18:10](https://www.youtube.com/watch?v=yvgxRzqx1Jg&t=1090s) Open Source Projects: bulk, embetter, human-learn \n* [19:10](https://www.youtube.com/watch?v=yvgxRzqx1Jg&t=1150s) Open Source: evol, scikit-lego \n* [20:00](https://www.youtube.com/watch?v=yvgxRzqx1Jg&t=1200s) Rasa: Chatbots, Benchmarking \n* [20:47](https://www.youtube.com/watch?v=yvgxRzqx1Jg&t=1247s) Unit Tests \n* [21:42](https://www.youtube.com/watch?v=yvgxRzqx1Jg&t=1302s) Open Source: Creating Packages \n* [24:10](https://www.youtube.com/watch?v=yvgxRzqx1Jg&t=1450s) Bulk, human-learn \n* [26:20](https://www.youtube.com/watch?v=yvgxRzqx1Jg&t=1580s) [27:03](https://www.youtube.com/watch?v=yvgxRzqx1Jg&t=1623s) Bulk in a notebook, bulk as a webapp \n* [27:45](https://www.youtube.com/watch?v=yvgxRzqx1Jg&t=1665s) Human in the loop \n* [29:03](https://www.youtube.com/watch?v=yvgxRzqx1Jg&t=1743s) Understanding the problem; Beans, Beef and Bread \n* [32:56](https://www.youtube.com/watch?v=yvgxRzqx1Jg&t=1976s) Algorithm on the wrong problem \n* [34:55](https://www.youtube.com/watch?v=yvgxRzqx1Jg&t=2095s) Module Improvement vs System Improvement \n* [37:20](https://www.youtube.com/watch?v=yvgxRzqx1Jg&t=2240s) Does your answer make sense? \n* [39:04](https://www.youtube.com/watch?v=yvgxRzqx1Jg&t=2344s) What's an important question that you believe remains unanswered in ML? \n* [41:48](https://www.youtube.com/watch?v=yvgxRzqx1Jg&t=2508s) How do you view the gap between the hype and reality of AI? \n* [46:28](https://www.youtube.com/watch?v=yvgxRzqx1Jg&t=2788s) Generative Models vs. Predictive Models \n* [49:18](https://www.youtube.com/watch?v=yvgxRzqx1Jg&t=2958s) Jumping to solutions \n* [50:08](https://www.youtube.com/watch?v=yvgxRzqx1Jg&t=3008s) Model vs. System \n* [50:48](https://www.youtube.com/watch?v=yvgxRzqx1Jg&t=3048s) [51:10](https://www.youtube.com/watch?v=yvgxRzqx1Jg&t=3070s) Who has influenced you in the field? \n* [55:18](https://www.youtube.com/watch?v=yvgxRzqx1Jg&t=3318s) Humble, Caring Presenters \n* [56:38](https://www.youtube.com/watch?v=yvgxRzqx1Jg&t=3398s) What's one piece of advice that you've received that's helped you? \n* [01:00:18](https://www.youtube.com/watch?v=yvgxRzqx1Jg&t=3618s) Advice for people just starting in the field \n* [01:03:15](https://www.youtube.com/watch?v=yvgxRzqx1Jg&t=3795s) What has a career in machine learning taught you about life? \n* [01:05:16](https://www.youtube.com/watch?v=yvgxRzqx1Jg&t=3916s) SpaCy \n* [01:06:10](https://www.youtube.com/watch?v=yvgxRzqx1Jg&t=3970s) Data-Centric Approach \n* [01:06:50](https://www.youtube.com/watch?v=yvgxRzqx1Jg&t=4010s) Wrap-up \n* [01:07:15](https://www.youtube.com/watch?v=yvgxRzqx1Jg&t=4035s) Follow, Explosion  \n* [01:07:48](https://www.youtube.com/watch?v=yvgxRzqx1Jg&t=4068s) Outro",
            "spoiler": false,
            "stickied": false,
            "title": "[N] Vincent Warmerdam: Calmcode, Explosion, Open Source and Data Science | Learning From Machine Learning #2",
            "upvote_ratio": 0.38,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10q5955/n_vincent_warmerdam_calmcode_explosion_open/"
        },
        {
            "author": "u/Zetsu-Eiyu-O",
            "created_utc": "01-31-2023 10:57:57",
            "distinguished": null,
            "edited": false,
            "id": "10q45pr",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10q45pr",
            "nsfw": false,
            "num_comments": 6,
            "permalink": "/r/MachineLearning/comments/10q45pr/d_generative_model_for_facts_extraction/",
            "score": 1,
            "selftext": "Is it possible to finetune a generative model (like T5) to do something like this:\n\n{\n\ninputs: \"XYZ <eot> XYZ was born in ABC. They now live in DEF.\",\n\ntargets: \"XYZ <t> born in <t> ABC <f> XYZ <t> lives in <t> DEF\"\n\n}\n\n[Like the transformer model fom this paper](https://github.com/google-research-datasets/wikifact)\n\nif so how should I go about approaching the problem? \n\nIs this task as simple as feeding it the inputs and targets or do you guys think it has more to it?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Generative Model FOr Facts Extraction",
            "upvote_ratio": 0.6,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10q45pr/d_generative_model_for_facts_extraction/"
        },
        {
            "author": "u/binaryshrey",
            "created_utc": "01-31-2023 09:22:03",
            "distinguished": null,
            "edited": false,
            "id": "10q1qns",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10q1qns",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/10q1qns/d_opensource_automl_services/",
            "score": 2,
            "selftext": "What're some good open-source auto-ml services mainly for image classification that're similar to Google's Vertex-AI",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Open-source auto-ml services",
            "upvote_ratio": 0.75,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10q1qns/d_opensource_automl_services/"
        },
        {
            "author": "u/l0g1cs",
            "created_utc": "01-31-2023 07:52:01",
            "distinguished": null,
            "edited": false,
            "id": "10pzktw",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "News",
            "locked": false,
            "name": "t3_10pzktw",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/10pzktw/n_monitor_openai_api_latency_tokens_rate_limits/",
            "score": 5,
            "selftext": "Relying on hosted inference with LLMs in productions, such as via OpenAI API, has some challenges. The use of APIs should be designed around unstable latency, rate limits, token counts, costs, etc. To make it observable we've built tracing and monitoring specifically for AI apps. For example, the OpenAI Python library is monitored automatically, no need to do anything. We'll be adding support for more libraries.\n\nHere is a blog post with more info and screenshots: [Monitor OpenAI API Latency, Tokens, Rate Limits, and More](https://graphsignal.com/blog/monitor-open-ai-api-latency-tokens-rate-limits-and-more/). And the [GitHub repo](https://github.com/graphsignal/graphsignal).",
            "spoiler": false,
            "stickied": false,
            "title": "[N] Monitor OpenAI API Latency, Tokens, Rate Limits, and More with Graphsignal",
            "upvote_ratio": 0.78,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10pzktw/n_monitor_openai_api_latency_tokens_rate_limits/"
        },
        {
            "author": "u/ruizard",
            "created_utc": "01-31-2023 05:54:28",
            "distinguished": null,
            "edited": false,
            "id": "10px4n6",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_10px4n6",
            "nsfw": false,
            "num_comments": 6,
            "permalink": "/r/MachineLearning/comments/10px4n6/p_fine_tuning_whisper_in_another_language/",
            "score": 9,
            "selftext": "Hi all, I'm trying to fine-tune Whisper AI to transcribe albanian speech to text but I have a problem in that I don't know how the dataset for training whisper model should look like. \n\nI already have voice audios and the transcript for that audio file but I need to know how to reformat it into a valid dataset for training Whisper.\n\nThanks in advance!",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Fine Tuning Whisper in another language",
            "upvote_ratio": 0.84,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10px4n6/p_fine_tuning_whisper_in_another_language/"
        },
        {
            "author": "u/fujidaiti",
            "created_utc": "01-31-2023 03:18:07",
            "distinguished": null,
            "edited": "02-01-2023 04:22:48",
            "id": "10pu9eh",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10pu9eh",
            "nsfw": false,
            "num_comments": 67,
            "permalink": "/r/MachineLearning/comments/10pu9eh/d_have_researchers_given_up_on_traditional/",
            "score": 246,
            "selftext": "This may be a silly question for those familiar with the field, but don't machine learning researchers expect any more prospects for traditional methods (I mean, \"traditional\" is other than deep learning)? I feel that most of the time when people talk about machine learning in the world today, they are referring to deep learning, but is this the same in the academic world? Have people who have been studying traditional methods switched to neural networks? I know that many researchers are excited about deep learning, but I am wondering what they think about other methods.\n\n\\[ EDITED \\]\n\nI\u2019m glad that I got far more responses than I expected! However, I would like to add here that my intention did not seem to come across to some people because of my inaccurate English.\n\nI think \u201chave given up\" was poorly phrased. What I really meant to say was, are ML researchers no longer interested in traditional ML? Have those who studied, say, SVM moved on to DL field? That was my point, but u/qalis gave me a good comment on it. Thanks to all the others.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Have researchers given up on traditional machine learning methods?",
            "upvote_ratio": 0.95,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10pu9eh/d_have_researchers_given_up_on_traditional/"
        },
        {
            "author": "u/answersareallyouneed",
            "created_utc": "01-30-2023 14:59:33",
            "distinguished": null,
            "edited": false,
            "id": "10pducv",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10pducv",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/10pducv/d_is_the_yolor_paper_worth_looking_into/",
            "score": 3,
            "selftext": "Doing a survey of object detection papers with plausible application to pose-estimation tasks. Came across the paper \"You Only Learn One Representation\" and, while the theory seems interesting, I want to hear people's opinions before doing a deep dive into the theory.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Is the YoloR paper worth looking into?",
            "upvote_ratio": 0.8,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10pducv/d_is_the_yolor_paper_worth_looking_into/"
        },
        {
            "author": "u/EducationalCicada",
            "created_utc": "01-30-2023 13:17:07",
            "distinguished": null,
            "edited": false,
            "id": "10pb982",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10pb982",
            "nsfw": false,
            "num_comments": 4,
            "permalink": "/r/MachineLearning/comments/10pb982/d_towards_a_tokenfree_future_in_nlp/",
            "score": 28,
            "selftext": "[https://peltarion.com/blog/data-science/towards-a-token-free-future-in-nlp](https://peltarion.com/blog/data-science/towards-a-token-free-future-in-nlp)",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Towards A Token-Free Future In NLP",
            "upvote_ratio": 0.85,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10pb982/d_towards_a_tokenfree_future_in_nlp/"
        },
        {
            "author": "u/qthai912",
            "created_utc": "01-30-2023 13:09:14",
            "distinguished": null,
            "edited": false,
            "id": "10pb1y3",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_10pb1y3",
            "nsfw": false,
            "num_comments": 212,
            "permalink": "/r/MachineLearning/comments/10pb1y3/p_i_launched_catchgpt_a_supervised_model_trained/",
            "score": 498,
            "selftext": "I\u2019m an ML Engineer at Hive AI and I\u2019ve been working on a ChatGPT Detector.\n\nHere is a free demo we have up: [https://hivemoderation.com/ai-generated-content-detection](https://hivemoderation.com/ai-generated-content-detection)\n\nFrom our benchmarks it\u2019s significantly better than similar solutions like GPTZero and OpenAI\u2019s GPT2 Output Detector. On our internal datasets, we\u2019re seeing balanced accuracies of >99% for our own model compared to around 60% for GPTZero and 84% for OpenAI\u2019s GPT2 Detector.\n\nFeel free to try it out and let us know if you have any feedback!",
            "spoiler": false,
            "stickied": false,
            "title": "[P] I launched \u201cCatchGPT\u201d, a supervised model trained with millions of text examples, to detect GPT created content",
            "upvote_ratio": 0.75,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10pb1y3/p_i_launched_catchgpt_a_supervised_model_trained/"
        },
        {
            "author": "u/abstractcontrol",
            "created_utc": "01-30-2023 10:47:09",
            "distinguished": null,
            "edited": false,
            "id": "10p7hup",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10p7hup",
            "nsfw": false,
            "num_comments": 2,
            "permalink": "/r/MachineLearning/comments/10p7hup/d_are_there_neural_net_plugins_to_assist_audio/",
            "score": 3,
            "selftext": "In order to improve my talking skills, I am doing a [little series](https://www.youtube.com/playlist?list=PL04PGV4cTuIVGO5ImYTk9wPVmbgdYbe7J) on how to setup Stable Diffusion on Paperspace, and I am astounded how much time it takes to do the audio editing. Well, part of the reason is that I've only been doing this for 3 days and my process is very inefficient, but it feels that in the current time, neural nets should be able to do things like remove uhms, lip smacking and breath intakes.\n\nI've looked around, and [this post](https://www.reddit.com/r/audioengineering/comments/1xtm1r/comment/cfej9oa/?utm_source=share&utm_medium=web2x&context=3) from 9 years ago says the only choice is to edit it by hand. Is that still true?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Are there neural net plugins to assist audio editing of Youtube screencasts?",
            "upvote_ratio": 0.67,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10p7hup/d_are_there_neural_net_plugins_to_assist_audio/"
        },
        {
            "author": "u/jiamengial",
            "created_utc": "01-30-2023 09:52:51",
            "distinguished": null,
            "edited": false,
            "id": "10p66zc",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10p66zc",
            "nsfw": false,
            "num_comments": 42,
            "permalink": "/r/MachineLearning/comments/10p66zc/d_whats_stopping_you_from_working_on_speech_and/",
            "score": 34,
            "selftext": "I've been working in the speech and voice space for a while now and am now building out some tooling in the space to make it easier for researchers/engineers/developers to build speech processing systems and features; I'd love to hear what people in ML struggle with when you're trying to build or work with speech processing for your projects/products (beyond speech-to-text APIs)",
            "spoiler": false,
            "stickied": false,
            "title": "[D] What's stopping you from working on speech and voice?",
            "upvote_ratio": 0.9,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10p66zc/d_whats_stopping_you_from_working_on_speech_and/"
        },
        {
            "author": "u/seanrescs",
            "created_utc": "01-30-2023 08:50:14",
            "distinguished": null,
            "edited": false,
            "id": "10p4lhq",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10p4lhq",
            "nsfw": false,
            "num_comments": 12,
            "permalink": "/r/MachineLearning/comments/10p4lhq/d_dl_university_research_pc_suggestions/",
            "score": 2,
            "selftext": "I am a researcher at a US university and have a budget of 25k to build a PC for training various ML algorithms (e.g. DRL, neuromorphic computing, VAE, etc). I'm trying to decide between going for prebuilds (like [https://lambdalabs.com/gpu-workstations/vector](https://lambdalabs.com/gpu-workstations/vector)) or building with consumer cards like 4090s.   \n\n\nAny advice on which is the most bang for the price? Im not sure how much Im giving up by going for consumer 24g cards vs a6000, 6000 ada but prebuild prices go up quick. Warrantee vs building it myself isn't an issue",
            "spoiler": false,
            "stickied": false,
            "title": "[D] DL university research PC suggestions?",
            "upvote_ratio": 0.6,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10p4lhq/d_dl_university_research_pc_suggestions/"
        },
        {
            "author": "u/Singularian2501",
            "created_utc": "01-30-2023 08:06:22",
            "distinguished": null,
            "edited": false,
            "id": "10p3afl",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_10p3afl",
            "nsfw": false,
            "num_comments": 12,
            "permalink": "/r/MachineLearning/comments/10p3afl/r_parsel_a_decompositional_framework_for/",
            "score": 93,
            "selftext": "Paper: [https://arxiv.org/abs/2212.10561](https://arxiv.org/abs/2212.10561) \n\nGithub: [https://github.com/ezelikman/parsel](https://github.com/ezelikman/parsel) \n\nTwitter: [https://twitter.com/ericzelikman/status/1618426056163356675?s=20](https://twitter.com/ericzelikman/status/1618426056163356675?s=20) \n\nWebsite: [https://zelikman.me/parselpaper/](https://zelikman.me/parselpaper/) \n\nCode Generation on APPS Leaderboard: [https://paperswithcode.com/sota/code-generation-on-apps](https://paperswithcode.com/sota/code-generation-on-apps) \n\nAbstract:\n\n>Despite recent success in large language model (LLM) reasoning, **LLMs struggle with hierarchical multi-step reasoning tasks like generating complex programs.** For these tasks, **humans often start with a high-level algorithmic design and implement each part gradually.** We introduce Parsel, a framework enabling automatic implementation and validation of complex algorithms with code LLMs, taking hierarchical function descriptions in natural language as input. We show that **Parsel can be used across domains requiring hierarchical reasoning, including program synthesis, robotic planning, and theorem proving.** We show that LLMs generating Parsel solve more competition-level problems in the APPS dataset, resulting in **pass rates that are over 75% higher than prior results from directly sampling AlphaCode and Codex**, while often using a smaller sample budget. We also find that LLM-generated **robotic plans using Parsel as an intermediate language are more than twice as likely to be considered accurate than directly generated plans.** Lastly, we explore how Parsel addresses LLM limitations and discuss how Parsel may be useful for human programmers. \n\nhttps://preview.redd.it/66zehsdps6fa1.jpg?width=811&format=pjpg&auto=webp&v=enabled&s=96db4cb832def624ad10f7383cde56c1444dcbcc\n\nhttps://preview.redd.it/is4pzwdps6fa1.jpg?width=1638&format=pjpg&auto=webp&v=enabled&s=5e6c3137b982c91c658b58d286e5036a46a7d55d\n\nhttps://preview.redd.it/szkbb0eps6fa1.jpg?width=711&format=pjpg&auto=webp&v=enabled&s=6eacbd0cdfc8ecc2c21ad1a46d87d8f367d9bbb5\n\nhttps://preview.redd.it/6lk1wzdps6fa1.jpg?width=1468&format=pjpg&auto=webp&v=enabled&s=5a37d08a5677d927c1b017d711558a6d859e8f3c\n\nhttps://preview.redd.it/8h7p8vdps6fa1.jpg?width=1177&format=pjpg&auto=webp&v=enabled&s=3e9926040e6af04ec8945fcfe81e51b5c94d5913",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Parsel: A (De-)compositional Framework for Algorithmic Reasoning with Language Models - Stanford University Eric Zelikman et al - Beats prior code generation sota by over 75%!",
            "upvote_ratio": 0.94,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10p3afl/r_parsel_a_decompositional_framework_for/"
        },
        {
            "author": "u/ProfessionalOverall8",
            "created_utc": "01-30-2023 07:02:09",
            "distinguished": null,
            "edited": false,
            "id": "10p1cwu",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_10p1cwu",
            "nsfw": false,
            "num_comments": 12,
            "permalink": "/r/MachineLearning/comments/10p1cwu/p_keras_model_production_deployment/",
            "score": 3,
            "selftext": " Hi guys.\n\nIt's been some time since I started developing my Keras models, but now is the first time I am trying to push it to production.\n\nMy Keras model looks like this:\n\n`model = Sequential()`\n\n`model.add(Bidirectional(LSTM(256, return_sequences=True)))`\n\n`model.add(Bidirectional(LSTM(256, return_sequences=True)))`\n\n`model.add(TimeDistributed(Dense(1, activation='sigmoid')))`\n\n`model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])`\n\nMy problem is I need to run through about 25 of these for every written sentence. There is going to be an online editor, where users can paste text for my analysis. That means up to about 300 words or about 20 sentences at once. With the current time to run each network (about 0.2s), that means 25 \\* 0,2 \\* 20 or about 100s per user input. I am going for 30 seconds at most with potentially dozens of users at once. Ideally on a Raspberry Pi 4.\n\nThe internet is surely gonna back me up I thought to myself and started googling. If only I know what kind of a rabbit hole I was about to fall into.\n\nFirst I converted my Keras model into a TensorFlow frozen graph model. 10x time improvement on CPU, but still at 0.2s on average.\n\nAnother thing I think may boost the performance is retraining the models for variable input shape (currently I always feed in 50 values). With the average sentence size of 16 words this may, from what I understand, lead to a 3 times boost?\n\nMy question is: now what? What can I do to make it faster? Is it even possible to run it on a Raspberry Pi 4 and get reasonable response times? If not, what is my best option on a tight budget?",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Keras model production deployment",
            "upvote_ratio": 0.71,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10p1cwu/p_keras_model_production_deployment/"
        },
        {
            "author": "u/smred123",
            "created_utc": "01-30-2023 06:17:03",
            "distinguished": null,
            "edited": false,
            "id": "10p0iir",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10p0iir",
            "nsfw": false,
            "num_comments": 3,
            "permalink": "/r/MachineLearning/comments/10p0iir/d_i_want_to_understand_the_broad_steps_for/",
            "score": 7,
            "selftext": "From the given [link!](https://www.adept.ai/act), I gather that it is a large-scale Transformer trained to use digital tools like a web browser. Right now, it\u2019s hooked up to a Chrome extension which allows it to observe what\u2019s happening in the browser and take certain actions, like clicking, typing, and scrolling, etc.\n\nI am interested in knowing the broad steps involved in building something like this.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] I want to understand the broad steps for building something like Adept.AI",
            "upvote_ratio": 0.74,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10p0iir/d_i_want_to_understand_the_broad_steps_for/"
        },
        {
            "author": "u/mettle",
            "created_utc": "01-30-2023 04:21:13",
            "distinguished": null,
            "edited": false,
            "id": "10oyllu",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10oyllu",
            "nsfw": false,
            "num_comments": 15,
            "permalink": "/r/MachineLearning/comments/10oyllu/discussion_chatgpt_and_language_understanding/",
            "score": 14,
            "selftext": "The general consensus seems to be that large language models, and ChatGPT in particular, have a problem with accuracy and hallucination. As compared to what, is often unclear, but let's say as compared to other NLP methods of question answering, language understanding or as compared to Google Search.\n\nI haven't really been able to find any reliable sources documenting this accuracy problem, though.\n\nThe SuperGLUE benchmark has GPT-3 ranked #24, not terrible, but outperformed by old models like T5, which seems odd. GLUE nothing. SQUAD nothing.\n\nSo, I'm curious:\n\n1. Is there any benchmark or metric reflecting the seeming step-function made by ChatGPT that's got everyone so excited? I definitely feel like there's a difference between gpt-3 and chatGPT, but is it measurable or is it just vibes?\n2. Is there any metric showing ChatGPT's problem with fact hallucination and accuracy?\n3. Am I off the mark here looking at question-answering benchmarks as an assessment of LLMs?\n\nThanks",
            "spoiler": false,
            "stickied": false,
            "title": "[Discussion] ChatGPT and language understanding benchmarks",
            "upvote_ratio": 0.75,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10oyllu/discussion_chatgpt_and_language_understanding/"
        },
        {
            "author": "u/gamerx88",
            "created_utc": "01-30-2023 04:15:09",
            "distinguished": null,
            "edited": false,
            "id": "10oyi6a",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10oyi6a",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/10oyi6a/dare_there_studies_on_textdavinci003s_zerofewshot/",
            "score": 5,
            "selftext": "Has anyone come across studies on GPT3 text-davinci-003's zero/few-shot performance over various NLP benchmarks and how they compare to current SoTA? E.g GLUE, SuperGLUE and over more classic ones like CoNLL 2003 NER.\n\nI thought it would be pretty interesting to see how far zero/few-shot learning with LLM has progressed with RLHF and instruction tuning. Am surprised that nobody has done such a benchmark yet.",
            "spoiler": false,
            "stickied": false,
            "title": "[D]Are There Studies on text-davinci-003's Zero/Few-shot Performance on Various Academic Benchmarks?",
            "upvote_ratio": 0.86,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10oyi6a/dare_there_studies_on_textdavinci003s_zerofewshot/"
        },
        {
            "author": "u/antodima",
            "created_utc": "01-30-2023 03:40:14",
            "distinguished": null,
            "edited": false,
            "id": "10oxy9j",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10oxy9j",
            "nsfw": false,
            "num_comments": 7,
            "permalink": "/r/MachineLearning/comments/10oxy9j/d_sparse_ridge_regression/",
            "score": 2,
            "selftext": "Hi all!\n\nGiven X \u2208 \u211d ^(Nx), Y \u2208 \u211d ^(Ny), \u03b2 \u2208 \u211d^(+), so\n\nW = YX^(T)(XX^(T)\\+\u03b2I)^(-1)   (with the Moore\u2013Penrose pseudoinverse)\n\nwhere A = YX^(T) and B = XX^(T)\\+\u03b2I.\n\nIf we consider an arbitrary number of indices/units < Nx, and so we consider only some columns of matrix A and some columns and rows (crosses) of B. The rest of A and B are zeros.\n\nThe approach above of sparsify A and B will break the ridge regression solution when W=AB^(-1)? If yes, there are ways to avoid it?\n\nMany thanks!",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Sparse Ridge Regression",
            "upvote_ratio": 0.75,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10oxy9j/d_sparse_ridge_regression/"
        },
        {
            "author": "u/AdSecure5364",
            "created_utc": "01-29-2023 20:12:55",
            "distinguished": null,
            "edited": false,
            "id": "10opvjw",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": null,
            "locked": false,
            "name": "t3_10opvjw",
            "nsfw": false,
            "num_comments": 2,
            "permalink": "/r/MachineLearning/comments/10opvjw/ddifference_in_usecases_for_aws_sagemaker_vs/",
            "score": 0,
            "selftext": "I was looking at Databricks because it integrates with AWS services like Kinesis, but it looks to me like SageMaker is a direct competitor to Databricks? We are heavily using AWS, is there any reason to add DataBricks into the stack or odes SageMaker fill the same role?\n\nThank you :)  \nPost on r/datascience too..",
            "spoiler": false,
            "stickied": false,
            "title": "[D]Difference in usecases for AWS Sagemaker vs Databricks?",
            "upvote_ratio": 0.25,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10opvjw/ddifference_in_usecases_for_aws_sagemaker_vs/"
        },
        {
            "author": "u/asi_dm",
            "created_utc": "01-29-2023 23:25:57",
            "distinguished": null,
            "edited": false,
            "id": "10otrnf",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_10otrnf",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/10otrnf/r_a_robust_hypothesis_test_for_tree_ensemble/",
            "score": 2,
            "selftext": "I'm looking for help/feedback with this paper. Please let me know if the method is interesting and if there's ways to improve it!\n\n[https://arxiv.org/abs/2301.10115](https://arxiv.org/abs/2301.10115)\n\nAbstract:\n\nGradient boosted decision trees are some of the most popular algorithms in applied machine learning. They are a flexible and powerful tool that can robustly fit to any tabular dataset in a scalable and computationally efficient way. One of the most critical parameters to tune when fitting these models are the various penalty terms used to distinguish signal from noise in the current model. These penalties are effective in practice, but are lacking in robust theoretical justifications. In this paper we develop and present a novel theoretically justified hypothesis test of split quality for gradient boosted tree ensembles and demonstrate that using this method instead of the common penalty terms leads to a significant reduction in out of sample loss. Additionally, this method provides a theoretically well-justified stopping condition for the tree growing algorithm. We also present several innovative extensions to the method, opening the door for a wide variety of novel tree pruning algorithms.",
            "spoiler": false,
            "stickied": false,
            "title": "[R] A Robust Hypothesis Test for Tree Ensemble Pruning",
            "upvote_ratio": 1.0,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10otrnf/r_a_robust_hypothesis_test_for_tree_ensemble/"
        },
        {
            "author": "u/tysam_and_co",
            "created_utc": "01-29-2023 19:41:09",
            "distinguished": null,
            "edited": false,
            "id": "10op6va",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_10op6va",
            "nsfw": false,
            "num_comments": 34,
            "permalink": "/r/MachineLearning/comments/10op6va/r_train_cifar10_in_under_10_seconds_on_an_a100/",
            "score": 141,
            "selftext": "[https://github.com/tysam-code/hlb-CIFAR10](https://github.com/tysam-code/hlb-CIFAR10)",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Train CIFAR10 in under 10 seconds on an A100 (new world record!)",
            "upvote_ratio": 0.93,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10op6va/r_train_cifar10_in_under_10_seconds_on_an_a100/"
        },
        {
            "author": "u/how-it-is-",
            "created_utc": "01-29-2023 15:23:48",
            "distinguished": null,
            "edited": false,
            "id": "10oj2ec",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_10oj2ec",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/10oj2ec/r_industrial_case_study_of_gnns_with_pytorch/",
            "score": 2,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Industrial Case Study of GNNs with PyTorch Geometric for Document Understanding",
            "upvote_ratio": 1.0,
            "url": "https://youtu.be/M1y3xzeqdsg"
        },
        {
            "author": "u/AttilaFazekas",
            "created_utc": "01-29-2023 15:01:44",
            "distinguished": null,
            "edited": "01-30-2023 01:56:06",
            "id": "10oii4a",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_10oii4a",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/10oii4a/r_incorrect_ranking_of_vessel_segmentation/",
            "score": 4,
            "selftext": "In a recent article, we reviewed dozens of image segmentation algorithms and pointed out mathematically that in many cases the reported performance scores could not be the results of the evaluation methods claimed by the authors.\n\nThe scores are primary indicators of value and serve as measures of the state-of-the-art to be outperformed by new algorithms. Unfortunately, algorithm rankings turned out to be incorrect in 100+ papers and the problem is systematic. The pressure to outperform flawed performance scores to get published keeps the trend on-going.\n\nHow should the community deal with a phenomenon like this: flaws uncovered, factual, undeniable yet on-going? Is the 258th algorithm proposed for a problem more valuable than reproducing a highly cited article? Should it be mandatory to share source code? Is there a merit in developing consistency checks like the ones we did? Any comments are welcome!\n\n[https://arxiv.org/abs/2111.03853](https://arxiv.org/abs/2111.03853)",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Incorrect Ranking of Vessel Segmentation Algorithms",
            "upvote_ratio": 0.83,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10oii4a/r_incorrect_ranking_of_vessel_segmentation/"
        },
        {
            "author": "u/TheRealMrMatt",
            "created_utc": "01-29-2023 14:16:24",
            "distinguished": null,
            "edited": "01-29-2023 15:09:01",
            "id": "10ohc3f",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10ohc3f",
            "nsfw": false,
            "num_comments": 18,
            "permalink": "/r/MachineLearning/comments/10ohc3f/d_remote_phd/",
            "score": 7,
            "selftext": "Hi all,\n\nDuring the pandemic many software companies transitioned their workforce to \"fully-remote\" or \"partially-remote\"; therefore, I was wondering if any reputable institutions offer a remote CS PhD?\n\nFor context, I know of several individuals who have sorted out remote work with their PIs on a per-person basis (typically after the first 1-2 years of study), but I am not aware of any labs or programs that advertise remote study.\n\nThank you in advance for the responses.\n\nCheers,\n\nMatt",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Remote PhD",
            "upvote_ratio": 0.64,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10ohc3f/d_remote_phd/"
        },
        {
            "author": "u/Singularian2501",
            "created_utc": "01-29-2023 13:21:21",
            "distinguished": null,
            "edited": false,
            "id": "10ofybj",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "News",
            "locked": false,
            "name": "t3_10ofybj",
            "nsfw": false,
            "num_comments": 5,
            "permalink": "/r/MachineLearning/comments/10ofybj/nr_compiling_and_running_glm130b_on_a_local/",
            "score": 13,
            "selftext": "Twitter link to his post: [https://twitter.com/alexjc/status/1617152800571416577?s=46&t=CMQT9rK4F1Lt7g7aX2vTJA](https://twitter.com/alexjc/status/1617152800571416577?s=46&t=CMQT9rK4F1Lt7g7aX2vTJA) \n\nalso important in that regard:\n\n**The case for 4-bit precision: k-bit Inference Scaling Laws - Tim Dettmers**\n\nPaper: [https://arxiv.org/abs/2212.09720](https://arxiv.org/abs/2212.09720) \n\nhttps://preview.redd.it/7nn0pfhn81fa1.jpg?width=585&format=pjpg&auto=webp&v=enabled&s=8aecd5774fabae48a453cc09bba8b4c2c5e5a16e\n\nhttps://preview.redd.it/0084vhhn81fa1.jpg?width=598&format=pjpg&auto=webp&v=enabled&s=61f1c325541d6deec62eba3d7d803a37c073151b",
            "spoiler": false,
            "stickied": false,
            "title": "[N][R] Compiling and running GLM-130B on a local machine (4x 3090s, int4 quantization) - Author: Alex J. Champandard",
            "upvote_ratio": 0.85,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10ofybj/nr_compiling_and_running_glm130b_on_a_local/"
        },
        {
            "author": "u/YoutubeStruggle",
            "created_utc": "01-29-2023 12:57:37",
            "distinguished": null,
            "edited": false,
            "id": "10ofcis",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_10ofcis",
            "nsfw": false,
            "num_comments": 24,
            "permalink": "/r/MachineLearning/comments/10ofcis/p_ai_content_detector/",
            "score": 0,
            "selftext": "Have you tried ChatGPT? It's super cool but some users are also using it to create automated content submissions and resulting in an increase in AI-generated plagiarism. I have made a tool as a college project to detect content generated using AI.  \nGo ahead and validate your content on [AI Content Detector](https://ai-content-detector.online/)  \nIf you are an educator worried about automated content submissions or developers worried about search engine penalties, this tool will help everyone to efficiently detect content generated using AI.",
            "spoiler": false,
            "stickied": false,
            "title": "[P] AI Content Detector",
            "upvote_ratio": 0.29,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10ofcis/p_ai_content_detector/"
        },
        {
            "author": "u/evanthebouncy",
            "created_utc": "01-29-2023 12:27:08",
            "distinguished": null,
            "edited": false,
            "id": "10oela2",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10oela2",
            "nsfw": false,
            "num_comments": 2,
            "permalink": "/r/MachineLearning/comments/10oela2/d_what_is_roughly_the_cost_of_humanannotation_vs/",
            "score": 6,
            "selftext": "Let's say I pull a pre-trained LLM off of huggingface. In broad strokes (making whatever assumptions appropriate), what is the relative cost of getting human annotation data versus actually incorporating those data in through training?\n\nI've been trying to get this stats and so far the ratio seems to be 2:1, meaning if you spent 10k dollars collecting human annotations, you should expect to spend 5k on compute (finetune, RLHF, ect)\n\nbut I'd be happy if someone with more experience can chime in.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] what is roughly the cost of human-annotation vs compute to adapt a LLM?",
            "upvote_ratio": 0.8,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10oela2/d_what_is_roughly_the_cost_of_humanannotation_vs/"
        },
        {
            "author": "u/a_khalid1999",
            "created_utc": "01-29-2023 10:55:39",
            "distinguished": null,
            "edited": false,
            "id": "10ocalm",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10ocalm",
            "nsfw": false,
            "num_comments": 26,
            "permalink": "/r/MachineLearning/comments/10ocalm/d_ai_theory_signal_processing/",
            "score": 32,
            "selftext": "On [This](https://ai.facebook.com/research/theory/) page of Meta AI research where they mention AI theory as a topic, they mention that they use techniques from Signal Processing. As someone with an Electrical Engineering background, and interests in Mathematics and AI, I found this very intriguing. Can someone tell me some of the ways signal processing has been used in AI theory? Some papers or some work done?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] AI Theory - Signal Processing?",
            "upvote_ratio": 0.94,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10ocalm/d_ai_theory_signal_processing/"
        },
        {
            "author": "u/AutoModerator",
            "created_utc": "01-29-2023 10:00:07",
            "distinguished": null,
            "edited": false,
            "id": "10oazg7",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10oazg7",
            "nsfw": false,
            "num_comments": 132,
            "permalink": "/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/",
            "score": 11,
            "selftext": "Please post your questions here instead of creating a new thread. Encourage others who create new posts for questions to post here instead!\n\nThread will stay alive until next one so keep posting after the date in the title.\n\nThanks to everyone for answering questions in the previous thread!",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Simple Questions Thread",
            "upvote_ratio": 0.92,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10oazg7/d_simple_questions_thread/"
        },
        {
            "author": "u/Ch1nada",
            "created_utc": "01-29-2023 09:54:19",
            "distinguished": null,
            "edited": false,
            "id": "10oauj5",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_10oauj5",
            "nsfw": false,
            "num_comments": 14,
            "permalink": "/r/MachineLearning/comments/10oauj5/p_automating_a_youtube_shorts_channel_with/",
            "score": 64,
            "selftext": "I\u2019ll try to get into detail about the implementation and difficulties in case it is useful for anyone else trying to do something similar with an applied ML project, so there\u2019s a TLDR at the end if you\u2019d like the short version/result.\n\nAt the end of last year I convinced myself to start 2023 by creating a side-project that I'd actually finish and deploy and perhaps earn some \u201cpassive\u201d income (spoiler, not so passive after all :P), and after some brainstorming I settled on making an automated Youtube channel about finance news since I had just gotten into investing. Shorts seemed to be more manageable and monetization is changing in February so I went with that.\n\nMy rough initial idea was to get online articles, summarize them, make a basic compilation with some combination of pymovie, opencv and stock photos and done. I was pretty worried about the summarization, since in my ML day job I mainly work with vision or sensor data in manufacturing not NLP. Also, I quickly realized pymovie with still images and some overlayed text was not very attractive for viewers (starting with myself).\n\nFast-forward a few days, and after some research online I came across two things, Huggingface transformers (yep, I know I\u2019ve been living under a rock :P) and After Effects scripting.  From here, it became mainly about figuring out exactly which ML models I needed to fine-tune for finance / social media and for what, then putting it all together.\n\nThe entire workflow looks something like this: the bot fetches online daily news about a topic (stocks or crypto), then sentiment analysis is performed on the title and the full text is summarized into a single sentence. I fine-tuned SBERT on \\~1.5M posts from /r/worldnews publicly available in Google Cloud BigQuery so that it could predict a \u201csocial engagement\u201d score that could be used to rank and filter the news that would make it into the video.\n\nFinally, all of this is combined into a single JSON object written into a .js file that can be used by another \u201ccontent creator\u201d script to render the video from a template using aerender in Python. The content of this template is generated dynamically based on the contents of the .js file via AE Expressions. This module also uses the TTS lib to generate voice-overs for the text, and is also responsible for generating the title (using NLTK to identify the main subjects of each title) and the video\u2019s description. Pexel stock videos are used for the background.\n\nIn principle automating the upload to Youtube could also be done, but at this stage I\u2019m handling this manually as the JSON generation is not as robust as I\u2019d like, so the output file often needs to be tweaked and fixed before the video can be finalized and uploaded. An examples is the summary being too short or vague when taken out of the context of the original article. If you increase the max\\_length of the summarizer to compensate, it can easily become too long to for the overlay to fit the pre-defined dimensions, or the total audio length can be too long for the max duration of a youtube short.\n\nWith some more work I\u2019m confident the whole process can be automated further. For those interested, feel free to check the result here:\n\n[Byte Size Bot channel](https://www.youtube.com/@bytesizebot)\n\nIf you have any questions or suggestions I\u2019d be happy to hear them.\n\nTLDR: Coded an automated (not 100% yet, but will get there) Youtube Shorts channel about finance news to create a passive income stream. Ended up being way harder, more fun and not so \u201cpassive\u201d than my initial expectations.",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Automating a Youtube Shorts channel with Huggingface Transformers and After Effects",
            "upvote_ratio": 0.96,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10oauj5/p_automating_a_youtube_shorts_channel_with/"
        },
        {
            "author": "u/TikkunCreation",
            "created_utc": "01-29-2023 08:42:09",
            "distinguished": null,
            "edited": false,
            "id": "10o96k8",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10o96k8",
            "nsfw": false,
            "num_comments": 6,
            "permalink": "/r/MachineLearning/comments/10o96k8/d_gptindex_vs_langchain/",
            "score": 15,
            "selftext": "Someone I work with wrote the below for our internal team (shared with permission) and I thought some here may find it helpful.\n\nRecently, I built an app that uses GPT-Index & LangChain to provide an answer to a question based on a piece of text as context. I found GPT-Index to be much easier and straightforward to integrate, but it seems like LangChain has more features and is more powerful. Here's my experience integrating both of them.\n\nGPT-Index\n\n- First thing I did was review their docs to make sure I understood what GPT-Index was, what it could do, and how I was going to use it\n\n- I went back and forth a couple times figuring out how I was going to use it. Then I found the quickstart guide\n\n- It seemed like the quickstart guide would work so I followed the guide and after a few tries, I was getting solid responses to the questions I asked it\n\nLangChain\n\n- I followed the same step, reviewing their docs. LangChain's docs has more to it because it seems like it does more, so this step took longer\n\n- It was tough for me to figure out how I needed to use LangChain. I had to ask for some help to better understand our use case\n\n- Once I thought I knew how I was going to use LangChain, I began coding. I ran into more errors with LangChain\n\n- It seems that my first approach wasn't correct, so I switched to something similar and I was finally getting a response. The response was 'I don't know'... I didn't know what to do about it\n\n- Then I checked out the logs of the data being passed through and found that the context was being cut off.\n\n- To make sure it worked, I asked a question relating to the text that was getting passed through. The response seemed to make sense, so now I know better where the issue is at\n\n- I still need to fix the context being cut off. I followed the docs of LangChain very closely, so I'm wondering if the docs are old or if I have the wrong implementation\n\nSo overall, if GPT Index solves your use case, start with that. We also did a variant built without GPT-Index and without langchain, and that one worked well too. We occasionally share stuff like this on genainews.org though the newsletter is mostly about new ai startups and products so figured it good to post here.\n\nAnyone else here that's worked with both GPT-Index and langchain and can offer additional thoughts?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] GPT-Index vs Langchain",
            "upvote_ratio": 0.8,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10o96k8/d_gptindex_vs_langchain/"
        },
        {
            "author": "u/shaner92",
            "created_utc": "01-29-2023 03:48:56",
            "distinguished": null,
            "edited": false,
            "id": "10o441p",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": null,
            "locked": false,
            "name": "t3_10o441p",
            "nsfw": false,
            "num_comments": 6,
            "permalink": "/r/MachineLearning/comments/10o441p/d_how_do_people_keep_up_with_ml_news_that_is_not/",
            "score": 23,
            "selftext": "Lately, NLP is taking up most of the public space, much of AI news is focused on LLM after Chat-GPT took the spotlight.  How do non-NLP people keep up with news?  I recently saw a post on reddit where tree models are still being improved.  There are other topics too, like the recent trend in Model Explainability which feels to have slowed down.\n\nI'd guess this all gets into the more categorical questions which I am wrapping up with **'How do YOU get your ML news'?**\n\n* How does information gathering differ between those in Applied ML and AI researchers (or even further, between those in Business Analytics and those in more 'AI' fields)\n* What sort of interesting things are out there in the world of ML now? (model or non-model related)\n* In looking for Use Cases, does this partially come down to your field? (Finance reads finance news, pharma reads pharma news)\n\n&#x200B;\n\nMany of the AI/ML Newsletters which I subscribed to when I was less experienced seemed to be full of variety, but as they are all converging to NLP recently maybe it is time to cleanse the subscriptions, or find some new resources.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] How do people keep up with ML news that is not NLP related?",
            "upvote_ratio": 0.93,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10o441p/d_how_do_people_keep_up_with_ml_news_that_is_not/"
        },
        {
            "author": "u/helliun",
            "created_utc": "01-29-2023 06:48:53",
            "distinguished": null,
            "edited": false,
            "id": "10o6wyx",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_10o6wyx",
            "nsfw": false,
            "num_comments": 13,
            "permalink": "/r/MachineLearning/comments/10o6wyx/p_targeted_summarization_a_tool_for_information/",
            "score": 135,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Targeted Summarization - A tool for information extraction",
            "upvote_ratio": 0.95,
            "url": "https://i.redd.it/d95ifbwns0fa1.gif"
        },
        {
            "author": "u/Illustrious_Row_9971",
            "created_utc": "01-28-2023 21:28:18",
            "distinguished": null,
            "edited": false,
            "id": "10nxqfg",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_10nxqfg",
            "nsfw": false,
            "num_comments": 39,
            "permalink": "/r/MachineLearning/comments/10nxqfg/r_instructpix2pix_learning_to_follow_image/",
            "score": 1144,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] InstructPix2Pix: Learning to Follow Image Editing Instructions",
            "upvote_ratio": 0.98,
            "url": "https://i.redd.it/413x5q54jwea1.jpg"
        },
        {
            "author": "u/tomiwa1a",
            "created_utc": "01-28-2023 20:49:13",
            "distinguished": null,
            "edited": false,
            "id": "10nwz5j",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_10nwz5j",
            "nsfw": false,
            "num_comments": 5,
            "permalink": "/r/MachineLearning/comments/10nwz5j/p_we_built_an_ml_search_engine_that_can_find/",
            "score": 44,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[P] We Built an ML Search Engine that can find exact timestamps for anything on Youtube using OpenAI Whisper and UKPLab's SBERT Sentence Transformers",
            "upvote_ratio": 0.91,
            "url": "https://v.redd.it/u08jvg2pbwea1"
        },
        {
            "author": "u/sambrojangles",
            "created_utc": "01-28-2023 19:47:57",
            "distinguished": null,
            "edited": false,
            "id": "10nvrvx",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10nvrvx",
            "nsfw": false,
            "num_comments": 4,
            "permalink": "/r/MachineLearning/comments/10nvrvx/discussion_stable_diffusion_models_with/",
            "score": 2,
            "selftext": "I was looking for research that centers around Stable Diffusion models but can be trained with seed images of a specific subject, so that if someone refers to a keyword like \"Me\" or \"I\" it would then produce images relative to the keyword of interest. Something like \"I am swimming in a beautiful ocean with mountains in the background and wearing a speedo\". Then the person subject in the photo would be myself since I referenced \"I\".",
            "spoiler": false,
            "stickied": false,
            "title": "[Discussion] Stable Diffusion Models with Subject/Keyword References",
            "upvote_ratio": 0.75,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10nvrvx/discussion_stable_diffusion_models_with/"
        },
        {
            "author": "u/tanelai",
            "created_utc": "01-28-2023 14:16:00",
            "distinguished": null,
            "edited": false,
            "id": "10nodn4",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_10nodn4",
            "nsfw": false,
            "num_comments": 40,
            "permalink": "/r/MachineLearning/comments/10nodn4/p_tinydiffusion_a_minimal_pytorch_implementation/",
            "score": 852,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[P] tiny-diffusion: a minimal PyTorch implementation of probabilistic diffusion models for 2D datasets",
            "upvote_ratio": 0.98,
            "url": "https://v.redd.it/xg4go739duea1"
        },
        {
            "author": "u/Dankmemexplorer",
            "created_utc": "01-28-2023 12:24:51",
            "distinguished": null,
            "edited": false,
            "id": "10nlriy",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10nlriy",
            "nsfw": false,
            "num_comments": 4,
            "permalink": "/r/MachineLearning/comments/10nlriy/d_could_multipleinput_transformers_reduce_the/",
            "score": 7,
            "selftext": "so it's big pop-sci news that we are [running out of quality textual training data](https://www.theatlantic.com/technology/archive/2023/01/artificial-intelligence-ai-chatgpt-dall-e-2-learning/672754/) (soft-paywalled article, but you get the idea) to produce chinchilla-optimal language models, and they appear to continue learning new abilities as data and parameter size increase.\n\nwhen an infant learns what a cat is, it is not only described, but the infant can see it and understand its form and behavior in a way it can then go on to describe and extrapolate from (even if they are blind, they can touch it and understand  its shape and feel its fur). LLMs have to do this the hard way: their generalized understanding of the shape and behaviour of a cat comes from textual descriptions of them (and they would need quite a lot in order to understand!)\n\nmost of the research i have seen into multiple input transformer models has been with the purpose of task completion (google's embodied language model robot butlers etc, which often use textual descriptions fed to a normal LLM, see https://innermonologue.github.io/ ) or image recognition and understanding (such as in CLIP) but not necessarily applying it to textual completion, which seems like it could benefit from a more visual understanding of the world \n\nso, in the medium or short term, to improve performance on text-completion tasks, what are your thoughts on using image training as well as textual to improve generalization for LLMs with fewer text tokens on a new architecture?\n\n(also, please excuse any ignorance i may posess: i'm a bit of an armchair ai enjoyer)",
            "spoiler": false,
            "stickied": false,
            "title": "[D] could multiple-input transformers reduce the pain of the training data acquisition problem?",
            "upvote_ratio": 1.0,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10nlriy/d_could_multipleinput_transformers_reduce_the/"
        },
        {
            "author": "u/Hub_Pli",
            "created_utc": "01-28-2023 12:16:17",
            "distinguished": null,
            "edited": false,
            "id": "10nlk3t",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10nlk3t",
            "nsfw": false,
            "num_comments": 5,
            "permalink": "/r/MachineLearning/comments/10nlk3t/gan_training_gradient_questions_d/",
            "score": 3,
            "selftext": "The main reason why this is not in the simple questions thread is the need to includee an image.  \nHere is an image of my generator's and discriminator's gradients being logged onto wandb. As you can see, they have these weird hasms, where the distribution of the gradients becomes very close to zero. These chasms are correlated for the discriminator and generator and seem very regular.   \n\n\nAnyone experienced anything like this and maybe has a hunch of what might be the cause?\n\nhttps://preview.redd.it/3qipyez6stea1.png?width=624&format=png&auto=webp&v=enabled&s=174c00a29799912e8c4a023ea743237ab1fcb831",
            "spoiler": false,
            "stickied": false,
            "title": "GAN Training Gradient questions [D]",
            "upvote_ratio": 1.0,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10nlk3t/gan_training_gradient_questions_d/"
        },
        {
            "author": "u/bridgeton_man",
            "created_utc": "01-28-2023 09:16:41",
            "distinguished": null,
            "edited": false,
            "id": "10nhdru",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10nhdru",
            "nsfw": false,
            "num_comments": 5,
            "permalink": "/r/MachineLearning/comments/10nhdru/d_goodness_of_fit_question/",
            "score": 2,
            "selftext": " \n\nFor regressions, R-squared and Adj. R-Squared are typically considered the primary goodness-of-fit measures.\n\nBut in many supervised machine-learning models, RMSE is the main measure that I keep running across. For example, decision tree models that I create in R using Rpart do that.\n\nSo, my question is how to compare the predictive accuracy of OLS regression models that report R-sq to equivalent Rpart regression trees that report RMSE.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Goodness of fit question",
            "upvote_ratio": 1.0,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10nhdru/d_goodness_of_fit_question/"
        },
        {
            "author": "u/yazriel0",
            "created_utc": "01-28-2023 09:13:49",
            "distinguished": null,
            "edited": false,
            "id": "10nhbfl",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "News",
            "locked": false,
            "name": "t3_10nhbfl",
            "nsfw": false,
            "num_comments": 23,
            "permalink": "/r/MachineLearning/comments/10nhbfl/n_openai_has_1000s_of_contractors_to_finetune/",
            "score": 39,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[N] OpenAI has 1000s of contractors to fine-tune codex",
            "upvote_ratio": 0.93,
            "url": "https://www.semafor.com/article/01/27/2023/openai-has-hired-an-army-of-contractors-to-make-basic-coding-obsolete"
        },
        {
            "author": "u/henshinger",
            "created_utc": "01-28-2023 08:17:41",
            "distinguished": null,
            "edited": false,
            "id": "10ng3pi",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_10ng3pi",
            "nsfw": false,
            "num_comments": 4,
            "permalink": "/r/MachineLearning/comments/10ng3pi/p_gpt_jupyterlab_jupyterlab_extension_to_use/",
            "score": 25,
            "selftext": "Hi everyone, I made a JupyterLab extension to use OpenAI\u2019s GPT models for code and text completion on your notebook cells.\n\nThis extension passes your current notebook cell to the  GPT API and completes your code/text for you. You can customize the GPT  parameters in the Advanced Settings menu.\n\nI made this extension when I couldn't find any Copilot/Codex extensions for JupyterLab. It doesn't make sense that ML folks don't have an easy way to use AI generated code in their own tools. VS Code does allow you use Copilot, but I've gotten used to Jupyter and a lot of ML/DS folks I know still prefer using Jupyter over VS code.\n\n# Installation\n\n    pip install gpt_jupyterlab \n\nGitHub Repo: [https://github.com/henshinger/gpt-jupyterlab/](https://github.com/henshinger/gpt-jupyterlab/) \n\n# Demo\n\n[GPT JupyterLab Demo](https://reddit.com/link/10ng3pi/video/y1smzr8wjsea1/player)\n\nNote: You will need your own OpenAI API Key to use this extension.\n\nWould love to get your feedback!",
            "spoiler": false,
            "stickied": false,
            "title": "[P] GPT JupyterLab - JupyterLab extension to use OpenAI\u2019s GPT models for code and text completion on your notebook cells.",
            "upvote_ratio": 0.96,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10ng3pi/p_gpt_jupyterlab_jupyterlab_extension_to_use/"
        },
        {
            "author": "u/Vegetable-Skill-9700",
            "created_utc": "01-28-2023 08:00:18",
            "distinguished": null,
            "edited": "02-01-2023 10:48:09",
            "id": "10nfquy",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_10nfquy",
            "nsfw": false,
            "num_comments": 16,
            "permalink": "/r/MachineLearning/comments/10nfquy/p_launching_my_first_ever_opensource_project_and/",
            "score": 58,
            "selftext": "I am building an open-source ML observability and refinement toolkit. \n\nThe tool helps ML practitioners to:\n1. Understand how their models are performing in production\n2. Catch edge-cases and outliers to help them refine their models\n3. Allow them to customise the tool according to their needs (hence, open-source)\n4. Bring data-security at the forefront (hence, self hosted)\n\nYou can check out the project https://github.com/uptrain-ai/uptrain and would love to hear feedback from the community",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Launching my first ever open-source project and it might make your ChatGPT answers better",
            "upvote_ratio": 0.87,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10nfquy/p_launching_my_first_ever_opensource_project_and/"
        },
        {
            "author": "u/davidmezzetti",
            "created_utc": "01-28-2023 07:45:28",
            "distinguished": null,
            "edited": false,
            "id": "10nffir",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_10nffir",
            "nsfw": false,
            "num_comments": 3,
            "permalink": "/r/MachineLearning/comments/10nffir/p_parse_research_papers_into_structured_data/",
            "score": 29,
            "selftext": "&#x200B;\n\nhttps://preview.redd.it/1t7spoqxdsea1.png?width=1920&format=png&auto=webp&v=enabled&s=afa8ff93292214a5e06aedd327f367e12bfd7929\n\npaperai is a semantic search and workflow application for medical/scientific papers. It can be used to take a set of research papers, parse the content and turn it into structured data.\n\npaperetl is the underlying library that parses basic metadata such as title, publication and date out of the papers. \n\nhttps://preview.redd.it/5jywynarfsea1.png?width=1084&format=png&auto=webp&v=enabled&s=4274e221a14f279e7ff89d86db076c1bbf1e31b6\n\nIn addition to standard metadata, paperai can also run extractive queries to build additional columns.\n\nhttps://preview.redd.it/8rzfj016esea1.png?width=1138&format=png&auto=webp&v=enabled&s=da8dfb2a94124861613f4262abc2bde5badc9971\n\nExample notebooks and Docker files can be found on GitHub.\n\n[paperai](https://github.com/neuml/paperai) | [paperetl](https://github.com/neuml/paperetl)",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Parse research papers into structured data",
            "upvote_ratio": 0.95,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10nffir/p_parse_research_papers_into_structured_data/"
        },
        {
            "author": "u/Background_Claim7907",
            "created_utc": "01-28-2023 07:18:21",
            "distinguished": null,
            "edited": false,
            "id": "10nevwk",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_10nevwk",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/10nevwk/p_annotating_text_with_sparse_human_annotations/",
            "score": 1,
            "selftext": "I want to automate the annotation of a domain-specific text (complicated contracts) by finetuning a BERT model. However the annotated text I've been provided by the domain experts has been sparsely annotated (i.e. paragraph 40-48 has been fully annotated, while 15 other paragraphs only have certain classes annotated for certain words. Most paragraphs have nothing annotated (like 70% of the entire corpus)\n\nAnother complication is that for 1 class, the entire paragraph should be annotated in this class, while for others it's a single word or a sentence. There are 7 classes in total and in the end, **all tokens should be annotated** to *one* of the 7 classes. 6 out of 7 classes are also pretty domain-specific and *not* something like 'location' or 'person' or POS. \n\nI've been thinking about using an annotation framework (i.e. LabelStudio or Prodigy) that supports custom models (i.e. finetuned BERT) and active learning to rapidly increase annotated texts by speeding up the work of human annotators (which are domain experts and usually don't have a lot of time for this). However, it's pretty unclear whether my use case would be support by this, especially with the issue of sparse text. \n\nI've also considered making the problem easier by using another model for the specific class that applies to an entire paragraph. And/or by using the fully annotated paragraphs for finetuning and using the sparse paragraphs for validation.\n\nA final consideration is using GPT-3, but I'm not sure how/if it is able to classify entire sentences/paragraphs with multiple classes and how the prompt should be formatted as.\n\nAny suggestions/ideas?",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Annotating text with sparse human annotations and different length chunks",
            "upvote_ratio": 0.67,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10nevwk/p_annotating_text_with_sparse_human_annotations/"
        },
        {
            "author": "u/hazardous1222",
            "created_utc": "01-28-2023 04:53:07",
            "distinguished": null,
            "edited": false,
            "id": "10ncfch",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_10ncfch",
            "nsfw": false,
            "num_comments": 4,
            "permalink": "/r/MachineLearning/comments/10ncfch/p_framework_agnostic_python_package_for_running/",
            "score": 9,
            "selftext": "[https://pypi.org/project/rwkvstic/](https://pypi.org/project/rwkvstic/)  \n\n\nCurrently supports tensorflow, pytorch, jax  \nAlso has support for tensor streaming, 8bit jit-quant and multi-gpu.  \nRun RWKV 7B on 8GB of vram or 14B on 16GB of vram.",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Framework agnostic python package for running RWKV, RNN based models.",
            "upvote_ratio": 0.85,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10ncfch/p_framework_agnostic_python_package_for_running/"
        },
        {
            "author": "u/SpatialComputing",
            "created_utc": "01-28-2023 04:47:39",
            "distinguished": null,
            "edited": false,
            "id": "10nccbg",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_10nccbg",
            "nsfw": false,
            "num_comments": 19,
            "permalink": "/r/MachineLearning/comments/10nccbg/r_meta_presents_mav3d_text_to_3d_video/",
            "score": 612,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "[R] META presents MAV3D \u2014 text to 3D video",
            "upvote_ratio": 0.96,
            "url": "https://v.redd.it/ybipwoqm9lea1"
        },
        {
            "author": "u/currentscurrents",
            "created_utc": "01-27-2023 21:53:22",
            "distinguished": null,
            "edited": false,
            "id": "10n5e8z",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10n5e8z",
            "nsfw": false,
            "num_comments": 13,
            "permalink": "/r/MachineLearning/comments/10n5e8z/d_could_forwardforward_learning_enable_training/",
            "score": 60,
            "selftext": "One problem with distributed learning with backprop is that the first layer can't update their weights until the computation has travelled all the way down to the last layer and then backpropagated back up. If all your layers are on different machines connected by a high-latency internet connection, this will take a long time.\n\nIn [forward-forward](https://www.cs.toronto.edu/~hinton/FFA13.pdf) learning, learning is local - each layer operates independently and only needs to communicate with the layers above and below it. \n\nThe results are almost-but-not-quite as good as backprop. But each layer can immediately update their weights based only on the information they received from the previous layer. Network latency no longer matters; the limit is just the bandwidth of the slowest machine.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Could forward-forward learning enable training large models with distributed computing?",
            "upvote_ratio": 0.95,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10n5e8z/d_could_forwardforward_learning_enable_training/"
        },
        {
            "author": "u/waiting4omscs",
            "created_utc": "01-27-2023 12:33:48",
            "distinguished": null,
            "edited": false,
            "id": "10ms7rt",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10ms7rt",
            "nsfw": false,
            "num_comments": 4,
            "permalink": "/r/MachineLearning/comments/10ms7rt/d_monitoring_and_retraining_models_with/",
            "score": 1,
            "selftext": "When a trained ML model is implemented to predict an adverse event, the user might take steps to avoid that event. The outcome of the user's actions could either be successful or failure.\n\nIn training with strictly observational data, a typical confusion matrix contains:\n\n1. \u0177=0, y=0 -> True Negative\n2. \u0177=0, y=1 -> False Negative\n3. \u0177=1, y=1 -> True Positive\n4. \u0177=1, y=0 -> False Positive\n\nWhen using the model, some results get confounded if the user acts based on the predictions\n\n1. \u0177=0, y=0, a=0 -> True Negative, No Intervention\n2. \u0177=0, y=1, a=0 -> False Negative, No Intervention\n3. \u0177=1, y=1, a=1 -> True Positive, Failed Intervention\n4. \u0177=1, y=0, a=1 -> False Positive OR Successful Intervention\n\nIgnoring the possibility that the intervention caused the adverse event, the involvement of the user may lead to an increase in the number of false positives that are perceived. Continuous monitoring becomes difficult due to perceived faster degradation of the model. Furthermore, retraining the model in the future may be hindered by labels that do not accurately reflect the true values.\n\nOne approach that I've been proposed is to make sure there is always a hold-out set. Allow some random records to get scores, but do never act on them. This gives both a monitoring and retraining dataset.\n\nAre there other solutions that people use here? I've found the papers below, but I cannot say that I completely understand how to practically implement them.\n\n* Monitoring machine learning (ML)-based risk prediction algorithms in the presence of confounding medical interventions (https://arxiv.org/abs/2211.09781)\n* Model updating after interventions paradoxically introduces bias (https://arxiv.org/abs/2010.11530)",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Monitoring and Retraining Models with Label-Changing Interventions",
            "upvote_ratio": 0.67,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10ms7rt/d_monitoring_and_retraining_models_with/"
        },
        {
            "author": "u/romantimm25",
            "created_utc": "01-27-2023 11:30:33",
            "distinguished": null,
            "edited": false,
            "id": "10mqm3g",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_10mqm3g",
            "nsfw": false,
            "num_comments": 8,
            "permalink": "/r/MachineLearning/comments/10mqm3g/p_using_algorithms_or_models_from_papers_for/",
            "score": 28,
            "selftext": "Hey!\n\nI am reading the GET3D paper by Nvidia. The paper is listed with the Nvidia license which states:\n\n3.3 Use Limitation. The Work and any derivative works thereof only    may be used or intended for use non-commercially. The Work or    derivative works thereof may be used or intended for use by Nvidia    or its affiliates commercially or non-commercially. As used herein,    \"non-commercially\" means for research or evaluation purposes only    and not for any direct or indirect monetary gain. \n\nDoes it mean there is no commercial way of using the ideas in the paper? Is it possible to use the ideas from that paper or any other paper by Nvidia in some product? As the idea from the paper is only the tool or a part of the product but is not the product itself.",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Using algorithms or models from papers for commercial use",
            "upvote_ratio": 0.96,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10mqm3g/p_using_algorithms_or_models_from_papers_for/"
        },
        {
            "author": "u/Around-star",
            "created_utc": "01-27-2023 08:57:32",
            "distinguished": null,
            "edited": false,
            "id": "10mmtky",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10mmtky",
            "nsfw": false,
            "num_comments": 1,
            "permalink": "/r/MachineLearning/comments/10mmtky/d_google_predoctoral_program_india_2023/",
            "score": 1,
            "selftext": "Has anyone got any interview email? Did they start the interview process?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Google Predoctoral Program (India) 2023",
            "upvote_ratio": 0.56,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10mmtky/d_google_predoctoral_program_india_2023/"
        },
        {
            "author": "u/MyActualUserName99",
            "created_utc": "01-27-2023 08:50:09",
            "distinguished": null,
            "edited": false,
            "id": "10mmniu",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10mmniu",
            "nsfw": false,
            "num_comments": 13,
            "permalink": "/r/MachineLearning/comments/10mmniu/d_imagenet2012_advice/",
            "score": 7,
            "selftext": "I'm currently at the point in my PhD career that I've developed some extremely successful components of CNNs, architecture, activation, etc. Outperforming default choices on CIFAR10, CIFAR100, Flowers, Caltech101, and other smaller datasets. With how success the results currently are, we want to publish to a top tier conference, specifically NeurIPS this Spring, deadline around May 13th. However, we (me and my advisor) agree that to publish at NeurIPS, our developments need to be backed up by ImageNet.\n\nThe problem is that we have never trained on ImageNet before (so no experience), and have a limited computational budget. Although our university personally owns 2 A100 40 GB GPUs that we can use, they are shared within the entire university, so a 2 day job takes about 1 week in queue (don't know if we can get the results in time by May). On the other hand, we also don't know if we can get a $2500 grant in time to use cloud resources.\n\nFor those who have trained on ImageNet, what are some common pitfalls, best ways to transfer data, downloading the dataset, etc? If you performed it on the cloud, how did you do so? How long was your time to train? Expenses? Did you run each model once or three times? Early stopping using validation or test set?\n\nNOTE: We will only be using Tensorflow...",
            "spoiler": false,
            "stickied": false,
            "title": "[D] ImageNet2012 Advice",
            "upvote_ratio": 0.77,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10mmniu/d_imagenet2012_advice/"
        },
        {
            "author": "u/TankAttack",
            "created_utc": "01-27-2023 08:45:45",
            "distinguished": null,
            "edited": false,
            "id": "10mmjvt",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10mmjvt",
            "nsfw": false,
            "num_comments": 14,
            "permalink": "/r/MachineLearning/comments/10mmjvt/d_best_large_language_model_for_named_entity/",
            "score": 7,
            "selftext": "I'd like to extract named entities, something like this:\n\n\"\\[Text\\]: Microsoft (the word being a portmanteau of \"microcomputer software\") was founded by Bill Gates on April 4, 1975, to develop and sell BASIC interpreters for the Altair 8800. Steve Ballmer replaced Gates as CEO in 2000, and later envisioned a \"devices and services\" strategy.\n\n\\[Name\\]: Steve Ballmer\n\n\\[Position\\]: CEO\n\n\\[Company\\]: Microsoft\n\n\"\n\nTried it on GPT-Neox with 20b parameters with mixed success, is there anything better out there to try for a few-shot learning (without fine tuning)?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Best large language model for Named Entity Extraction?",
            "upvote_ratio": 0.82,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10mmjvt/d_best_large_language_model_for_named_entity/"
        },
        {
            "author": "u/ferquinve",
            "created_utc": "01-27-2023 07:15:35",
            "distinguished": null,
            "edited": false,
            "id": "10mkjrc",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_10mkjrc",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/10mkjrc/r_etlp_eventbased_threefactor_local_plasticity/",
            "score": 6,
            "selftext": "> Neuromorphic perception with event-based sensors, asynchronous hardware and spiking neurons is showing promising results for real-time and energy-efficient inference in embedded systems. The next promise of brain-inspired computing is to enable adaptation to changes at the edge with online learning. However, the parallel and distributed architectures of neuromorphic hardware based on co-localized compute and memory imposes locality constraints to the on-chip learning rules. We propose in this work the Event-based Three-factor Local Plasticity (ETLP) rule that uses (1) the pre-synaptic spike trace, (2) the post-synaptic membrane voltage and (3) a third factor in the form of projected labels with no error calculation, that also serve as update triggers. We apply ETLP with feedforward and recurrent spiking neural networks on visual and auditory event-based pattern recognition, and compare it to Back-Propagation Through Time (BPTT) and eProp. We show a competitive performance in accuracy with a clear advantage in the computational complexity for ETLP. We also show that when using local plasticity, threshold adaptation in spiking neurons and a recurrent topology are necessary to learn spatio-temporal patterns with a rich temporal structure. Finally, we provide a proof of concept hardware implementation of ETLP on FPGA to highlight the simplicity of its computational primitives and how they can be mapped into neuromorphic hardware for online learning with low-energy consumption and real-time interaction. \n\nFull paper: [https://arxiv.org/abs/2301.08281](https://arxiv.org/abs/2301.08281)",
            "spoiler": false,
            "stickied": false,
            "title": "[R] ETLP: Event-based Three-factor Local Plasticity for online learning with neuromorphic hardware",
            "upvote_ratio": 0.88,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10mkjrc/r_etlp_eventbased_threefactor_local_plasticity/"
        },
        {
            "author": "u/carlthome",
            "created_utc": "01-27-2023 04:02:41",
            "distinguished": null,
            "edited": false,
            "id": "10mhbqv",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10mhbqv",
            "nsfw": false,
            "num_comments": 41,
            "permalink": "/r/MachineLearning/comments/10mhbqv/d_musiclm_generating_music_from_text/",
            "score": 149,
            "selftext": "How far do you think this can go? Is it a memorization machine or can it create new songs?\n\nhttps://google-research.github.io/seanet/musiclm/examples/",
            "spoiler": false,
            "stickied": false,
            "title": "[D] MusicLM: Generating Music From Text",
            "upvote_ratio": 0.97,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10mhbqv/d_musiclm_generating_music_from_text/"
        },
        {
            "author": "u/Secure-Technology-78",
            "created_utc": "01-26-2023 23:48:12",
            "distinguished": null,
            "edited": false,
            "id": "10mdhxb",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_10mdhxb",
            "nsfw": false,
            "num_comments": 28,
            "permalink": "/r/MachineLearning/comments/10mdhxb/r_sparsegpt_massive_language_models_can_be/",
            "score": 207,
            "selftext": ">Large  Language Models (LLMs) from the Generative Pretrained Transformer (GPT)  family have shown remarkable performance on a wide range of tasks, but  are difficult to deploy because of their massive size and computational  costs. For instance, the top-performing GPT-175B model has 175 billion  parameters, which total at least 320GB (counting multiples of 1024) of  storage in half-precision (FP16) format, leading it to require at least  five A100 GPUs with 80GB of memory each for inference. It is therefore  natural that there has been significant interest in reducing these costs  via model compression. To date, virtually all existing GPT compression  approaches have focused on quantization, that is, reducing the precision  of the numerical representation of individual weights. A complementary  approach for model compression is pruning, which removes network  elements, from individual weights (unstructured pruning) to  higher-granularity components such as entire rows/columns of the weight  matrices (structured pruning). This approach has a long history, and has  been applied successfully in the case of vision and smaller-scale  language models and tasks. Yet, the best-performing pruning methods  require extensive retraining of the model to recover from the accuracy  loss due to removed elements, which is extremely expensive in the case  of GPT-scale models. While some one-shot pruning methods also exist,  which compress the model without retraining, they are unfortunately too  computationally-expensive to be applied to models with billions of  parameters. Thus, to date, there is virtually no work on accurate  pruning of GPT3-scale models. Overview. In this paper, we propose  SparseGPT, the first accurate one-shot pruning method which works  efficiently at the scale of models with 10-100 billion parameters.  SparseGPT works by reducing the pruning problem to an extremely  large-scale instance of sparse regression. It is based on a new  approximate sparse regression solver, used to solve a layer-wise  compression problem, which is efficient enough to execute in a few hours  on the largest openly-available GPT models (175B parameters), using a  single GPU. At the same time, SparseGPT is accurate enough to drop  negligible accuracy post-pruning, without any fine-tuning. For example,  when executed on the largest publicly-available generative language  models (OPT-175B and BLOOM-176B), SparseGPT induces 50-60% sparsity in  one-shot, with minor accuracy loss, measured either in terms of  perplexity or zero-shot accuracy.\n\nFull paper: [https://arxiv.org/abs/2301.00774](https://arxiv.org/abs/2301.00774)",
            "spoiler": false,
            "stickied": false,
            "title": "[R] SparseGPT: Massive Language Models Can Be Accurately Pruned in One-Shot",
            "upvote_ratio": 0.96,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10mdhxb/r_sparsegpt_massive_language_models_can_be/"
        },
        {
            "author": "u/BeautyInUgly",
            "created_utc": "01-26-2023 22:40:52",
            "distinguished": null,
            "edited": false,
            "id": "10mcape",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10mcape",
            "nsfw": false,
            "num_comments": 40,
            "permalink": "/r/MachineLearning/comments/10mcape/d_meta_ai_residency_2023/",
            "score": 20,
            "selftext": "Now that apps are closed did anyone hear back yet? please follow this thread and update your status below, tbh I don't really think I have much of a chance but I'm excited none the less.\n\n&#x200B;\n\n**to follow a thread please press the bell on the top right**",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Meta AI Residency 2023",
            "upvote_ratio": 0.78,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10mcape/d_meta_ai_residency_2023/"
        },
        {
            "author": "u/madmax_br5",
            "created_utc": "01-26-2023 21:51:20",
            "distinguished": null,
            "edited": "01-26-2023 23:28:16",
            "id": "10mbct5",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10mbct5",
            "nsfw": false,
            "num_comments": 20,
            "permalink": "/r/MachineLearning/comments/10mbct5/d_moving_away_from_unicode_for_more_equal_token/",
            "score": 7,
            "selftext": "Edit: as has been explained in the comments, unicode is not the issue so much as the byte-pair encoding scheme, which artificially limits the vocabulary size of the model and leads to less common language using more tokens. I'd like to discuss the impacts of increasing the vocabulary size on transformer model computational requirements. \n\nMany languages, like Chinese, Japanese Kanji, Korean, Telugu, etc use complex logograms to represent words and concepts. Unfortunately, these languages are severely \"punished\" in GPT3 because they are expensive to tokenize due to the way unicode represents them. Instead of unicode representing them as a single code point, logograms are typically represented as a sum of multiple graphemes, meaning that multiple unicode code points underlie their description. This makes it far more expensive to prompt and generate in these languages, which is kind of unintentionally quite racist and eurocentric.\n\nFor example, let's take the following sentence and count the tokens used in multiple langauges:\n\nHello, I am a tall man: **7 tokens**\n\n(Chinese) \u4f60\u597d\uff0c\u6211\u662f\u4e2a\u9ad8\u4e2a\u5b50: **17 tokens**\n\n(Japanese) \u3053\u3093\u306b\u3061\u306f\u3001\u79c1\u306f\u80cc\u306e\u9ad8\u3044\u7537\u3067\u3059: **21 tokens**\n\n(Hindi) \u0939\u0948\u0932\u094b, \u092e\u0948\u0902 \u090f\u0915 \u0932\u0902\u092c\u093e \u0906\u0926\u092e\u0940 \u0939\u0942\u0901: **41 tokens**\n\n(Korean) \uc548\ub155\ud558\uc138\uc694 \uc800\ub294 \ud0a4\uac00 \ud070 \ub0a8\uc790\uc785\ub2c8\ub2e4: **45 tokens**\n\n(Telugu) \u0c39\u0c32\u0c4b, \u0c28\u0c47\u0c28\u0c41 \u0c2a\u0c4a\u0c21\u0c35\u0c3e\u0c1f\u0c3f \u0c2e\u0c28\u0c3f\u0c37\u0c3f\u0c28\u0c3f: **68 tokens!!!**\n\nYes, it's about ten times as expensive to use GPT3 for Telugu. That isn't good, especially if we want to ensure equal access to this technology globally. More than 80 million people speak this language! This also means that besides the cost, the context-length for these languages is much shorter in practice, making practical applications lag years behind what's possible on european languages. Imagine if you only had 400 tokens total context to work with. That's what GPT3 with Telugu is like today.\n\nHowever, this seems straightforward to fix. Unicode is merely a portability standard, it need not be the input mechanism for NLP models. Why not just preconvert from unicode into a different representation with a larger vocabulary (such as 18-bit) and use one code point per symbol, skipping the whole grapheme thing? It would seem to add negligible processing to the embedding and decoding step, which is a very small portion of overall compute compared to the attention mechanisms, which IIRC represent about 95% of the compute.\n\nIs there some reason why increasing the token vocabulary size and moving away from unicode within the embedding stage would be problematic?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Moving away from Unicode for more equal token representation across global languages?",
            "upvote_ratio": 0.68,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10mbct5/d_moving_away_from_unicode_for_more_equal_token/"
        },
        {
            "author": "u/KarmaCut132",
            "created_utc": "01-26-2023 20:59:07",
            "distinguished": null,
            "edited": false,
            "id": "10mab6p",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": null,
            "locked": false,
            "name": "t3_10mab6p",
            "nsfw": false,
            "num_comments": 6,
            "permalink": "/r/MachineLearning/comments/10mab6p/d_why_are_there_no_end2end_speech_recognition/",
            "score": 1,
            "selftext": " I'm new to CTC. After learning about CTC and its application in End2End training for Speech Recognition, I figured that if we want to generate a target sequence (transcript), given a source sequence features, we could use the vanilla Encoder-Decoder architecture in Transformer (also used in T5, BART, etc) alone, without the need of CTC, yet why people are only using CTC for End2End Speech Recoginition, or using hybrid of CTC and Decoder in some papers ?  \nThanks.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Why are there no End2End Speech Recognition models using the same Encoder-Decoder learning process as BART (no CTC) ?",
            "upvote_ratio": 0.56,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10mab6p/d_why_are_there_no_end2end_speech_recognition/"
        },
        {
            "author": "u/Individual-Cause-616",
            "created_utc": "01-26-2023 16:31:00",
            "distinguished": null,
            "edited": false,
            "id": "10m4l0b",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10m4l0b",
            "nsfw": false,
            "num_comments": 6,
            "permalink": "/r/MachineLearning/comments/10m4l0b/d_score_based_vs_diffusion_models/",
            "score": 4,
            "selftext": "I know there is a mathematical way to show that the two approaches of score matching models and diffusion models are the same. I wonder, if there in practice/code are the same either? I already tried to find some PyTorch implementations of score based models but didn\u2019t find anything yet - just for diffusion models.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] score based vs. Diffusion models",
            "upvote_ratio": 0.68,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10m4l0b/d_score_based_vs_diffusion_models/"
        },
        {
            "author": "u/TheCockatoo",
            "created_utc": "01-26-2023 14:36:11",
            "distinguished": null,
            "edited": false,
            "id": "10m1sdm",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": null,
            "locked": false,
            "name": "t3_10m1sdm",
            "nsfw": false,
            "num_comments": 13,
            "permalink": "/r/MachineLearning/comments/10m1sdm/d_why_are_gans_worse_than_latent_diffusion_models/",
            "score": 29,
            "selftext": "I guess what I'm trying to figure out is, what are the main reasons that DMs are outperforming GANs in text2img generation? Thanks!",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Why are GANs worse than (Latent) Diffusion Models for text2img generation?",
            "upvote_ratio": 0.87,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10m1sdm/d_why_are_gans_worse_than_latent_diffusion_models/"
        },
        {
            "author": "u/currentscurrents",
            "created_utc": "01-26-2023 12:06:57",
            "distinguished": null,
            "edited": false,
            "id": "10ly7rw",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": null,
            "locked": false,
            "name": "t3_10ly7rw",
            "nsfw": false,
            "num_comments": 34,
            "permalink": "/r/MachineLearning/comments/10ly7rw/r_why_can_gpt_learn_incontext_language_models/",
            "score": 234,
            "selftext": "Dec 2022 paper from Microsoft research: https://arxiv.org/abs/2212.10559v2\n\n>Large pretrained language models have shown surprising In-Context Learning (ICL) ability. With a few demonstration input-label pairs, they can predict the label for an unseen input without additional parameter updates. Despite the great success in performance, the working mechanism of ICL still remains an open problem. In order to better understand how ICL works, this paper explains language models as meta-optimizers and understands ICL as a kind of implicit finetuning.",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Why Can GPT Learn In-Context? Language Models Secretly Perform Gradient Descent as Meta-Optimizers",
            "upvote_ratio": 0.95,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10ly7rw/r_why_can_gpt_learn_incontext_language_models/"
        },
        {
            "author": "u/aadityaura",
            "created_utc": "01-26-2023 13:57:11",
            "distinguished": null,
            "edited": "01-26-2023 14:29:06",
            "id": "10m0uvd",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_10m0uvd",
            "nsfw": false,
            "num_comments": 3,
            "permalink": "/r/MachineLearning/comments/10m0uvd/p_a_python_module_to_generate_optimized_prompts/",
            "score": 54,
            "selftext": "Hi folks,\n\nI was working on a personal experimental project related to GPT-3, which I thought of making it open source now. It saves much time while working with LLMs.\n\nIf you are an industrial researcher or application developer, you probably have worked with GPT-3 apis.\n\nA common challenge when utilizing LLMs such as GPT-3 and BLOOM is their tendency to produce uncontrollable & unstructured outputs, making it difficult to use them for various NLP tasks and applications.To address this, we developed Promptify, a library that allows for the use of LLMs to solve NLP problems including Named Entity Recognition, Binary Classification, Multi-Label Classification, and Question-Answering and return a python object for easy parsing to construct additional applications on top of GPT-n based models.\n\n## \n\n## Features \ud83d\ude80\n\n* \ud83e\uddd9\u200d\u2640\ufe0f NLP Tasks (NER, Binary Text Classification, Multi-Label Classification etc)  in 2 lines of code with no training data required\n* \ud83d\udd28 Easily add one shot, two shot, or few shot examples to the prompt\n* \u270c Output always provided as a Python object (e.g. list, dictionary) for easy parsing and filtering\n* \ud83d\udca5 Custom examples and samples can be easily added to the prompt\n* \ud83d\udcb0 Optimized prompts to reduce OpenAI token costs\n\nGITHUB: [https://github.com/promptslab/Promptify](https://github.com/promptslab/Promptify)\n\nExamples: [https://github.com/promptslab/Promptify/tree/main/examples](https://github.com/promptslab/Promptify/tree/main/examples)\n\nFor quick demo -> [Colab](https://colab.research.google.com/drive/16DUUV72oQPxaZdGMH9xH1WbHYu6Jqk9Q?usp=sharing)\n\nI hope it will be helpful in your research. Thanks :)\n\n[NER example ](https://preview.redd.it/p3k8sqexzfea1.png?width=1236&format=png&auto=webp&v=enabled&s=8675a40203e0ba684297a242a337177a92367ec5)\n\n&#x200B;\n\nhttps://preview.redd.it/vnz4mf0i6gea1.png?width=1398&format=png&auto=webp&v=enabled&s=2146654fec504e470bee70cb8cf0922e98b08fab",
            "spoiler": false,
            "stickied": false,
            "title": "[P] A python module to generate optimized prompts & solve different NLP problems using GPT-n based models and return structured python object for easy parsing",
            "upvote_ratio": 0.95,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10m0uvd/p_a_python_module_to_generate_optimized_prompts/"
        },
        {
            "author": "u/what_comes_next",
            "created_utc": "01-25-2023 16:19:36",
            "distinguished": null,
            "edited": false,
            "id": "10lbiwv",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": null,
            "locked": false,
            "name": "t3_10lbiwv",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/10lbiwv/n_upcoming_talk_open_problems_in_deep_neural/",
            "score": 2,
            "selftext": " [Open Problems in Deep Neural Networks: An Optimal Control Perspective](https://www.meetup.com/bethesda-data-science-networking-meetup/events/291034298/)\n\nFeb 13, 6:30 ET\n\n**About the talk:**\n\nBackpropagation is a widely used algorithm for training neural networks. Its key step, Stochastic Gradient Descent (SGD) has become one of the bedrocks of deep learning. Despite wide adoption, mathematically rigorous study of SGD's convergence for deep neural networks is still ongoing.\n\nJoin us as graduate student [Amoolya Tirumalai](https://www.linkedin.com/in/amoolya-tirumalai-51b493200/) discusses an approach to the convergence problem inspired by optimal control theory. Following the Pontryargin maximum principle, an alternative forward-backward iterative system will be described. Toy examples will be shown, and problems in robustness and security will be discussed.\n\n**About the speaker:**\n\nAmoolya Tirumalai is a 4th year PhD Candidate in Electrical Engineering at the University of Maryland, College Park. His interests are (robust) optimal control, partial differential equations, differential games, mean-field games, safety-critical control, and (robust) machine learning.\n\nHis thesis titled '*Multi-agent inference, decision-making and control: models, structure and performance evaluation*' will be defended in August 2023. Mr. Tirumalai was conferred a BS in Biomedical Engineering from the Georgia Institute of Technology in 2018.",
            "spoiler": false,
            "stickied": false,
            "title": "[N] Upcoming talk: \"Open Problems in Deep Neural Networks: An Optimal Control Perspective\"",
            "upvote_ratio": 1.0,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10lbiwv/n_upcoming_talk_open_problems_in_deep_neural/"
        },
        {
            "author": "u/lookinsidemybutthole",
            "created_utc": "01-26-2023 12:10:48",
            "distinguished": null,
            "edited": false,
            "id": "10lyb7r",
            "is_original_content": false,
            "is_self": false,
            "link_flair_text": null,
            "locked": false,
            "name": "t3_10lyb7r",
            "nsfw": false,
            "num_comments": 11,
            "permalink": "/r/MachineLearning/comments/10lyb7r/a_watermark_for_large_language_models/",
            "score": 42,
            "selftext": "",
            "spoiler": false,
            "stickied": false,
            "title": "A Watermark for Large Language Models",
            "upvote_ratio": 0.81,
            "url": "https://arxiv.org/abs/2301.10226"
        },
        {
            "author": "u/angkhandelwal749",
            "created_utc": "01-26-2023 11:53:46",
            "distinguished": null,
            "edited": false,
            "id": "10lxwgd",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10lxwgd",
            "nsfw": false,
            "num_comments": 24,
            "permalink": "/r/MachineLearning/comments/10lxwgd/discussion_github_like_alternative_for_ml/",
            "score": 20,
            "selftext": "Versioning and collaboration on code for software engineers is a reasonably solved problem through GitHub since the task at hand predominantly involves just maintaining different copies of just simple vanilla code in different folders. On the other hand, ML engineers face the humungous task of maintaining different versions on not just code, but hyper parameters, data, models, data lineage and labels and storing this on GitHub currently does not allow you to track the changes on each variable well. What are the software/open source tools currently used for the same? Is their a space for a new company to be built here?",
            "spoiler": false,
            "stickied": false,
            "title": "[Discussion] Github like alternative for ML?",
            "upvote_ratio": 0.82,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10lxwgd/discussion_github_like_alternative_for_ml/"
        },
        {
            "author": "u/lorepieri",
            "created_utc": "01-26-2023 09:32:46",
            "distinguished": null,
            "edited": false,
            "id": "10lui3i",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10lui3i",
            "nsfw": false,
            "num_comments": 2,
            "permalink": "/r/MachineLearning/comments/10lui3i/are_there_any_projects_working_at_an_open_source/",
            "score": 8,
            "selftext": "I'm looking into projects which augment the RLHF training approach of chatGPT with explicit rules, such as in [https://paperswithcode.com/paper/constitutional-ai-harmlessness-from-ai](https://paperswithcode.com/paper/constitutional-ai-harmlessness-from-ai). \n\nIdeally there would be both rules and priority levels between the rules, similarly to the Asimov laws of robotics. \n\nThe Open-Assistant project ([https://github.com/LAION-AI/Open-Assistant](https://github.com/LAION-AI/Open-Assistant)) captures the spirit, but it is looking to replicate chatGPT at the moment.",
            "spoiler": false,
            "stickied": false,
            "title": "Are there any projects working at an open source version of Constitutional AI? [D]",
            "upvote_ratio": 0.73,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10lui3i/are_there_any_projects_working_at_an_open_source/"
        },
        {
            "author": "u/Blutorangensaft",
            "created_utc": "01-26-2023 09:09:26",
            "distinguished": null,
            "edited": false,
            "id": "10ltyki",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10ltyki",
            "nsfw": false,
            "num_comments": 12,
            "permalink": "/r/MachineLearning/comments/10ltyki/d_quantitative_measure_for_smoothness_of_nlp/",
            "score": 1,
            "selftext": "I would like to measure the smoothness of an NLP-autoencoder's latent space. The idea is to sample two Gaussian vectors v1 and v2 in the latent space of the AE, and generate N-1 points between them like so:\n\nvi = v1 + (v2 - v1) / (N * i)\n\nMy idea is to then decode these vectors and measure the BLEU score between d(vi) and d(vi+1) for all N-2 comparisons.\n\nIs this idea reasonable, do you have a better one? Is there a technique from AEs with images that can be useful here?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Quantitative measure for smoothness of NLP autoencoder latent space",
            "upvote_ratio": 0.6,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10ltyki/d_quantitative_measure_for_smoothness_of_nlp/"
        },
        {
            "author": "u/epistoteles",
            "created_utc": "01-26-2023 08:03:52",
            "distinguished": null,
            "edited": false,
            "id": "10lsirk",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10lsirk",
            "nsfw": false,
            "num_comments": 0,
            "permalink": "/r/MachineLearning/comments/10lsirk/d_what_are_some_of_your_favorite_ml_research/",
            "score": 20,
            "selftext": "And what are your own best practices when creating one (e.g. adding a QR code that links to the GitHub project or paper PDF)?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] What are some of your favorite ML research posters?",
            "upvote_ratio": 0.82,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10lsirk/d_what_are_some_of_your_favorite_ml_research/"
        },
        {
            "author": "u/Blutorangensaft",
            "created_utc": "01-26-2023 06:09:50",
            "distinguished": null,
            "edited": false,
            "id": "10lqd34",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10lqd34",
            "nsfw": false,
            "num_comments": 5,
            "permalink": "/r/MachineLearning/comments/10lqd34/d_fastest_and_most_accurate_model_for_casing/",
            "score": 0,
            "selftext": "What is the state of the art regarding freely available casing models, i.e. DNNs, that try to restore the original casing of a text with uniform (either lowercase or capital letters) casing? I value both speed and accuracy, as I have to process a large corpus of text.",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Fastest and most accurate model for casing",
            "upvote_ratio": 0.43,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10lqd34/d_fastest_and_most_accurate_model_for_casing/"
        },
        {
            "author": "u/besabestin",
            "created_utc": "01-26-2023 04:48:19",
            "distinguished": null,
            "edited": false,
            "id": "10lp3g4",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10lp3g4",
            "nsfw": false,
            "num_comments": 36,
            "permalink": "/r/MachineLearning/comments/10lp3g4/few_questions_about_scalability_of_chatgpt_d/",
            "score": 23,
            "selftext": "I have two questions about chatGPT. I don't come from a machine learning background. I am just a programmer. So bear with me if they sound a bit dumb.\n\nI was checking about chatGPT a bit the last week. I went through their papers and also tried out a fine tuning by myself by creating some fictional world and giving it some examples. \n\nThe first thing I wondered is what is very special about the model than the large data and parameter set it has, that other competitors can't do. I ask this because I have seen a lot of \"google killer\" discussions in some places. From what I understood from their papers I thought it is something another company with the computing power and the filtered data can have up and running in few months. I see their advantage in rolling out to the public because with feedbacks from actual users all over the world it can potentially be retrained.\n\nThe second thing I wondered is its scalability. It feels to me that it is a very big challenge to keep it scalable in the future. Currently getting a long text out of it is kind of painful because it has to continuously generate. I think it is continuously calculating with the huge parameter set it has. I wonder also about new trends, if it needs to be retrained. I also used it for a fine tuning, where I created a fictional world with its own law and rules and the fine tuning took hours in the queue - so is it creating separate parameters for my case? that would be a lot considering how much parameter set they have.",
            "spoiler": false,
            "stickied": false,
            "title": "Few questions about scalability of chatGPT [D]",
            "upvote_ratio": 0.8,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10lp3g4/few_questions_about_scalability_of_chatgpt_d/"
        },
        {
            "author": "u/NaturalGradient",
            "created_utc": "01-26-2023 04:27:56",
            "distinguished": null,
            "edited": false,
            "id": "10lot3v",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_10lot3v",
            "nsfw": false,
            "num_comments": 22,
            "permalink": "/r/MachineLearning/comments/10lot3v/p_evotorch_040_dropped_with_gpuaccelerated/",
            "score": 151,
            "selftext": "Find the release notes here:\n\n[https://github.com/nnaisense/evotorch/releases/tag/v0.4.0](https://github.com/nnaisense/evotorch/releases/tag/v0.4.0)\n\nA big highlight is how fast these implementations are! I genuinely believe GPU-acceleration is the future of Evolutionary algorithms, and EvoTorch and its integration into the PyTorch ecosystem is a fantastic enabler for this.   \n\nTo demonstrate the raw speed provided by the new release, I compared EvoTorch's CMA-ES implementation to that provided by the popular pycma package on the 80-dimensional Rastrigin problem and tracked the run-time:\n\n[Performance was measured over 50 runs on the 80-dimensional Rastrigin problem](https://preview.redd.it/w3qwefgr6dea1.jpg?width=458&format=pjpg&auto=webp&v=enabled&s=e056e6aa42e07b050ea2a187ae3b07de2b789f6f)\n\nThe crazy thing to note is that when we switch to GPU (Tesla V100), we can efficiently run CMA-ES with population sizes going into 100k+!",
            "spoiler": false,
            "stickied": false,
            "title": "[P] EvoTorch 0.4.0 dropped with GPU-accelerated implementations of CMA-ES, MAP-Elites and NSGA-II.",
            "upvote_ratio": 0.96,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10lot3v/p_evotorch_040_dropped_with_gpuaccelerated/"
        },
        {
            "author": "u/Due-Wall-915",
            "created_utc": "01-25-2023 23:16:07",
            "distinguished": null,
            "edited": false,
            "id": "10lka00",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10lka00",
            "nsfw": false,
            "num_comments": 13,
            "permalink": "/r/MachineLearning/comments/10lka00/machine_learning_and_black_box_numerical_solverd/",
            "score": 6,
            "selftext": "Anybody know some methods and techniques for integrating a numerical solver with the neural network .. how do you calculate the gradients of the solver when you don\u2019t know the details of such solver- black box solver.",
            "spoiler": false,
            "stickied": false,
            "title": "Machine learning and black box numerical solver[D]",
            "upvote_ratio": 0.88,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10lka00/machine_learning_and_black_box_numerical_solverd/"
        },
        {
            "author": "u/debrises",
            "created_utc": "01-25-2023 18:17:39",
            "distinguished": null,
            "edited": false,
            "id": "10leaq9",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Project",
            "locked": false,
            "name": "t3_10leaq9",
            "nsfw": false,
            "num_comments": 9,
            "permalink": "/r/MachineLearning/comments/10leaq9/p_diffusion_models_best_practices/",
            "score": 16,
            "selftext": "I'm about to start an experimental project that involves training a denoising diffusion model on the medical data (small dataset).\n\nCould you please share useful resources, tips, tricks and heuristics for dealing with diffusion models?",
            "spoiler": false,
            "stickied": false,
            "title": "[P] Diffusion models best practices",
            "upvote_ratio": 0.9,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10leaq9/p_diffusion_models_best_practices/"
        },
        {
            "author": "u/IndependentIce4553",
            "created_utc": "01-25-2023 16:45:24",
            "distinguished": null,
            "edited": false,
            "id": "10lc538",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10lc538",
            "nsfw": false,
            "num_comments": 2,
            "permalink": "/r/MachineLearning/comments/10lc538/d_alphatensor_benchmark_code_in_colab/",
            "score": 3,
            "selftext": "Hello everybody\n\nI was wondering if anybody tried to run the main factorisation code [https://github.com/deepmind/alphatensor/blob/main/benchmarking/factorizations.py](https://github.com/deepmind/alphatensor/blob/main/benchmarking/factorizations.py) from alpha tensor on Google Colab, with Colab's GPUs ( Tesla T4).\n\nI know that Tesla T4 is not as the same as the V100 used in Deep Mind's paper, however, I can see that the tensor formulation for the matrix multiplication is highly inefficient, compared to standard JAX matrix multiplication.\n\nAny suggestion where am I wrong?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Alphatensor benchmark code in Colab",
            "upvote_ratio": 0.81,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10lc538/d_alphatensor_benchmark_code_in_colab/"
        },
        {
            "author": "u/BigDreamx",
            "created_utc": "01-25-2023 15:17:07",
            "distinguished": null,
            "edited": false,
            "id": "10l9zly",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Discussion",
            "locked": false,
            "name": "t3_10l9zly",
            "nsfw": false,
            "num_comments": 6,
            "permalink": "/r/MachineLearning/comments/10l9zly/d_publication_resume/",
            "score": 3,
            "selftext": "If we submit a publication to ICML and it is under anonymous review, can I list the title and authors on my resume which will be on my personal webpage?",
            "spoiler": false,
            "stickied": false,
            "title": "[D] Publication Resume",
            "upvote_ratio": 0.67,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10l9zly/d_publication_resume/"
        },
        {
            "author": "u/emailnazneen",
            "created_utc": "01-25-2023 15:10:17",
            "distinguished": null,
            "edited": "01-25-2023 15:36:31",
            "id": "10l9tet",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_10l9tet",
            "nsfw": false,
            "num_comments": 5,
            "permalink": "/r/MachineLearning/comments/10l9tet/r_blogpost_on_comparing_chatbots_like_chatgpt/",
            "score": 160,
            "selftext": "[https://huggingface.co/blog/dialog-agents](https://huggingface.co/blog/dialog-agents) breaks down the techniques behind ChatGPT -- instruction fine-tuning, supervised fine-tuning, chain-of-thought, read teaming, and more.\n\nhttps://preview.redd.it/fv16fsemd9ea1.png?width=889&format=png&auto=webp&v=enabled&s=bc723c4cc71ec0457bb1c2ac07f5fa6e4a3a4ccf",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Blogpost on comparing Chatbots like ChatGPT, LaMDA, Sparrow, BlenderBot 3, and Claude",
            "upvote_ratio": 0.94,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10l9tet/r_blogpost_on_comparing_chatbots_like_chatgpt/"
        },
        {
            "author": "u/Meddhouib10",
            "created_utc": "01-25-2023 08:08:46",
            "distinguished": null,
            "edited": false,
            "id": "10kzfwm",
            "is_original_content": false,
            "is_self": true,
            "link_flair_text": "Research",
            "locked": false,
            "name": "t3_10kzfwm",
            "nsfw": false,
            "num_comments": 7,
            "permalink": "/r/MachineLearning/comments/10kzfwm/r_best_service_for_scientific_paper_correction/",
            "score": 4,
            "selftext": "Hello,\nAnyone ever used a paper revision service and can recommend one ?\n\nI\u2019m publishing my first paper next month and I want to have feedback from an expert on this domain.\n\nThanks !",
            "spoiler": false,
            "stickied": false,
            "title": "[R] Best service for scientific paper correction",
            "upvote_ratio": 0.7,
            "url": "https://www.reddit.com/r/MachineLearning/comments/10kzfwm/r_best_service_for_scientific_paper_correction/"
        }
    ]
}