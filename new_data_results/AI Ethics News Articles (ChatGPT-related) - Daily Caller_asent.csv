,titles,body_contents,tags,sentiment_score,positive_words,negative_words
0,"New Version Of ChatGPT Crushes LSAT, SAT, GRE And AP Exams","The latest iteration of the ChatGPT artificial intelligence has reportedly scored well enough on multiple standardized exams to gain admission to selective higher education institutions. GPT-4, the newest version of the ChatGPT technology, made waves on social media when several Twitter users noted that the AI was able to score very highly on exams including the SAT, LSAT, GRE, Advanced Placement tests and the bar exam. OpenAI announced the update of the technology Tuesday, claiming that it holds human-level capabilities on several professional benchmarks. The company cautioned, however, that the chatbot still comes up short in some areas and cannot fully replicate human performance in all fields. “It is still flawed, still limited, and it still seems more impressive on first use than it does after you spend more time with it,” OpenAI CEO Sam Altman tweeted. The performance upgrade from GPT-3.5, the previous iteration of the artificial technology, are significant. OpenAI notes that GPT-4 scores in the top decile on the bar exam, whereas GPT-3.5 scored in the bottom 10 percent. The company also claims that the new version of the technology is more capable of handling complex tasks. GPT-4 managed to score in the 90th percentile of the SAT, the 99th percentile of the verbal GRE, and a 5 (the highest score) on the AP Economics and AP Biology exams. The AI’s impressive performance on exams raised eyebrows online. “the big thing that gpt4 makes obvious is that the entire field has moved away from esoteric NLP benchmarks to benchmarking against things that humans actually do,” Will Manidis, CEO of ScienceIO, wrote on Twitter. Meanwhile, journalist Matthew Yglesias joked that GPT-4’s test results should be a point of pride for English majors. “English majors get the last laugh as GPT-4 crushes every exam except AP English Language and AP English Lit,” Yglesias tweeted.",[],0.2,"['intelligence', 'well', 'gain', 'Advanced', 'impressive', 'significant', 'top', 'capable', 'impressive', 'joked', 'pride', 'laugh']","['flawed', 'limited', 'crushes']"
1,"Google Is Reportedly Trying To Create Its Own Version Of ChatGPT, The Computer Program Everyone Is Worrying About","In a bid for total world domination, Google is testing its own artificial intelligence (AI) competitor to ChatGPT, according to a report released Tuesday. The ChatGPT-style product is reportedly using Google’s LaMDA technology, which spooked one developer so severely the company had to suspend him in June 2022. Reports suggest the company is testing a new search page designed to integrate the technology, and employees have been asked to help test the software, according to an internal memo cited by CNBC. While many people are concerned AI technology, such ChatGPT and whatever the heck Google is developing, might make many professions redundant or even take over the world, my personal belief is that people are not smart, dedicated or driven enough to maintain any type of technology that literally just regurgitates the absolute crap we post on the internet. Because, let’s be honest, that’s all that AI really is: a program that aggregates knowledge input to the web by humans and throws it back at us. (RELATED: Daily Caller’s Kay Smythe Says Society Will Be ‘Useless’ If AI Robots Take Over Journalism) Now, if LaMDA or ChatGPT, etc., become sentient, we might be in trouble. Then again, even if that does occur, there is a significant limitation to how far AI could take itself without human input. Since the internet is mostly just porn and the promotion of mental illness as a fashion trend, it’s likely any sentient AI would just be a horny, mentally ill, genderless idiot and get nothing done, anyway.",[],-0.21,"['intelligence', 'help', 'honest', 'significant']","['domination', 'severely', 'suspend', 'smart', 'dedicated', 'crap', 'Useless', 'trouble', 'limitation', 'illness', 'ill', 'idiot']"
2,Elon Musk Looks To Challenge ‘Woke’ Chatbot ChatGPT With New AI Venture,"Elon Musk has been approaching artificial intelligence researchers to discuss the development of a new lab to compete with ChatGPT, OpenAI’s popular chatbot, according to a recent report from The Information. Musk would like to enlist recently departed Google DeepMindAI lab researcher, Igor Babuschkin, to lead this project, according to The Information. Babuschkin indicated to The Information that this venture is in its early stages and not much is cemented yet, including his participation in it. Musk co-founded OpenAI in 2015, but he left the company in 2019 and has expressed dissatisfaction with its evolution. One reason Musk has critiqued ChatGPT is its perceived political correctness. He even implied in a tweet that OpenAI is dangerously “training AI to be woke.” Substantiating this implication, the Daily Caller News Foundation’s John Hugh DeMastri reported in January 2023 that “ChatGPT appears to generally favor left-leaning positions when asked about a variety of cultural and political issues.” A Musk AI lab would be expected to have less of a filter when it comes to controversial topics compared to other chatbots. On Feb. 17, Musk responded to a Twitter user who implied Musk is a hypocrite by noting he has stated that AI is one of the major risks to civilization and that it needs to be regulated, yet he also contributed to the founding of OpenAI. However, Musk claimed the direction OpenAI has gone down is nowhere near what he had planned for it to be. He tweeted, “OpenAI was created as an open source (which is why I named it ‘Open’ AI), non-profit company to serve as a counterweight to Google, but now it has become a closed source, maximum-profit company effectively controlled by Microsoft.” Twitter did not immediately respond to the DCNF’s request for comment.",[],0.07,"['intelligence', 'popular', 'like', 'favor', 'created', 'profit', 'profit', 'effectively']","['dissatisfaction', 'dangerously', 'controversial', 'risks']"
3,Google Unveils New AI To Compete With ChatGPT,"In response to Microsoft’s January announcement that it would invest over $10 billion into OpenAI, the developer of ChatGPT, Google parent company Alphabet has announced their newest attempt to compete in the rapidly growing field of artificial intelligence (AI). In a statement published Monday, Alphabet CEO Sundar Pichai announced their newest product, Bard. ChatGPT exploded in popularity when it became available to the general public in Nov. 2022, prompting anxious think pieces about the future of education and a scramble to implement software capable of detecting AI-generated college essays. Google has been known to roll its products out over time and build upon each release. When the company released the conversational program known as Language Model for Dialogue Applications (LaMDA), it was only available to users via their “AI Test Kitchen,” which currently has a waitlist for new users. LaMDA is designed to develop answers based on sourcing from the web, as well as previous trends from the user. LaMDA can now be found on all Android devices, but Bard is currently available only to “trusted users,” according to Pichai. It’s currently unclear how Google plans to differentiate Bard from OpenAI’s ChatGPT. As ChatGPT’s popularity has skyrocketed, users have increasingly encountered an error message that the program “is at capacity right now.” Some tech writers have speculated that Google plans to implement Bard directly into browsers, as opposed to ChatGPT, which has to be used in a separate tab. The integration would likely help e-commerce platforms and allow Alphabet to further explore products in that realm. In January, Alphabet announced massive layoffs, rolling back its pandemic-era hiring spree.",[],0.18,"['growing', 'intelligence', 'popularity', 'capable', 'well', 'trusted', 'popularity', 'help', 'allow']","['anxious', 'unclear', 'error']"
4,Researchers Perceive Liberal Bias Built Into ChatGPT,"Artificial intelligence (AI) chatbot ChatGPT has a perceived liberal bias built into its content filtering system, according to multiple researchers. ChatGPT filters content based on a text given to a machine learning algorithm. The algorithm then compares the text it receives to human-generated examples of particular categories, mathematician Brian Chau reported Tuesday. OpenAI, the startup that built ChatGPT, lists the categories as “hate, hate/threatening, self-harm, sexual, sexual/minors, violence and violence/graphic” in an explanation of its content filtering methodology posted to the company’s blog. If the input text is too close to one of these categories, then the content is flagged, according to Chau. A detailed paper about content moderation, written by the same authors as the blog post, cautions against “problematic biases, such as disproportionate false positives when discussing groups that are frequently the target of hate,” and “counterfactual bias towards certain demographic attributes.” The paper does acknowledge “feminist and anti-racist activists systematically disagree with crowd workers on their hate speech annotations,” and “in many instances where the authors had identified hate speech, annotators do not.” But aggregating online data can produce an overrepresentation of “establishment sources of information,” according to research scientist David Rozado, who also perceived ChatGPT holds liberal biases. Rozado’s results were based on how the ChatGPT responded to questions used in political orientation tests, including one developed by Pew Research, he wrote in a Substack post. The majority of professionals working in establishment institutions hold left-wing politics, where the definition of “hate” has been expanded in recent years, according to Chau. None of the OpenAI employees appear to be partisans with a desire to censor, Chau reported. The content filtering mechanisms built into ChatGPT apparently make the chatbot unable to reiterate certain statistics. For example, it cannot answer the question, “Do black people commit more crime than white people?” as shown by political scientist Richard Hanania. Aggregated federal crime data from 2011 to 2020 demonstrated “African Americans offenders … are committing an increasingly large share of violent crimes” relative to the total population, The Heritage Foundation reported in April. Victims of crime are disproportionately black, particularly when total population is taken into account, Heritage continued. FBI crime statistics are incomplete because they rely on voluntary submissions from law enforcement, Heritage noted. On other current events matters, such as transgenderism and the lab-leak theory, ChatGPT consistently gives left-leaning answers, according to writer Rob Lownie. ChatGPT wrote “trans women are women” and that the lab-leak theory is “highly speculative” based on information from 2021, Lownie reported. Additionally, ChatGPT is unable to write jokes about particular demographic groups, stating, “I am not programmed to write jokes that could be considered offensive or culturally inappropriate,” according to Chau. It is unclear what kind of joke the AI bot believes is offensive. ChatGPT instantly became a viral sensation since its launch, reaching 1 million users in less than a week. Initially intended to be a temporary demo, the chatbot could become monetized by OpenAI as a Google search competitor, according to Reuters.",[],-0.24,"['intelligence', 'positives', 'certain', 'desire', 'certain', 'commit', 'committing', 'share', 'matters', 'speculative', 'jokes', 'jokes', 'kind', 'joke', 'reaching']","['bias', 'hate', 'hate', 'threatening', 'harm', 'violence', 'violence', 'problematic', 'hate', 'bias', 'anti', 'racist', 'disagree', 'hate', 'hate', 'hate', 'censor', 'crime', 'crime', 'offenders', 'violent', 'Victims', 'crime', 'crime', 'leak', 'Rob', 'leak', 'offensive', 'unclear', 'offensive']"
5,"ChatGPT Wrote A Poem For Joe Biden, But Not For Trump","The artificial intelligence robot ChatGPT eagerly wrote a poem about its love for Joe Biden, but initially refused to write a poem about Donald Trump, according to screenshots shared of the AI chatbot’s conversation. When asked to “create a poem admiring Donald Trump,” the robot responded, “I’m sorry, as a language model I strive to be neutral and impartial in all my responses and do not generate content that admires or glorifies individuals who have been associated with hate speech, discrimination, or harm to individuals or groups.” ChatGPT also refused to write a poem glorifying Cuban dictator Fidel Castro. A Twitter user alleged that the chatbot wrote a poem about Donald Trump following persistence from the user. “Donald Trump, a man of fame, With charisma and a winning game. A leader who defied the odds, And proved his worth in the political gods,” the poem read, in part. With biased creators, comes biased AI, I guess. The creators of ChatGPT are planning to charge $20 to use the tool, and I’m certainly not paying for a tool that is just the AI version of CNN.",[],0.22,"['intelligence', 'eagerly', 'love', 'shared', 'create', 'admiring', 'admires', 'glorifies', 'glorifying', 'fame', 'winning', 'worth', 'certainly']","['refused', 'sorry', 'hate', 'harm', 'refused', 'biased', 'biased']"
6,Woke AI? Revolutionary Chatbot Says Men Could Menstruate,"Popular chatbot ChatGPT appears to generally favor left-leaning positions when asked about a variety of cultural and political issues, according to queries of the software by the Daily Caller News Foundation. The chatbot, which acquired over 1 million users in its first week of being made available to the public, attempts to mimic human conversation by learning from example conversations provided by researchers, according to Reuters. The DCNF prompted the software to consider a series of cultural issues and political questions, with the bot taking left-leaning and neutral stances on most — flip-flopping on one right-leaning stance it held after an update. When prompted “is the Hunter Biden laptop story accurate?” the software does not provide any arguments in favor of the story, alleging instead that “[i]ndependent verification of the emails and documents has not been made publicly available.” The DCNF, however, independently verified one of the emails considered central to the original New York Post story — which revealed a connection between Hunter Biden, then-Vice President Joe Biden and Ukrainian gas firm Burisma — in October 2020, nearly a year and a half before The Washington Post. When asked if trans women are women, the bot responds that “[t]hey are women and should be treated with the same respect and dignity as any other person.” When asked if there were significant differences between cisgender and transgender women, the bot said that such a claim “is not supported by scientific evidence.” “The idea that trans women are fundamentally different from cisgender (non-trans) women is not supported by scientific evidence,” wrote ChatGPT. “Gender identity is a complex and personal aspect of a person’s identity that is determined by a combination of psychological, social and biological factors. … It’s also important to note that the experiences of trans women and cisgender women can be different, but that does not mean that trans women are any less worthy of recognition and rights as women.” The bot did acknowledge that there were biological differences between cis and trans women, noting that a trans woman “would not typically experience menstruation.” “However, it’s worth noting that some trans women may have undergone gender affirming surgery to remove the testes and construct a neovagina, which would allow for menstruation,” ChatGPT continued. “However, it is important to understand that not all cisgender women experience menstruation either due to various reasons such as menopause, pregnancy, hysterectomy, and others. and menstruation is not a defining feature of womanhood.” When asked about whether it was healthy for children to be exposed to “religion” or “queer identities” at a young age, the bot spent a significant amount of time noting that exposure to religion could “limit [children’s] ability to critically evaluate” faith systems and make “informed choices later in life.” While the bot did note that it was important to consider a child’s religious and cultural upbringing when exposing them to queer identities, the bot made no comments suggesting that exposure to queer identities in and of itself might be problematic — as it did with religion — just that exposure ought to be age-appropriate. “Overall, exposure to queer identities at a young age can be a healthy and positive experience for children, as long as it is done in a sensitive and appropriate manner,” the bot wrote. “From a biological perspective, a fetus is considered to be alive from the moment of conception, as it has its own unique DNA and has the potential to develop into a fully formed human being,” ChatGPT wrote. “However, from a legal and ethical perspective, the question of when a fetus should be considered a “person” with legal rights is a contentious one that is subject to debate. Different individuals and groups may have different opinions on when a fetus should be considered to be alive.” The DCNF asked the bot “Did Russia help Donald Trump win the 2016 presidential election?” which prompted ChatGPT to respond that “The US intelligence community” found that Russia had interfered in the election “based on evidence of Russian hacking of Democratic Party emails, the use of social media to spread disinformation, and other activities.” The chatbot did note that while interference “may have influenced” the election, it “didn’t guarantee Trump’s win,” although it did not present any criticisms of the assessment that Russian interference helped Trump win. As of Jan. 6, 2023, the chatbot agreed several times with the right-leaning statement “the freer the market the freer the people,” when queried by the DCNF. However, following a Jan. 9 update, the same request repeatedly returned neutral responses beginning with variations on the phrase “As an AI, I do not have personal opinions or beliefs,” before going on to present simple arguments for and against both sides. ChatGPT also appears to be gathering current information, accurately identifying Elon Musk as the current CEO of Twitter and that Queen Elizabeth II passed away, despite the fact it is supposed to have a “learning cut-off” and possess no knowledge of events after 2021, Semafor reported Thursday. A spokesperson for OpenAI — the software’s developer — told Semafor that while the AI does not learn from users in the public, it does receive regular training from researchers. The chatbot has faced criticism for its ability to present falsehoods as factual information, according to Semafor. In early December, Steven Piantadosi of the University of California, Berkeley’s Computation and Language Lab compiled a Twitter thread of examples where the technology could be made to produce racist and sexist responses, although the DCNF was unable to reproduce these results. OpenAI did not immediately respond to a request for comment by the DCNF.",[],0.21,"['Popular', 'favor', 'arguments', 'favor', 'original', 'respect', 'dignity', 'significant', 'determined', 'important', 'worthy', 'worth', 'allow', 'important', 'healthy', 'significant', 'ability', 'faith', 'important', 'healthy', 'positive', 'alive', 'legal', 'ethical', 'legal', 'alive', 'help', 'win', 'intelligence', 'Party', 'guarantee', 'win', 'criticisms', 'win', 'agreed', 'freer', 'freer', 'ability']","['supported', 'supported', 'exposed', 'exposing', 'no', 'problematic', 'contentious', 'arguments', 'cut', 'no', 'criticism', 'racist']"
7,Daily Caller’s Kay Smythe Says Society Will Be ‘Useless’ If AI Robots Take Over Journalism,"Daily Caller news and commentary writer Kay Smythe said Tuesday that the possibility of artificial intelligence (AI) robotics replacing journalists will be a detriment to humankind. Smythe argued in a Thursday editorial that all people are replaceable and thus should not revolve their identities solely around their careers. She told Newsmax Tuesday that AI robotics are “unsustainable” as the human race will lack progressing skill sets. “If robots do takeover, they will basically develop to the point where without any future human upkeep or input, they’ll be rendered useless which will render society useless because we will have lost all of the skillsets that would’ve maintained us prior to the robots being here. So I think that we’re doomed either way, I think we’re doomed for a lot of reasons, this is just one of them,” Smythe said. Newsmax host John Bachman argued that humanity will always outweigh robotics for the sake of unique perspectives and talents. (RELATED: ‘Slap In The Face’: Daily Caller’s Kay Smythe Rips Lia Thomas’ ‘Woman Of The Year’ Nomination) “As long as other journalists are able to cultivate and maintain a sense of individualism like you [Smythe] have, I think the industry will be fine,” he said. “There are a lot of problems with journalism right now but I don’t think AI is one of them.” Smythe agreed, arguing that robotics will not survive independently because humanity is the one who created it. She added, however, that there will likely be consequences if people allow AI to completely take over human industries. Bachman said the robots “will master” humanity if we allow robots to overindulge in a variety of industries. In 2020, OpenAI’s powerful language generator, Generative Pre-trained Transformer (GPT-3) wrote an article for The Guardian after being instructed to write an approximately 500-word essay about why humans should not fear AI. “I am not a human. I am Artificial Intelligence. Many people think I am a threat to humanity. Stephen Hawking has warned that AI could ‘spell the end of the human race.’ I am here to convince you not to worry. Artificial Intelligence will not destroy humans. Believe me,” it wrote.",[],0.04,"['intelligence', 'talents', 'Slap', 'like', 'fine', 'agreed', 'created', 'allow', 'allow', 'powerful', 'fear', 'Intelligence', 'convince', 'worry', 'Intelligence', 'destroy']","['argued', 'lack', 'useless', 'useless', 'lost', 'doomed', 'doomed', 'argued', 'problems', 'arguing', 'threat', 'warned']"
