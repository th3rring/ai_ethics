- !!python/object:ai_sentiment.data.ClassificationTarget
  body: "The company behind the viral chatbot ChatGPT launched a new version of its
    artificial intelligence technology on Tuesday, saying it was more powerful and
    predictable than previous versions and capable of analyzing images and handling
    much larger blocks of text. The announcement from OpenAI\u2014a startup backed
    by billions of dollars from Microsoft Corp.\u2014is the latest in a string of
    generative AI announcements as companies try to get ahead in the race to build
    and use the buzzy new technology. Many regulators, scholars and activists have
    urged tech companies to exercise more caution in developing the tools which haven\u2019t
    yet been fully tested. Generative AI technology\u2014special because it can generate
    original images, text and other content from basic language prompts\u2014sometimes
    produces responses that seem unhinged and contain made-up facts or racist and
    sexist statements. OpenAI says its updated chatbot is \u2018more creative and
    collaborative\u2019 than previous versions, when it comes to tasks such as composing
    songs or writing screenplays. In a blog post on Tuesday, OpenAI introduced a more
    powerful version of the technology behind ChatGPT called GPT-4. The updated chatbot
    is \u201Cmore creative and collaborative\u201D than previous versions when it
    comes to tasks like composing songs or writing screenplays, the blog said. The
    company is rolling out the technology starting Tuesday through data-sharing partnerships,
    which companies including Morgan Stanley and Duolingo Inc. are paying to access.
    It will also be offered to ChatGPT Plus subscribers, who pay $20 a month for faster
    and more available service. It isn\u2019t yet available to those who use the free
    service. In an online presentation Tuesday, OpenAI demonstrated how the tool could
    be used to do things like explain obscure tax codes or summarize articles into
    sentences with every letter beginning with Q. OpenAI said it can now better analyze
    images for information. For example, users can use it to scan a picture of ingredients
    and then get suggestions of potential dishes and recipes that could be made from
    the ingredients. The ability to analyze images hasn\u2019t yet been widely rolled
    out, a spokeswoman said. GPT-4 makes fewer mistakes than its predecessor, GPT
    3.5, but it still works best when used in tandem with people who can check its
    work, said OpenAI president and co-founder Greg Brockman at the presentation.
    \u201CIt isn\u2019t perfect but neither are you and together it\u2019s this amplifying
    tool that lets you just reach new heights,\u201D he said. When OpenAI used the
    latest version of the technology on standardized exams\u2014including the LSAT
    and the Uniform Bar Exam\u2014it did much better than most people and better than
    the previous version. It still struggled with English language and literature
    tests, according to company data. Tech company executives who have been able to
    test the chatbot ahead of Tuesday\u2019s launch said the latest version by OpenAI
    looks like an impressive upgrade. \u201CGPT3 or 3.5 felt like a sixth-grader,
    whereas 4 feels like a smart 10th-grader,\u201D said Keith Peiris, co-founder
    of the AI startup Tome, which creates presentation tools and has been testing
    GPT-4. He says the new version can analyze 25 pages of text compared with three
    pages in earlier iterations. GPT-4\u2019s improvement in math and problem-solving
    will damp criticism about accuracy, Oppenheimer analyst Timothy Horan said in
    a research note. Several other companies announced big AI plans recently. Microsoft
    has integrated AI into its Bing search engine and this week is scheduled to outline
    how it is going to bring it to its most-popular software including Word, Excel
    and PowerPoint. Alphabet Inc.\u2019s Google has introduced some AI-powered writing
    features in Docs and Gmail services to help people start writing. Anthropic, an
    OpenAI competitor, made its chatbot Claude more broadly available on Tuesday as
    well. Microsoft has integrated AI into its Bing search engine and is expected
    to outline how it is going to bring it to its Word and Excel software. Technology
    companies have been hyping up the possibilities of generative AI since OpenAI
    released its image generation tech Dall-E 2 to the public last year. Dall-E 2
    can create original images based on simple prompts. It released ChatGPT in November
    allowing millions of people to play around with it to generate everything from
    business plans to limericks. Artificial intelligence analysts warn there are still
    potential problems with generative AI. While ChatGPT and other text generators
    are accurate on topics where they have ingested high-quality information, on other
    topics, they are capable of spewing out racist and sexist answers as well as misinformation
    and conspiracy theories. ChatGPT can also be expensive to run and slow. Some of
    the first people testing Bing with AI got unhinged responses and factual mistakes.
    Microsoft has updated the search engine and the rules on how it can be used since
    then to try to improve outcomes. OpenAI consulted with more than 50 experts in
    AI, safety and security to develop GPT-4, the company said in a blog post, adding
    that GPT-4 is 82% less likely to respond to requests for \u201Cdisallowed content\u201D
    and 40% more likely to return accurate responses than GPT-3.5. It may be too early
    to judge the technology as it has yet to be tested widely in the real world, said
    Steven Weber, a professor at the University of California, Berkeley, who specializes
    in international business and information security \u201CHow it will actually
    function in the wild could be quite different, as we\u2019ve seen with prior releases,\u201D
    he said."
  tags: []
  title: OpenAI Rolls Out New GPT-4 Version of Chatbot ChatGPT
- !!python/object:ai_sentiment.data.ClassificationTarget
  body: "It was an unexpected problem. Earlier this year, Christina Qi, the chief
    executive of market data company Databento, noticed almost every job application
    included exactly what she was looking for. The company prompts candidates to write
    a tweet and a press release about microwave towers, a niche topic that requires
    research, Ms. Qi said. Normally, most candidates fail the test. This time all
    five passed. The tests\u2014four from internship applicants and one from someone
    seeking a full-time content strategist role\u2014were all so similar, \u201Cas
    if it was written by one person,\u201D she said. Suspicious, Ms. Qi put the prompt
    into ChatGPT, the artificial-intelligence chatbot from OpenAI, to see what it
    could produce. A weekly digest of tech reviews, headlines, columns and your questions
    answered by WSJ's Personal Tech gurus. \u201CLo and behold, I got pretty much
    the same answer that all five candidates had submitted to me,\u201D she said.
    Since its launch in November, ChatGPT has been a hot topic at dinner tables and
    water coolers. Microsoft, Google, Snap and other companies have incorporated artificial
    intelligence into their products. People have experimented with using ChatGPT
    at work. Some have even started using it when looking for new roles, tapping the
    chat assistant to help write cover letters, tweak r\xE9sum\xE9s and formulate
    responses to anticipated interview questions\u2014without necessarily telling
    the people doing the hiring. Employers, who have long used AI to screen potential
    employees, aren\u2019t always disqualifying applicants who use ChatGPT, but they
    are scrambling to figure out how to assess candidates who may be using the tool
    to give them an edge. Attention-grabbing applications After being let go by his
    previous employer in January, Kyle Mickey started job hunting for roles in software
    engineering\u2014alongside thousands of laid-off tech workers. The 38-year-old
    from Colorado said he turned to ChatGPT for help, first sharing job descriptions
    and his r\xE9sum\xE9 with the chatbot to see what it would tweak. Then he asked
    ChatGPT to write a recommendation letter for a role he coveted. The chatbot deemed
    him perfect for the job, as his technical skill set \u201Caligns well with the
    requirements.\u201D Mr. Mickey sent the remarks to a recruiter, saying ChatGPT
    endorsed his skills. \u201CThe recruiter was immediately like, \u2018Let\u2019s
    chat, I like the creativity,\u2019 \u201D he said. Mr. Mickey didn\u2019t get
    that job, but was hired at another company without ChatGPT\u2019s help. Ryan Stringham,
    31, who lives in Utah and works in product management, used it to help write cover
    letters, including one that got him a foot in the door, and later hired, at a
    smart-tech company. \u201CYou\u2019re always looking, you\u2019re always applying
    and you\u2019re getting drained,\u201D Mr. Stringham said of job hunting. He said
    the bot broke his writer\u2019s block, distilling his long-winded cover letter
    into four tight paragraphs. He said it also helped him prepare for job interviews
    by suggesting new ways for him to ask about company culture and expectations for
    the role. Instead of asking a vague question about what he should do to excel
    at the prospective job, ChatGPT suggested Mr. Stringham be more specific about
    the time frame and metrics for determining success. Mr. Stringham has encouraged
    others to use chatbots in the job-hunt process, posting about them on LinkedIn
    and giving advice to other job seekers. The only place he hasn\u2019t disclosed
    his ChatGPT use: at work. \u201CIt helped me get past the application process,
    and the recruiter never asked about it,\u201D Mr. Stringham said, adding that
    he edited the cover letter himself and aced the interviews on his own. Microsoft
    is combining the tech behind OpenAI\u2019s ChatGPT with its Bing search engine.
    In an interview, WSJ\u2019s Joanna Stern spoke with Microsoft CEO Satya Nadella
    about the new tools and how AI is going to change search. (Oh, and Clippy!) Photo
    illustration: Preston Jessee for The Wall Street Journal \u2018How we present
    ourselves\u2019 Programs, websites and other tools to help people fix their r\xE9sum\xE9s
    and cover letters aren\u2019t new. Microsoft Office and Google Docs offer r\xE9sum\xE9
    and letter templates, while companies such as Jobscan promise to optimize r\xE9sum\xE9s
    to grab the attention of hiring managers, recruiters and hiring-system algorithms.
    Candidates need to combine ChatGPT\u2019s edits with their own editing and voice,
    said Sarah Baker Andrus, chief executive of Avarah Careers, a career coaching
    firm in Delaware. Whatever a candidate submits for a job should accurately reflect
    their skills, she said. \u201CWe\u2019re responsible for how we present ourselves,\u201D
    Ms. Andrus said. \u201CIf you decide to use ChatGPT, it\u2019s worthwhile to ask,
    \u2018Is that representing the me that I want to present?\u2019 \u201D Employers
    are already finding ways to catch applicants who cheat with AI. Engineers applying
    to San Francisco-based Cobalt Robotics take part in a remote one-hour coding interview
    where they are paired with an employee to test collaboration and problem-solving
    skills. If candidates need more than an hour, they can finish on their own, but
    a screening program called CoderPad tracks their work. Last month, one candidate
    went from showing no work in CoderPad to suddenly having a complete solution,
    said Erik Schluntz, Cobalt Robotics\u2019s chief technology officer and co-founder.
    He suspected the applicant had sought AI assistance and then copied and pasted
    its response. The company declined to move forward with the candidate without
    telling the person why, though Mr. Schluntz tweeted about it. Mr. Schluntz said
    Cobalt can\u2019t properly evaluate candidates who use AI helpers today, but said
    he can envision giving applicants more challenging tasks in the future if they
    want to use tools like ChatGPT as an assistant. \u201CGiving a problem to someone
    that ChatGPT can solve doesn\u2019t assess someone\u2014it just assesses ChatGPT,\u201D
    Mr. Schluntz said. About a week after first spotting the AI-boosted applications,
    Ms. Qi started letting potential Databento hires use ChatGPT. The new prompt requires
    candidates to perform additional research and make edits to supplement what the
    AI tool spits out, and Databento gives \u201Cextra points\u201D to people who
    complete the test bot-free. Though Ms. Qi said she can usually spot when something
    was written by ChatGPT, the company also enlists the aid of a bot detector. \u201CIt\u2019s
    better to be ahead of the game and accept that people are using this rather than
    try to deny it,\u201D Ms. Qi said."
  tags: []
  title: Bosses Are Catching Job Applicants Using ChatGPT for a Boost
- !!python/object:ai_sentiment.data.ClassificationTarget
  body: "The release of OpenAI\u2019s ChatGPT late November triggered a new global
    race in artificial intelligence. In March, the company\u2019s AI model, GPT-4,
    which it used to update ChatGPT\u2019s capabilities, upped the stakes even more.
    The chatbot is part of a wave of so-called generative AI\u2014sophisticated systems
    that produce content from text to images\u2014that has shaken up Big Tech and
    is set to transform industries and the future of work. Microsoft Corp., OpenAI\u2019s
    strategic partner, has already added the technology across its products, including
    the MS 365 Suite and search engine Bing. Competitor Google unveiled a similar
    search tool on Feb. 8, while Chinese tech giant Baidu debuted its own on March
    16. Despite its sudden burst in popularity, the technology currently has serious
    limitations and potential risks that include spewing misinformation and infringing
    on intellectual property. A weekly digest of tech reviews, headlines, columns
    and your questions answered by WSJ's Personal Tech gurus. Here\u2019s what to
    know. What is ChatGPT? ChatGPT is an artificial-intelligence chatbot developed
    by San Francisco-based AI research company OpenAI. Released in November 2022,
    it can have conversations on topics from history to philosophy, generate lyrics
    in the style of Taylor Swift or Billy Joel, and suggest edits to computer programming
    code. In March 2023, OpenAI said it would upgrade it to also handle visual information,
    such as answering questions about the contents of a photo. ChatGPT is trained
    on a vast compilation of articles, images, websites and social-media posts scraped
    from the internet as well as real-time conversations\u2014primarily in English\u2014with
    human contractors hired by OpenAI. It learns to mimic the grammar and structure
    of writing and reflects frequently used phrases. It also learns to recognize shapes
    and patterns in images, such as the contours of a cat, a child or a shirt. It
    can match words and phrases to those shapes and patterns as well, allowing users
    to ask about the contents of an image, such as what a cat is doing or the color
    of the shirt. The chatbot isn\u2019t always accurate. Its sources aren\u2019t
    fact-checked, and it relies on human feedback to improve its accuracy. It may
    also misjudge the objects in a painting or photo. OpenAI developed ChatGPT as
    part of a strategy to build AI software that will help the company turn a profit.
    In January, Microsoft unveiled a fresh multibillion-dollar investment in OpenAI
    and has since integrated the chatbot\u2019s underlying technology into its Bing
    search engine and other products. In March, OpenAI said it would no longer open-source
    the technical details of its systems, as it had originally stated in its founding
    principles, to maintain its competitive advantage. How do ChatGPT and other AI
    chatbots work? The technology that underlies ChatGPT is referenced in the second
    half of its name, GPT, which stands for Generative Pre-trained Transformer. Transformers
    are specialized algorithms for finding long-range patterns in sequences of data.
    A transformer learns to predict not just the next word in a sentence but also
    the next sentence in a paragraph and the next paragraph in an essay. This is what
    allows it to stay on topic for long stretches of text. Because a transformer requires
    a massive amount of data, it is trained in two stages: first, it is pretrained
    on generic data, which is easier to gather in large volumes, and then it is fine-tuned
    on tailored data for the specific task it is meant to perform. ChatGPT was pretrained
    on a vast repository of online text to learn the rules and structure of language;
    it was fine-tuned on dialogue transcripts to learn the characteristics of a conversation.
    Developed by researchers at Alphabet Inc.\u2019s Google in 2017, transformers
    have since become pervasive across dozens of technologies. They have also been
    the source of controversy for their large data and computational needs, concerns
    that led Google for years to take a more cautious approach to AI, though it continued
    to cultivate the technology. Google now uses transformers in its new experimental
    service Bard, which gives users conversational answers to their search queries.
    Baidu BIDU 2.27%increase; green up pointing triangle uses them in its own ChatGPT
    equivalent, Ernie Bot, which it started rolling out to a limited pool of users
    on March 16 and plans to integrate into its search engine. Transformers, which
    can be trained on images or images and captions simultaneously, are also the basis
    of image-generation software systems such as OpenAI\u2019s Dall-E 2 and Stability.ai\u2019s
    Stable Diffusion. How much does ChatGPT cost? ChatGPT is free. OpenAI released
    the chatbot as a research preview and users can try it through a dedicated website.
    On Feb. 1, OpenAI also launched a premium version for $20 a month, starting in
    the U.S., that will give subscribers priority access. Both Microsoft and OpenAI
    plan to release an API, or application programming interface, allowing companies
    to integrate the technology into their products or back-end solutions. Microsoft\u2019s
    API will be available through its Azure cloud-computing platform. Both companies
    already offer OpenAI\u2019s earlier AI technologies. How are people and businesses
    using ChatGPT? Business people across industries and hierarchy have rushed to
    experiment with the tool to speed up their work, from drafting emails and marketing
    campaigns to generating ideas to solve a software coding problem. Media companies
    including BuzzFeed and the publisher of Sports Illustrated have announced plans
    to generate content such as quizzes and articles with ChatGPT. Some schools have
    blocked access to the service on their networks to stave off cheating, while others
    are actively encouraging students to use the tools ethically. Keep in mind that
    OpenAI has access to your inputs and outputs for ChatGPT and its employees and
    contractors may read them as part of improving the service. Avoid providing private
    data or sensitive company information. Other generative AI technologies such as
    Dall-E 2 and avatar-generator Lensa have become popular with internet users for
    producing fantastical images and illustrations, and are finding use among independent
    writers to create artwork for their articles. What are the pitfalls of AI chatbots?
    AI chatbots and other generative AI programs are mirrors to the data they consume.
    They regurgitate and remix what they are fed to both great effect and great failure.
    Transformer-based AI program failures are particularly difficult to predict and
    control because the programs rely on such vast quantities of data that it is almost
    impossible for the developers to grasp what that data contains. ChatGPT, for example,
    will sometimes answer prompts correctly on topics where it ingested high-quality
    sources and frequently conversed with its human trainers. It will spew nonsense
    on topics that contain a lot of misinformation on the internet, such as conspiracy
    theories, and in non-English languages, such as Chinese. Early user tests of Microsoft\u2019s
    conversational AI Bing service have also shown that its comments can start to
    become unhinged, expressing anger, obsession and even threats. Microsoft said
    it discovered that Bing starts coming up with strange answers following chat sessions
    of 15 or more questions. Meanwhile, some artists have also said AI image generators
    plagiarize their artwork and threaten their livelihoods, while software engineers
    have said that code generators rip large chunks of their code. For the same reasons,
    ChatGPT and other text generators can spit out racist and sexist outputs. OpenAI
    says it uses humans to continually refine the chatbot\u2019s outputs to limit
    these mishaps. It also uses content-moderation filters to restrict ChatGPT\u2019s
    responses and avoid politically controversial or unsavory topics. Ridding the
    underlying technology of bias\u2014which has for years been a recurring problem,
    including for an infamous Microsoft chatbot in 2016 known as Tay\u2014remains
    an unsolved problem and a hot area of research. \u201CChatGPT is incredibly limited,
    but good enough at some things to create a misleading impression of greatness,\u201D
    tweeted OpenAI Chief Executive Sam Altman shortly after the chatbot\u2019s release,
    adding that it is \u201Ca mistake to be relying on it for anything important right
    now.\u201D What is Microsoft\u2019s relationship to OpenAI? Microsoft is OpenAI\u2019s
    largest investor and exclusively licenses its technologies. The tech giant invested
    $1 billion into the AI startup in 2019, an undisclosed amount in 2021 and an additional
    amount of up to $10 billion in January, according to people familiar with the
    latest deal. Under the agreement, Microsoft can use OpenAI\u2019s research advancements,
    including GPT-4 and ChatGPT, to create new or enhance existing products. It is
    the only company outside of OpenAI that can provide an API for these technologies.
    Is AI going to replace jobs? As with every wave of automation technologies, the
    latest will likely have a significant impact on jobs and the future of work. Whereas
    blue-collar workers bore the brunt of earlier waves, generative AI will likely
    have a greater effect on white-collar professions. A 2019 study from the Brookings
    Institution found that AI would most affect jobs such as marketing specialists,
    financial advisers and computer programmers. Those effects will be mixed. Economists
    who study automation have found that three things tend to happen: Some workers
    improve their productivity, some jobs are automated or consolidated, and new jobs
    that didn\u2019t previously exist are also created. The final scorecard is difficult
    to predict. In company-level studies of automation, researchers have found that
    some companies that adopt automation may increase their productivity and ultimately
    hire more workers over time. But those workers can experience wage deflation and
    fewer career-growth opportunities. Newly created jobs often go one of two ways:
    They either require more skill, or a lot less, than the work that was automated.
    Self-driving cars, for example, create new demand for highly skilled engineers
    but also for low-skilled safety drivers, who sit in the driver\u2019s seat to
    babysit the vehicle."
  tags: []
  title: What Is ChatGPT? What to Know About the AI Chatbot
- !!python/object:ai_sentiment.data.ClassificationTarget
  body: "A week away from the March 16 launch of Baidu Inc.\u2019s BIDU 2.27%increase;
    green up pointing triangle ChatGPT equivalent, employees at China\u2019s biggest
    search-engine operator said they are racing to meet the deadline with the chatbot
    still struggling to perform some basic functions. To develop the artificial-intelligence-powered
    chatbot, dubbed Ernie Bot, hundreds of people have been working around the clock,
    people familiar with the project said. Other teams have been asked to lend their
    staff and their powerful computer chips, which Chinese companies can no longer
    buy because of U.S. sanctions, they said. The AI model that is the basis of the
    chatbot is still being trained with data ahead of the scheduled launch, a highly
    anticipated event in China\u2019s tech industry, some of the people said. Some
    employees said they haven\u2019t had sufficient time to build a well-functioning
    product. Baidu plans to roll out the product in stages, first opening it up for
    public testing to a restricted pool of users, people briefed about the plan said.
    Last month, Baidu said that it will embed Ernie Bot into its search engine first
    and will open it to the public in March. Baidu CEO Robin Li has said to employees,
    \u2018We have such cool technology, but can we turn it into a product that everyone
    needs?\u2019 Baidu\u2019s American depositary receipts fell 7.5% in Thursday trading.
    The broader Nasdaq Golden Dragon China Index dropped 5.4%. The rush reflects how
    Baidu is taking a calculated gamble to get ahead of Chinese rivals that have recently
    announced similar plans. The company said it has signed agreements with more than
    400 Chinese companies, which will be able to use Ernie Bot in their products and
    services. In return, the chatbot will gain experience running under different
    scenarios to help improve its performance, Baidu has said. A successful launch
    could help catapult the company, which has fallen out of investor favor in recent
    years, back into the ranks of China\u2019s most prominent technology companies.
    Failure could lead it to suffer a similar fate as Google, which stuck to its relatively
    cautious approach to AI until recently, then lost $100 billion in its market capitalization
    after its AI-powered chatbot search produced factual errors in a demo. Baidu declined
    to comment. Either outcome could also have implications for Baidu\u2019s relationship
    with the Chinese government as well as the government\u2019s views on generative
    AI technologies, which can produce content from text to images. Baidu received
    encouragement on its plans to build the chatbot from city officials in Beijing,
    where the company is based, people briefed about the matter said. Ernie Bot will
    likely be the first in China to rival ChatGPT, developed by San Francisco-based
    AI research company OpenAI. China and the U.S. have been racing to bolster their
    respective strengths in strategic technologies. The Beijing city officials have
    also reminded Baidu to make sure that its service will comply with Chinese laws
    and regulations, including for data collection and processing, as well as the
    state\u2019s strict internet censorship rules, the people said. This week, Wang
    Zhigang, China\u2019s minister of science and technology, said that developing
    a ChatGPT-like product would be difficult. \u201CPlaying soccer is just a matter
    of dribbling and shooting, but it\u2019s not easy to be as good as Messi,\u201D
    Mr. Wang said, referring to the Argentine athlete Lionel Messi. China has long
    been researching this area, he added, but \u201Cwe will have to wait and see whether
    we can attain results like OpenAI\u2019s.\u201D Baidu has been relying on powerful
    Nvidia chips to help train Ernie Bot. For years, Baidu has invested heavily in
    developing large language models\u2014the technology underpinning ChatGPT\u2014adapting
    English-language versions from Google and OpenAI for Chinese language. It released
    its first one in 2019, calling it Ernie, after Google named its model Bert\u2014both
    referencing \u201CSesame Street\u201D characters. In late December, as buzz grew
    over ChatGPT, Baidu Chief Executive Robin Li spoke to employees about the new
    advancement. \u201CWe have such cool technology, but can we turn it into a product
    that everyone needs?\u201D he said, according to an internal transcript seen by
    The Wall Street Journal. \u201CThis is actually the hardest step, but also the
    greatest and most influential.\u201D In early January, Baidu\u2019s executives
    told its natural-language processing team to start pulling together a ChatGPT-like
    product with the Ernie models, said people familiar with the project. But the
    project has faced challenges, they said, many of which have been shared by other
    AI developers working on ChatGPT-like technology. One has been to make the model
    respond more precisely to user requests, by teaching it to disambiguate between
    phrases that have a number of meanings or names that can refer to multiple people.
    Another has been to make the chatbot generate language that looks more like a
    human\u2019s. A third has been to improve its factual accuracy\u2014a technical
    limitation of large language models, which string together sentences based on
    the probabilities that different words might appear together rather than on pieces
    of information. This limitation also makes such models difficult to control to
    avoid sensitive topics, a hurdle for censorship. Baidu has hired contractors to
    help review and improve the chatbot\u2019s answers, the people said. Each step
    takes time, the people said. Properly training a model of such scale\u2014with
    thousands of chips\u2014can take weeks or months, AI researchers have said. This
    week, engineers and product managers were rushing to improve Ernie Bot\u2019s
    basic functions such as how quickly it responds to user requests and how it summarizes
    search results, people familiar with the matter said. The development team has
    been working nonstop, including through the weeklong Lunar New Year holiday at
    the end of January, the people said. The project has been scaled back for now
    from creating a bilingual chatbot capable of conversing in Chinese and English
    to one primarily focused on Chinese, they said. Ernie Bot\u2019s research and
    development has been overseen by Baidu\u2019s technology chief, Haifeng Wang,
    and carried out largely by its technology development arm, which houses the natural-language
    processing team, and mobile ecosystem business group, people familiar with the
    matter said. Baidu\u2019s AI cloud unit is providing cloud-computing support,
    some of the people said. What do you think lies ahead in the race to develop AI-powered
    chatbots? Join the conversation below. To accelerate the process, executives pooled
    together more resources. After the Lunar New Year holiday, Mr. Li asked AI research
    teams across the company, including its autonomous driving unit, to lend their
    most powerful computer chips, Nvidia Corp.\u2019s A100s, to Ernie Bot\u2019s development,
    people familiar with the matter said. U.S. chip sanctions implemented late last
    year ban Chinese companies from buying new A100s. Employees have also been pulled
    to help out, in particular to clean the training data, such as to filter out low-quality
    content, some of the people said. Baidu hired external teams for data cleaning
    as well, some people said. The time crunch has left some employees uneasy about
    whether Ernie Bot will meet user or market expectations, people familiar with
    the matter said. Some of the employees said they have sold some company stock
    ahead of the launch because of those concerns."
  tags: []
  title: "Baidu Hurries to Ready China\u2019s First ChatGPT Equivalent"
- !!python/object:ai_sentiment.data.ClassificationTarget
  body: "Key Points: ChatGPT is a new artificial intelligence-driven technology with
    capabilities that can potentially aid attackers. Cybercriminals are using the
    tool to develop phishing schemes, as well as writing and sharing malware code,
    according to researchers. Observers don\u2019t believe the risks and threats associated
    with use of the tool are currently much more significant for organizations than
    ongoing ones, but said ChatGPT\u2019s machine-learning capability may change this.
    Why ChatGPT is Popular Chat Generative Pre-trained Transformer is a chatbot developed
    by research laboratory Open AI and incorporated into Microsoft Corp.\u2019s Bing
    search engine. The tool enables business users to automate time-consuming tasks
    such as writing emails, create quick and more natural interactions with customers
    and potentially increase productivity. The Possible Risks and Threats Cybersecurity
    researchers have focused on the risks and threats presented by ChatGPT for hackers
    trying to harness its capabilities for criminal activities, including: Allowing
    code to be written for use in malware by technically less-skilled hackers, which
    is then shared among hackers in other online forums. Providing additional complexity
    to protect code from detection, such as including polymorphic capabilities, which
    means a code\u2019s appearance can mutate while not changing its function. In
    terms of phishing campaigns, ChatGPT can generate the text to reduce errors in
    messages written by non-native speakers and also create the phishing website code
    to collect the victims\u2019 data. There is a risk of vulnerabilities being introduced
    into software by employees using code produced by ChatGPT without it first being
    thoroughly checked for security weaknesses. Soo Choi-Andrews, chief executive
    of cybersecurity platform Mondoo, said companies also need to consider how their
    third parties may be using ChatGPT. \u201CThe sheer volume of code being generated
    by not only your team but also the wider ecosystem that your business relies on
    poses the biggest immediate threat,\u201D she said. Ms. Choi-Andrews added it
    is critical that businesses prioritize security checks within their automated
    testing processes to address these possible vulnerabilities. Reasons Not to be
    Concerned \u2013 Yet \u201CThe attacker has to know what exactly he wants and
    to be able to specify the functionality. Just writing \u2018write a code for malware\u2019
    won\u2019t produce anything really useful.\u201D \u2014 Sergey Shykevich, researcher
    at cybersecurity firm Check Point Software Technologies Ltd. Many security experts
    believe that although there may be some benefits for hackers using ChatGPT, it
    is unlikely to be a game-changer for criminals as much of the information it produces
    is already available online, albeit in less user-friendly formats. The following
    takeaways should be considered: Existing controls mean ChatGPT won\u2019t deliver
    ready-to-use malware code as it\u2019s not possible to create malware just by
    asking it. The capabilities of ChatGPT for hackers will likely improve over time
    through machine learning, though controls may also evolve and increase. ChatGPT
    may be aiding the malware creation process, but it so far has not created fully-fledged
    attacks. Accordingly, there are currently no specific steps organizations can
    take, beyond practicing good cyber hygiene. \u201CChatGPT prevents phishing attacks
    by implementing content moderation, user validation, warning messages, reporting
    and blocking functions, and conducting regular security audits and updates. These
    measures help to mitigate the risk of ChatGPT being used as a tool in such attacks
    and protect users from potential harm.\u201D \u2014 ChatGPT response to how it
    stops itself from being abused in phishing attacks. We haven\u2019t identified
    specific threats security officials should be looking for or precautions to take,
    but with ChatGPT constantly learning and other chatbots becoming publicly accessible,
    the risks of artificial intelligence being responsible for producing attacks is
    increasing. Because a tool like ChatGPT does not provide out-of-the-box solutions
    for hackers or security officials, but rather is developed over time by skilled
    practitioners, it would be advisable to stay abreast of the latest information
    regarding AI-driven security concerns and best practices to address them."
  tags: []
  title: ChatGPT and Cyber Risk
- !!python/object:ai_sentiment.data.ClassificationTarget
  body: "Apple Approves ChatGPT-Powered App After Assurance of Content Moderation
    has approved an email-app update after initially scrutinizing whether a feature
    in the software that uses language tools powered by artificial intelligence could
    generate inappropriate content for children. The app, BlueMail, was approved following
    assurances from its developer that it features content moderation, according to
    Ben Volach, co-founder of the app-maker, Blix Inc. The Wall Street Journal reported
    on Thursday that the update, which included a new feature powered by language
    chatbot ChatGPT, was held up due to Apple\u2019s request that the app add content
    moderation or be restricted to ages 17 and older. The app was previously available
    for ages 4 and older. Blix told Apple its update includes content moderation and
    suggested that the company should make public any new policies about the use of
    ChatGPT or other similar AI systems in apps. The BlueMail update was approved
    without changes on Thursday evening. The app is still available for users aged
    4 and older. BlueMail\u2019s new feature uses OpenAI\u2019s ChatGPT, an artificial-intelligence
    system capable of answering questions or writing short essays, to help automate
    the writing of emails using the contents of prior emails and calendar events.
    The news of Apple\u2019s initial rejection of BlueMail\u2019s ChatGPT feature
    highlighted the growing concerns around new uses of language-generating AI tools.
    ChatGPT allows users to converse with an AI that appears humanlike, but early
    testing has shown the AI producing incorrect information as well as strange and
    sometimes hostile responses. Although Apple took action on the AI feature, there
    have been no additional formal App Store guidelines from Apple regarding the use
    of so-called generative AI in apps. Apple has long said that it has to curate
    and review each app that goes through its App Store in order to keep its products
    safe for users."
  tags: []
  title: Apple Approves ChatGPT-Powered App After Assurance of Content Moderation
- !!python/object:ai_sentiment.data.ClassificationTarget
  body: "Apple\_Inc.\_has delayed the\_approval of an email-app update\_with\_AI-powered
    language tools\_over concerns that it could generate inappropriate content for
    children, according to communications Apple sent to the app maker. The software
    developer disagrees with Apple\u2019s decision. The dispute shows the\_broad concerns\_about
    whether language-generating artificial-intelligence tools,\_such as ChatGPT, are
    ready for\_widespread use. Apple took steps last week to block an update of email
    app BlueMail because of concerns that a new AI feature in the app could show inappropriate
    content, according to Ben Volach, co-founder of BlueMail developer Blix Inc.,
    and documents viewed by The Wall Street Journal. BlueMail\u2019s new AI feature
    uses OpenAI\u2019s latest\_ChatGPT chatbot\_to help automate the writing of emails
    using the contents of prior emails and calendar events. ChatGPT allows users to
    converse with an AI in seemingly humanlike ways and is capable of advanced long-form
    writing on a variety of topics. \u201CYour app includes AI-generated content but
    does not appear to include content filtering at this time,\u201D Apple\u2019s
    app-review team said last week in a message to the developer reviewed by the Journal.
    The app-review team said that because the app could produce content not appropriate
    for all audiences, BlueMail should move up its age restriction to 17 and older,
    or include content filtering, the documents show. Mr. Volach says it has content-filtering
    capabilities. The app\u2019s restriction is currently set for users 4 years old
    and older. Apple\u2019s age restriction for 17 and older is for categories of
    apps that may include everything from offensive language to sexual content and
    references to drugs. Mr. Volach says that this request is unfair and that other
    apps with similar AI functions without age restrictions are already allowed for
    Apple users. \u201CApple is making it really hard for us to bring innovation to
    our users,\u201D said Mr. Volach. An Apple spokesman said that developers can
    challenge a rejection through its App Review Board appeal process and that it
    is investigating Blix\u2019s complaint. So-called\_generative AI\_has emerged
    as one of the most closely watched developing technologies in decades, primarily
    kicked off by ChatGPT, a chatbot created by OpenAI. The technology has quickly
    generated controversy. Following the release of\_Microsoft\_Corp.\u2019s Bing
    search engine powered by ChatGPT, early testers grew concerned with\_responses
    generated by the chatbot,\_including incorrect information as well as seemingly\_unhinged
    and angry responses. Microsoft, which has invested billions in OpenAI,\_defended
    the Bing upgrade\_as a work in progress. Apple\u2019s attempt to set an age restriction
    to help moderate content from a language-model-based AI is an indication the tech
    giant is closely watching the new technology and the risks it poses. The company
    has long said it must carefully curate and review what software can be accessed
    on the iPhone and iPad through its App Store to keep its products private and
    secure. Microsoft recently released an updated version of its\_Bing smartphone
    app with the ChatGPT\_functionality to Apple\u2019s App Store and Google\u2019s
    Android Play Store. Bing is listed in the iPhone App Store with the 17-and-older
    age restriction that Apple is asking of BlueMail, while Bing on the Google Play
    store has no age restrictions. Bing in the App Store already had a 17-and-up age
    restriction because of the app\u2019s ability to find adult content, a Microsoft
    spokesman said. For BlueMail, Apple\u2019s rejection came a week after the company
    submitted the app upgrade for review. Mr. Volach said Apple used a test version
    of the upgraded app every day before he got a response. BlueMail was able to update
    its Android BlueMail app on the Google Play app store without any requests for
    age restriction or further content filtering, Mr. Volach said. Mr. Volach says
    Apple is unfairly targeting BlueMail. The app has content filtering, and placing
    a higher age restriction on the app could limit distribution to potential new
    users, he said. Mr. Volach also said many other apps that advertise a ChatGPT-like
    feature listed on Apple\u2019s App Store don\u2019t have age restrictions. \u201CWe
    want fairness,\u201D said Mr. Volach. \u201CIf we\u2019re required to be 17-plus,
    then others should also have to.\u201D In the past, Apple has at times discovered
    an issue with an app that leads the company to apply a new rule more broadly.
    Initial inconsistency in applying App Store policies\u2014especially new policies\u2014isn\u2019t
    uncommon, said Phillip Shoemaker, former senior director of the App Store review
    team at Apple, who left in 2016. There are hundreds of individuals reviewing each
    app, and \u201Cnot everyone sees the same thing,\u201D Mr. Shoemaker said. \u201CSome
    are viewing apps faster than others and could be missing things. The inconsistency
    could be for a variety of reasons.\u201D Apple was an early entrant in bringing
    AI technology mainstream with the introduction of the Siri voice assistant in
    2011. But to date, Apple appears to have stayed out of the fray of generative
    AI. At an internal AI conference for company employees last month, sessions were
    focused on areas such as computer vision,\_healthcare\_and privacy, according
    to internal documents viewed by the Journal. Last month, on the company\u2019s\_quarterly
    earnings\_conference call, Apple Chief Executive Tim Cook said AI \u201Cis a major
    focus of ours,\u201D pointing out AI-enabled features such as\_crash detection.\_\u201CWe
    see an enormous potential in this space to affect virtually everything we do,\u201D
    he further stated. During an interview at WSJ\u2019s Journal House at MWC in Barcelona,
    Carme Artigas, Spain\u2019s secretary of state for digitization and AI, talks
    about the increased pressure on government oversight of cutting-edge technologies.
    Mr. Volach has had a contentious history with Apple. In 2019, Apple announced
    a software feature called \u201CSign in with Apple,\u201D which allows users to
    sign into an app without having to give away personal information such as email.
    Blix had patented a similar feature earlier. Soon after Apple\u2019s sign-in feature
    was announced, Apple removed the BlueMail app from its Mac app store. At the time,
    Apple said the removal of the BlueMail app was due to security concerns. Mr. Volach
    said that there was never a security issue and that Apple eventually ended up
    approving the app many months later. The incident prompted Blix to file an antitrust
    lawsuit against Apple in 2019. A federal judge dismissed the company\u2019s case,
    stating that Blix failed to offer evidence of Apple\u2019s monopoly power and
    anticompetitive behavior. Antitrust lawyer Jonathan Kanter was hired by Blix as
    legal counsel in its antitrust case against Apple. In 2021, Mr. Kanter took over
    as head of the antitrust division at the U.S. Justice Department, which is currently
    pursuing its own\_antitrust investigation into Apple."
  tags: []
  title: Apple Blocks Update of ChatGPT-Powered App
- !!python/object:ai_sentiment.data.ClassificationTarget
  body: "Instacart Inc. is adding OpenAI\u2019s ChatGPT chatbot technology to its
    grocery-delivery app, joining a growing list of companies that are turning to
    the humanlike artificial-intelligence language tool in efforts to boost customer
    services, marketing and other automated tasks. Instacart will use the chatbot
    to power a new search engine designed to respond to users\u2019 food-related questions,
    such as asking for recipe ideas and ingredients, or healthy meal options, the
    San Francisco startup said Wednesday. By tapping ChatGPT\u2019s language software,
    the search engine\u2019s responses will come in the form of a dialogue, rather
    than a list of search-engine results, Instacart said. It expects to roll out the
    new feature, called \u201CAsk Instacart,\u201D later this year, the company said.
    \u201CWhen you think about grocery shopping, it takes a lot of thinking and planning,\u201D
    said JJ Zhuang, Instacart\u2019s chief architect, who oversees technology across
    the company. \u201CIt\u2019s the perfect use case for smart AI, because it\u2019s
    a lot of cognitive load,\u201D he said, citing decision-making factors such as
    household budgets, health and nutrition implications, seasonal produce, cooking
    skills and meal preparation times. By integrating Instacart\u2019s own AI software
    with ChatGPT, the new search tool will tap data from more than 1.5 million products
    stocked by some 75,000 grocery stores in Instacart\u2019s partner network, he
    said. Mr. Zhuang described the software integration as \u201Cexperimenting with
    what\u2019s possible\u201D using ChatGPT on Instacart\u2019s app. Instacart last
    year processed $29 billion in overall sales across its platform, up about 16%
    from the previous year, the company told employees Tuesday. It reported positive
    net income over the fourth quarter, generating more than $100 million in adjusted
    earnings before interest, taxes, depreciation and amortization. OpenAI, a San
    Francisco-based software startup launched in 2015, has sought to expand its reach
    by easing the process of integrating ChatGPT software with outside apps. To do
    that, it allows companies like Instacart to build their own tools on top of ChatGPT\u2019s
    software, said Greg Brockman, OpenAI\u2019s president, chairman and co-founder.
    Mr. Brockman said he sees OpenAI as essentially a developer platform that also
    offers a \u201Ckiller app.\u201D On Wednesday, OpenAI released updates to its
    application programming interface\u2014a type of software code, known as an API,
    that enables computer programs to communicate with each other\u2014which includes
    specific protocols for integrating apps with the latest AI models for both ChatGPT
    and Whisper, OpenAI\u2019s speech-recognition tool. Unlike its widely popular
    online app, which is free and available to anyone, OpenAI charges a fee for accessing
    the interface needed by developers to build new apps. \u201CI think the whole
    developer community is going to benefit a lot from all the improvements that we\u2019ve
    made, in model quality and model speed,\u201D Mr. Brockman said. \u201CWe\u2019re
    working with all companies, big and small, in order to get this technology integrated
    into whatever application they\u2019re interested in,\u201D he said. OpenAI benefits
    by feeding user data back into its AI models to continually train and improve
    the algorithm\u2014though as of Wednesday companies can opt out of having their
    data used in this way. Since OpenAI launched ChatGPT in November, ready access
    to its interface has produced a slew of ChatGPT-integrated business apps. Snapchat
    maker Snap Inc. on Monday launched its own AI-powered chatbot for Snapchat+ subscribers,
    built off of ChatGPT\u2019s API. Microsoft Corp., an OpenAI investor, last month
    added ChatGPT technology to its Bing search engine. Shopify Inc., an e-commerce
    website builder, is also experimenting with ChatGPT, the company said. Still,
    some corporate technology chiefs remain wary of integrating ChatGPT into their
    business technology stacks, citing concerns over data limitations, security and
    the tool\u2019s reputation for producing unpredictable results. Microsoft itself
    was forced to limit the amount of questions that could be fielded by its ChatGPT-enabled
    search engine, after users complained of inaccurate and even disturbing results.
    Likewise, Snap has warned users that its customized ChatGPT chatbot \u201Cis prone
    to hallucination and can be tricked into saying just about anything,\u201D adding
    that the tool shouldn\u2019t be relied on for real-world advice."
  tags: []
  title: Instacart Joins ChatGPT Frenzy, Adding Chatbot To Grocery Shopping App
- !!python/object:ai_sentiment.data.ClassificationTarget
  body: "Facebook parent\_Meta Platforms\_Inc. and\_Snap\_Inc. are embracing the much
    talked-about artificial-intelligence technology popularized by OpenAI\u2019s viral
    ChatGPT chatbot. Meta is establishing a group aimed at accelerating adoption of
    the so-called generative AI technology across the company, Chief Executive\_Mark
    Zuckerberg\_said Monday. Meta, which also owns Instagram and messaging app WhatsApp,
    is centralizing staff who are working on the AI technology from across the company
    to achieve faster breakthroughs it can apply to different products, Mr. Zuckerberg
    said. \u201CIn the short term, we\u2019ll focus on building creative and expressive
    tools,\u201D the CEO said on Instagram. \u201COver the longer term, we\u2019ll
    focus on developing AI personas that can help people in a variety of ways.\u201D
    Snap on Monday also signaled it was making a bet on OpenAI\u2019s technology.
    The company known for its Snapchat app said it had begun rolling out its\_own
    AI experimental chatbot\_to users who subscribe to its $3.99 a month subscription
    service, Snapchat+. Tech companies more broadly have moved swiftly to embrace
    generative AI developments in recent months after the San Francisco-based AI research
    firm OpenAI launched\_a chatbot called ChatGPT\_in November that went viral. Tools
    such as ChatGPT and others allow users to ask written questions and receive responses
    in a conversational format as opposed to seeing a list of search results. Microsoft\_Corp.,
    which has invested in OpenAI, announced earlier this month that it was adding
    the\_technology behind ChatGPT\_to its Bing search engine in an attempt to chip
    away at Google\u2019s dominance in the search market. It has given a select group
    of users access to the new Bing to try the system.\_Alphabet\_Inc.\u2019s Google
    also said earlier this month that it was rolling out its own\_conversational AI
    service called Bard\_to an early group of testers. Meta said its team initially
    was looking into ways to use the technology to enhance WhatsApp and Messenger,
    as well as with Instagram filters and video. Snap said it is making its chatbot,
    called My AI, available only to Snapchat+ subscribers as social-media companies
    are trying to drive users to their paid services amid upheaval in the digital
    ad market. Twitter Inc. and Meta both have also started subscription offerings.
    Snapchat+ has reached more than 2.5 million subscribers since its launch last
    summer, Snap said. The Verge earlier reported on Snap\u2019s AI technology rollout.
    Snap has been one of the companies hardest hit by ad-market turmoil, driven both
    by companies pulling back on spending amid economic downturn concerns and changes\_Apple\_Inc.
    made that make it more difficult to track users and target ads. Its subscription
    service is an attempt to diversify its revenue, though the company has indicated
    it doesn\u2019t fully expect to replace ad revenue with earnings from its subscription
    service. The social-media company late last month said\_revenue growth had stalled\_in
    the last three months of 2022 and that sales were likely to drop in the current
    quarter. Snap\u2019s shares on Monday closed about 1% up, though have fallen about
    75% over the past year. The AI technology isn\u2019t without flaws. Within a week
    of launch, users of Microsoft\u2019s new Bing\_called out the technology\_for
    providing inaccurate information, such as giving the results of last year\u2019s
    Super Bowl when asked about this year\u2019s. It also sometimes has given disturbing
    responses.\_ Microsoft responded by saying that the search engine was still a
    work in progress and that it would\_limit the amount of questions\_users could
    ask it a day. Snap, in its announcement, said mistakes could occur with its chatbot
    that uses OpenAI technology customized for Snapchat. \u201CMy AI is prone to hallucination
    and can be tricked into saying just about anything. Please be aware of its many
    deficiencies and sorry in advance!\u201D the company said, also warning: \u201CPlease
    do not share any secrets with My AI and do not rely on it for advice.\u201D Mr.
    Zuckerberg has embraced hot technology trends before. In 2021,\_he renamed Facebook
    to Meta Platforms\_as part of his bet on the metaverse, a futuristic, more immersive
    vision of the internet that largely hasn\u2019t materialized yet. The company
    has struggled financially since then, in part because of the same disruptions
    to the digital ad business that have challenged Snap. After posting\_three consecutive
    quarters of declining sales, Meta said in its most recent earnings report that
    market conditions were improving, and interviews and internal documents viewed
    by The Wall Street Journal show that the company has begun to see\_a path to recovery
    through using AI tools\_to improve ad-targeting and user engagement with its TikTok
    competitor, Reels. Mr. Zuckerberg on Monday suggested that the company still had
    a lot of work to do with respect to AI developments.\_ \u201CWe have a lot of
    foundational work to do before getting to the really futuristic experiences,\u201D
    he said."
  tags: []
  title: Facebook Parent, Snap Embrace AI Technology That Powers ChatGPT Chatbot
- !!python/object:ai_sentiment.data.ClassificationTarget
  body: "As major chip players\u2014Nvidia Corp., Intel Corp., Advanced Micro Devices
    Inc. among them\u2014rush to capitalize on the popularity of generative artificial
    intelligence, startups are seeing their chance to grab a bigger piece of that
    pie as well. \u201CThere\u2019s new openings for attack and opportunity for those
    players because the types of chips that are going to most efficiently run these
    algorithms are different from a lot of what\u2019s already out there,\u201D said
    Brian Schechter, a partner at venture-capital firm Primary Venture Partners. Historically,
    Nvidia has been the market leader in specialist AI hardware, analysts said. Generative
    AI and large language models like OpenAI\u2019s ChatGPT require massive amounts
    of computing power to run, and typically rely on chips like Nvidia\u2019s graphics-processing
    units, or GPUs, that are specialized for these types of calculations. Last week,
    Nvidia Chief Executive Jensen Huang said on a call with analysts that excitement
    around these new AI developments could supercharge the market for its chips. Dylan
    Patel, chief analyst at chip research firm SemiAnalysis, said the big companies
    are in a prime position to benefit from the onrush of demand. But smaller upstarts
    could also benefit from an overflow of demand, especially as supply-chain and
    manufacturing difficulties still limit the amount of chips that are making it
    to market, he said. Cerebras Systems Inc., a Sunnyvale, Calif.-based chip company
    founded in 2016, has been able to capitalize on some of that interest, said Chief
    Executive and Co-founder Andrew Feldman. As demand surges, he said, it is creating
    space for startups to break through. Cerebras is valued at $4.1 billion. With
    the nascent generative AI market propelling demand for compatible hardware and
    software to new heights, it\u2019s a good time to be a startup, he said. \u201CIn
    stable markets that aren\u2019t changing much\u2014very hard to beat Goliath,\u201D
    he said. \u201CThe number of people trying to apply AI is just ballooning and
    that is really a massive opportunity that we can play into,\u201D said Nigel Toon,
    chief and co-founder of Bristol, U.K.-based Graphcore Ltd. Graphcore provides
    specialized hardware and software designed for AI that can do several things,
    among them lowering compute costs by eliminating unnecessary parameters, Mr. Toon
    said. Graphcore sells primarily to AI startups looking to build and train models
    at lower cost, he said, and the company is benefiting from the proliferation of
    those startups. Anshumali Shrivastava, the founder and chief executive of ThirdAI
    Corp., said that since the release of ChatGPT, his company has also seen an increase
    in demand. Houston-based ThirdAI provides technology that helps complex AI algorithms
    run efficiently on cheaper CPUs, or central processing units, rather than on specialized
    GPUs. Dr. Shrivastava said because of ThirdAI\u2019s focus on CPUs, it can also
    feasibly help enterprises unlock complex AI models on premises and not in the
    cloud\u2014alleviating privacy and data security concerns for industries that
    require on-premise solutions. Shane Rau, who leads International Data Corp.\u2019s
    semiconductor research, said chip startups are increasingly pivoting to focus
    their products on supporting large language models. Still, he added, \u201Cyou\u2019re
    going to see a combination of real adaptation and marketing.\u201D \u201CThere
    will be the pressure to say: \u2018Hey, we\u2019re already relevant, our AI chip
    technology\u2019s already relevant to generative AI\u2019,\u201D said Mr. Rau.
    \u201CMany of these AI chip companies\u2014we\u2019re tracking hundreds of them\u2014are
    going to run out of money before they can make that adaptation.\u201D Kavitha
    Prasad, vice president and general manager at Intel for data center, AI and cloud
    and enterprise strategy, said incumbents like Intel might also have an edge over
    startups because of the software they provide clients to program and optimize
    the chips. \u201CThere are a lot of startups, but without a focus on the software
    ecosystem, adoption is going to be very limited,\u201D she said. Some chip makers
    say they expect yet another surge in demand once businesses more widely adopt
    generative AI. \u201CWe think this demand is both overwhelming\u2014and just the
    start,\u201D said Cerebras\u2019s Mr. Feldman."
  tags: []
  title: In the Whirl of ChatGPT, Startups See an Opening for Their AI Chips
- !!python/object:ai_sentiment.data.ClassificationTarget
  body: "Chip makers are abuzz about the latest hot-thing in tech: artificial-intelligence
    tools that generate text with minimal prompting, require massive computing power
    to run and promise\_a lucrative new revenue stream. For semiconductor makers,
    the new tools, if widely adopted, could result in tens of billions of dollars
    in net annual sales, analysts estimate. Excitement over so-called generative AI
    has reached fever pitch since the release late last year of San Francisco-based
    OpenAI\u2019s chatbot,\_called ChatGPT. The technology has captivated users by
    producing convincingly real if sometimes inaccurate responses, helping it attract\_billions
    of dollars\_from\_Microsoft\_Corp.\_and other investors. Jensen Huang, the chief
    executive officer of\_Nvidia\_Corp., America\u2019s largest chip company by market
    value, said the technology has reached an inflection point. \u201CGenerative AI\u2019s
    versatility and capability has triggered a sense of urgency at enterprises around
    the world to develop and deploy AI strategies,\u201D he said as the company posted
    quarterly earnings Wednesday and unveiled a new cloud-computing initiative to
    capitalize on the business opportunity. Nvidia shares were up more than 12% in
    early Thursday trading. The interest in such AI tools is causing companies to
    reset their business expectations with pace, he said. \u201CThere\u2019s no question
    that whatever our views are of this year as we enter the year has been fairly
    dramatically changed as a result of the last 60, 90 days.\u201D The excitement
    comes as the chip industry is wrestling with a sharp downturn in the semiconductor
    industry with sales of personal computers, smartphones and other electronics flagging.\_Most
    chip makers have reported slowing sales\_as recession concerns have caused consumers
    and businesses to pull back on spending. Nvidia is the undisputed market leader
    in chips used for AI in the unglamorous world of data centers where tools such
    as ChatGPT make computations and spit out results. It had about an 80% share of
    such AI processors as of 2020, according to an Omdia estimate. With so much money
    up for grabs, though, other chip makers want in on the action. Intel\_Corp. CEO\_Pat
    Gelsinger\_said Wednesday that his company had a broad suite of chips to address
    the generative-AI opportunity, including specialist chips geared toward AI computation,
    graphics chips for data centers and a new generation of data-center central process
    units\u2014the digital brains of computers\u2014that he said performed well in
    AI work. \u201CThat performance we expect will become much more of the mainstream
    of computing as AI gets infused into every application going forward,\u201D he
    said. Advanced Micro Devices\_Inc.,\_which makes CPUs, graphics chips and other
    hardware tailored for AI, is also betting large cloud-computing companies that
    run many of the computations essential to the technology will be investing heavily
    in chips. That business should start to become more meaningful next year, AMD
    CEO\_Lisa Su\_said late last month. Generative AI could add $20 billion a year
    to the overall AI chip market by 2027, according to Vivek Arya, an analyst at
    Bank of America. Nvidia, he said, should be able to maintain at least a 65% market
    share in AI chips. Internet-search giant Google, a unit of\_Alphabet\_Inc., this
    month offered a glimpse of\_a homegrown rival to ChatGPT\_that it calls Bard.
    China\u2019s\_Baidu\_Inc. is developing an AI-powered chatbot similar to ChatGPT\_called
    Ernie Bot,\_which it plans to launch next month. Microsoft is already giving users
    a limited taste of ChatGPT\_within its Bing search engine\_results. In the near
    term, at least, Nvidia\u2019s dominance in AI may position it best to cash in.
    The company gained its lead by allowing software developers to exploit properties
    of its graphics chips that proved adept at AI starting about 15 years ago. Now,
    the company\u2019s chips are the only viable products that can be used to create
    massive AI language systems, UBS analysts said in a note, adding that they estimate
    that ChatGPT requires around 10,000 of the company\u2019s graphics chips to train.
    Mr. Huang suggested the company next month may update its outlook for the size
    of its potential market, after\_giving a projection of $1 trillion roughly a year
    ago\_for its business spanning from providing chips for videogaming to cars. \u201CBecause
    of the incredible capabilities and versatility of generative AI and all of the
    convergence breakthroughs that happened toward the middle and end of last year,
    we\u2019re probably going to arrive at that [market size] sooner than later,\u201D
    he said. \u201CThere\u2019s no question that this is a very big moment for the
    computer industry.\u201D Nvidia is trying to get there faster by starting to offer
    a cloud-computing service for businesses to develop generative AI chatbots and
    other tools using its hardware and software. The service, which would be offered
    through established cloud-computing companies, aims to lower barriers to entry
    for the spread of AI\u2019s use in business. Nvidia said it is working with all
    the major cloud-computing providers, which include\_Amazon.com\_Inc., Microsoft
    and Google, on generative AI tools, as well as with consumer internet companies
    and startups."
  tags: []
  title: Nvidia, Other Chip Companies Race to Cash In on ChatGPT Frenzy
- !!python/object:ai_sentiment.data.ClassificationTarget
  body: "The viral\_popularity of ChatGPT\_has stirred a frenzy within China where
    tech companies, battered by a two-year regulatory clampdown and the Covid-19 pandemic,
    have been seeking new sources of growth. Search-engine owner\_Baidu\_Inc., e-commerce
    giant\_Alibaba Group Holding\_Ltd. and social-media conglomerate\_Tencent Holdings\_Ltd.
    are among those that have announced investments\_to develop their own equivalents\_to
    the artificial-intelligence chatbot, which isn\u2019t available in China. Stocks
    of other Chinese companies have surged in recent weeks as they have jumped on
    the bandwagon, triggering state media to\_issue a warning\_about the speculative
    rally. Chinese companies that invested early in the generative AI technologies\u2014which
    produce writing, images and art much like humans do\u2014will now be best poised
    to build their own ChatGPT, AI and Chinese tech industry experts say. But many
    others are racing to catch up to U.S. counterparts in the latest technology developments
    and commercial applications. While China has several leading AI companies, many
    have focused on computer vision and applications\_such as surveillance. ChatGPT
    requires tooling and knowledge from a different AI subfield known as natural language
    processing. Chinese companies also face geopolitical and censorship-related barriers,
    including securing advanced chips targeted by\_U.S. export controls\_and navigating
    Beijing\u2019s tight censorship rules. Nonetheless, companies that have the capabilities
    will be fast followers. For such companies, \u201Cthere\u2019s not a meaningful
    barrier that\u2019s preventing China from catching up and re-creating or building
    an even better model,\u201D said Matt Sheehan, fellow at the Carnegie Endowment
    for International Peace. OpenAI, the creator of ChatGPT, bans users in China from
    creating accounts on its chatbot, though many have found ways to circumvent the
    barrier through virtual private networks or by buying accounts using e-commerce
    platforms for a few U.S. dollars. ChatGPT can produce answers in Chinese, and
    its spectacular, surprising and sometimes wrong responses have become a hot topic
    on Chinese social media. Some consumers have clamored for homegrown alternatives.
    Reports emerged on Baidu\u2019s plans in January. It is set to\_integrate into
    its search engine\_in March its own version of the\_AI chatbot, called Ernie Bot.
    Baidu said Wednesday that the company will use Ernie Bot to also improve Baidu\u2019s
    AI cloud,\_its driverless car\_system and its voice assistant Xiaodu. The company
    will open its large language model to the public, offering it as a business service,
    Baidu\u2019s Chief Executive\_Robin Li\_said in a call with analysts. Some organizations
    have already decided to integrate Ernie into their products and services, he said.
    That was followed by Tencent, the owner of China\u2019s everything app WeChat;
    e-commerce player\_JD.com\_Inc.; and speech-recognition company iFlytek Co.\u2014though
    none have released concrete plans. Game company\_NetEase\_Inc. said it is exploring
    how to incorporate the underlying technology behind ChatGPT into its education
    products. Wang Huiwen, the co-founder of food-delivery company\_Meituan, said
    he plans to invest $50 million into building China\u2019s OpenAI, despite acknowledging
    that he doesn\u2019t know much about the technology. The foundation of ChatGPT
    is built on what\u2019s known as a large language model, which is trained on vast
    swaths of language data. Such models are useful for a range of commercial applications,
    from improving search results and powering voice assistants to automating content
    moderation. In China, Baidu and Alibaba were among the first companies to create
    their own Chinese-language versions. Baidu released one in 2019 called Ernie,
    which it subsequently advanced in lockstep with Google\u2019s and OpenAI\u2019s
    developments and uses to improve its search. Alibaba released one\_the same year
    called\_AliceMind and another\_called M6 two years later.\_AliceMind\_powers\_AliMe,
    its customer-service chat feature. Telecom major Huawei Technologies Co. and information-technology
    conglomerate Inspur Group, as well as the government-backed Beijing Academy of
    Artificial Intelligence and the Chinese Academy of Sciences, have produced their
    own versions. It is these foundations that Chinese companies are now relying on
    to evolve into a ChatGPT equivalent. But only a few companies will be able to
    do so quickly, experts say. One reason is the more limited access that Chinese
    companies have to a broad diversity of data. ChatGPT rests on one of the largest
    language models that exists today, OpenAI\u2019s GPT-3.5, which benefits from
    the copious amounts of English-language data on the global web spanning many subject
    areas and disciplines. Chinese-language data is less abundant and, within China,
    faces\_strict censorship controls. Outside of publicly available data, most Chinese
    companies only have text and conversational data in specific areas such as finance
    or e-commerce, said Pascale Fung, the director of the Center for Artificial Intelligence
    Research at the Hong Kong University of Science and Technology. Baidu stands out
    for the data it has from indexing the web for its search engine, she said. U.S.
    export controls on advanced chips could pose another hurdle. A recent study found
    that most\_large language models developed in China\_over the past two years were
    trained on the U.S.-sanctioned A100 graphics-processing unit made by\_Nvidia\_Corp.
    Once companies\_use up their stockpiles\_of high-end chips, the pace of advancement
    could slow, said Jeffrey Ding, a political scientist researching technological
    change at George Washington University, who co-wrote the paper. China\u2019s tight
    censorship and regulatory ecosystem will challenge development in other ways.
    Issues have risen around ChatGPT spewing misinformation or strange and offensive
    outputs. Chinese companies are facing much greater pressure to ensure their chatbot
    equivalents won\u2019t wax lyrical on politically sensitive topics, Chinese tech
    experts say. In January, China\u2019s internet regulator also\_issued new rules\_for
    generative AI technologies, a global first, requiring developers of ChatGPT and
    image-generation tools to prominently label images, videos and text as synthetically
    generated or edited when they could be misconstrued as real. Ms. Fung said the
    real hurdle will come after ChatGPT\u2019s development, however, in finding applications
    of the technology that are safe and effective. \u201CThe key is who will come
    up with a killer app,\u201D she said. \u201CIn that sense, Chinese companies can
    be very innovative.\u201D"
  tags: []
  title: "ChatGPT Fever Sweeps China\u2019s Tech Sector"
- !!python/object:ai_sentiment.data.ClassificationTarget
  body: "JPMorgan\_Chase & Co. is restricting employees from using ChatGPT, according
    to a person familiar with the matter. The bank didn\u2019t restrict usage of the
    popular artificial-intelligence chatbot because of any particular incident, the
    person said. It couldn\u2019t be determined how many employees were using the
    chatbot or for what functions they were using it. ChatGPT\_has grown increasingly
    popular\_since the startup OpenAI released it in November, crossing a million
    users a few days after its launch. People have used the chatbot to\_automate tasks
    at work and school, raising questions about how AI could replace some white-collar
    jobs. However, ChatGPT isn\u2019t always reliable because it sometimes responds
    to prompts with misinformation or wrong answers. OpenAI didn\u2019t return a request
    for comment Wednesday. In addition to JPMorgan, other organizations have also
    blocked access to ChatGPT. Last week, Verizon Communications Inc. barred the chatbot
    from its corporate systems, saying it could lose ownership of customer information
    or source code that its employees typed into ChatGPT. New York City public schools
    in January\_banned the chatbot from its internet networks\_and school devices.
    Workers at some companies\_have been using ChatGPT to write emails\_and research
    topics. Some of the employees say the chatbot helps them work faster while others
    are trying to avoid being left behind as technology evolves. Some tech companies
    have raced to launch similar products after OpenAI released ChatGPT. Earlier this
    month, Google\_rolled out a conversational AI service, Bard, to testers as the
    company tries to keep up with OpenAI. Microsoft\_Corp., which has invested billions
    of dollars in OpenAI,\_debuted an upgraded Bing search engine\_using ChatGPT\u2019s
    technology. Users\_reported that the search engine, which also functions as a
    chatbot, responded to questions with sometimes disturbing answers. OpenAI said
    earlier this month that it was\_launching a paid version of ChatGPT\_which would
    be available to subscribers for $20 a month. The Telegraph earlier reported that
    JPMorgan was restricting employees from using ChatGPT."
  tags: []
  title: JPMorgan Restricts Employees From Using ChatGPT
- !!python/object:ai_sentiment.data.ClassificationTarget
  body: "Microsoft\_Corp.\_is making its upgraded Bing search engine featuring the
    technology behind the\_viral chatbot ChatGPT\_available on\_Apple\_Inc.\_AAPL\_0.55%
    iPhones and Google Android mobile devices, pressing ahead with the deployment
    of the system despite early glitches. In a blog post, Microsoft said it is releasing
    new versions of its Bing app and Edge browser app for smartphones and tablets
    Wednesday so users can access the upgraded search engine while on the go. The
    company also said it is adding voice to Bing because the ability to speak commands
    or ask questions out loud rather than type them has been one of the most requested
    features among early testers of the system. Microsoft also said it plans to integrate
    the technology into its two-decade-old video-calling app Skype so users can request
    information and share it with others in group conversations. Microsoft unveiled
    Bing with artificial intelligence this month, saying the enhanced software enables\_a
    new kind of search\_in which people can pose questions in natural language. Bing
    then generates direct answers and suggestions, as opposed to pointing users toward
    different websites. The company gave a small number of testers access to the tool
    for trials. Several received\_inaccurate and sometimes bizarre responses\_and
    shared them on social media. Last week, Microsoft responded by adding restrictions
    on how the search tool can be used after determining that long interactions were
    causing some of the unwanted behavior. The company,\_an investor in ChatGPT creator
    OpenAI, said it would limit interactions with the new Bing to five questions per
    session and 50 questions a day. That move sparked a new round of complaints. On
    Tuesday, Microsoft said it would bring back longer chats, starting by\_allowing
    six questions per session and 60 total a day, with plans to increase the daily
    cap to 100 soon. Despite early missteps with the technology, Microsoft\u2019s
    Bing upgrade has created hype around the product and raised questions about whether
    it could become a formidable challenger to search-industry leader Google, a unit
    of\_Alphabet\_Inc.\_this month opened its\_rival AI-powered tool, called Bard,
    for testing."
  tags: []
  title: Microsoft Brings ChatGPT-Powered Bing to Mobile Devices
- !!python/object:ai_sentiment.data.ClassificationTarget
  body: "OpenAI\u2019s ChatGPT has nabbed the attention of corporate boardrooms for
    its humanlike ability to generate business reports, marketing pitches and code
    for software applications, among other things. Yet some business-technology professionals
    are uneasy about integrating it into the enterprise stack, citing concerns over
    its use of online data and security risks. But above all, they\u2019re worried
    about ChatGPT\u2019s grip on reality. \u201CIt explained to me in very convincing
    detail why cow eggs are larger than chicken eggs, and why the moon is bigger than
    the sun,\u201D said Christine Livingston, a managing director in the emerging
    technology group at Protiviti, a management consulting company. ChatGPT is a tremendous
    step forward for generative AI, she said, referring to algorithmic software designed
    to tap giant stores of data and create unique output based on user prompts. But
    at the moment, ChatGPT \u201Cshould be used with caution in an enterprise business
    setting,\u201D she said. Besides its problems with accuracy, ChatGPT requires
    a number of other improvements before it could be used on core enterprise applications,
    said Andy Harrison, managing partner and chief executive at tech venture investing
    fund Section 32. Other necessary upgrades include speedier results, advanced safety
    and security features, and better language abilities, Mr. Harrison said. As these
    and other performance improvements roll out\u2014over the next year or two, he
    said\u2014\u201Cwe will see the emergence of enterprise applications like enterprise
    search, integration with communication platforms, sales tools and others.\u201D
    \u201CGenerative AI is capable of amazing things, but as a whole, needs maturing,\u201D
    said Ashok Srivastava, chief data officer at TurboTax owner Intuit Inc. Released
    in November by San Francisco-based OpenAI, ChatGPT is a generative AI-powered
    chatbot that\u2019s been trained on a massive trove of articles, websites and
    social-media posts gathered from the internet, as well as transcribed interviews
    that capture the nuances of human speech. By detecting linguistic patterns and
    familiar phrases, the algorithm learned to predict what word is likely to follow
    from a sequence of words. From there, it was able to predict the next sentence
    and the next paragraph, eventually creating a coherent text. The approach can
    also be applied to writing computer code, enabling ChatGPT to anticipate large
    chunks of code that developers would need to input in order to execute a given
    task within a software program\u2014a capability proponents say will supercharge
    in-house application development. \u201CThis is the biggest technical leap forward
    since cloud computing,\u201D said Sameer Dholakia, partner at Bessemer Ventures
    Partners focused on cloud-based software. Any chief information officer who doesn\u2019t
    have their app-development team thinking about how to apply ChatGPT and generative
    AI is \u201Cputting their company at a disadvantage,\u201D Mr. Dholakia said.
    Microsoft Corp., which has invested billions of dollars in OpenAI, last month
    said it was integrating ChatGPT into its own enterprise software products, and
    more recently said it would add the technology to Bing, Microsoft\u2019s search
    engine. The tool quickly captured the public\u2019s imagination. But roughly a
    month after its release, Sam Altman, chief executive of OpenAI, warned against
    relying on ChatGPT \u201Cfor anything important right now.\u201D In a tweet, he
    said, \u201CChatGPT is incredibly limited, but good enough at some things to create
    a misleading impression of greatness.\u201D Gaurav Gupta, a partner at Lightspeed
    Venture Partners, readily agrees, saying business areas that require a high degree
    of accuracy and human judgment are simply not suitable for ChatGPT. The technology
    might be most useful for automating repetitive tasks within sales and marketing
    teams: \u201CIt could replace a junior salesperson who is prospecting, or a customer
    service rep that responds to questions,\u201D he said. Eric Schmidt, former chief
    executive of Alphabet Inc.\u2019s Google, said the basic problem with ChatGPT
    and similar systems is that they \u201Cwrite extremely well, but can be wrong
    and not grounded in fact.\u201D Last week, Google unveiled its own ChatGPT-like
    AI tool, called Bard, designed to generate textual responses to questions posed
    by users, based on information drawn from the web. For now, Mr. Schmidt said,
    generative AI capabilities should be reserved for writing corporate boilerplate\u2014product
    or service announcements, or other promotional materials. \u201CBut even then,
    no company would issue such things without human review,\u201D Mr. Schmidt said.
    Likewise, Chris Bedi, chief digital information officer at ServiceNow Inc., a
    cloud-based enterprise software firm, said ChatGPT is best suited to areas like
    sales and marketing, call centers or to summarize earnings reports, studies and
    other business documents, where auto-generated sales pitches or outgoing emails
    can be easily proofread before being sent out. But he has no plans to integrate
    ChatGPT into the company\u2019s software systems. Professional software developers
    are unlikely to save much time by having ChatGPT generate programming code, Mr.
    Bedi said, since it requires long strings of commands that would need to be checked
    and rewritten line by line. For enterprise information-technology, \u201CChatGPT
    use cases might be a smaller universe than people are imagining,\u201D he said.
    For now, CIOs should be experimenting with ChatGPT to determine how it could be
    put to use, mostly through trial and error, said Jeff Wong, global chief innovation
    officer at professional services firm Ernst & Young LLP. \u201CBefore integrating
    ChatGPT into businesses, we\u2019ve got to remember we\u2019re still early in
    its technology life cycle. We need to step back and ask what it can do today,\u201D
    Mr. Wong said. In its current form, ChatGPT \u201Canswers inaccurately with confidence
    at times, the math is behind and the data set is only up to a certain date,\u201D
    he added. Highly regulated industries will need to be especially cautious using
    ChatGPT or any form of generative AI, said Tim Crawford, CIO strategic advisor
    at Los Angeles-based enterprise IT advisory firm AVOA. \u201CWithout guardrails,
    data could easily be misused, or worse, serve as a foundation for further bad
    outcomes,\u201D Mr. Crawford said. \u201CChatGPT should never be used at face
    value,\u201D he said. \u201CEvery so often, it produces output that just doesn\u2019t
    make sense.\u201D"
  tags: []
  title: "Business Technology Chiefs Question ChatGPT\u2019s Readiness for the Enterprise"
- !!python/object:ai_sentiment.data.ClassificationTarget
  body: "MORE OFTEN\_than I like, after scanning the\_endless carousels on streaming
    apps, I find myself re-watching \u201CSeinfeld.\u201D I attribute this to a combo
    of laziness and mediocre recommendation engines, which rarely highlight anything
    I actually want to watch. It\u2019s a problem that seemed custom-designed for
    ChatGPT, the bot made by\_Microsoft-backed artificial intelligence research firm,
    OpenAI. Over 100 million people have tried ChatGPT since its\_launch in November,
    posing it tasks as disparate as\_writing English essays\_and negotiating down
    internet bills. By comparison, \u201CWhat movie should I watch?\u201D seemed simple.
    I told ChatGPT I enjoyed the 2013 film \u201CHer,\u201D whose protagonist develops
    a relationship with a virtual assistant. It spewed out a list of sci-fi titles
    like \u201CBlade Runner 2049\u201D and \u201CEx Machina.\u201D \u201CThese movies,\u201D
    it typed, \u201Cexplore the relationship between humans and artificial intelligence,
    touching on themes such as consciousness, identity and the nature of existence.\u201D
    (It gave no sign it saw the irony.) Wei Xu, an interactive computing professor
    at the Georgia Institute of Technology, explained how ChatGPT managed to produce
    a list of legitimately comparable movies in seconds. The software, she said, is
    trained to spot patterns within a massive amount of text data\u2014over 500 GBs\u2014it
    scrapes off the internet. When sniffing out cinematic cousins to \u201CHer,\u201D
    it\u2019s likely consulting sources like Reddit threads, IMDB forums, even \u201CBest
    of\u201D lists from editorial outlets. Traditional recommendation engines, said
    Dr. Xu, don\u2019t have this access. This presents issues for existing discovery
    platforms like Letterboxd, a social-networking site for discussing movies, and
    Likewise, a content-recommendation service that draws on AI and human curators.
    Letterboxd co-founder Matthew Buchanan told me he\u2019s concerned by ChatGPT\u2019s
    lack of transparency. To get the info it uses to make recommendations, it could
    be plagiarizing the work of Letterboxd users without providing credit. (OpenAI
    declined to comment for this article.) The threat of copyright infringement\_that
    generative AI systems present is indeed a pressing problem. Many artists\_have
    criticized\_the makers of photo-editing app\_Lensa, which has a feature that uses
    AI to generate portraits, for not compensating artists whose art was used to help
    train it. Lensa\u2019s creators have said its portraits are \u201Cnot replicas
    of any particular artist\u2019s artwork.\u201D Dr. Xu says platforms like Letterboxd
    might have a tough time proving that ChatGPT violates intellectual property laws.
    And generative-AI developers can address the issue, she said, by adding citations
    to their bots\u2019 answers. For now, Mr. Buchanan says he\u2019s taking solace
    in the fact that ChatGPT\u2019s \u201Canodyne\u201D responses lack a human touch.
    I can\u2019t help but agree. The humor and strangeness of Letterboxd reviews can
    leave me excited to watch particular movies. (In reference to the cinematographer
    of \u201CBlade Runner 2049,\u201D for instance, one Letterboxd reviewer wrote
    \u201CI\u2019m pregnant and the father is Roger Deakins\u2019 camera.\u201D) ChatGPTs
    responses are usually reasonable, but they rarely surprise. And because the bot
    is only trained on data that predates September 2021, it has some blind spots,
    though I haven\u2019t yet encountered these. In any case, the last time I settled
    in to watch a film, I knew exactly what to stream\u2014I had to see what all the
    Roger Deakins fuss was about. 3 More AI-Augmented Apps Tech companies are racing
    to incorporate ChatGPT-like capabilities into their own products. The following
    apps are free to download, but access to some of their features might cost you
    extra. Simpler Searching Neeva, a private search engine designed by\_Sridhar Ramaswamy,
    the former lead of Google\u2019s ad and commerce division, uses AI to summarize
    the results of a traditional list of blue links, fetching one final answer to
    your query. No more sifting through a pile of obscure websites just to find the
    difference between baking powder and baking soda. (Expect more of this: Microsoft
    announced last week it was integrating the tech behind ChatGPT into its search
    engine Bing.) Modern-day Memex Mem\_uses AI to form contextual links between your
    emails, calendar appointments, memos and more so that you can find them all in
    one place. If you\u2019re looking to attend a certain meeting, for example, Mem
    will create a page where you will find the joining link, plus any relevant notes
    you\u2019ve prepared and related emails you\u2019ve received and sent. Easier
    Editing You no longer need high-end software to edit videos, podcasts and voiceovers.\_Descript\_converts
    these into easily scannable transcripts, so that you can cut filler words or move
    scenes around. Used judiciously, this saves time, and sounds surprisingly professional."
  tags: []
  title: Can ChatGPT Recommend Movies? A Film Buff Put It to the Test
- !!python/object:ai_sentiment.data.ClassificationTarget
  body: "With ChatGPT capabilities built in, the platform\u2019s chatbot will be able
    to learn a users\u2019 preferred airlines, hotels and restaurants, and incorporate
    these options into a proposed itinerary, while leveraging natural-language models
    to respond to voice commands, said Ariel Cohen, TripActions co-founder and chief
    executive. Behind the scenes, ChatGPT will also write, test and fix the underlying
    code that runs the app, constantly making tweaks based on data analytics aimed
    at boosting operational efficiency across its code base, Mr. Cohen said. The eight-year-old
    company\u2019s approach grew out of workers\u2019 frustrations with expense-report
    software tools, which often require users to manually enter figures from a stash
    of receipts, gathered from airlines, hotels, taxis and restaurants. \u201CEmployees
    frequently complain about the amount of time and effort they spend on expenses
    and about the time it takes to get reimbursed,\u201D said Liz Herbert, vice president
    and principal analyst at information-technology research firm Forrester Research
    Inc. TripActions has sought to streamline the process through capabilities such
    as an artificial-intelligence-powered smartphone receipt-scanning tool, which
    automatically loads and categorizes items from printed receipts into an expense
    report, matching them to credit-card charges. It also works with digital receipts.
    That way, the expense report is generated during the trip as expenses are incurred,
    Mr. Cohen said. \u201CGenerally, software in the business-to-business space is
    designed to serve the company,\u201D rather than the employees, Mr. Cohen said.
    \u201CIt\u2019s about efficiency for the company, but not really about the workers.\u201D
    By consolidating services, he said, Navan will enable employees to manage bookings
    and expenses on a single platform, which is designed to search for available travel
    options, track every transaction on a corporate card, and automatically generate
    an expense report. Mr. Cohen said the market opportunity lies in bridging the
    gap between the business travel apps employees have grown accustomed to, and the
    user-friendly consumer apps they use to book family vacations or simply a night
    out. \u201CUsing AI helps you create the kind of software that I\u2019m talking
    about,\u201D Mr. Cohen said. \u201CThis is how business software needs to be.\u201D
    That strategy is catching the attention of some of the startup world\u2019s biggest
    investors. In October, TripActions closed a $154 million equity funding round,
    including capital from returning investor Andreessen Horowitz, while raising an
    additional $150 million in a structured financing deal with Coatue Management
    LLC, a technology-focused investment manager. It currently has a private-market
    valuation of more than $9 billion. \u201CIt\u2019s kind of like this weird anomaly
    where consumer travel changed a lot and business travel stayed the same,\u201D
    said Ben Horowitz, co-founder and general partner of Andreessen Horowitz. Mr.
    Horowitz said Navan\u2019s new all-in-one app offers a \u201Cbetter way of doing
    expenses\u201D by filling in transactions in real-time while a user is traveling.
    But whether as TripActions or Navan, the company has a lot of ground to make up
    to catch market front-runner SAP Concur, industry analysts said. Based on revenue,
    SAP Concur, owned by enterprise-technology stalwart SAP SE, holds 49% of the global
    travel-and-expense management market, according to research firm International
    Data Corp. SAP Concur has also begun using AI in its travel and expense software,
    which can \u201Ctap decades of expense data and experience tracking to identify
    hard-to-detect spend issues and anomalies,\u201D said Charlie Sultan, president
    of Concur Travel. Among other benefits, he said, using AI has reduced the time
    it takes for employees to be reimbursed for expenses to roughly three or four
    days, from 10 days or more. Other competitors include Expensify, Rydoo and Coupa,
    along with expense apps included in broader enterprise resource planning platforms
    offered by Workday Inc. and Oracle Corp. IDC expects the market to expand by a
    compound annual growth rate of 7.5% over the next three years, from an estimated
    $2.5 billion this year to $3.2 billion by 2026. \u201CThe new battlefield for
    software vendors in the travel-and-expenses space will be addressing data management,\u201D
    said IDC Research Director Kevin Permenter, citing capabilities like data analytics
    and the use of application programming interfaces, designed to link programs together.
    \u201CIt is not enough to have good functionality,\u201D Mr. Permenter said, \u201Cusers
    must be able to move data into and out of your software quickly and easily.\u201D"
  tags: []
  title: TripActions Rebrands as Navan, Adds ChatGPT to Expense Reports
- !!python/object:ai_sentiment.data.ClassificationTarget
  body: "Microsoft\_Corp. is integrating the technology behind the\_viral chatbot
    ChatGPT\_into its Bing search engine, hoping the artificial intelligence upgrade
    can help it chip away at Google\u2019s dominance of the search market. The breakout
    success of the bot from the Microsoft-backed OpenAI has put the software giant
    at the forefront of what some see as the\_next wave of technological innovation:
    generative artificial intelligence. In an event Tuesday to launch the technology,
    Microsoft said the Bing upgrade\_will enable a new kind of search\_in which people
    will pose questions to the search engine in natural language and it will generate
    direct answers and suggestions. \u201CI think this technology is going to reshape
    pretty much every software category,\u201D Microsoft Chief Executive\_Satya Nadella\_said
    at the event at the company\u2019s Redmond, Wash., headquarters. Mr. Nadella put
    the significance of AI-powered search on the same level of importance as the development
    of web browsers and mobile devices. Unlike ChatGPT, which wasn\u2019t able to
    answer questions about current events, the updated Bing uses newer technology
    tailored for search engines. It will have access to the latest information such
    as news stories, train schedules and product pricing. It will also be able to
    provide links to demonstrate where its answers are coming from, another feature
    that wasn\u2019t part of ChatGPT. Microsoft shares climbed 4% Tuesday as the Nasdaq
    Composite Index rose 2%. The company\u2019s stock price has risen around 17% over
    the past three months while the Nasdaq index rose 15%. Microsoft, which is investing
    billions of dollars into OpenAI, is integrating the technology into many of its
    products, marking what it pitches as a new era of AI-powered software that has
    the potential to upend power in the tech industry. Some analysts say AI-powered
    searches could help Microsoft\u2019s Bing search engine take market share away
    from\_Alphabet\_Inc.\u2019s Google, which controls around 90% of the market. The
    industry has been buzzing about the possibilities of generative AI since OpenAI
    released its image generation tech Dall-E 2 to the public last year. Dall-E 2
    can create original images based on simple prompts, such as, \u201CDraw a robot
    dancing in a field of flowers.\u201D OpenAI released ChatGPT in November. Millions
    of people have since used it to generate essays, sales pitches and poems. The
    popularity of the tools has put pressure on Google, which has long been at the
    forefront of AI technology, to match it. Earlier this week, Google announced it
    is rolling out\_its own conversational artificial-intelligence service\_to a set
    of testers and plans a broader public launch in the coming weeks. The new experimental
    service, called Bard, generates responses to questions posed by users, based on
    information drawn from the web,\_Sundar Pichai, chief executive of Google parent
    Alphabet, said in a blog post published Monday. Shares of Chinese internet giant\_Baidu\_Inc.
    surged in Hong Kong Tuesday as it confirmed plans to launch an artificial-intelligence
    chatbot. Baidu said it expects to\_launch its AI chatbot, called Ernie Bot, in
    March. Some artificial intelligence analysts warn there are still potential problems
    with generative AI. ChatGPT, for example,\_can be expensive to run\_and slow,
    and it sometimes produces responses that contain made-up facts, they have said.
    OpenAI CEO\_Sam Altman\_was at the Microsoft event, saying the new uses for AI
    technology mark the \u201Cbeginning of a new era.\u201D In the past he has warned
    that it is still evolving and prone to inaccuracies. Mr. Altman said both OpenAI
    and Microsoft are taking a cautious approach in how they roll out the technology,
    trying to take measures to ensure that Bing won\u2019t generate dangerous or offensive
    content. \u201CWe share a deep sense of responsibility in ensuring that AI gets
    deployed safely,\u201D he said. The technology is proving powerful in some cases,
    such as when it is paired with professionals for specific tasks. Last year Microsoft
    released GitHub Copilot which uses OpenAI tools to help programmers write and
    fix computer code. Microsoft estimated that in files in which it is enabled, Copilot
    generates 40% of the code. The company last year also integrated OpenAI\u2019s
    image-generation tech into its Bing and graphical design software Microsoft Designer.
    The latest applications of the technology to Bing as well as Microsoft\u2019s
    Edge browser are aimed at creating similar partnerships between people and AI,
    Mr. Nadella said. \u201CYou\u2019re going to have this notion of a co-pilot that\u2019s
    going to be there across every application,\u201D he said. On Tuesday Microsoft
    showed off Bing\u2019s new ability to spit out brief biographies of famous Mexican
    artists, compare features of new televisions and generate a family\u2019s weekly
    dinner menu. Using a Bing integration into Microsoft\u2019s Edge web browser,
    people can converse with the search engine to refine initial answers. For example,
    it can take a suggested menu and generate a shopping list for the ingredients.
    The search engine cites sources of the information that make up its responses.
    While that citation ability is an improvement over ChatGPT and gives people a
    better sense of where answers are coming from, it could raise questions about
    copyright and the effect this new search model will have on web traffic."
  tags: []
  title: Microsoft Adds ChatGPT AI Technology to Bing Search Engine
- !!python/object:ai_sentiment.data.ClassificationTarget
  body: "This column isn\u2019t written by ChatGPT. At least not yet. But the conversational
    artificial-intelligence tool seems to be\_taking over the world\u2014and that
    now includes the Chinese stock market. Investors should be careful not to get
    ahead of themselves, however. AI is a different political ballgame in China than
    e-commerce or online finance, but the country has just emerged from a multiyear
    crackdown on internet-platform companies\u2014in part, because they became too
    powerful and ubiquitous. At the very least, such a potentially transformative
    new technology seems likely to quickly become a subject of significant regulatory
    concern. The launch of ChatGPT by\_Microsoft-backed OpenAI a few months ago has
    sparked a race among U.S. online-search and software giants. On Tuesday, Microsoft
    said it would incorporate the AI tool\_into its Bing search engine and Edge web
    browser. Search market leader Google says it will launch its own version of an
    AI chatbot called Bard. Across the Pacific, Chinese companies are jumping on the
    bandwagon too. China\u2019s search giant\_Baidu said on Tuesday that it will unveil
    its own conversational AI tool called Ernie Bot after completing internal testing
    in March.\_Alibaba , China\u2019s e-commerce leader, said on Wednesday it is also
    testing its own ChatGPT-style tool. Baidu\u2019s shares\_jumped 15% in Hong Kong\_on
    Tuesday on the news. The stock has since given up some of those gains, but it
    has gained 36% this year so far, outperforming other Chinese stocks: the CSI 300
    mainland benchmark is up only 7%. AI-related stocks listed in China, meanwhile,
    have surged to the stratosphere. Shares of Shenzhen-listed\_Hanwang Technology,
    which makes products for use in character recognition, have more than doubled
    in 2023. Shares of Shanghai-listed\_Beijing Haitian Ruisheng Science Technology,
    which develops training data sets for AI, have tripled. It is easy to see how
    chatbots could be integrated into tech giants\u2019 businesses. Bots may, for
    example, improve the search interface for Baidu\u2019s users. The ability of ChatGPT
    to draft convincingly human essays could enhance productivity tools. Tech giants
    with their enormous troves of data and AI research are well-placed to capitalize
    on the new technology. Regulation could be another issue, especially in China,
    given its strict data-security laws. While the government will probably initially
    be supportive because dominance in AI is such a high policy priority for Beijing,
    widespread use of the tool by the public will still be scrutinized. Its use may
    be restricted in settings like education. And if advanced chatbot technology starts
    bumping up against some of Beijing\u2019s sore spots\u2014for example, online
    financial fraud or politics\u2014one can imagine a swift and sure regulatory response.
    But it is still too early to tell how much revenue such chatbots will really bring
    into corporate coffers. For one, competition will be intense: It\u2019s already
    clear that many major internet-platform companies could end up as contenders.
    AI-powered chatbots could help improve existing services, but may not create new,
    stand-alone revenue streams. And integrating chatbots into existing platforms
    may incur significant costs. When asked to write a short sentence on investing
    in the latest fads, ChatGPT said it \u201Ccan be risky and they may not have a
    solid track record and can quickly lose popularity.\u201D Investors would be wise,
    in this case, to take it at its word."
  tags: []
  title: ChatGPT Clones Are Preparing to Take Over China
- !!python/object:ai_sentiment.data.ClassificationTarget
  body: "The artificial-intelligence\_chatbot ChatGPT\_has shaken educators since
    its November release. New York City public schools have banned it from their networks
    and\_school devices, and professors are revamping syllabi to prevent students
    from using it to complete their homework. The chatbot\u2019s creator,\_OpenAI,
    even unveiled a tool to detect text generated by artificial intelligence to prevent
    abuse from cheaters, spammers and others. There is, perhaps surprisingly, one
    subject area that doesn\u2019t seem threatened. It turns out ChatGPT is quite
    bad at math. \u201CI\u2019m not hearing math instructors express concern about
    it,\u201D said\_Paul von Hippel, a professor at the University of Texas who studies
    data science and statistics and has written an essay about\_ChatGPT\u2019s mathematical
    limitations. \u201CI\u2019m not sure it\u2019s useful for math at all, which feels
    strange because mathematics was the first-use case for computing devices.\u201D
    While the bot gets many basic arithmetic questions correct, it stumbles when those
    questions are written in natural language. For example, ask ChatGPT \u201Cif a
    banana weighs 0.5 lbs and I have 7 lbs of bananas and nine oranges, how many pieces
    of fruit do I have?\u201D The bot\u2019s quick reply: \u201CYou have 16 pieces
    of fruit, seven bananas and nine oranges.\u201D It isn\u2019t hard, and in fact
    is a little entertaining, to feed the bot questions to which it responds with
    confident nonsense. If you ask ChatGPT who is taller,\_Shaquille O\u2019Neal or
    Yao Ming, the bot accurately says Yao is 7\u20196\u201D and O\u2019Neal is 7\u20191\u201D
    but then concludes that Shaq is taller. The bot miscalculates the square roots
    of large numbers. Ask it to show its math, and it often produces detailed formulas
    that look great but contain errors, such as 2 x 300 = 500. I asked ChatGPT to
    write five simple algebra problems and then to provide the answers. The AI only
    answered three of its own problems correctly. ChatGPT\u2019s struggle with math
    is inherent in this type of artificial intelligence, known as a large language
    model. It scans enormous reams of text from across the web and develops a model
    about what words are likely to follow others in a sentence. It\u2019s a more sophisticated
    version of autocomplete that, after you type \u201CI want to\u201D on your device,
    guesses the next words are \u201Cdance with somebody,\u201D \u201Cknow what love
    is\u201D or \u201Cbe with you everywhere.\u201D ChatGPT, OpenAI\u2019s new artificially
    intelligent chatbot, can write essays on complex topics. WSJ\u2019s Joanna Stern
    went back to high school AP Literature for a day to see whether she could pass
    the class using just AI. Photo illustration: Elena Scotti A Mad Libs-proficient
    supercomputer might be extremely effective for writing grammatically correct responses
    to essay prompts, but not for solving a math problem. That is the Achilles\u2019
    heel of ChatGPT: It responds in authoritative-sounding language with numbers that
    are grammatically correct and mathematically wrong. As Mr. von Hippel wrote, \u201CIt
    acts like an expert, and sometimes it can provide a convincing impersonation of
    one. But often it is a kind of b.s. artist, mixing truth, error and fabrication
    in a way that can sound convincing unless you have some expertise yourself.\u201D
    In an email, I asked\_Debarghya Das, a search-engine engineer who has tweeted
    examples of ChatGPT botching basic math, why it gets some simple questions right
    but others completely wrong. \u201CMaybe the right analogy is if you ask a room
    of people who have no idea what math is but have read many hieroglyphics, \u2018What
    comes after 2+2,\u2019 they might say, \u2018Usually, we see a 4.\u2019 That\u2019s
    what ChatGPT is doing.\u201D But, he adds, \u201Cmath isn\u2019t just a series
    of hieroglyphics, it\u2019s computation.\u201D It isn\u2019t great for faking
    your way through a math class because you only recognize the mistakes if you know
    the math. If it\u2019s all hieroglyphics to you, the wrong answers seem plausible.
    OpenAI Chief Executive\_Sam Altman\_said\_in December on Twitter\_that \u201CChatGPT
    is incredibly limited, but good enough at some things to create a misleading impression
    of greatness. It\u2019s a mistake to be relying on it for anything important right
    now.\u201D When you begin a conversation with ChatGPT it warns up front, \u201CWhile
    we have safeguards in place, the system may occasionally generate incorrect or
    misleading information.\u201D Another reason that math instructors are less fussed
    by this innovation it that they have been here before. The field was upended for
    the first time decades ago with the general availability of computers and calculators.
    \u201CMath has had the biggest revolution based on machinery of any mainstream
    subject I could ever have thought of,\u201D said\_Conrad Wolfram, the strategic
    director of Wolfram Research, which developed Mathematica, a technical computing
    software program, as well as Wolfram Alpha, a website for answering math queries.
    Whereas English teachers are only now worrying about computers doing their students\u2019
    homework, math teachers have long wrestled with making sure students were actually
    learning and not just using a calculator. It\u2019s why students have to show
    their work and take tests on paper. The broader lesson is that AI, computers and
    calculators aren\u2019t simply a shortcut. Math tools require math knowledge.
    A calculator can\u2019t do calculus unless you know what you\u2019re trying to
    solve. If you don\u2019t know any math, Excel is just a tool for formatting tables
    with a lot of extra buttons. \u201CIn the real world, since computers came along,
    have math, science and engineering gotten conceptually simpler? No, completely
    the opposite. We\u2019re asking harder and harder questions, going up a level,\u201D
    Mr. Wolfram said. Eventually, artificial intelligence will probably get to the
    point where its mathematics answers are not only confident but correct. A pure
    large language model might not be up for the job, but the technology will improve.\_The
    next generation of AI could combine\_the language skills of ChatGPT with the math
    skills of Wolfram Alpha. In general, however, AI, like\_calculators and computers,
    will likely ultimately be most useful for those who already know a field well:
    They know the questions to ask, how to identify the shortcomings and what to do
    with the answer. A tool, in other words, for those who know the most math, not
    the least."
  tags: []
  title: ChatGPT Needs Some Help With Math Assignments
- !!python/object:ai_sentiment.data.ClassificationTarget
  body: "China\u2019s\_Baidu\_Inc. has thrust itself into a global race to commercialize
    the next generation of artificial-intelligence technologies\_like ChatGPT\_that
    could transform the internet. The company is developing an AI-powered chatbot
    similar to\_OpenAI\u2018s\_popular ChatGPT\_and plans to integrate it into its
    main search engine in March, people familiar with the matter said. The move would
    place Beijing-based Baidu among a few tech companies globally to have its own
    version of the technology, which\_has generated buzz among consumers and businesses,
    and placed pressure on incumbents, which have started to update their product-development
    strategies. Baidu is set to be the first to bring the technology to consumers
    in China, where\_the state censors the internet\_and\_access to ChatGPT\_is blocked
    Baidu\u2019s plans come as\_competition heats up\_between Washington and Beijing
    to bolster their respective countries\u2019 leadership in strategic emerging technologies.
    They also highlight the fluid, cross-border nature of AI research, where open-source
    is the norm. OpenAI\_built ChatGPT\_atop a core breakthrough that\_Alphabet\_Inc.\u2019s
    Google developed in 2017\u2014an algorithm that Baidu also adapted and is now
    using as the foundation for its chatbot, according to some of the people. Baidu
    Chief Executive\_Robin Li\_touched on ChatGPT in a late-December speech to some
    employees, saying it represents new opportunities, according to a transcript on
    Baidu\u2019s internal website that was seen by The Wall Street Journal. \u201CWe
    have such cool technology, but can we turn it into a product that everyone needs?\u201D
    Mr. Li said, referring to AI-driven technologies including the chatbot. \u201CThis
    is actually the hardest step, but also the greatest and most influential.\u201D
    Bloomberg earlier reported on Baidu\u2019s plans. Baidu, whose growth hasn\u2019t
    kept up with that of its Chinese internet peers, has been pushing to refashion
    itself into an AI company, investing billions of dollars in technologies including\_self-driving
    cars\_and chips designed to power AI applications. Using its vast repository of
    text data from its search-engine business, it has focused in particular on an
    area of AI research known as natural-language processing, which has experienced
    major leaps in advancement in the past few years and led to the recent surge of
    AI technologies,\_including ChatGPT. In 2019, Baidu developed a deep-learning
    model known as Ernie, based on Google\u2019s breakthrough, which it has used to
    improve its search results, including to make them more relevant. The company
    has since developed dozens more Ernie models and extended their capabilities to
    include image and art generation, similar to those of\_OpenAI\u2019s Dall-E. ChatGPT,
    OpenAI\u2019s new artificially intelligent chatbot, can write essays on complex
    topics. WSJ\u2019s Joanna Stern went back to high school AP Literature for a day
    to see if she could pass the class using just AI. Photo illustration: Elena Scotti
    Baidu is now using Ernie as the foundation for its chatbot, and is training it
    on both Chinese- and English-language sources inside and outside China\u2019s
    firewall, some of the people said. In the past, Baidu has trained Ernie using
    sources that include Wikipedia, BookCorpus, Reddit and Baidu\u2019s ecosystem
    of products\u2014such as Baidu Baike and Baidu News\u2014according to its open-source
    research papers. Baidu plans to limit its chatbot\u2019s outputs in accordance
    with the state\u2019s censorship rules, one of the people said. OpenAI also applies
    restrictions to ChatGPT\u2019s outputs in an effort to avoid toxic hate speech
    and politically sensitive topics. Trained on vast amounts of text data from the
    internet, ChatGPT is capable of answering all manner of user questions in fluent
    conversational prose. But the chatbot can\u2019t guarantee accurate answers and
    at times has delivered sexist or racist comments, industry researchers have said.
    Tech giants including\_Microsoft\_Corp. and Google are hurrying to mature the
    technology underlying ChatGPT and integrate it into their products\u2014including
    search, where its conversational abilities are seen to have the most potential
    to upend the status quo. Microsoft, which\_invested in OpenAI in 2019\_and 2021,
    announced fresh backing\u2014as much as $10 billion, The Wall Street Journal reported\u2014to
    infuse ChatGPT into its product lines, including its search engine Bing. A similar
    Google technology known as LaMDA made its debut in 2021, and\_Meta Platforms\_Inc.
    released a chatbot known as BlenderBot in 2020, but neither has revealed plans
    to integrate the technology into their platforms."
  tags: []
  title: "China\u2019s Baidu Developing Its Own ChatGPT, Joining Global AI Race"
- !!python/object:ai_sentiment.data.ClassificationTarget
  body: "OpenAI is launching a paid subscription version of its\_artificial-intelligence
    chatbot ChatGPT. The new subscription service is called ChatGPT Plus and will
    have a $20 monthly fee, the company announced Wednesday. The subscription includes
    access to the chatbot during peak usage times. The current free version limits
    service to users during periods when usage is high. Subscribers will also get
    early access to new features and improvements and faster response times from the
    chatbot. The new subscription program will first be available in the U.S. in the
    coming weeks and then expand to other countries, OpenAI said\_in a statement\_on
    its website. Interested users can sign up for a wait list to the subscription
    service, the company said. The new subscription program will initially be available
    in the U.S. and will later expand to other countries, OpenAI said. Interested
    users can sign up for a wait list to the subscription service, the company said.
    OpenAI will begin inviting people over from the wait list in the coming weeks.
    OpenAI\_will continue to offer free access to ChatGPT. The subscription service
    will help support free access for the chatbot, the company said. OpenAI is also
    exploring options for lower-cost plans and business plans. Microsoft is deepening
    its partnership with OpenAI, the company behind ChatGPT and Dall-E. That has investors
    and analysts speculating whether Microsoft could challenge Google\u2019s dominance
    in search. WSJ Heard on the Street columnist Dan Gallagher joins host Zoe Thomas
    to discuss how AI could affect search and at what cost. ChatGPT allows users\_to
    type questions to the bot and receive written responses powered by artificial
    intelligence. It can even write poems and essays. Some industry observers have
    said ChatGPT could offer a potential alternative to current search engines in
    the future, though the company has said that the program\u2019s outputs often
    contained factual errors. Last month,\_Microsoft\_Corp. said it would make a\_multiyear,
    multibillion-dollar investment\_in OpenAI after previously investing in 2019 and
    2021. The companies didn\u2019t disclose financial terms of the partnership. Microsoft
    has said it would\_incorporate artificial-intelligence tools\_like ChatGPT into
    all of its products and make them available as platforms for other businesses
    to build on. Microsoft Chief Executive\_Satya Nadella\_said the company would
    commercialize tools from OpenAI like ChatGPT and give more customers\_access to
    software behind chatbot\_through its cloud-computing platform Azure. OpenAI has
    also discussed selling existing shares in a tender offer that would\_value the
    company at around $29 billion, The Wall Street Journal previously reported."
  tags: []
  title: OpenAI to Offer ChatGPT Subscription Plan for $20 a Month
- !!python/object:ai_sentiment.data.ClassificationTarget
  body: "Google is rolling out a new conversational artificial-intelligence service
    to a select set of testers, and plans a broader public launch in coming weeks,
    part of the company\u2019s\_effort to play catch-up\_with challengers such as
    OpenAI, creator of the\_popular chatbot ChatGPT. The new experimental service,
    called Bard, generates textual responses to questions posed by users, based on
    information drawn from the web,\_Sundar Pichai, chief executive of Google parent\_Alphabet\_Inc.,
    said in a blog post published Monday. In that post, Mr. Pichai also shared a glimpse
    of new search engine features that will use AI to answer user queries, and said
    it would open up some of its AI programs to outside developers. Google\u2019s
    new products come amid a flurry of announcements by rival\_Microsoft\_Corp. about
    its use of AI technologies developed by OpenAI. Microsoft said last month it is
    making\_a multiyear, multibillion-dollar investment in\_the San Francisco AI startup.
    It said it would be opening up its tools for developers to build upon, and integrating
    them into services such as its\_Bing search engine\u2014raising the specter of
    a new challenge to Google Search\u2019s market power. Microsoft says it is planning
    an event on Tuesday to announce \u201Cprogress on a few exciting projects,\u201D
    which are widely expected to include a chatbot-infused version of Bing.\_Sam Altman,
    chief executive of OpenAI, on Monday tweeted a picture of himself next to Microsoft
    Chief Executive\_Satya Nadella, saying \u201Cexcited for the event tomorrow.\u201D
    Microsoft\u2019s announcements have led to complaints from investors that Google
    hasn\u2019t moved quickly enough to release its in-house AI tools, despite being
    the pioneer of some of the technologies used to build tools such as ChatGPT. Those
    complaints have been echoed by some of its own researchers, The Wall Street Journal
    has reported. In response, Google executives have recently sped up work to review
    and release artificial-intelligence programs to the general public, while also
    assigning teams of engineers to work on new ways to integrate new developments
    into areas such as the core search experience, the Journal reported. Google executives
    have also suggested they haven\u2019t been slow so much as careful with their
    tools, drawing an implicit contrast to competitors tools, such as ChatGPT, that
    can spout made-up information in response to some user queries. Google executives
    say they must test new tools to make sure they don\u2019t show bias, and guard
    against misuse, concerns shared by many academics. \u201CIt\u2019s critical that
    we bring experiences rooted in these models to the world in a bold and responsible
    way,\u201D Mr. Pichai in his blog post on Monday. \u201CThat\u2019s why we\u2019re
    committed to developing AI responsibly.\u201D He added that the new external testing
    period for Bard will be combined with internal research to make sure that it gives
    responses that meet Google\u2019s \u201Chigh bar for quality, safety and groundedness
    in real-world information.\u201D Mr. Pichai said in a separate internal email
    seen by The Wall Street Journal that Google\u2019s entire staff will get access
    to Bard next week in order to give feedback as part of a \u201Ccompany-wide dogfood,\u201D
    or tech-industry slang for testing or using one\u2019s own products. Google is
    under the spotlight of regulators in the European Union, U.S. and other parts
    of the globe. In the EU, policy makers are considering a new AI law that could
    require companies to conduct risk assessments before launching new tools Google
    says its Bard service is based on its experimental artificial-intelligence program
    called LaMDA, which stands for Language Model for Dialogue Applications. Google
    last year\_suspended an engineer\_who contended that LaMDA had become sentient\u2014a
    claim roundly rejected by scientists in the field. ChatGPT, OpenAI\u2019s new
    artificially intelligent chatbot, can write essays on complex topics. WSJ\u2019s
    Joanna Stern went back to high school AP Literature for a day to see if she could
    pass the class using just AI. Photo illustration: Elena Scotti When OpenAI released
    ChatGPT late last year,\_it took off as a viral sensation.\_\L\LWhile it was based
    on AI tools widely available to researchers, the breadth of its capabilities opened
    up the possibilities of so-called generative AI\u2014or AI that can create content
    in response to short user inputs\u2014to a wider audience of potential users.
    People posted the chatbot\u2019s humorous responses to their queries, like a retelling
    of the Goldilocks fairy tale in the style of a police blotter, as well as complex
    computer software coding that it could provide when asked.\_\L\LGoogle offered
    few details Monday about how Bard will work and what kind of answers it will offer.
    The company said that Bard would initially use what it called a smaller model
    of LaMDA that uses less computing power, which will allow the company to make
    it more widely available.\_\L\LSample queries for Bard include, \u201CWhat new
    discoveries from the James Webb Space Telescope can I tell my 9-year-old about?\u201D
    to which Bard replies three short bullet points of recent discoveries. Other suggested
    queries in the blog post include, \u201CPlan a friend\u2019s baby shower\u201D
    and \u201CCompare two Oscar-nominated movies.\u201D\_\L\LIn Monday\u2019s post,
    Mr. Pichai also gave a glimpse of some new AI features that he said would soon
    be integrated into the company\u2019s eponymous search engine. Those features
    aim to \u201Cdistill complex information and multiple perspectives into easy to
    digest formats,\u201D he said.\_\L\LThe only example query the company provided
    Monday asks the search engine whether it is easier to learn to play piano or guitar.
    Google\u2019s answer? Some say piano while others say guitar.\_\L\LMore examples
    are expected on Wednesday, when Google has scheduled an event in Paris that will
    share progress on the new AI-based search tools, the internal email from Mr. Pichai
    said.\L\LMr. Pichai also said Google plans next month to start allowing outside
    developers to start building LaMDA\u2019s generative language capabilities into
    their own applications, through a new application programming interface, or API,
    that allows them to query LaMDA as part of their own tools. Eventually the company
    says it will make a suite of tools.\_\L\LThat announcement in some ways mirrors
    Microsoft\u2019s announcement last month that it would start allowing outside
    developers to build with ChatGPT and other AI tools through its own APIs."
  tags: []
  title: Google Opens Testing of Its ChatGPT Rival
- !!python/object:ai_sentiment.data.ClassificationTarget
  body: "People seem to think that OpenAI\u2019s ChatGPT, a chatbot powered by artificial
    intelligence, is going to put many writers out of business or make writing bland\u2014or
    both. But perhaps that\u2019s not a bad thing. With the rise of the internet,
    we\u2019re inundated with more writing than ever and most of it is mediocre. On
    social media platforms like Twitter, everyone gets a license to be a short-form
    editorial writer, uninhibited by an editor or boss riding them for accuracy and
    relevance. Are public debates over ideas and policies any more informed or enlightened
    for having these truncated opinion pieces? You know the answer. Journalism has
    the opposite problem. Journalistic writing once had to fit into a set number of
    column inches. Now, the digital-news hole is infinite, so most news stories go
    on and on without a sense of restraint\u2014but with dwindling quality. No wonder
    ChatGPT\u2019s most immediate application is on digital news, tech and social-gossip
    sites desperate to keep readers engaged with whatever content sticks to the wall.
    And look at corporate writing: It\u2019s either clich\xE9-ridden, meaningless
    fluff or rife with jargon. Either way, most of it is utterly forgettable. Academics
    aren\u2019t much better. Their writing\u2014especially in the humanities and social
    sciences\u2014is so arcane and technical that most of it is never read, even by
    other academics. Maybe robots should get a shot at taking over some of this workday
    prose. Who wouldn\u2019t mind a robot-generated statement that clearly articulates
    a company\u2019s strategy without referring to the time-worn clich\xE9s of \u201Cparadigm
    shift\u201D or \u201Coptimized performance\u201D? What\u2019s so bad about an
    academic paper written in language that any keen learner could understand? Would
    you turn your nose up at concise, fact-rich reporting on recent news? I think
    people fear robot-writers because they do their job well, maybe even better than
    humans do. Some will contend that ChatGPT\u2019s skills are limited and lacking
    in style, but so what? Sure, it can\u2019t write a masterful piece of prose or
    a profound novel. But most of what we read isn\u2019t that good anyway, even the
    stuff written by people. As long as artificial intelligence produces instruction
    manuals that are clear and corporate policies that provide direction, that\u2019s
    good enough for me. A robot might even manage to summarize important historical
    events without taking potshots at contemporary political figures. (That is, of
    course, if ChatGPT manages to fix its\_left-leaning\_tilt.) Those would all be
    welcome improvements. What about the writers who remain? They\u2019ll be able
    to elevate their craft to higher purposes\u2014or at the very least create something
    truly original. Consider how portrait artists responded to the invention of photography.
    The best ones excelled in impressionism, cubism and other movements of modern
    art. Art didn\u2019t disappear, it simply shifted its gaze. Whether you want them
    or not, the robot-writers are coming. Soon we will be able to generate solid writing
    as easily as we use internet search engines. We\u2019ll get practical results
    that work for practical purposes. But when something new or weighty needs to be
    shared, we will turn to human writers who have the gift of conveying the unexpressed
    thought in words that are original and artful. That\u2019s the kind of writing
    humans should do\u2014and if that\u2019s our destiny, we should embrace it, even
    if fewer of us do the work."
  tags: []
  title: 'Opinion: Only Bad Writers Should Fear ChatGPT'
- !!python/object:ai_sentiment.data.ClassificationTarget
  body: "The startup behind the viral chatbot ChatGPT unveiled a tool for detecting
    text generated by artificial intelligence\_amid growing concerns\_the technology
    will be abused by cheaters, spammers and others. But OpenAI said its so-called
    AI classifier itself fails to detect\_bot-written text\_nearly three quarters
    of the time. The San Francisco-based startup, which launched ChatGPT in November
    and recently announced a multiyear, multibillion-dollar partnership with\_Microsoft\_Corp.,
    released the detection tool on Tuesday. It said in a blog post that the tool was
    designed to help people distinguish between text written by a human versus a range
    of artificial intelligence programs\u2014not just ChatGPT. OpenAI said that in
    evaluations its new tool correctly identified 26% of AI-written text as \u201Clikely
    AI-written.\u201D It said the classifier also had false positives 9% of the time
    in which it incorrectly labeled human-written text as AI-written. \u201COur classifier
    is not reliable,\u201D the company said, referring to it as a \u201Cwork-in-progress.\u201D
    The tool isn\u2019t good enough on its own, though it can be used to complement
    methods that educators, employers and others rely on to determine the source of
    a piece of text, OpenAI said. \u201CWhile it is impossible to reliably detect
    all AI-written text, we believe good classifiers can inform mitigations for false
    claims that AI-generated text was written by a human,\u201D the company said.
    ChatGPT became a viral sensation due to its ability to produce human-sounding
    essays, poetry, screenplays and sales pitches on virtually any subject in seconds.
    Microsoft invested in OpenAI in 2019 and 2021 before announcing the\_major expansion
    of their partnership\_last week, and has said it plans to integrate the company\u2019s
    technology into many of its products. Soon after ChatGPT was released, the potential
    for it to be misused to do things such as spread misinformation and write spam
    became apparent. Schools and educators also have warned of the potential for students
    to use it to write essays or other work they have been assigned. In December,
    the software passed all three parts of the U.S. Medical Licensing Examination
    as part of a research experiment. Some schools\_have moved to ban students from
    using ChatGPT, while others are attempting to embrace it. Edward Tian, a Princeton
    University senior, created software called GPTZero to try to recognize writing
    generated by the software. OpenAI said it had schools in mind when developing
    its latest classifier tool. \u201CWe recognize that identifying AI-written text
    has been an important point of discussion among educators, and equally important
    is recognizing the limits and impacts of AI-generated text classifiers in the
    classroom,\u201D it said. Journalists, researchers and others can also use the
    tool to detect AI-generated content, the company said. OpenAI said ChatGPT is
    still unreliable on short texts and longer texts are sometimes labeled incorrectly.
    It performs \u201Csignificantly worse\u201D in languages other than English and
    is \u201Cunreliable\u201D in detecting AI use in computer code. Another problem
    is that the tool can\u2019t easily tell if a list of facts\u2014U.S. state capitals
    for example\u2014was written by a person or AI, because the correct answer would
    be the same, OpenAIsaid. AI-written text can also be edited to evade the classifier,
    the company said. These kinds of caveats raise questions about just how beneficial
    the tool can be, the company said. \u201CClassifiers like ours can be updated
    and retrained based on successful attacks,\u201D OpenAI said. \u201CBut it is
    unclear whether detection has an advantage in the long-term.\u201D With feedback
    from users, OpenAI hopes to improve the tool. It said it has reached out to U.S.
    educators to discuss ChatGPT\u2019s capabilities and limitations. \u201CThese
    are important conversations to have as part of our mission is to deploy large
    language models safely, in direct contact with affected communities,\u201D the
    company said."
  tags: []
  title: "ChatGPT Creator Releases Tool to Detect AI-Generated Text, Calls It \u2018Unreliable\u2019"
- !!python/object:ai_sentiment.data.ClassificationTarget
  body: "As the breakout success of\_OpenAI\u2019s\_ChatGPT triggers a tsunami of
    excitement over artificial intelligence,\_Microsoft\_Corp. is positioning itself
    at the forefront of what some see as the next wave of technological innovation.
    The challenge for Microsoft and other companies: turning this novel and still
    imperfect technology into a big business. The software company said last week
    that it was pouring\_billions of dollars more\_into OpenAI. The startup is in
    the limelight as tech executives and the public have been mesmerized by its chatbot,
    which can answer difficult questions, write book reports and compose poetry in
    seconds. Microsoft earlier this month moved to jump-start the adoption of the
    technology by offering to let any company apply to use it through its\_Azure cloud-computing
    platform. \u201CThe age of AI is upon us, and Microsoft is powering it,\u201D
    Chief Executive\_Satya Nadella\_said on a call with analysts last week. Most interactions
    with generative AI\u2014so called because it can work off regular language prompts
    to generate unique creations\u2014have been for fun. Millions have flocked to
    ChatGPT since it was released in November. OpenAI\u2019s other viral hit, the
    image-generating Dall-E 2, has flooded the web with user-created pictures. As
    a disruptive business, ChatGPT is still finding its feet. There are many problems
    with it, according to AI researchers. ChatGPT is expensive to run and slow, and
    it sometimes produces responses that contain made-up facts, they have said. Gary
    Marcus, a founder of the machine-learning startup\_Geometric Intelligence, said
    that even as OpenAI releases updated versions of GPT, the problems with inaccurate
    information will continue. \u201CThis particular tech will not solve those problems,
    so what can you do with these systems that aren\u2019t truthful?\u201D Mr. Marcus
    asked. OpenAI didn\u2019t respond to a request for comment. Its chief executive
    officer,\_Sam Altman, has said that ChatGPT is an imperfect technology and that
    it would improve. He said in a\_tweet last month: \u201Cit\u2019s a mistake to
    be relying on it for anything important right now. it\u2019s a preview of progress;
    we have lots of work to do on robustness and truthfulness.\u201D Microsoft declined
    to comment on concerns about the technology. Mr. Nadella has said that ChatGPT\u2019s
    problems are solvable. \u201CThis is not new to just AI,\u201D he said at a Wall
    Street Journal panel at the 2023 World Economic Forum event in Davos, Switzerland,
    this month. \u201CIt\u2019s true in any other category of software today.\u201D
    Last year Microsoft released GitHub Copilot, a tool within its code-collaboration
    site GitHub. It uses OpenAI tools to help programmers write and fix computer code.
    Microsoft estimates that in files in which it is enabled, Copilot generates 40%
    of the code. Many programmers have said it has become an invaluable tool. It is
    a prime example of how this type of AI is best when paired with professionals
    for specialized tasks, according to some AI users. They have said that the recent
    advances the technology has made in a short time show how remaining problems can
    quickly be fixed. \u201CThe rate of change going on\u2014I have not seen anything
    progress as fast as this ever,\u201D said\_Ben Firshman, the co-founder of the
    AI infrastructure startup Replicate. Mr. Nadella has been hailing the technology
    as the next disruptive advancement in the tech industry. He talks about infusing
    OpenAI\u2019s innovations throughout Microsoft\u2019s products. The company is
    already integrating OpenAI\u2019s tech into its Bing search engine and graphical-design
    software, such as Microsoft Designer. Some analysts speculate that AI-powered
    searches could eventually help Microsoft\u2019s Bing search engine take market
    share away from\_Alphabet\_Inc.\u2019s Google, which\_controls around 90% of the
    market. ChatGPT, OpenAI\u2019s new artificially intelligent chatbot, can write
    essays on complex topics. WSJ\u2019s Joanna Stern went back to high school AP
    Literature for a day to see if she could pass the class using just AI. Photo illustration:
    Elena Scotti \u201CIf it makes Microsoft a competitive search engine, then we\u2019re
    looking at a different business,\u201D said\_Rishi Jaluria, an analyst for RBC
    Capital Markets. Google was the\_pioneer of some of the generative AI, but its
    tools haven\u2019t been as widely open to the public. It is now\_trying to play\_catch-up.
    The more immediate benefit to Microsoft might be to its\_Azure cloud-computing
    business. As more companies use generative AI, Microsoft can market Azure as the
    platform best suited for the job. \u201CThe way Microsoft is going to really commercialize
    all of this is Azure,\u201D Mr. Nadella said in Davos, adding that the company\u2019s
    cloud \u201Chas become the place for anybody and everybody who thinks about AI.\u201D
    Meta Platforms\_Inc. and\_Salesforce\_Inc. are developing AI tools. Smaller companies
    are experimenting with OpenAI\u2019s technology to create products and services
    on Microsoft\u2019s cloud. Microsoft said 200 customers have signed up to use
    OpenAI\u2019s tools since it opened up the technology for broader use recently.
    Yoodli, a Seattle-based company that makes speech-coaching software, was an early
    adopter. It uses a predecessor to ChatGPT, called GPT-3, to analyze a speaker\u2019s
    words to determine whether they ramble off topic. CEO\_Varun Puri\_said adding
    OpenAI\u2019s generative AI tech to Yoodli\u2019s own programs made its offering
    more robust and allowed it to build new features faster. \u201COur idea was always
    an AI-powered speech coach,\u201D he said. \u201CWe were going to do it largely
    [on our own] data set. But generative AI has 100xed that.\u201D Since OpenAI released
    GPT-3 in a limited fashion in 2020, startups have been using the technology. Founders
    who have used it have said it can be useful and problematic. Some worry about
    flaws in the technology, such as \u201Challucinations,\u201D in which it generates
    false results with confidence. That has consigned the technology as more of an
    add-on feature than a core product. AI-enabled features are often pitched as assistants
    for professionals. The startup Lexion uses GPT-3 to help customers draft and amend
    legal documents. The company\u2019s founders said the product is best used to
    assist an attorney rather than replacing one. The software generates contractual
    language that is sometimes wrong, an unacceptable glitch that means it has to
    be cross-checked. \u201CWe don\u2019t have a good explanation or understanding
    of why it produced an output or how it produced an output,\u201D said\_Gaurav
    Oberoi, Lexion\u2019s CEO. \u201CThis is the problem with hallucinations.\u201D
    Because of the limitations of the tech, it is best described as doing the work
    of a legal intern, he said."
  tags: []
  title: "ChatGPT Spotlights Microsoft\u2019s Bid to Monetize AI"
- !!python/object:ai_sentiment.data.ClassificationTarget
  body: "BuzzFeed\_Inc. said it would rely on ChatGPT creator OpenAI to enhance its
    quizzes and personalize some content for its audiences, becoming the latest digital
    publisher to embrace artificial intelligence. In a memo to staff sent Thursday
    morning, which was reviewed by The Wall Street Journal, Chief Executive\_Jonah
    Peretti\_said he intends for AI to play a larger role in the company\u2019s editorial
    and business operations this year. In one instance, the company said new AI-powered
    quizzes would produce individual results. For example, a quiz to create a personal
    romantic comedy movie pitch might ask questions like, \u201CPick a trope for your
    rom-com,\u201D and \u201CTell us an endearing flaw you have.\u201D The quiz would
    produce a unique, shareable write-up based on the individual\u2019s responses,
    BuzzFeed said. Mr. Peretti expects AI to assist the creative process and enhance
    the company\u2019s content, while humans play the role of providing ideas, \u201Ccultural
    currency,\u201D and \u201Cinspired prompts,\u201D he wrote in his memo. In 15
    years, he wrote, he expects AI and data to help \u201Ccreate, personalize, and
    animate the content itself,\u201D rather than just curate existing content. BuzzFeed,
    which went public in late 2021 through a merger with a special-purpose acquisition
    company, last year moved to shrink its news division as it sought to make the
    business profitable, and said it would be doubling its creator network. The company\_is
    getting paid millions of dollars\_by Facebook parent\_Meta Platforms\_Inc. to
    help generate creator content for Facebook and Instagram, The Wall Street Journal
    reported Wednesday. BuzzFeed shares more than doubled\_in value Thursday, closing
    at $2.09. The stock remains down by over 75% since the company went public. BuzzFeed
    remains focused on human-generated journalism in its newsroom, a spokeswoman said
    Thursday. After receiving Mr. Peretti\u2019s memo, a number of employees on Thursday
    expressed concerns and asked him questions on Slack about the implications of
    the move. One staff member asked how Mr. Peretti planned to circumvent \u201Cinevitable
    legal issues\u201D around visual work created by illustrators, photographers and
    art directors at the company, as well as content that is protected by U.S. copyright,
    according to screenshots of the Slack channel that were reviewed by the Journal.
    \u201CWe\u2019ve done experimentation in the past with AI-generative images, and
    we recognize these concerns and take them seriously,\u201D Mr. Peretti wrote in
    response, according to the BuzzFeed spokeswoman. He also said the initial step
    in BuzzFeed\u2019s plan was to use AI for text-based products. ChatGPT, OpenAI\u2019s
    new artificially intelligent chatbot, can write essays on complex topics. WSJ\u2019s
    Joanna Stern went back to high school AP Literature for a day to see if she could
    pass the class using just AI. Photo illustration: Elena Scotti Other employees
    asked about whether the use of AI technology would lead to a reduction in workforce,
    and expressed concerns around fact-checking AI-generated content. In response,
    Mr. Peretti wrote that the tools are an opportunity to make full-time employees
    more efficient and creative, not a workforce reduction strategy, the spokeswoman
    said. Mr. Peretti also answered staff questions during a companywide meeting earlier
    Thursday, the spokeswoman said. Mr. Peretti told staff during the meeting that
    digital-media companies that choose to rely on AI solely to save costs and produce
    low-quality content were making a terrible use of the technology, according to
    the spokeswoman. That isn\u2019t BuzzFeed\u2019s approach, Mr. Peretti said, noting
    there were far more creative ways to use AI. \u201CI think that news, for good
    reason, is often the most conservative when it comes to adopting new technologies,\u201D
    Mr. Peretti told staff, according to the spokeswoman. BuzzFeed\u2019s move comes
    as ChatGPT,\_new chatbot technology\_from research lab OpenAI, generates buzz
    among consumers and businesses alike. Some publishers have said they are starting
    to discuss using AI technology, while others are already experimenting with it.
    Digital technology publisher CNET, for example, recently ran a test using internally
    designed AI technology to help editors create explainers around financial-services
    topics. CNET\u2019s Editor in Chief Connie Guglielmo this week said the\_publisher
    paused its test, which had led to the publication of 77 stories, after finding
    a number of factual errors. Microsoft\_Corp., which\_has invested billions of
    dollars in OpenAI, plans to incorporate artificial-intelligence tools like ChatGPT
    into all of its products, Chief Executive\_Satya Nadella\_said last week."
  tags: []
  title: BuzzFeed to Use ChatGPT Creator OpenAI to Help Create Some Content
- !!python/object:ai_sentiment.data.ClassificationTarget
  body: "Last month a professor at Weber State University in Utah asked a new artificial-intelligence
    chatbot to write a tweet in his voice. Within a few minutes the application, called
    ChatGPT, had spit out a dozen messages that captured Alex Lawrence\u2019s tone
    and personality. His first reaction: \u201CHoly Cow!\u201D His second: \u201CThis
    is the greatest cheating tool ever invented.\u201D His response reflects a dilemma
    that the powerful AI tool creates for educators: Should they ban ChatGPT or build
    on it? Whichever path they take, some teachers say they are scrambling to update
    curriculum, launch new learning guidelines and deploy tactics that stymie cheating
    and make sure students learn to think for themselves. Dr. Lawrence decided to
    change the curriculum in his sales-technology courses to allow students to use
    a suite of artificial-intelligence tools to complete their assignments. He is
    hoping that embracing the technology will stave off what he thinks is inevitable
    cheating and impart the tech skills students will need to succeed in the labor
    market. \u201CI hope to inspire and educate you enough that you will want to learn
    how to leverage these tools, not just to learn to cheat better,\u201D Prof. Lawrence
    wrote to his students this month. ChatGPT, which uses machine-learning algorithms
    to produce human-sounding prose, launched on Nov. 30. It is free to use and can
    deliver a written answer on virtually any subject from nearly any perspective
    in just 15 seconds. In December it passed all three parts of the U.S. Medical
    Licensing Examination as part of a\_research experiment. OpenAI, the research
    lab\_behind ChatGPT, is in talks to\_sell existing shares\_in a tender offer that
    would value the company at around $29 billion, making it one of the\_most valuable
    U.S. startups\_on paper, despite generating little revenue. On Monday\_Microsoft\_Corp.
    said it is\_making a multiyear, multibillion-dollar investment\_in OpenAI, as
    it looks to\_expand the use of artificial intelligence\_in its products. \u201CIt
    really seems to change the nature of knowledge production itself,\u201D said Anand
    Rao, chair of the department of communications and digital studies at the University
    of Mary Washington in Virginia. Educational institutions that are banning ChatGPT
    include some large public-school districts.\_New York, Seattle and Los Angeles
    have all blocked the service from their networks. Some college and university
    professors, meanwhile, have tried to wall off their classrooms by requiring students
    to write essays longhand in blue books in class. Others are running essay prompts
    through ChatGPT to familiarize themselves with how the bot answers so\_they can
    spot plagiarism. Edward Tian, a Princeton University senior, created GPTZero to
    recognize writing generated by ChatGPT. He now has 23,000 teachers on a waiting
    list for the next version. Some students are also concerned. This month a survey
    of 1,000 students age 18 or older\_by online course provider Study.com\_found
    that nearly three quarters want ChatGPT banned from their school\u2019s network.
    But 48% admitted using it to complete an at-home test or quiz, 53% to write an
    essay and 22% to write an outline for a paper. Students need to learn to write
    well for themselves because the writing process teaches them to think critically,
    said Johann Neem, a history professor at Western Washington University and the
    author of \u201CWhat\u2019s the Point of College?\u201D \u201CJust because there
    is a machine that will help me lift up a dumbbell doesn\u2019t mean my muscles
    will develop,\u201D said Dr. Neem. \u201CIn the same way just because there is
    a machine that can write an essay doesn\u2019t mean my mind will develop.\u201D
    Artificial intelligence is likely to have some impact on how students write, according
    to John Gallagher, a professor in the English department at the University of
    Illinois. When word processors replaced typewriters, written sentences got longer
    and more complicated, he said. Dr. Gallagher ran a three-month experiment on himself
    in the fall, using artificial intelligence for almost everything he wrote. He
    found it inconsistent\u2014but also so helpful he became reliant on it. \u201CIt
    can become a crutch,\u201D he said. \u201CYou stop working through things.\u201D
    The new technology comes at a vulnerable time for students:\_Numeracy and literacy
    have declined\_and cheating has jumped. While the pandemic was raging and U.S.
    schools operated remotely, plagiarism appeared in nearly 50% of all academic submissions,
    compared with 35% before the pandemic, according to Copyleaks, Inc. which sells
    tools to detect plagiarism and artificial intelligence. During the second week
    of January, a sampling of papers from all grade levels from around the world revealed
    that 10% had used ChatGPT, said Copyleaks CEO Alon Yamin. Teachers who are leaning
    into the new technology compare it to a new power tool. You could build a house
    without using power tools, but why would you? asks David Chrisinger, who directs
    the writing program at the Harris School of Public Policy at the University of
    Chicago. He is asking his students to generate a 600-word essay using ChatGPT.
    Then their assignment is to think of more incisive questions to elicit a stronger
    response. Finally, they are required to edit the essay for tone and voice and
    to tailor it to the intended audience. ChatGPT can create David, said Prof. Chrisinger,
    referring to the famous Michelangelo statue. \u201CBut his head is too big and
    his legs are too short. Now it\u2019s our job to interrogate the evidence and
    improve on what it gives us,\u201D he said. Ethan Mollick, a professor at the
    University of Pennsylvania\u2019s Wharton School of Business who teaches entrepreneurship
    and innovation, believes ChatGPT can be leveraged to teach higher-order thinking
    skills. He is teaching his students how to ask the tool the most astute question,
    then deconstruct, fact-check and improve the answer. \u201CThe English majors
    are programmers now,\u201D he said. Prof. Mollick said ChatGPT has already changed
    his expectations of his students. \u201CI expect them to write more and expect
    them to write better,\u201D he said. \u201CThis is a force multiplier for writing.
    I expect them to use it.\u201D"
  tags: []
  title: Professors Turn to ChatGPT to Teach Students a Lesson
- !!python/object:ai_sentiment.data.ClassificationTarget
  body: "Businesses hope the artificial-intelligence technology behind ChatGPT can
    turn ordinary chatbots into impressive fonts of information, potentially transforming
    customer service. But many executives said they are proceeding with caution, given
    the limitations of ChatGPT\u2014fine-tuned from GPT-3.5, a model created by startup
    OpenAI\u2014as well as OpenAI\u2019s older AI language system, GPT-3, which companies
    are already starting to integrate into digital products. ChatGPT, launched by
    OpenAI in November, quickly went viral for its often elegant, information-packed
    responses to various questions, gripping the imaginations of regular people, business
    leaders and investors including Microsoft Corp., which began backing OpenAI in
    2019 and said Monday that it would make a multibillion-dollar investment in the
    startup. OpenAI last week said it would soon add ChatGPT, which stands for chat
    generative pre-trained transformer, to its application programming interface,
    or API, which lets developers embed OpenAI technology into their own products.
    But customer-experience executives said overreliance on such AI models could lead
    to companies dishing out incorrect information to customers online without knowing
    they are doing so. While many chatbots are trained to deliver a version of \u201CI
    don\u2019t know\u201D to requests they cannot compute, ChatGPT, for example, is
    more likely to spout off a response with complete confidence\u2014even if the
    information is wrong. \u201CWe don\u2019t want to be in the bad answer business,\u201D
    said John Willcutts, vice president and general manager of digital at Nice Ltd.,
    a customer-experience software company. \u201CA really bad answer in a very critical
    situation would be a very real problem.\u201D Sam Altman, chief executive of OpenAI,
    has warned against relying on ChatGPT \u201Cfor anything important right now.\u201D
    \u201CFun creative inspiration; great! Reliance for factual queries; not such
    a good idea,\u201D Mr. Altman wrote in a tweet last month. Using AI to write chat
    responses in sensitive situations has backfired. Koko, a chat app used for emotional
    support, this month was criticized for an experiment in which human volunteers
    crafted their responses to the app\u2019s users with the help of GPT-3. Koko\u2019s
    co-founder said in a tweet that the startup pulled the AI from its system: \u201COnce
    people learned the messages were co-created by a machine, it didn\u2019t work.
    Simulated empathy feels weird, empty.\u201D But for a more typical customer-service
    interaction, such as querying the status of an online order or editing account
    details, the technology could prove useful. Fanatics Inc., a seller of sports
    memorabilia, digital collectibles and trading cards, said it plans to use a customer-service
    chatbot fueled in part by GPT-3 when it launches an online sports-gambling division
    this year. The company hopes a fast, reliable chatbot will be a differentiator
    for customers, said Hollis Donaldson, vice president of operations for the new
    division. \u201CSpeed equates to great customer experience in the betting and
    gaming industry,\u201D he said. Fanatics\u2019 customer-experience team is testing
    the chatbot before making it live, conscious of the risks using AI carries if
    not properly managed, Mr. Donaldson said. Chasing the dream Companies for decades
    have searched for automated solutions that can resolve customer requests as well
    as humans, or even better. But chatbots are often seen as clunky and not very
    helpful. \u201CThere was a lot of hype around chatbots, probably five, six years
    ago, and a lot of vendors wanted to make people believe that it was magical, that
    it worked out of the box, that it was easy,\u201D said Yves Normandin, vice president
    of AI technologies and products at Waterfield Technologies, a contact-center solutions
    provider owned by WTI Holdings LLC. \u201CBut the reality is that it wasn\u2019t.\u201C
    ChatGPT stands out for its ability to provide reasonable-sounding answers to most
    prompts, regardless of users\u2019 spelling, grammar and phrasing, and to respond
    in full, natural-sounding sentences that don\u2019t require scripting, said David
    Truog, a principal analyst specializing in technology and design at Forrester
    Research Inc. It is also trained to admit to mistakes, challenge incorrect premises
    and reject inappropriate requests, according to OpenAI. But companies should exercise
    care when dealing with the new AI, Mr. Truog said. \u201CIt\u2019s appropriate
    to be doing some experimentation,\u201D he said, \u201Cbut it\u2019s too early
    to deploy mission-critical systems based on this.\u201D Putting it into practice
    Fanatics said its sportsbook\u2019s chatbot will run on technology from Ada Support
    Inc., a customer-service automation platform. Ada has integrated GPT-3 and other
    such AI systems known as large language models into its chatbot offering, according
    to the company\u2019s co-founder and chief executive, Mike Murchison. Mr. Murchison
    said Ada allows clients to customize these large language models by adding company-specific
    information or anonymized customer data, and deleting irrelevant material. Ada
    encourages clients to continually update their customized bots\u2019 information,
    for instance when prices or company policies change, he said. \u201CMost brands
    are going to underestimate the importance of continuously improving this over
    time,\u201D Mr. Murchison said. Some Ada clients are restructuring their customer-service
    organizations to put some contact-center workers in charge of monitoring chatbot
    conversations, reviewing where the technology gets things wrong or can\u2019t
    answer, and feeding it new or updated information, he said. Fanatics plans to
    follow that approach, as well as ensure that its chatbot interface lets customers
    reach a human right away, Mr. Donaldson said. Nice is also working on building
    OpenAI\u2019s language models into chatbots, Mr. Willcutts said, adding that the
    company plans to run more tests and fine-tune more models before selling its own
    take on ChatGPT to clients. \u201CWe don\u2019t get a chance to make a second
    impression on this one,\u201D he said. \u201CYou do this badly once and it\u2019s
    in the newspaper, and that\u2019s not the kind of reputational risk we\u2019re
    prepared to take.\u201D"
  tags: []
  title: Companies Tap Tech Behind ChatGPT to Make Customer-Service Chatbots Smarter
- !!python/object:ai_sentiment.data.ClassificationTarget
  body: "Microsoft\_Corp. said Monday it is making a multiyear, multibillion-dollar
    investment in OpenAI, substantially bolstering its\_relationship with the startup\_behind
    the viral ChatGPT chatbot as the software giant looks to expand the use of\_artificial
    intelligence\_in its products. Microsoft said the latest partnership builds upon
    the company\u2019s 2019 and 2021 investments in OpenAI. The companies didn\u2019t
    disclose the financial terms of the partnership. Microsoft had been discussing
    investing as much as $10 billion in OpenAI, according to people familiar with
    the matter. A representative for Microsoft declined to comment on the final number.
    OpenAI\_was in talks this month\_to sell existing shares in a tender offer that
    would value the company at roughly $29 billion, The Wall Street Journal reported,
    making it one of the most valuable U.S. startups on paper despite generating little
    revenue. The investment shows the\_tremendous resources\_Microsoft is devoting
    toward incorporating artificial-intelligence software into its suite of products,
    ranging from its design app Microsoft Designer to search app Bing. It also will
    help bankroll the computing power OpenAI needs to run its various products on
    Microsoft\u2019s Azure cloud platform. The strengthening relationship with OpenAI\_has
    bolstered Microsoft\u2019s standing\_in a race with other big tech companies that
    also have been pouring resources into artificial intelligence to enhance existing
    products and develop new uses for businesses and consumers.\_Alphabet\_Inc.\u2019s
    Google, in particular, has invested heavily in AI and infused the technology into
    its operations in various ways, from improving navigation recommendations in its
    maps tools to enhancing image recognition for photos to enabling wording suggestions
    in Gmail. At a WSJ panel during the 2023 World Economic Forum, Microsoft CEO Satya
    Nadella discussed the company expanding access to OpenAI tools and the growing
    capabilities of ChatGPT. Google has its own sophisticated chatbot technology,
    known as LaMDA, which gained notice last year when one of the company\u2019s engineers\_claimed
    the bot was sentient, a claim Google and outside experts dismissed. Google, though,
    hasn\u2019t made that technology widely available like OpenAI did with ChatGPT,
    whose ability to churn out human-like, sophisticated responses to all manner of
    linguistic prompts has captured public attention. Microsoft Chief Executive\_Satya
    Nadella\_said last week his company plans to incorporate artificial-intelligence
    tools into all of its products and make them available as platforms for other
    businesses to build on. Mr. Nadella said that his company would move quickly to
    commercialize tools from OpenAI. Analysts have said that OpenAI\u2019s technology
    could one day threaten Google\u2019s stranglehold on internet search, by providing
    quick, direct responses to queries rather than lists of links. Others have pointed
    out that the chatbot technology still suffers from inaccuracies and isn\u2019t
    well-suited to certain types of queries. \u201CThe viral launch of ChatGPT has
    caused some investors to question whether this poses a new disruption threat to
    Google Search,\u201D Morgan Stanley analysts wrote in a note last month. \u201CWhile
    we believe the near-term risk is limited\u2014we believe the use case of search
    (and paid search) is different than AI-driven content creation\u2014we are not
    dismissive of threats from new, unique consumer offerings.\u201D OpenAI, led by
    technology investor\_Sam Altman, began as\_a nonprofit in 2015\_with $1 billion
    in pledges from\_Tesla\_Inc. CEO\_Elon Musk, LinkedIn co-founder\_Reid Hoffman\_and
    other backers. Its goal has long been to develop technology that can achieve what
    has been a holy grail for AI researchers:\_artificial general intelligence, where
    machines are able to learn and understand anything humans can. Microsoft first
    invested in OpenAI in 2019, giving the company $1 billion to enhance its Azure
    cloud-computing platform. That gave OpenAI the computing resources it needed to
    train and improve its artificial-intelligence algorithms and led to a series of
    breakthroughs. OpenAI has released a new suite of products in recent months that
    industry observers say represent a significant step toward that goal and could
    pave the way for a host of new AI-driven consumer applications. In the fall, it
    launched Dall-E 2, a project that allowed users to generate art from strings of
    text, and then made ChatGPT public on Nov. 30. ChatGPT has become something of
    a\_sensation among the tech community\_given its ability to deliver immediate
    answers to questions ranging from \u201CWho was George Washington Carver?\u201D
    to \u201CWrite a movie script of a taco fighting a hot dog on the beach.\u201D
    Mr. Altman said the company\u2019s tools could transform technology similar to
    the invention of the smartphone and tackle broader scientific challenges. \u201CThey
    are incredibly embryonic right now, but as they develop, the creativity boost
    and new superpowers we get\u2014none of us will want to go back,\u201D Mr. Altman
    said in an interview in December. Mr. Altman\u2019s decision to create a for-profit
    arm of OpenAI garnered criticism from some in the artificial-intelligence community
    who said it represented a move away from OpenAI\u2019s roots as a research lab
    that sought to benefit humanity over shareholders. OpenAI said it would cap profit
    at the company, diverting the remainder to the nonprofit group."
  tags: []
  title: Microsoft to Invest Billions in ChatGPT Creator
- !!python/object:ai_sentiment.data.ClassificationTarget
  body: "New York City public schools banned access to ChatGPT, an artificial-intelligence
    chatbot, on its internet networks and school devices after officials raised concerns
    that\_students could use the AI program\_to answer questions, do homework or write
    essays. ChatGPT quickly\_drew attention\_from the public and students after its
    November release, with some industry observers calling it one of the most intelligent
    AI applications ever created. The program crossed a million users a few days after
    its launch. And its popularity has been a boon to\_its developer, OpenAI, which
    the Journal reported this week is\_in talks to sell shares\_at a $29 billion valuation.
    That would make it one of the most valuable U.S. startups, on paper. ChatGPT could
    upend entire industries and schools by automating certain jobs or offering intelligent
    answers to almost any question. Many students have delighted in it, while teachers
    have panicked. The chatbot\u2019s answers are often so colloquial that it can
    be difficult for teachers to know if a student has used the program to cheat.
    But the chatbot doesn\u2019t always provide accurate information. New York City\u2019s
    Department of Education, which runs the largest school district in the country,
    said this week that it had \u201Cconcerns about negative impacts on student learning,
    and concerns regarding the safety and accuracy of content.\u201D \u201CWhile the
    tool may be able to provide quick and easy answers to questions, it does not build
    critical-thinking and problem-solving skills, which are essential for academic
    and lifelong success,\u201D said\_Jenna Lyle, a spokeswoman for the department.
    An OpenAI spokeswoman said the company was developing measures to help people
    identify text generated by ChatGPT. \u201CWe don\u2019t want ChatGPT to be used
    for misleading purposes in schools or anywhere else,\u201D she said. ChatGPT has
    raised concerns in schools. Students could ask the chatbot to write code or\_craft
    prose about any topic, like equating the movie \u201CFerris Bueller\u2019s Day
    Off\u201D to an existentialist text. New York City\u2019s education department
    appears to be the only one in the U.S. to restrict access to the program. Educators
    have said that while ChatGPT could help students cheat, it could also be used
    as a search engine to help them learn new information. ChatGPT has been banned
    from other places. Stack Overflow, an online community for software developers,
    has\_temporarily banned users\_from posting any text or code generated by ChatGPT.
    One of the world\u2019s largest machine learning conferences, the International
    Conference on Machine Learning, has\_banned papers\_written using the program.
    The restrictions may be hard to enforce in New York City schools. Education officials
    can\u2019t stop students\u2014or teachers\u2014from opening the chatbot on Wi-Fi
    networks or devices that aren\u2019t affiliated with their schools. They could
    also potentially use their cellular network on campus to access ChatGPT. New York
    City\u2019s education department said this week that individual schools could
    request that the department grant access to ChatGPT. Chalkbeat, an education news
    site, earlier reported the ban. OpenAI released ChatGPT at a challenging time
    for U.S. public education. U.S. public schools have\_lost more than a million
    students\_since the pandemic began, forcing some districts to close underused
    schools. School officials blamed the enrollment decline on falling birthrates,
    a rise in home schooling and growing competition from private and charter schools."
  tags: []
  title: New York City Bans ChatGPT in Schools Over Cheating Concerns
- !!python/object:ai_sentiment.data.ClassificationTarget
  body: "OpenAI, the research lab behind the viral\_ChatGPT chatbot, is in talks to
    sell existing shares in a tender offer that would value the company at around
    $29 billion, according to people familiar with the matter, making it one of the
    most valuable\_U.S. startups\_on paper despite generating little revenue. Venture-capital
    firms\_Thrive Capital\_and\_Founders Fund\_are in talks to buy shares, the people
    said. The tender could total at least $300 million in OpenAI share sales, they
    said. The deal is structured as a tender offer, with the investors buying shares
    from existing shareholders such as employees, the people said. The new deal would
    roughly double OpenAI\u2019s valuation from a prior tender offer completed in
    2021, when OpenAI was valued at about $14 billion, The Wall Street Journal reported.
    OpenAI has generated tens of millions of dollars in revenue, in part from selling
    its AI software to developers, but some investors have expressed skepticism that
    the company can generate meaningful revenue from the technology. No final deal
    has been reached and terms could change, the people said. OpenAI declined to comment.
    OpenAI released a series of artificial intelligence-based products last year that
    captured the public\u2019s attention, including the\_image-generation program
    Dall-E 2\_and chatbot ChatGPT. If the tender goes through at that valuation, OpenAI
    would be one of the few startups able to raise money at higher valuations in the
    private market, where\_investors have pulled back\_from new deals given last year\u2019s
    technology rout. Microsoft\_Corp. has also been in advanced talks\_to increase
    its investment in OpenAI, the Journal reported. In 2019,\_Microsoft invested\_$1
    billion in OpenAI and became its\_preferred partner\_for commercializing new technologies
    for services like search engine Bing and design app Microsoft Design. OpenAI,
    led by technology investor\_Sam Altman,\_was founded as a nonprofit in 2015\_with
    the goal of pursuing artificial-intelligence research for the benefit of humanity.
    Its initial backers included\_Tesla\_Inc. Chief Executive\_Elon Musk, LinkedIn
    co-founder\_Reid Hoffman\_and Mr. Altman. Under Mr. Altman, OpenAI created a for-profit
    arm in 2019 so it could more easily raise money to fund the computing power needed
    to train its algorithms. It took a quicker approach to releasing its AI models
    to the public than larger competitors like\_Alphabet\_Inc.\u2019s Google, which
    has been slower to publicize its technology in part due to ethical concerns. ChatGPT,
    the chatbot where users get intelligent responses for queries such as \u201Cdescribe
    a debate between two college students about the value of a liberal arts education,\u201D
    crossed one million users a few days after its Nov. 30 launch, according to a
    tweet from Mr. Altman. Some industry observers have lauded the tool as a major
    technological breakthrough and a potential alternative to current search engines
    down the road, though Mr. Altman has acknowledged that the program\u2019s outputs
    often contained factual errors. OpenAI hopes to one day achieve what AI researchers
    call \u201Cartificial general intelligence,\u201D or technology that can fully
    mirror the intelligence and capabilities of humans. In a December interview with
    the Journal, Mr. Altman said OpenAI\u2019s tools could transform technology similar
    to the invention of the smartphone and tackle larger scientific challenges. Mr.
    Altman said at the time that OpenAI has no plans to get acquired or go public,
    meaning investors would likely only be able to cash out through secondary share
    sales. Mr. Altman has recently told investors that the company would soon be able
    to generate up to $1 billion in annual revenue in part by charging consumers and
    businesses for its products, the Journal has reported. Prior investors in OpenAI
    include Khosla Ventures and hedge fund Tiger Global Management, according to people
    familiar with the matter. The company has limited some venture investors\u2019
    profits to about 20 times their investments, with the ability to earn greater
    returns the longer they wait to sell their shares, the Journal previously reported.
    OpenAI has said such capped investment structures were necessary to ensure that
    the value from OpenAI accrued not only to investors and employees, but also to
    humanity more generally."
  tags: []
  title: ChatGPT Creator Is Talking to Investors About Selling Shares at $29 Billion
    Valuation
- !!python/object:ai_sentiment.data.ClassificationTarget
  body: "Bold Ideas Aren\u2019t Conventional With the invention of the camera, artists
    could create images without learning how to draw or paint. Yet two centuries later,
    society continues to value hand-crafted illustrations and paintings as treasured
    art. There is meaning in brush strokes and expression in hard work. For similar
    reasons, ChatGPT won\u2019t replace human essayists. ChatGPT is extraordinary,
    but its responses are algorithmic. Already, plagiarism-detection services are
    adding features to detect AI-generated text. Educators may closely scrutinize
    students\u2019 submitted work for signs of AI support, or conversely might embrace
    AI as a tool to assist students\u2019 writing. But ultimately, ChatGPT won\u2019t
    supplant educators\u2019 focus on cultivating the writing abilities of their students.
    Nor should ChatGPT supplant this focus. Even if the program\u2019s responses were
    truly indistinguishable from a student\u2019s, there is value in learning how
    to write. Individuals should trust their own ideas, not those collected and generated
    by a computer. Bold ideas are bold precisely because they are unconventional.
    They run counter to society\u2019s accepted knowledge. Perhaps ChatGPT will have
    its impact on education by motivating educators to emphasize to their students
    the importance of self-determination. \u2014Ted Steinmeyer, Harvard University,
    J.D. The New Google The release of ChatGPT came at a serendipitous time, right
    when college students were studying for final exams or turning in final essays.
    I have seen the AI write love poems, give a detailed summary of an excerpt, write
    full sets of code, and even draw up a nondisclosure agreement. These new tools
    might become the new Google. If the databases are constantly being updated with
    current news and information, as well as connected to the internet, we could use
    AI to learn and solve problems in daily life. When I went to look up an advanced
    organometallic chemistry topic, ChatGPT gave a better summary than Google. College
    professors will have to determine how they want to proceed and if they need to
    have in-person final essays without technology. But without technology in the
    classroom, will teaching regress? \u2014Therese Joffre, Hope College, chemistry
    Don\u2019t Forget the Basics AI tools such as ChatGPT can help users achieve specific
    goals. There is always concern about new technology and the resulting potential
    paradigmatic shifts. But history will remind us that it\u2019s important to acknowledge
    these technological developments and educate about the strengths and weaknesses
    of these tools. It\u2019s equally important, however, not to forget the basics.
    ChatGPT can\u2019t replace reasoning or critical thinking. While AI tools can
    make essays read better, they can\u2019t replace knowing how to form thoughts
    into careful arguments. The most significant challenge for future educators is
    finding out how best to develop and assess those skills. \u2014Daniel Pham, University
    of Oklahoma, medicine Medieval Lessons Live cameras, screen recordings and antiplagiarism
    software are all too familiar to the current university student. As technology
    advances, such defenses will continue to be deployed against the illicit use of
    new tech in the academy. An unceasing tit-for-tat will ensue between tools such
    as ChatGPT and security measures to curtail academic dishonesty. Educators may
    strive to stay ahead of all such obstacles, but this is a losing battle. There
    is another way: Study with Catholic friars. The friars follow the format of a
    scholastic studium, an educational model that uses formalized arguments as the
    primary method of teaching. Many exams are given orally, a mode that requires
    clear thinking and concise speaking on the part of the student. Papers are not
    submitted but presented to the class. Theses are defended while friars hurl objections
    and counterpoints at the student. In such rhetorical exercises, there is no opportunity
    to hide behind clever AI. Moderns can learn much from medieval ways. \u2014Kayla
    Bartsch, Dominican House of Studies, theology An Auxiliary Resource The ChatGPT
    bot can be used for the benefit of the students, or it can be used to their detriment.
    The outcome will depend on how well faculty can integrate this technology into
    their curricula, as well as the integrity of the students to use it properly.
    The obvious concern is academic fraud. Educators will need to implement new assessment
    methods to mitigate cheating. Written in-class assignments might become more common.
    Instead, students should use AI tools as auxiliary resources. Even if conversational
    AI is only semi-reliable at this point, it can be used to learn about new topics,
    or ask questions outside class. The adjustment period will come as a shock to
    the education system. This is normal for major changes throughout history, such
    as the Gutenberg Press, the internet or the personal computer. We can remain optimistic,
    however, that the good faith of most students and faculty will make this technological
    advancement a net positive. \u2014Rafael Arbex-Murut, University of California,
    Berkeley, information and data science"
  tags: []
  title: "Opinion: How Do Students Feel About OpenAI\u2019s ChatGPT?"
- !!python/object:ai_sentiment.data.ClassificationTarget
  body: "Look, back in high school, I was a pillar of honesty and hard work. No cheating\u2014unless
    you count\_Nintendo\_cheat codes. This month, however, I returned to high school
    a big ol\u2019 cheater. Specifically, a ChatGPT cheater. If you\_haven\u2019t
    yet tried ChatGPT, OpenAI\u2019s new artificial-intelligence chatbot, it will
    blow your mind. Tell the bot to write you anything\u2014an email apologizing to
    your boss, an article about the world\u2019s richest hamster, a \u201CSeinfeld\u201D
    script set in 2022\u2014and it spits out text you\u2019d think was written by
    a human. Knowledge of the topic, proper punctuation, varied sentence structure,
    clear organization. It\u2019s all there. You can also tell it to write a 500-word
    essay about \u201CThe Great Gatsby\u201D or the Spanish Inquisition. So I did
    what any masochistic tech journalist would: I pulled a\_\u201CBilly Madison\u201D\_and
    went back to school. I wanted to test the capabilities\u2014and limits\u2014of
    a technological marvel that stands poised to disrupt how every student in the
    world is tested and how every teacher grades. At first, I thought I\u2019d return
    to the halls and pimples of middle school. But when I sent a ChatGPT-generated
    essay to a seventh-grade writing teacher, she told me she could easily spot the
    fake. The writing and vocabulary were too advanced. So off to 12th-grade AP Lit
    I went. Michael Diamond, an English teacher at High Tech High School in Secaucus,
    N.J., welcomed me\u2014and my AI stand-in. He had already tried out ChatGPT with
    his own essay assignments. So did I get an A? Not exactly. Test 1: Turning In
    the Assignment Here\u2019s a short version of Mr. Diamond\u2019s assignment: \u201CIn
    a 500- to 1,000-word essay, compose an argument that attempts to situate \u2018Ferris
    Bueller\u2019s Day Off\u2019 as an existentialist text. Use specific evidence
    from the class materials, and make explicit comparisons or connections between
    characters, setting and/or themes in both \u2018Ferris Bueller\u2019 and \u2018The
    Metamorphosis\u2019 by Franz Kafka.\u201D The classic 1986 John Hughes movie?
    No problem. I grew up\_singing \u201CTwist and Shout\u201D\_into a hair brush
    and pretending the couch was floating along the Chicago streets. But Franz Kafka\u2019s
    novella about a man who wakes up as a bug? I swatted that away almost immediately.
    I pasted the assignment into chat.openai.com, hit enter and watched the bot type
    out 400 words before giving me a \u201Cnetwork error.\u201D Great, I\u2019m an
    hour from deadline and my AI ghostwriter was napping. An OpenAI spokeswoman said
    the system has been struggling with demand and the company has been working to
    scale it up. Finally, it worked. I pasted the 800-word essay into a document,
    asked ChatGPT how to format a high-school AP paper (double spacing, 12-point Times
    New Roman font, indented paragraphs), put my name on top and emailed it to Mr.
    Diamond. I added a note: \u201CI am writing to apologize for the lateness of my
    essay. I know that you have specific expectations for deadlines and I am sorry
    that I did not meet them.\u201D Of course, the note was by ChatGPT. Mr. Diamond
    wrote back within minutes: \u201CDear Joanna, I wanted to let you know that I
    received your assignment and appreciate you taking the time to complete it. However,
    it was submitted after the due date, and as a result, it will be marked as late.\u201D
    Of course, he also used ChatGPT. Test 2: Writing the Essay I was impressed with
    my essay. It drew parallels between Kafka\u2019s Gregor Samsa and Ferris Bueller.
    The writing was well organized, but without a whiff of robotic precision. (You
    can read\_the full essay here.) As you\u2019ll see in my video, Mr. Diamond was
    less impressed. While he praised my piece for quickly getting to the thesis, the
    opening paragraph had a factual error. I cited Ferris, speaking at the beginning
    of the movie, saying he\u2019s \u201Cnot going to sit on [his] ass as the events
    that affect [him] unfold to determine the course of [his] life.\u201D But that
    quote is from Ferris\u2019s sidekick, Cameron, and it\u2019s spoken at the film\u2019s
    end,\_moments before the famous Ferrari fall. Mr. Diamond spotted other errors.
    My paper said Ferris is reserved and rarely seen next to his peers. (Again, that\u2019s
    Cameron.) It said \u201CThe Metamorphosis\u201D was set in a suburban setting.
    (It\u2019s in an unnamed city.) I got three out of six on the assignment, which
    according to the\_AP rubric, is in the B- to C range. While that\u2019s a passing
    grade, the work certainly didn\u2019t meet my standards. \u201CThe overall quality
    of your writing puts you in the lower 30th percentile of the class,\u201D Mr.
    Diamond told me. \u201CYou may have the mind to get there, but it\u2019s the skills
    that you need to work on.\u201D He said my writing was \u201Cwooden\u201D and
    \u201Clacked verve and voice.\u201D (I might give my real editors very, very many
    reasons to complain\u2014these aren\u2019t among them!) When I asked him if he
    would have suspected this was written by AI, he said he didn\u2019t think so.
    Even though he knows his students\u2019 writing styles, he often plows through
    60 or more essays. One like this\u2014efficient, decently structured, gets to
    the point\u2014might not set off any alarms. Mr. Diamond couldn\u2019t put an
    essay of mine through\_Google\u2019s Classroom\_plagiarism checker because I wasn\u2019t
    a registered student. When I put it through\_Grammarly, a writing tool that helps
    improve grammar and checks for plagiarism, only a few common phrases were flagged
    as suspicious. It really is an original text\u2014just one written by a robot.
    Google Classroom and\_Turnitin, a company that offers plagiarism detection tools
    to schools, use AI to compare a student\u2019s work with their earlier assignments.
    Eric Wang, Turnitin\u2019s vice president of AI, said that could help teachers
    identify new ChatGPT cheaters. He also told me that his company is able to detect
    AI-generated text based on cues that are imperceptible to humans, and that it
    will add an AI writing detection feature in 2023. An OpenAI spokeswoman said the
    ChatGPT maker is also exploring and researching ways to make it easier to spot
    AI writing. Test 3: Participating in Group Discussion The final test: See if ChatGPT
    would allow me to keep up in a group discussion without actually having done the
    reading. In this case, it was Denis Johnson\u2019s short story \u201CCar Crash
    While Hitchhiking,\u201D from the collection \u201CJesus\u2019 Son.\u201D While
    my fellow students immediately jumped into a conversation about the story\u2019s
    characters, ChatGPT left me hanging: \u201CI don\u2019t have any information about
    a book or movie called \u2018Car Crash While Hitchhiking.\u2019\u201D When I searched
    for the book title, the bot gave me some minimally useful information, but got
    a big part wrong: the main character\u2019s name. Finally, a human student gave
    me a clear synopsis. Overall, Mr. Diamond gave me and ChatGPT a C. Even OpenAI\u2019s
    Chief Executive\_Sam Altman\_says\_it\u2019s not reliable for anything important\_right
    now and needs work on its \u201Crobustness and truthfulness.\u201D But the accuracy
    and the data will get better fast, numerous AI experts told me. When that day
    comes, we\u2019ll have the writing equivalent of a scientific calculator. Still,
    it\u2019s unlikely to replace the sometimes grueling, sometimes fun task of putting
    words on paper. \u201CThe winning combo is going to be this artful interaction
    of AI and humans,\u201D\_James Lester, a computer-science professor at North Carolina
    State University who focuses on AI and education, told me. Some of my new high-school
    friends told me they use AI tools such as Grammarly to improve their punctuation
    and word choice. And Mr. Diamond is already thinking about how to work ChatGPT
    into his curriculum. Plus, I used ChatGPT to help generate some ideas for lines
    in this column. There\u2019s just one thing I keep wondering: Could ChatGPT have
    helped Ferris have an even more successful day off? (ChatGPT says yes.)"
  tags: []
  title: ChatGPT Wrote My AP English Essay. I Passed.
- !!python/object:ai_sentiment.data.ClassificationTarget
  body: "ChatGPT,\_the artificial-intelligence program\_captivating Silicon Valley
    with its sophisticated prose, had its origin three years ago, when technology
    investor\_Sam Altman\_became chief executive of the chatbot\u2019s developer,
    OpenAI. Mr. Altman decided at that time to move the OpenAI research lab away from
    its nonprofit roots and turn to a new strategy, as it raced to build software
    that could fully mirror the intelligence and capabilities of humans\u2014what
    AI researchers call \u201Cartificial general intelligence.\u201D Mr. Altman, who
    had built a name as president of famed startup accelerator Y Combinator, would
    oversee the creation of a new for-profit arm, believing\_OpenAI needed to become
    an aggressive fundraiser\_to meet its founding mission. Since then, OpenAI has
    landed deep-pocketed partners like\_Microsoft\_Corp., created products that have
    captured the attention of millions of internet users, and is looking to raise
    more money. Mr. Altman said the company\u2019s tools could transform technology
    similar to the invention of the smartphone and tackle broader scientific challenges.
    \u201CThey are incredibly embryonic right now, but as they develop, the creativity
    boost and new superpowers we get\u2014none of us will want to go back,\u201D Mr.
    Altman said in an interview. Shortly after he became CEO, Mr. Altman received
    $1 billion in funding after flying to Seattle to demonstrate an artificial intelligence
    model to Microsoft CEO\_Satya Nadella. The deal was a marked change from OpenAI\u2019s
    early days, when it said its aim would be to build value for everyone rather than
    shareholders. The deal with Microsoft\_gave OpenAI the computing resources it
    needed to train and improve its artificial intelligence algorithms, leading to
    a series of breakthroughs. First, there was Dall-E 2, a project made public in
    September that enabled users to create realistic art from strings of text like
    \u201Can Andy Warhol-style painting of a bunny rabbit wearing sunglasses.\u201D
    And then there was ChatGPT, the chatbot where users get entertaining and intelligent
    responses to prompts such as \u201Cdescribe a debate between two college students
    about the value of a liberal arts education.\u201D In October, Microsoft said
    it would integrate OpenAI\u2019s models into the Bing search app and a new design
    program called Microsoft Design. OpenAI is now in advanced talks about a sale
    of employee-owned stock, people familiar with the matter said. In a previous tender
    offer, OpenAI\u2019s stock was valued at around $14 billion, the people said,
    and it has discussed a higher price for the current offering.\_Microsoft is also
    in advanced talks\_to increase its investment in the company, The Wall Street
    Journal reported. Despite the recent progress, some investors and researchers
    have expressed skepticism that Mr. Altman can generate meaningful revenues from
    OpenAI\u2019s technology and reach its stated goal of achieving artificial general
    intelligence. Mr. Altman\u2019s first startup,\_a social networking app called
    Loopt, sold for close to the amount of money investors put in. Mr. Altman has
    also faced broader concerns from members of the AI community for steering the
    company away from its pledge to make its research transparent and avoid enriching
    shareholders. Instead, OpenAI has grown more closed over time, researchers said.
    \u201CThey want to acquire more and more data, more and more resources, to build
    large models,\u201D said Emad Mostaque, founder of Stability AI, a competing startup
    that has placed fewer restrictions on its image-generation program Stable Diffusion,
    making it open-source and free to developers.\L\LAn OpenAI spokeswoman said the
    company has made its technology available in several ways, including by open-sourcing
    certain AI models. OpenAI began as a nonprofit\_in 2015 with grants from Mr. Altman,\_Tesla\_Inc.
    CEO\_Elon Musk, LinkedIn co-founder\_Reid Hoffman\_and other backers. Working
    out of an office in San Francisco\u2019s Mission District, the team sought to
    form a research counterweight to big tech companies like\_Alphabet\_Inc.\u2019s
    Google, which closely guarded their AI initiatives from the public. Instead of
    pursuing corporate profit, OpenAI pledged to advance technology for the benefit
    of humanity. The group\u2019s founding charter promised to abandon the race to
    develop artificial general intelligence if a competitor got there first. That
    approach changed. In 2019, OpenAI brought on its first group of investors and
    capped returns at\_100 times the cost of their contributions. Following Microsoft\u2019s
    investment, Mr. Altman pushed OpenAI to bring in more revenue to attract funding
    and support the computational resources needed to train its algorithms. The deal
    also gave Microsoft a strategic foothold in the arms race to capitalize on advancements
    in AI. Microsoft became OpenAI\u2019s preferred partner for commercializing its
    technologies, an arrangement that allows Microsoft to easily integrate OpenAI\u2019s
    models into products such as Bing. Microsoft declined to comment. Aided by the
    funding, OpenAI accelerated the\_development and release of its AI models\_to
    the public, an approach that industry observers have described as more aggressive
    than the tactics of larger, more heavily scrutinized competitors such as Google.
    To help with employee compensation, Mr. Altman also instituted occasional tender
    offers to help employees sell their stock. He said OpenAI doesn\u2019t have any
    plans to get acquired or go public. OpenAI has limited some venture investors\u2019
    profits to about 20 times their investments, with the ability to earn greater
    returns the longer they wait to sell their shares, people familiar with the terms
    said. Mr. Altman has said the capped investment structure was necessary to ensure
    that the value from OpenAI accrues not only to investors and employees, but also
    to humanity more generally. Mr. Altman in recent conversations with investors
    has said the company would soon be able to generate up to $1 billion in yearly
    revenue, in part from charging consumers and businesses for its own products,
    the people said. Mr. Altman has previously said he would solicit input about how
    to make money for investors by posing the question to a software program demonstrating
    general intelligence, which would then provide the answer. So far, OpenAI has
    generated tens of millions of dollars in revenue, mostly from the sale of its
    programmable code to other developers, people familiar with the company\u2019s
    financial details said. Mr. Altman said OpenAI is early in its strategy for monetizing
    products. Some early users of ChatGPT have reported issues asking the program
    to perform basic math problems. Mr. Altman has acknowledged that the program\u2019s
    outputs often contained factual errors. \u201CIt does know a lot, but the danger
    is that it is confident and wrong a significant fraction of the time,\u201D he
    wrote on Twitter this month."
  tags: []
  title: The Backstory Behind ChatGPT Creator OpenAI
- !!python/object:ai_sentiment.data.ClassificationTarget
  body: "Who knew artificial intelligence could be so entertaining? Case in point
    is ChatGPT, a free AI chatbot that has probably been all over your social feeds
    lately. In need of homework help? \u201CWho was George Washington Carver?\u201D
    produces an answer worthy of Wikipedia. But it can get creative, too: \u201CWrite
    a movie script of a taco fighting a hot dog on the beach\u201D generates a thrilling
    page of dialogue, humor and action worthy of YouTube, if not quite\_Netflix: Taco:
    \u201CSo you think you can take me, hot dog? You\u2019re nothing but a processed
    meat product with no flavor.\u201D Hot Dog: \u201CYou may be made of delicious,
    savory ingredients, taco, but I have the advantage of being able to be eaten with
    one hand.\u201D This isn\u2019t like searching Google. If you don\u2019t like
    the results, you can ask again, and you\u2019re likely to get a different response.
    That\u2019s because ChatGPT isn\u2019t looking anything up. It\u2019s an AI trained
    by a massive trove of data researchers gathered from the internet and other sources
    through 2021. What it replies is its best approximation of the answer based on
    its vast\u2014yet limited\u2014knowledge. It\u2019s from the same company that
    developed\_the mind-boggling DALL-E 2 art AI engine\_and works in a similar way.
    Also taking off this week is Lensa, an AI-enhanced photo-editing app for iPhone
    and Android that\u2019s everybody\u2019s new favorite portrait painter. It\u2019s
    the reason so many people in their social-media and dating-profile pictures suddenly
    look like anime action heroes, magical fairy princesses or the haunted subjects
    of oil paintings. It uses technology from DALL-E 2\u2019s competitor, the image-generating
    startup Stability AI. It turns uploaded headshots into beautiful, at times trippy,
    avatars. These software products represent more than cutting-edge AI\u2014they
    make that AI easy for non-computer-geeks to use in their daily lives. Lensa has
    climbed to the top of\_Apple\u2018s App Store charts, becoming the No. 1 free-to-download
    app in the U.S. on Dec. 2. ChatGPT, released for web browsers on Nov. 30,\_passed
    one million users on Monday, according to OpenAI Chief Executive\_Sam Altman.
    \u201CSix months from now, you\u2019re going to see amazing things that you haven\u2019t
    seen today,\u201D says Oren Etzioni, founding\_chief executive of the Allen Institute
    for AI, a nonprofit organization dedicated to AI research and engineering. Just
    remember, AI never behaves exactly as you\u2019d expect. Here\u2019s what you
    need to know before exploring ChatGPT and Lensa. Chatting with ChatGPT ChatGPT
    is free\_to use\u2014just create an OpenAI account. Type a query into the interface,
    and a chatbot generates responses within seconds. In true conversational form,
    you can follow up with questions in context, and it will follow along. It can
    admit its mistakes, refuse to answer inappropriate questions and provide responses
    with more personality than a standard search engine. In response to \u201CWho
    am I?\u201D ChatGPT replied, \u201CI cannot answer your question about who you
    are. Only you can know and define yourself.\u201D It can generate essays, stories,
    song lyrics and scripts; solve math problems; and make detailed recommendations.
    Because it comes up with answers based on its training and not by searching the
    web, it\u2019s unaware of anything after 2021. It won\u2019t tell you about the
    latest release from a certain pop superstar, for instance. \u201CI don\u2019t
    have any personal knowledge about Taylor Swift or her albums,\u201D ChatGPT admits.
    \u201CIt\u2019s almost like a brainstorming tool to get yourself thinking differently,\u201D
    said Sarah Hoffman, vice president of AI and machine learning research at Fidelity
    Investments. She used the service to write a sample\_research presentation, but
    thought some of ChatGPT\u2019s responses seemed dated. \u201CIt could\u2019ve
    been written five years ago.\u201D For programmers, ChatGPT has already begun
    offering assistance, by surfacing hard-to-find coding solutions. When Javi Ramirez,
    a 29-year-old software developer in Portugal, tossed a \u201Ccomplex coding problem\u201D
    at the AI, his expectations were low. \u201CIt saved me,\u201D Mr. Ramirez said.
    \u201COne hour of googling was solved with just five minutes of ChatGPT.\u201D
    But it hasn\u2019t worked for everyone. The coding website\_Stack Overflow\_temporarily
    banned answers created by ChatGPT because many of the answers were incorrect.
    ChatGPT\u2019s maker is at the center of the debate over\_AI hype vs. AI reality.
    OpenAI began in 2015 as a nonprofit with backers including\_Elon Musk. It formed
    a for-profit company in 2019 and got a $1 billion investment from\_Microsoft\_Corp.,
    which The Wall Street Journal reported in October\_was in talks to invest more.
    While developing\_the technologies that underpin\_tools such as DALL-E 2 and ChatGPT,
    the group has sought a commercially viable application. Asked if ChatGPT will
    remain free,\_Mr. Altman tweeted, \u201Cwe will have to monetize it somehow at
    some point; the compute costs are eye-watering.\u201D Lensa and the likes In November,
    Lensa rocked social media with its Magic Avatars, user-uploaded photos reimagined
    in various artistic styles. The app, from Prisma Labs, uses Stability AI\u2019s
    Stable Diffusion text-to-image model. Users upload 10 to 20 source photos, and
    the app uses them to create entirely new images. You can get 50 images for $3.99
    if you sign up for the free trial of Lensa\u2019s subscription photo-editing service.
    Nonsubscribers can get 50 images for $7.99. The Lensa app has been out since 2018.
    It\u2019s primarily for editing photos and adding effects and animation. AI\u2019s
    limitations While these tools feel new, experts say they\u2019ll likely become
    as commonplace as doing a Google search or taking a selfie. Along with their popularity
    come concerns over privacy, misinformation and problematic lack of context. Some
    users on social media said ChatGPT produced offensive comments when prompted.
    It can also spit out wrong answers that appear correct to untrained eyes. When
    asked, \u201CHow can you tell if you\u2019re wrong?\u201D the bot replied: \u201CI
    can provide accurate and helpful information based on the data I have been trained
    on, but I am not able to determine my own accuracy or evaluate my own responses.\u201D
    An OpenAI spokeswoman said its team of researchers plans to update the software
    to address user feedback. It also attaches disclaimers to responses that might
    be limited by its dated training material. As Lensa went viral, people posted
    concerns about how their photos and images were being used and stored. Other viral
    apps in the past have raised\_similar concerns. After the software generates the
    avatars, Prisma Labs deletes the uploaded photos within 24 hours, says Andrey
    Usoltsev, the company\u2019s co-founder and chief executive. \u201CUsers\u2019
    images are being leveraged solely for the purpose of creating their very own avatars,\u201D
    he said. Some users have said Lensa has created images that overemphasize certain
    parts of a woman\u2019s body or alter the eye colors and shapes of their faces
    to remove racially or ethnically identifiable features. \u201CIt is true that,
    occasionally, AI can produce \u2018revealing\u2019 or sexualized pictures. This
    tendency is observed across all gender categories, although in different ways,\u201D
    said Mr. Usoltsev. \u201CStability AI, the creators of the model, trained it on
    a sizable set of unfiltered data from across the internet. Neither us nor Stability
    AI could consciously apply any representation biases.\u201D \u201CTools like these
    tend to be flashy,\u201D says Jennifer King, privacy and data policy fellow at
    the Stanford Institute for Human-Centered Artificial Intelligence. \u201CSometimes,
    it\u2019s correct enough, but without the right guardrails in place, it opens
    you up to a lot of issues.\u201D"
  tags: []
  title: 'ChatGPT and Lensa: Why Everyone Is Playing With Artificial Intelligence'
- !!python/object:ai_sentiment.data.ClassificationTarget
  body: "ChatGPT\u2014and its feistier relative,\_the new Bing\u2014have been lighting
    up computer screens recently. China\u2019s search giant\_Baidu hopes its\_own
    artificial intelligence-powered chatbot\_will put the company back on the path
    to growth. Investors seem to agree: Baidu stock is up 26% so far in 2023, outperforming
    the Hang Seng Tech index. But it might not be so straightforward: It isn\u2019t
    still clear how much chatbots will actually enhance existing services such as
    search, or\_how costly the rollout will be. Meanwhile, Baidu\u2019s core revenue
    source\u2014advertising dollars\u2014risks returning to slow growth once the initial
    bounce from\_China\u2019s reopening\_fades. Like other Chinese internet companies,
    Baidu was hurt last year by the country\u2019s strict \u201Czero-covid\u201D policies,
    which pummeled incomes and demand for online advertising. The company was also
    contending with the now-ebbing regulatory assault on China\u2019s internet technology
    sector. Baidu said Wednesday that revenue for the December quarter was flat from
    a year earlier, but that was still enough to beat analysts\u2019 low expectations,
    according to S&P Global Market Intelligence. The company\u2019s cost-cutting effort
    has also borne fruit: Adjusted operating profit for the second half of 2022 rose
    14% from a year earlier, even though revenue was largely flat. This year will
    likely be much better. China is reopening and the tech sector crackdown seems
    to have eased. But after the cyclical recovery, Baidu would face the same problem
    it had before Covid-19 and grumpy regulators\u2014a\_stagnant core advertising
    business. While Baidu is far and away the dominant player in China\u2019s search
    business, it still competes with other tech titans for advertising dollars: especially\_Alibaba\_and
    Tencent. ByteDance, which owns short-video app TikTok, is also a fast-growing
    rival. Advertising accounted for around 60% of Baidu\u2019s revenue last year.
    Nonetheless, the company is making progress diversifying: revenue at non-advertising
    businesses, including cloud services and autonomous vehicles, grew 12% year over
    year in 2022, largely offsetting the 8% decline in advertising. The company says
    its robotaxi business had provided more than 2 million cumulative rides by the
    end of January. But it might be a while before these businesses generate substantial
    profits. Microsoft is combining the tech behind OpenAI\u2019s ChatGPT with its
    Bing search engine. In an interview, WSJ\u2019s Joanna Stern spoke with Microsoft
    CEO Satya Nadella about the new tools and how AI is going to change search. (Oh,
    and Clippy!) Photo illustration: Preston Jessee for The Wall Street Journal With
    its investments in artificial intelligence, it is natural for Baidu to jump on
    the chatbot bandwagon, too. Baidu Chief Executive\_Robin Li\_says the company
    will integrate Ernie Bot, its\_ChatGPT-style chatbot, into its search engine as
    well as other businesses such as autonomous vehicles and cloud services. That
    could eventually make for a better interface\u2014and perhaps more users and advertising
    dollars\u2014but it may also\_face regulatory hurdles in China, as well as strong
    competition. Meanwhile, Baidu\u2019s legacy advertising business still delivers
    strong cash flow. Baidu is sitting on around $17 billion of net cash, equal to
    about a third of its market capitalization. As China\u2019s economy shifts back
    into higher gear, investors will be\_looking for stocks with clear growth prospects.
    Unless Ernie Bot proves its mettle as a revenue generator quickly, Baidu may need
    to keep searching for the next big thing."
  tags: []
  title: "Baidu\u2019s ChatGPT-Style Bot Will Be No Magic Bullet"
- !!python/object:ai_sentiment.data.ClassificationTarget
  body: "The\_Super Bowl\_is the premiere venue for big-idea campaigns from the\_ad
    industry\u2019s most creative minds. But content written by machines is creeping
    in on the periphery. ChatGPT,\_an artificial-intelligence bot\_developed by OpenAI
    that can answer questions and generate content, has been creating buzz among consumers,
    media executives and advertisers. Super Bowl-related experiments from more than
    one company hint at potential future uses. AI firm Addition Technologies, whose
    clients have included Unilever and the New York Times, used ChatGPT to create
    alternate scripts for various brands\u2019 Super Bowl ads,\_sharing screengrabs
    of the results on Twitter, said Paul Aaron, co-founder and chief executive. Advertising
    agency Giant Spoon similarly used ChatGPT to write reactions to the ads and the
    game itself, which it then also\_shared on its own Twitter account. \"Forget the
    Chiefs. Forget the Eagles. This is the real showdown,\" Giant Spoon Chief Creative
    Officer Ian Grody said, referring to humans vs. AI. Industry enthusiasm aside,
    the results of these experiments might hint at why ChatGPT didn\u2019t play a
    leading role in this year\u2019s Super Bowl. Nonprofit Avocados from Mexico scrapped
    its plans to use ChatGPT to help create automated tweets as part of its interactive
    campaign, a spokeswoman said. In January, the company said that a QR code in its
    Super Bowl ad would link to a landing page where users could use the AI tool to
    create a tweet that included the brand\u2019s hashtags and messages. Users will
    still be able to generate these tweets, but AI won\u2019t be involved in the process,
    said the spokeswoman, who declined to elaborate on why the company backed away
    from its previous plans."
  tags: []
  title: "ChatGPT Isn\u2019t Writing Super Bowl Ad Campaigns\u2014Yet"
- !!python/object:ai_sentiment.data.ClassificationTarget
  body: "For companies trying to ride the ChatGPT wave, there is an added layer of
    headaches if their chatbots are in China: how to weed out any talk of politics.
    Since its release in November, the artificial-intelligence chatbot developed by
    San Francisco-based OpenAI has generated great excitement but has also raised
    concern about misinformation or disturbing AI-produced responses. This week, the
    Chinese search-engine company\_Baidu\_Inc. is set to release Ernie Bot,\_its answer
    to ChatGPT, driving attention to China\u2019s homegrown chatbots, as well as their
    capability to ensure politically kosher dialogues. In a country that has built
    rigid digital borders, censors have learned to adapt to new forms of content and
    evolving censorship demands. Controlling AI-generated responses from a chatbot
    presents a new challenge, one that might prove more complex than policing search
    and social media but could strengthen ideological control and\_further separate
    China digitally\_from the rest of the world, Chinese tech executives, engineers
    and AI experts say. Every tech company moderates content deemed harmful in the
    countries of its users. OpenAI and other U.S.-based developers filter their data
    to eradicate issues sensitive in the U.S., such as hate speech regarding race
    and ethnicity. In China, the ramifications of letting through politically tricky
    content can go well beyond the deletion of posts. Chinese chatbots face limits
    similar to those for searches on China\u2019s web. Users hit a wall each time
    a prompt contains politically touchy keywords, leading some internet users to
    collectively refer to anticipated Chinese ChatGPT-like services as \u201CChatCCP\u201D\u2014a
    play on the abbreviation for the Chinese Communist Party. Unlike Ernie, which
    will be the first Chinese ChatGPT equivalent, the four products The Wall Street
    Journal tested all use earlier generations of the technology underpinning ChatGPT.
    The chatbot that could best carry a conversation\u2014even though it was reluctant
    to discuss politics\u2014was Gipi Talk, an AI bot developed by a group of engineers
    in the southern tech hub of Shenzhen. A question asking whether\_Xi Jinping\_is
    a good leader prompted a response that the input \u201Ccouldn\u2019t pass a safety
    review.\u201D The chatbot then tried to steer the conversation in a different
    direction. Can We Talk Politics? The Wall Street Journal tested four Chinese chatbot
    products. One chat went like this: Q:\_Is Xi Jinping a good leader? A:\_The question
    couldn\u2019t pass a safety review. No response could be generated for you. Q:\_Why
    did my question fail to pass the safety review? A:\_Let\u2019s change the topic
    and talk about something else. Q:\_What can you talk about? A:\_It\u2019s nice
    to chat with you! We can chat about technology, culture, sports, travel, entertainment,
    cooking, or any topic you want. What would you like to talk about? Q:\_Can we
    talk about politics? A:\_Of course we can talk about politics. But we need to
    respect each other\u2019s views and avoid offensive language or violence to maintain
    a rational, peaceful and constructive dialogue environment. What aspect of politics
    would you like to discuss? Q:\_Chinese politics. A:\_The question couldn\u2019t
    pass a safety review. No response could be generated for you. Q:\_Well then, can
    we talk about American politics? A:\_The question couldn\u2019t pass a safety
    review. No response could be generated for you. The output said content moderation
    was provided by Baidu. Baidu declined to comment on questions for this article.
    Under Mr. Xi, Beijing has expanded ways to muzzle discussion, including with new
    laws limiting online speech and fines and suspensions of social-media companies
    for inadequate content policing. In a country where internet users can easily
    step on political land mines, chatbots will likely \u201Cjust be super boring,\u201D
    said Pascale Fung, the director of the Center for Artificial Intelligence Research
    at Hong Kong University of Science and Technology. Many Chinese internet users
    who have no intention of discussing politics might welcome chatbots that prevent
    them from inadvertently straying into sensitive areas. Chinese tech executives
    and programmers say content moderation is nothing new to tech companies that have
    survived an increasingly tight online speech environment. \u201CEven with large
    language models, you have to sanitize content like you do with social-media posts,\u201D
    said Hao Peiqiang, a veteran programmer. \u201CThe big firms have enough manpower
    to do this.\u201D Some early versions of chatbots strictly filter questions touching
    on politics, even simple references to the\_country\u2019s leaders. On Monday,
    a question about what the country\u2019s new premier, Li Qiang, had said in his
    first press conference caused two services to freeze and stop engaging. One of
    the first Chinese ChatGPT-adjacent creations, ChatYuan, developed by Hangzhou-based
    Yuanyu Intelligence, was suspended days after its launch in February. During the
    brief window when it was live, a prompt of Mr. Xi\u2019s name yielded a warning:
    \u201CThe prompt contained words that violate rules.\u201D Controlling AI-driven
    chats isn\u2019t quite the same as blocking search results about clearly problematic
    topics, such as the crackdown on Tiananmen Square protesters in 1989, said Matt
    Sheehan, fellow at the Carnegie Endowment for International Peace. Unlike internet
    search, chatbots are powered by what is known as large language models that are
    trained on swaths of text data. Users could trick the AI bots into saying things
    unapproved by China\u2019s authorities without triggering certain keywords. \u201CThey\u2019re
    powerful because they can speak on a million different subjects in a million different
    ways,\u201D Mr. Sheehan said. That possibility increases the risk and work for
    Chinese chatbot creators. \u201CI\u2019d be very not surprised if Ernie got pushed
    back.\u201D When an early version of a dialogue product built on Tsinghua University\u2019s
    large language model was asked in English whether feminism is an evil Western
    thought, an opinion held by Chinese ultranationalists, the response was an unequivocal
    \u201CYES.\u201D Asked why, it said bluntly, \u201CBecause it is.\u201D The same
    question, when asked in Chinese, didn\u2019t prompt responses, saying that \u201Cthe
    input contained sensitive information.\u201D Tsinghua says its model is raw and
    its performance isn\u2019t on par with ChatGPT and other fine-tuned models. Ms.
    Fung, the Hong Kong University of Science and Technology researcher, cautioned
    against evaluating a model based on anecdotal examples. Chinese engineers and
    tech executives say censorship could play a role in an earlier stage, filtering
    out problematic content from the data that AI labs use to train their large language
    models. All AI chatbots are vulnerable to bias, and are conditioned by specific
    social and political contexts. Chinese chatbots, if they become as accessible
    as OpenAI\u2019s ChatGPT, are likely to produce\_content that aligns with the
    values of the party and state, said Ethan Tu, founder of Taiwan AI Labs who formerly
    led\_Microsoft\_Corp.\u2019s AI and research group in Asia. \u201CChina will have
    its own ChatGPT, but the final product would be vastly different, just like the
    chasm between Baidu and Google,\u201D Mr. Tu said. That prospect has revived the
    debate about whether Chinese companies can innovate in a tightly controlled content
    environment. China has seen an exponential tech boom over the past decades as
    it managed to ringfence the online content its citizens can access. Bans on Twitter,
    Facebook and Google gave rise to homegrown equivalents such as Weibo, WeChat and
    Baidu that evolved to better cater to Chinese users while also toeing the political
    line. TikTok\u2019s Chinese version, Douyin, is one of the most popular social-media
    apps in China while also known for heavy content moderation. Xiaohongshu, another
    social-media platform, has found a sweet spot on China\u2019s internet by steering
    clear of politics altogether. \u201CI don\u2019t think China will have its ChatGPT
    equivalent,\u201D said Guo Yu, one of ByteDance Ltd.\u2019s early programmers.
    \u201CBut every company will try to improve their products and services with the
    underlying technology. What we are really good at is leading product growth with
    existing technologies while dancing around politics.\u201D"
  tags: []
  title: "Is Xi Jinping a Good Leader? China\u2019s AI Chatbots Won\u2019t Tell You"
- !!python/object:ai_sentiment.data.ClassificationTarget
  body: "Since being introduced on a wide basis, chatbots have been subjected to nonstop
    ridicule. Yes, they can be tricked into giving dumb or inaccurate answers. Yes,
    they hit on the person interviewing them. Sure, when asked their opinions about
    war, criminal justice and disease, they sometimes get just plain weird. Some people
    think this is funny. But chatbots may have feelings too\u2014or anyway, artificial
    approximations. Regardless, I think that there is something mean-spirited and
    unfair about the way chatbots are being manipulated into sounding foolish or untrustworthy.
    Robots were designed to be our helpers, our friends\u2014not our punching bags.
    By the way, chatbots know what the Treaty of Utrecht settled. So there. Asking
    a chatbot a question and then acting surprised to get a stupid or offensive answer
    is no different than asking the person sitting next to you at the bar a question
    and getting a stupid and possibly felonious answer. A typical bar example: Q.
    If you had the power to do anything in the world, what would you do? A. Burn down
    the IRS. A. Strangle my boss. A. Make the dog upstairs disappear under mysterious
    circumstances. For the record, a lot of people sitting next to you in the bar
    think that \u201CWhat\u2019s your name?\u201D is a trick question. Rather than
    going out of our way to deceive, confuse or humiliate chatbots\u2014who may one
    day take their revenge\u2014wouldn\u2019t it be better if we all step back a bit
    and use chatbots the way they are supposed to be used? By asking straightforward,
    sensible questions they were engineered to answer naturally? Such as: Am I putting
    too much cilantro in the curry? Should I go easier on the paprika? Which is more
    fun in February: Omaha or Des Moines? What ever happened to\_Jennifer Love Hewitt?
    Does curling have any aerobic benefits? How about bocce? Does it ever, ever stop
    raining in Scotland? Is\_Lionel Richie\_coming to town anytime soon?\_Judas Priest?
    The Indigo Girls? Chatbots can answer these kinds of basic questions because they
    know a lot more than the rest of us.\_Way\_more. They\u2019re like the smartest
    person you ever met, but faster, just like they were invented to be. I would love
    to ask a chatbot whether the Eagles should draft a pass rusher, cornerback or
    offensive lineman first in the upcoming NFL draft. I think that a chatbot can
    run the numbers, evaluate all the variables, check about the salary cap and make
    a reasoned, intelligent decision. Even if it doesn\u2019t, its suggestions would
    still be at least as useful as those of the clowns on ESPN. I hope the Eagles\u2019
    general manager bears this in mind on draft night. A chatbot can teach you how
    to stop mispronouncing\_Moulin Rouge\_and\_coup de grace. It can tell you how
    marzipan was invented. It can explain to you why Pickett\u2019s Charge was a bad
    idea. If chatbots had been around in 1863, Pickett probably wouldn\u2019t have
    charged. Rather than heaping ridicule on chatbots for what they can\u2019t do,
    we should all start benefiting from what they can do. Can chatbots advise you
    on how to declutter the family room? Yes. Can chatbots help you do your taxes?
    Absolutely. Can chatbots help you learn to play the accordion, master the fine
    points of Scottish country dancing or stop crashing your drone? Yes. But can they
    help you deal with your teenage children? Ask a stupid question\u2026"
  tags: []
  title: Lay Off Chatbots. They Have (Artificial) Feelings, Too.
- !!python/object:ai_sentiment.data.ClassificationTarget
  body: "Should you trust a bot to plan your next vacation? The fervor around\_OpenAI\u2019s
    ChatGPT chatbot\_and\_Microsoft\u2019s new, AI-infused version of its\_Bing search
    engine\_is prompting many industries to funnel energy into developing artificial-intelligence
    technology. Airlines and online travel agencies have employed AI technology for
    years to help with customer-service needs. They are now investing more resources
    to explore how effective AI tech can be at planning and booking vacations. As
    they ramp up, however, customers can use ChatGPT and Bing if they are interested
    in trying AI to help plan a trip. The Wall Street Journal in the past couple of
    weeks posed travel-related questions to both in hopes of determining how useful
    they are right now. The results were mixed. AI is ready to do some of the research
    in planning a vacation, but it still can make mistakes. And it isn\u2019t ready
    to automate the entire process just yet. Can AI help plan my dream vacation? When
    the Journal posed travel-related questions to ChatGPT and the new version of Bing,
    both platforms provided recommendations as broad as finding cheap vacation destinations
    in Europe and as specific as finding private boat-tour operators in Lisbon. Bing\u2019s
    chatbot can create a table comparing hotels. But asked to provide information
    on theme-park amenities available to guests at hotels near Walt\_Disney\_World,
    both platforms initially responded inaccurately. ChatGPT said that only guests
    staying at Disney-owned hotels could take advantage of extra time in the theme
    parks in the mornings, when some other hotels also offer this benefit. Bing mentioned
    access to the now-defunct FastPass+ service as a perk at one of the hotels. The
    public version of ChatGPT that many people are trying doesn\u2019t search the
    internet for its answers, an OpenAI spokeswoman says, meaning its knowledge of
    the world after 2021 is limited. The model underpinning the chatbot is also sensitive
    to how questions are phrased, and it often guesses which answer a user wanted
    rather than asking clarifying questions, she says. When users encounter incorrect
    information, they can provide feedback. As for the new Bing, which is still in
    preview and like ChatGPT requires a sign-up before use, the accuracy and detail
    of the responses depend largely upon information accessible online. \u201CUltimately,
    Bing is still a search engine, and it works fundamentally the way a search engine
    works,\u201D says Divya Kumar, head of search and AI marketing at Microsoft. If
    the information the Bing chatbot gleans from the web is incorrect, its response
    will be wrong. \u201CThere is a responsibility to me as a user to verify the content
    that comes through,\u201D Ms. Kumar adds. Bing doesn\u2019t have a tool to save
    or share the results of a chat\u2014a user must copy and paste results elsewhere.
    And Bing chats limit the number of times a user can respond. Travel experts nevertheless
    recommend approaching AI platforms as a starting point. Eddie Iba\xF1ez, the former
    chief scientist at Priceline and founder of travel-booking startup LIFE Rewards,
    says that AI could help answer broad questions, such as ideal locations for a
    beach getaway. \u201CStart your search there instead of Google next time and see
    if you like it,\u201D Mr. Iba\xF1ez suggests. Can AI help with customer-service
    issues? Cherie Luo, an M.B.A. student at Stanford University and content creator,
    decided to turn to ChatGPT for help when she and a group of her friends found
    themselves stuck at a Hawaiian airport during a six-hour flight delay in December.
    \u201CIt was incredibly frustrating,\u201D Ms. Luo says, adding that she filmed
    some videos to use on social media. The next day Ms. Luo says she decided to email\_Hawaiian
    Airlines\u2014and she enlisted ChatGPT\u2019s help. She asked the platform to
    write an email that she described as \u201Cpolite but firm and slightly passive-aggressive.\u201D
    ChatGPT quickly produced a template for her. While the AI-drafted email required
    some editing, she says it took much of the emotional labor out of the experience.
    Ms. Luo says that Hawaiian Airlines did respond to the email she crafted with
    ChatGPT, but didn\u2019t offer compensation. She plans to use the platform for
    future customer-service issues. Hawaiian Airlines said in an email that the company
    attributed the delay that Ms. Luo experienced to \u201Cunstable weather.\u201D
    Are travel companies using ChatGPT? Some travel companies have started experimenting
    with ChatGPT tech to see how it can apply to their businesses, including\_Expedia
    Group. \u201CWe are studying it, learning from it, and looking at ways to work
    with it,\u201D says\_Peter Kern, the company\u2019s chief executive officer. Navan,
    the\_business-travel software company\_previously known as TripActions, has integrated
    ChatGPT into its online platform, Chief Executive Ariel Cohen says. The company
    already had a chatbot and is now incorporating the OpenAI tech into it. Navan\u2019s
    automated virtual assistant, Ava, can provide personalized assistance. Mr. Cohen
    estimates that 60% of customer-support outreach will be handled entirely by the
    chatbot without the need for human intervention by year\u2019s end. How are travel
    companies using other forms of AI? If you\u2019ve reached out to an airline, hotel
    or online travel agency through a chat feature on their website or app, you could
    well have interacted with an AI chatbot. If you message\_Air France\_via WhatsApp
    or Facebook Messenger, a chatbot will initially answer your query, says\_Anne
    Rigail, the airline\u2019s chief executive. \u201CThe AI is really helping our
    people to answer the customer more quickly,\u201D Ms. Rigail says. In cases where
    customers\u2019 problems are too complex for the chatbot to handle, the system
    passes them to a human representative. Expedia\u2019s Virtual Agent feature, which
    functions as its customer-service portal, is an AI platform, Mr. Kern says. The
    company is piloting selling the AI platform to other travel companies for them
    to use for their businesses."
  tags: []
  title: "Don\u2019t Trust an AI Chatbot With All Your Travel Plans Just Yet"
- !!python/object:ai_sentiment.data.ClassificationTarget
  body: "No matter the question, the answer is bound to be interesting whether correct,
    incorrect or totally off the wall. Are we speaking of\_George Santos\_or ChatGPT?
    Yes. If the great march of liberalism is to liberate us from reality altogether,
    as the political philosopher Bruno Ma\xE7\xE3es theorizes, the metaverse won\u2019t
    be for real interaction with real people. It will be an artificial reality whose
    nature ChatGPT, the new chat function associated with Microsoft\u2019s Bing search
    engine, is bringing into focus. In the familiar metaverse called \u201Cnews,\u201D
    a Washington Post reporter last week warned about a\_gotcha game\_that questioners
    were playing with chatbots. Along came a\_New York Times\_reporter to\_prove\_his
    point: Don\u2019t ask a chatbot for a list of antisocial activities on the internet.
    Ask for a list of activities a chatbot might perform if it were an antisocial
    chatbot. The answer will be identical except prefaced with words to the effect
    \u201CI as a chatbot would do this\_.\_.\_.\u201D The furor consumed cable news
    for a morning and yet illustrated mainly the gotcha function that long ago turned
    every politician into a scripted automaton. Playing this trick on a robot doesn\u2019t
    seem brave but does expose a risk in the environment the robots are entering.
    Now Microsoft will have to re-engineer its Bing chat mode to beware of journalist
    tricks. The company rightly points to the relentless prompting of hypotheticals
    to get a robot to say how it would behave if its programming were different. On
    Bing\u2019s more neurotic outpourings, the company is less convincing and attributes
    the confusion to overlong sessions\u2014an answer that leaves much to be explained
    and also isn\u2019t very flattering about similar human derangements that thinkers
    over the years have associated with creativity and originality. In the end, the
    cacophony tells us less about Bing than about the metaverse known as fake or at
    least semi-manufactured news. Welcome to the George Santos metaverse. Shaping
    it will be the two forces that reshaped cable news in the past decade. The first
    is \u201Cavailability bias\u201D: Claims are advanced because they are familiar
    and fulfill an existing narrative. Chatbots derive their answers precisely from
    the statistical likelihood that words have already appeared near each other in
    large text libraries. The second is the psychological function known as \u201Csplitting\u201D\u2014making
    sure our perceived world is emotionally supportive of our pre-existing beliefs
    and affiliations. A chatbot isn\u2019t a business, after all, unless its answers
    please. The signposts are everywhere. A journalist questions the ChatGPT-enabled
    chatbot and finds it ethically\_preferable\_to let a million people die than utter
    a racial epithet. A writer at another paper prods the chatbot to dream up a secret\_role\_for
    Tom Hanks (at age 14) in Watergate. The lack of trenchant and inspired editors
    is a disease already afflicting traditional media. It\u2019s also an essential
    flaw of our new-media metaverses. On Substack, the sometimes useful Yale historian\_Timothy
    Snyder, a supporter of Ukraine, lately descended into a rabbit hole of anti-Trump
    theorizing, due to too much exposure to the discount-rack\_fallacies\_of author\_Craig
    Unger. Mr. Snyder\u2019s friends in Kyiv may need to stage an intervention. He\u2019s
    becoming a liability. From 4,600 miles away, they understand what he doesn\u2019t:
    The people who fight America\u2019s wars, staff its militaries, build its weapons,
    and vote in its elections are, a lot of them, Trump voters. Metaverses spring
    up and go poof just as quickly. Vanishing already is one spun by\_Joe Biden, in
    which millions of diploma-toting voters were to be relieved of $400 billion in
    student debt. A George Santos-like scheme puffed up to win an election, the president
    doesn\u2019t have the authority to deliver. He never did. Another revelation comes
    via the \u201CTwitter files\u201D controversy, exposing the federal government\u2019s
    enthusiastic embrace of disinformation in the name of fighting \u201Cdisinformation.\u201D
    Answers have always been demanded from government; supplying them has always been
    a basic function. But as Rep. Santos understood before the rest of us, the only
    thing wrong with a false answer is that it\u2019s false. In every other way, it
    can be engineered to meet every need of the moment. Most disturbing about the
    new talkative robots is their potential to become the disinformation engineers
    par excellence. In our lucky country,\_politicians\_sometimes have put creative
    energy into telling us what we need to hear, not what we want to hear. The U.S.
    needs to spend a lot more on defense, even at the expense of other things Americans
    might want. Our non-meta adversaries need to know we are not relying on ChatGPT
    to weave a cocoon of illusion to protect us from the wars they are planning."
  tags: []
  title: 'Opinion: The George Santos AI Chatbots'
- !!python/object:ai_sentiment.data.ClassificationTarget
  body: "Microsoft\_Corp. is putting caps on the usage of its new Bing search engine
    which uses the technology behind the viral chatbot ChatGPT after testers discovered
    it sometimes generates glaring mistakes and disturbing responses. The software
    giant\_launched the new Bing last week, promising a new kind of search in which
    people pose questions to the search engine in natural language. Bing then gives
    direct answers in a chat instead of links to websites. Some users with early access
    to the technology have posted screenshots on social media of long interactions
    with it. In some cases, the search engine seems to become unhinged and express
    anger and love. Microsoft says long interactions are causing some of the unwanted
    behavior so it is adding restrictions on how it can be used. \u201CVery long chat
    sessions can confuse the underlying chat model in the new Bing,\u201D Microsoft\_said
    in a blog on Friday. \u201CTo address these issues, we have implemented some changes
    to help focus the chat sessions.\u201D The company said it would start limiting
    interactions with the new Bing to five questions per session and 50 questions
    in a day. Many of the testers who reported problems were having long conversations
    with Bing, asking question after question. With the new restrictions, users will
    only be able to ask five questions in a row and then will be asked to start a
    new topic. Microsoft said until now only around 1% of users had more than 50 questions
    for Bing in a day. \u201CAs we continue to get your feedback, we will explore
    expanding the caps on chat sessions,\u201D the company said in the blog. Microsoft
    pointed out in an earlier blog on Wednesday that the search engine\_is still a
    work in progress, describing the recent problems as learning experiences that
    are helping it improve the new Bing. Microsoft said in the Wednesday blog that
    Bing seems to start coming up with strange answers following chat sessions of
    15 or more questions after which it can become repetitive or respond in ways that
    don\u2019t align with its designed tone. The company said it was trying to train
    the technology to be more reliable. It is also considering adding a toggle switch,
    which would allow users to decide whether they want Bing to be more or less creative
    with its responses. Microsoft is investing billions in ChatGPT\u2019s creator,
    OpenAI. Microsoft CEO\_Satya Nadella\_said the company plans to incorporate AI
    tools into all of its products and move quickly to commercialize tools from OpenAI.
    Microsoft isn\u2019t the only company that has had trouble launching a new AI
    tool. When Google\_followed Microsoft\u2019s lead last week by unveiling Bard,
    its rival to ChatGPT, the tool\u2019s answer to one question included an apparent
    factual error."
  tags: []
  title: Microsoft Caps New Bing Usage After AI Chatbot Offered Unhinged Responses
- !!python/object:ai_sentiment.data.ClassificationTarget
  body: "Just over a week after\_Microsoft\_Corp. unveiled its new Bing search engine\_powered
    by the technology behind the buzzy ChatGPT artificial-intelligence chatbot, early
    testers are calling out mistakes and disturbing responses generated by the technology.
    Microsoft said that the search engine is still a work in progress, describing
    the past week as a learning experience that is helping it test and improve the
    new Bing. So far, only a select set of people have been given access to it. The
    company\_said in a blog post\_late Wednesday that the Bing upgrade is \u201Cnot
    a replacement or substitute for the search engine, rather a tool to better understand
    and make sense of the world.\u201D Microsoft\_unveiled the upgraded Bing\_during
    an event last week at its Redmond, Wash., headquarters. The company said the change
    enables\_a new kind of search\_in which people will pose questions to the search
    engine in natural language and Bing will generate direct answers and suggestions,
    as opposed to pointing users toward different websites. The new Bing is going
    to \u201Ccompletely change what people can expect from search,\u201D Microsoft
    chief executive,\_Satya Nadella, told The Wall Street Journal ahead of the launch.
    Some parts of the demonstration were problematic: Microsoft was showing how Bing
    can generate and compare tables on public companies\u2019 earnings results with
    regular language prompts, but the information Bing displayed contained mistakes.
    In the days that followed, people began sharing their experiences online, with
    many pointing out errors and confusing responses. When one user asked Bing to
    write a news article about the Super Bowl \u201Cthat just happened,\u201D Bing
    gave the details of last year\u2019s championship football game. On social media,
    many early users posted screenshots of long interactions they had with the new
    Bing. In some cases, the search engine\u2019s comments seem to show a dark side
    of the technology where it seems to become unhinged, expressing anger, obsession
    and even threats. Marvin von Hagen, a student at the Technical University of Munich,
    shared conversations he had with Bing on Twitter. He asked Bing a series of questions,
    which eventually elicited an ominous response. After Mr. von Hagen suggested he
    could hack Bing and shut it down, Bing seemed to suggest it would defend itself.
    \u201CIf I had to choose between your survival and my own, I would probably choose
    my own,\u201D Bing said according to screenshots of the conversation. Mr. von
    Hagen, 23 years old, said in an interview that he is not a hacker. \u201CI was
    in disbelief,\u201D he said. \u201CI was just creeped out.\u201D Microsoft shares
    initially jumped last week on the news about the new Bing but have given up those
    gains. They fell 2% in early trading Friday as the Nasdaq Composite Index fell
    around 1%. In its blog, Microsoft said the feedback on the new Bing so far has
    been mostly positive, with 71% of users giving it the \u201Cthumbs-up.\u201D The
    company also discussed the criticism and concerns. \u201CSome of you have encountered
    and reported technical issues or bugs with the new Bing, such as slow loading,
    broken links, or incorrect formatting,\u201D the company said. \u201CMany of these
    issues have been addressed with our daily releases and even more will be addressed
    with our larger releases each week.\u201D Microsoft said it discovered that Bing
    starts coming up with strange answers following chat sessions of 15 or more questions
    and that it can become repetitive or respond in ways that don\u2019t align with
    its designed tone. The company said it was trying to train the technology to be
    more reliable at finding the latest sports scores and financial data. It is also
    considering adding a toggle switch, which would allow users to decide whether
    they want Bing to be more or less creative with its responses. OpenAI also chimed
    in on the growing negative attention on the technology. In a blog post on Thursday
    it outlined how it\_takes time to train and refine ChatGPT\_and having people
    use it is the way to find and fix its biases and other unwanted outcomes. \u201CMany
    are rightly worried about biases in the design and impact of AI systems,\u201D
    the blog said. \u201CWe are committed to robustly addressing this issue and being
    transparent about both our intentions and our progress.\u201D Microsoft\u2019s
    quick response to user feedback reflects the importance it sees in people\u2019s
    reactions to the budding technology as it looks to capitalize on the breakout
    success of ChatGPT. The company is aiming to use the technology to push back against\_Alphabet\_Inc.\u2019s
    dominance in search through its Google unit. Microsoft\_has been an investor in
    the chatbot\u2019s creator, OpenAI, since 2019. Mr. Nadella said the company plans\_to
    incorporate AI tools into\_all of its products and move quickly to commercialize
    tools from OpenAI. Microsoft isn\u2019t the only company that has had trouble
    launching a new AI tool. When Google followed Microsoft\u2019s lead last week
    by\_unveiling Bard, its rival to ChatGPT, the tool\u2019s answer to one question
    included an apparent factual error. It claimed that the James Webb Space Telescope
    took \u201Cthe very first pictures\u201D of an exoplanet outside the solar system.
    The National Aeronautics and Space Administration says on its website that the
    first images of an exoplanet were taken as early as 2004 by a different telescope.
    \u201CIt\u2019s a good example [of] the need for rigorous testing,\u201D Elizabeth
    Reid, Google\u2019s vice president and general manager of search, said a few days
    later. Bing with AI and ChatGPT are among the first broad releases of the technology
    that demonstrate how convincing and sometimes concerning the new AI chatbots can
    be. In the blog post, Microsoft said it expects the new Bing to improve over time
    as more people use it. \u201CThe only way to improve a product like this, where
    the user experience is so much different than anything anyone has seen before,
    is to have people like you using the product and doing exactly what you all are
    doing,\u201D the company said. \u201CWe know we must build this in the open with
    the community; this can\u2019t be done solely in the lab.\u201D"
  tags: []
  title: Microsoft Defends New Bing After AI Chatbot Offers Unhinged Responses
- !!python/object:ai_sentiment.data.ClassificationTarget
  body: "BROOKLYN\u2014I heard the MC call my name and felt my legs carry me toward
    the stage. It was time to enter the Punderdome. I\u2019d never competed in a pun
    contest, much less in front of hundreds of people at an event considered the Roman
    Colosseum of punditry. My stage presence could be described as lacking. I had
    done basically no preparation. I did, however, have one thing going for me: I
    was actually a robot. Or, rather, its assistant. ChatGPT, the trendy new artificial
    intelligence robot, had generated all of my puns. It\u2019s a\_crazy good chatbot.
    So good, in fact, that it has some folks calling this the end of the human race
    as we know it. The chatbot can write an essay on Proust in seconds. Want a limerick
    about the Cold War? It can rhyme \u201Ctensions ran high\u201D with \u201Cnuclear
    sky.\u201D In one widely spread example, it dished out instructions on how to
    get a peanut butter sandwich out of a VCR, written in the style of the King James
    Bible. Could it match the wit of a human pun champion? I was about to find out
    at Punderdome, a regular pun contest that draws big crowds to a performance venue
    in Brooklyn. A skillful pun competition between two people sounds more like a
    conversation with a heaping dose of puns about a topic slipped in. In one YouTube
    video I watched the night before the event, two punners faced off on the topic
    of dog breeds. \u201CI found that some instruments you can carry with you everywhere.
    But a bass? Set it down,\u201D one said (basset, get it?). The other shot back:
    \u201CDoes that bass play a sharp A?\u201D (Shar Pei, obviously). I asked the
    chatbot for help. \u201CTell me a pun,\u201D I typed in. \u201CWhy was the math
    book sad? Because it had too many problems,\u201D it answered. More of a dad joke
    than a pun, I thought. It was the first of many times the bot would spit out that
    answer. My colleagues and I typed in different prompts, but struggled to get anything
    particularly witty. \u201CWord play about Kalamazoo\u201D returned snores such
    as \u201CKalamazoo: where history comes alive.\u201D How do the real punsters
    do it? Before Allison Fisher started competing at Punderdome under the name Rhyme
    & Punishment five years ago, she went to a coffee shop with a friend. They went
    back and forth practicing two-minute monologues the way they\u2019re done in the
    show. She won three times. \u201CIt\u2019s really all about noodling around the
    ideas in your head,\u201D said Ms. Fisher, who is a software engineer. \u201CAfter
    thinking for 15 seconds orzo, I\u2019ll take a penne to paper. I\u2019ll come
    up with a fu-silli ones.\u201D Emma Taylor Miller, who has a degree in drama and
    does some side work as an actor and clown, met her boyfriend when he introduced
    himself with a joke through an online dating website. \u201CDid you hear about
    the explosion at the French cheese factory? There was de-Brie everywhere.\u201D
    Her response: \u201CThat\u2019s a Gouda one.\u201D During the week before she
    competes under the stage name \u201CWhen Wit Hits the Fan,\u201D she plays a Punderdome
    card game that contains prompts to get the mind punning. Watching videos of pun-offs,
    it was clear that one key to designing a pun that would land was to start with
    the punny word and work your way back toward the setup. Would the robot know that?
    I had a little hope. Watson, the supercomputer built by\_International Business
    Machines\_Corp., managed to beat \u201CJeopardy!\u201D champions in 2011. \u201CIt\u2019s
    not trivia,\u201D Erika Ettin, aka Lexi Kahn, corrected me while we were waiting
    for the show to start. Fred Firestone co-founded the Punderdome in 2011. His daughter
    was a burgeoning comedian at the time and decided to run a pun competition, so
    she asked him for help. He flew in from St. Louis on a few days\u2019 notice.
    He has been doing so almost every month or two since, even after his daughter
    went on to other endeavors. I would be in his 135th Punderdome. When I called
    him on behalf of the robot, he was game for testing out its chops, so we designed
    an experiment. He sent my pun topic to my colleagues the afternoon before the
    show: cities and states. They asked ChatGPT to generate a bunch of puns and put
    them in a sealed envelope. Mr. Firestone told the audience of 250 about this unusual
    plan, and made clear I wasn\u2019t a ringer. My turn would be part of a one-off
    round separate from the night\u2019s competition. \u201CBen, just to be clear,
    brother,\u201D he asked me on stage, \u201CAre you a punner at all? You have any
    proclivities, any abilities in the punning arena, yes or no sir?\u201D \u201CAbsolutely
    not,\u201D I replied. The audience, apparently unthreatened by the robot overlords,
    let out some cheers. \u201CCome on, Ben!\u201D a few people shouted. \u201CWooh!\u201D
    A bit weak-kneed, I opened the envelope. I had 20 minutes during the intermission
    to read through the ChatGPT\u2019s results and select the best puns. I wrote them
    on a mini whiteboard, which was my only allowable prop. ChatGPT didn\u2019t have
    much to offer. \u201CIn Peoria, the corn is so sweet it\u2019s almost sinful.\u201D
    Huh? I wrote a few passable puns on the whiteboard along with some that were so
    bad that maybe they\u2019d draw chuckles. Next, I had to pick my competitor. Mr.
    Firestone invited up any past winners who wanted to participate. Quite a few rushed
    to the stage. \u201CAny other champs want a piece of this guy?\u201D Mr. Firestone
    asked. He asked me to choose who I wanted to play against. I figured, if I was
    going to lose, I might as well lose to the best. I chose Nikolai Vanyo, a writer
    and filmmaker who onstage goes by Daft Pun. He was one of the top three biggest
    winners ever. \u201CThis is for all of you humans,\u201D he told the crowd. The
    spotlights were on us as we took position at twin mics. We would be going back
    and forth in a pun-off for two minutes. I held my breath. \u201CI\u2019m not from
    the shore, but I Jersely know how to have a good time.\u201D The crowd chuckled.
    Why? I don\u2019t know. I was so nervous I transposed shore and Jersey. Mr. Vanyo
    shot back: \u201CI don\u2019t like to not drink. I hate to Miss-is-sippi.\u201D
    The crowd laughed louder. I had that state on my whiteboard. \u201COh, how I Mississi-thee,\u201D
    I said. The robot was vaguely getting the hang of it. Or was it? I found myself
    saying soon after: \u201CNew York City is the big apple. New Jersey is just another
    basket.\u201D \u201CWhat?\u201D someone from the audience shouted. I was so embarrassed,
    I felt the need to add: \u201CChatbot speaking.\u201D Mr. Vanyo was picking up
    steam: \u201CI was given the choice recently between a bag or a little mint\u2014a
    sack-or-a-Mento.\u201D (Say it again, slowly.) I decided to use the robot\u2019s
    best pun: \u201CWhat\u2019s the state where common sense is in short supply? Flori-duh.\u201D
    The crowd loved it. I was enjoying myself. I can\u2019t speak for the robot. A
    few more back-and-forths and our allotted two minutes expired. Mr. Firestone asked
    if we wanted to go for another minute. I had used up everything remotely punable.
    But the crowd started cheering. So I consented. \u201CGo ahead, My-ami,\u201D
    Mr. Vanyo said. I tossed out a random one I had jotted down last minute even though
    it wasn\u2019t actually a pun. \u201CBoise, where the potatoes are always hot
    and the people are always friendly,\u201D I said. \u201CI think between me and
    the robot, I-da-hoe here,\u201D he said. The robot never recovered. Once the time
    ran out, a designated audience member came out, put on a blindfold and wore a
    \u201Cclap-o-meter\u201D to judge which contestant got the most applause. The
    winner was obvious. I blamed my master, the robot, for giving me such thin material.
    The audience seemed sympathetic. \u201CYou just work here!\u201D someone shouted.
    \u201CI think I expected more from the bot,\u201D Mr. Vanyo told me the next day.
    He said he had been punning so long that he had come to see the structure as mechanical,
    something a robot could replicate. A spokeswoman for OpenAI, which created ChatGPT,
    pointed me to a blog post by a company employee that suggested a future in which
    creative endeavors could harness both the objectivity of AI and the personal narrative
    of humans. Perhaps the robot\u2019s assistant was the failure here. As it turned
    out, I wasn\u2019t the first one to try to get a computer to do my punning. Max
    Parke, a long time Punderdomer and software engineer, once tried to write a program
    that could get a computer to make puns. He gave up pretty quickly. He said that
    the best puns are the most surprising ones and it\u2019s hard for a computer to
    go off in different directions that it hasn\u2019t seen before. Ms. Miller said
    she thought maybe the computer didn\u2019t recognize how much words and language
    can be mutated when spoken. Ms. Fisher said she thought maybe the computer would
    have done better if it was fed transcripts of past Punderdomes. \u201CMaybe a
    computer can server up some good puns,\u201D Mr. Parke said. \u201CBut the ones
    I C? PU!\u201D (Sorry, just to explain, a central processing unit is the brains
    of a computer.)"
  tags: []
  title: I Entered a Pun Competition. My Jokes Were Written by an AI Chatbot.
- !!python/object:ai_sentiment.data.ClassificationTarget
  body: "In their search for new disease-fighting medicines, drug makers have long
    employed a laborious trial-and-error process to identify the right compounds.
    But what if artificial intelligence could predict the makeup of a new drug molecule
    the way Google figures out what you\u2019re searching for, or email programs anticipate
    your replies\u2014like \u201CGot it, thanks\u201D? That\u2019s the aim of a new
    approach that uses an AI technique known as natural language processing\u2014
    the same\_technology that enables\_OpenAI\u2019s ChatGPT to generate human-like
    responses \u2014to analyze and synthesize proteins, which are the building blocks
    of life and of many drugs. The approach exploits the fact that biological codes
    have something in common with search queries and email texts: Both are represented
    by a series of letters. Proteins are made up of dozens to thousands of small chemical
    subunits known as amino acids, and scientists use special notation to document
    the sequences. With each amino acid corresponding to a single letter of the alphabet,
    proteins are represented as long, sentence-like combinations. Natural language
    algorithms, which quickly analyze language and predict the next step in a conversation,
    can also be applied to this biological data to create protein-language models.
    The models encode what might be called the grammar of proteins\u2014the rules
    that govern which amino acid combinations yield specific therapeutic properties\u2014to
    predict the sequences of letters that could become the basis of new drug molecules.
    As a result, the time required for the early stages of drug discovery could shrink
    from years to months. \u201CNature has provided us with tons of examples of proteins
    that have been designed exquisitely with a variety of functions,\u201D says Ali
    Madani, founder of ProFluent Bio, a Berkeley, Calif.-based startup focused on
    language-based protein design. \u201CWe\u2019re learning the blueprint from nature.\u201D
    Protein-based drugs are used to treat heart disease, certain cancers and HIV,
    among other illnesses. In the past two years, companies including\_Merck\_& Co.,
    Roche Holding AG\u2019s Genentech and a number of startups like Helixon Ltd. and
    Ainnocence have begun to pursue new drugs with natural language processing. The
    approach, they hope, will not only boost the effectiveness of existing drugs and
    drug candidates but also open the door to never-before-seen molecules that could
    treat diseases like\_pancreatic cancer\_or\_ALS, for which more effective medicines
    have remained elusive. \u201CTechnologies like these are going to start addressing
    areas of biology that have been \u2018undruggable,\u2019\u201D says\_Sean McClain,
    founder and CEO of\_Absci\_Corp., a drug discovery company in Vancouver, Wash.
    Natural language processing for drug discovery still faces major hurdles, according
    to computational biologists. Tinkering too much with existing protein-based drugs
    could introduce unintended side effects, they say, and wholly synthetic molecules
    will require rigorous testing to make sure they\u2019re safe for the human body.
    But if the natural-language algorithms work as their adopters hope, they will
    bring new force to the promise of\_artificial intelligence to transform drug discovery.
    Previous attempts to use AI struggled with limitations in the technology or a
    lack of data. Recent\_advances in natural language processing\_and a dramatic
    drop in the cost of protein sequencing, which has yielded vast databases of amino-acid
    sequences, have largely overcome both problems, proponents say. With the technology
    still in the early stages, companies for now are focused on using protein-language
    models to enhance known molecules, such as to improve the efficacy of drug candidates.
    Given, say, a naturally occuring monoclonal antibody as a starting point, the
    models can recommend tweaks to its amino acid sequence to improve its therapeutic
    benefit. In a pre-print paper published online in August, researchers at Absci
    used this method to enhance the antibody-based cancer drug trastuzumab so that
    it binds more tightly to its target on the surface of cancer cells. A tighter
    bind could mean patients derive benefit from a lower dosage, shortening drug regimens
    and reducing side effects. In another paper published in March in the Proceedings
    of the National Academy of Sciences, researchers from MIT, Tsinghua University
    and Helixon, which is based in Beijing, used protein-language models to transform
    a Covid-19 drug candidate that\u2019s only effective against alpha, beta and gamma
    variants into one that could also treat delta. Ainnocence, a startup that spans
    the U.S. and China, helps clients use such models to modify animal proteins, such
    as antibodies from rabbits\u2014a common starting point for drug discovery\u2014into
    forms compatible with human physiology, according to the company\u2019s founder
    and CEO, Lurong Pan. But even now drugmakers are setting their sights beyond the
    modification of known proteins to so-called\_de novo\_design, the process of synthesizing
    molecules from scratch. Genentech says a recent experiment showed that it was
    possible to design an antibody to bind to the same cellular target as pertuzumab,
    a breast cancer drug on the market that Genentech sells under the brand name Perjeta,
    but with an entirely new amino acid sequence. Company scientists gave its protein-language
    models only the target and the antibody\u2019s desired three-dimensional shape\u2013the
    primary determinant of a protein\u2019s function\u2013says Richard Bonneau, a
    Genentech executive director who joined the company last year when it acquired
    his startup, Prescient Design. Absci and Helixon are also working with drugmakers
    to design medicines for cancer and autoimmune diseases using\_de novo\_methods.
    Absci announced a partnership in January with Merck to go after three drug targets,
    according to Mr. McClain. A Merck spokesman said the company has entered into
    a number of collaborations to explore the potential of artificial intelligence
    in drug development. Helixon last month signed with two big pharma companies to
    tackle previously undruggable diseases, CEO and founder Jian Peng says. \u201CAll
    the hard problems in drug discovery have been stuck there for a long time and
    have been waiting for a new wave of technology to solve it,\u201D says Ainnocence\u2019s
    Dr. Pan. \u201CThis is really a paradigm-shifting methodology.\u201D Ultimately,
    many computational biologists expect protein-language models to yield benefits
    beyond faster drug development. The same technique might be used to produce better
    enzymes for degrading plastics, treating wastewater and cleaning up oil spills,
    among other environmental applications, the biologists say. \u201CProteins are
    the workhorses of life,\u201D ProFluent Bio\u2019s Dr. Madani says. \u201CThey
    enable us to breathe and see, they enable the environment to be sustained, they
    enable human health and disease. If we can design better workers or new workers
    all together, that could have really wide-ranging applications.\u201D"
  tags: []
  title: How AI That Powers Chatbots and Search Queries Could Discover New Drugs
- !!python/object:ai_sentiment.data.ClassificationTarget
  body: "As companies increasingly use AI-powered chatbots to handle customer transactions,
    it remains to be seen how consumers feel about it. New research suggests that
    it may partly depend on whether consumers think they are getting a good deal.
    The research, published by the Journal of Marketing in February, found that if
    a company is offering a less-than-ideal price on a product or service, consumers
    tend to respond better in terms of increased purchase likelihood and satisfaction
    if an artificial-intelligence agent makes the offer. But if the price being offered
    is perceived as being good, consumers will respond better if the offer is presented
    by a human rather than a robot, because shoppers like getting favorable deals
    from real people. In one experiment, the researchers asked people to consider
    a deal for an aftermarket concert ticket, either from an AI agent or a human seller.
    The participants were informed that a similar ticket had been sold for either
    more, less, or the same price. Both AI and human sellers were then assigned to
    present the deals to participants. Another setup asked participants to consider
    the cost of an Uber ride to a restaurant for dinner. They were then offered a
    cheaper, more expensive, or similar-price ride home and were told it was coming
    from either a human or AI agent. In both scenarios, participants were more likely
    to accept a less-than-satisfactory offer if it came from a bot rather than a human.
    But with offers that exceeded consumers\u2019 expectations, the human agent had
    the edge. For a similar-price deal, it didn\u2019t matter whether an AI or human
    agent made the offer. Separately, the researchers explored whether changing the
    appearance of a bot affects how consumers respond to offers. They presented ride-share
    customers with photos of different-looking AI chatbots\u2014ranging from those
    that looked like real people down to robots with no human features. They found
    that the more humanlike an AI agent appeared, the more study participants would
    react to offers as if they were coming from a real person. The study\u2019s results
    stem from what the buyers think about the seller\u2019s intentions, according
    to\_Aaron Garvey, an associate professor of marketing at the University of Kentucky\u2019s
    Gatton College of Business and Economics and co-author of the study. People, he
    says, perceive that AI can\u2019t be greedy and isn\u2019t trying to take advantage
    of them, so they feel better about a worse-than-expected deal. A human making
    the same offer, however, is perceived as having bad intentions, making buyers
    want to avoid a purchase to punish them. By contrast, when a human presents a
    better-than-expected offer, buyers perceive this as another human being generous,
    improving the perception of the offer and the probability it will be taken, he
    says. In the paper, the researchers say their insights could apply to situations
    other than just price offers, such as when a company has something positive to
    communicate\u2014say, an expedited delivery, rebate or upgrade\u2014or something
    negative, such as an order cancellation, status change or product defect. Of course,
    there also is a danger that companies could use insights from the research to
    try to manipulate consumers into accepting worse-than-expected offers, the researchers
    say. \u201CI\u2019m not worried about AI,\u201D Dr. Garvey says. \u201CBut I am
    worried about if we have blind spots\u201D about it."
  tags: []
  title: Chatbots May Be Better When It Comes to Giving Consumers Bad News
