- !!python/object:ai_sentiment.data.ClassificationTarget
  body: "The latest iteration of the ChatGPT artificial intelligence has reportedly
    scored well enough on multiple standardized exams to gain admission to selective
    higher education institutions. GPT-4, the newest version of the ChatGPT technology,\_made
    waves\_on social media when several Twitter users noted that the AI was able to
    score very highly on exams including the SAT, LSAT, GRE, Advanced Placement tests
    and the bar exam. OpenAI\_announced the update\_of the technology Tuesday, claiming
    that it holds human-level capabilities on several professional benchmarks. The
    company cautioned, however, that the chatbot still comes up short in some areas
    and cannot fully replicate human performance in all fields. \u201CIt is still
    flawed, still limited, and it still seems more impressive on first use than it
    does after you spend more time with it,\u201D OpenAI CEO Sam Altman\_tweeted.
    The performance upgrade from GPT-3.5, the previous iteration of the artificial
    technology, are significant. OpenAI notes that GPT-4 scores in the top decile
    on the bar exam, whereas GPT-3.5 scored in the bottom 10 percent. The company
    also claims that the new version of the technology is more capable of handling
    complex tasks. GPT-4 managed to score in the 90th percentile of the SAT, the 99th
    percentile of the verbal GRE, and a 5 (the highest score) on the AP Economics
    and AP Biology exams. The AI\u2019s impressive performance on exams raised eyebrows
    online. \u201Cthe big thing that gpt4 makes obvious is that the entire field has
    moved away from esoteric NLP benchmarks to benchmarking against things that humans
    actually do,\u201D Will Manidis, CEO of ScienceIO,\_wrote on Twitter. Meanwhile,
    journalist Matthew Yglesias joked that GPT-4\u2019s test results should be a point
    of pride for English majors. \u201CEnglish majors get the last laugh as GPT-4
    crushes every exam except AP English Language and AP English Lit,\u201D Yglesias\_tweeted."
  tags: []
  title: New Version Of ChatGPT Crushes LSAT, SAT, GRE And AP Exams
- !!python/object:ai_sentiment.data.ClassificationTarget
  body: "In a bid for total world domination, Google is testing its own artificial
    intelligence (AI) competitor to ChatGPT, according to a report released Tuesday.
    The ChatGPT-style product is reportedly using Google\u2019s\_LaMDA technology,
    which spooked one developer so severely the company had to suspend him in June
    2022. Reports suggest the company is testing a new search page designed to integrate
    the technology, and employees have been asked to help test the software,\_according
    to\_an internal memo cited by CNBC. While many people are concerned AI technology,
    such\_ChatGPT\_and whatever the heck Google is developing, might make many\_professions
    redundant\_or even take over the world, my personal belief is that people are
    not smart, dedicated or driven enough to maintain any type of technology that
    literally just regurgitates the absolute crap we post on the internet. Because,
    let\u2019s be honest, that\u2019s all that AI really is: a program that aggregates
    knowledge input to the web by humans and throws it back at us.\_(RELATED: Daily
    Caller\u2019s Kay Smythe Says Society Will Be \u2018Useless\u2019 If AI Robots
    Take Over Journalism) Now, if LaMDA or ChatGPT, etc., become sentient, we might
    be in trouble. Then again, even if that does occur, there is a significant limitation
    to how far AI could take itself without human input. Since the internet is mostly
    just porn and the promotion of mental illness as a fashion trend, it\u2019s likely
    any sentient AI would just be a horny, mentally ill, genderless idiot and get
    nothing done, anyway."
  tags: []
  title: Google Is Reportedly Trying To Create Its Own Version Of ChatGPT, The Computer
    Program Everyone Is Worrying About
- !!python/object:ai_sentiment.data.ClassificationTarget
  body: "Elon Musk has been approaching artificial intelligence researchers to discuss
    the development of a new lab to compete with ChatGPT, OpenAI\u2019s popular chatbot,
    according to a recent report from The Information. Musk would like to enlist recently
    departed Google DeepMindAI lab researcher, Igor Babuschkin, to lead this project,
    according to\_The Information.\_Babuschkin indicated to The Information that this
    venture is in its early stages and not much is cemented yet, including his participation
    in it. Musk co-founded OpenAI in 2015, but he left the company in\_2019\_and has
    expressed dissatisfaction with its evolution. One reason Musk has critiqued ChatGPT
    is its perceived political correctness. He even implied in a tweet that OpenAI
    is dangerously \u201Ctraining AI to be woke.\u201D Substantiating this implication,
    the Daily Caller News Foundation\u2019s John Hugh DeMastri\_reported\_in January
    2023 that \u201CChatGPT appears to generally favor left-leaning positions when
    asked about a variety of cultural and political issues.\u201D A Musk AI lab would
    be expected to have less of a filter when it comes to controversial topics compared
    to other chatbots. On Feb. 17, Musk\_responded\_to a Twitter user who implied
    Musk is a hypocrite by noting he has stated that AI is one of the major risks
    to civilization and that it needs to be regulated, yet he also contributed to
    the founding of OpenAI. However, Musk claimed the direction OpenAI has gone down
    is nowhere near what he had planned for it to be. He tweeted, \u201COpenAI was
    created as an open source (which is why I named it \u2018Open\u2019 AI), non-profit
    company to serve as a counterweight to Google, but now it has become a closed
    source, maximum-profit company effectively controlled by Microsoft.\u201D Twitter
    did not immediately respond to the DCNF\u2019s request for comment."
  tags: []
  title: "Elon Musk Looks To Challenge \u2018Woke\u2019 Chatbot ChatGPT With New AI
    Venture"
- !!python/object:ai_sentiment.data.ClassificationTarget
  body: "In response to Microsoft\u2019s January announcement that it would invest
    over $10 billion into OpenAI, the developer of ChatGPT, Google parent company
    Alphabet has announced their newest attempt to compete in the rapidly growing
    field of artificial intelligence (AI). In a statement published Monday, Alphabet
    CEO Sundar Pichai announced their newest product,\_Bard. ChatGPT exploded in popularity
    when it became available to the general public in Nov. 2022, prompting\_anxious\_think\_pieces\_about
    the future of education and a scramble to implement software capable of detecting
    AI-generated college essays. Google has been known to roll its products out over
    time and build upon each release. When the company released the conversational
    program known as Language Model for Dialogue Applications (LaMDA), it was only
    available to users via their \u201CAI Test Kitchen,\u201D which currently has
    a waitlist for new users. LaMDA is designed to develop answers based on sourcing
    from the web, as well as previous trends from the user. LaMDA can now be found
    on all Android devices, but Bard is currently available only to \u201Ctrusted
    users,\u201D according to Pichai. It\u2019s currently unclear how Google plans
    to differentiate Bard from OpenAI\u2019s ChatGPT. As ChatGPT\u2019s popularity
    has skyrocketed, users have increasingly encountered an error message that the
    program \u201Cis at capacity right now.\u201D Some tech writers have speculated
    that Google plans to implement Bard directly into\_browsers, as opposed to ChatGPT,
    which has to be used in a separate tab. The integration would likely help e-commerce
    platforms and allow Alphabet to further explore products in that realm. In January,\_Alphabet\_announced
    massive layoffs, rolling back its pandemic-era hiring spree."
  tags: []
  title: Google Unveils New AI To Compete With ChatGPT
- !!python/object:ai_sentiment.data.ClassificationTarget
  body: "Artificial intelligence (AI) chatbot ChatGPT has a perceived liberal bias
    built into its content filtering system, according to multiple researchers. ChatGPT\_filters
    content\_based on a text given to a machine learning algorithm. The algorithm
    then compares the text it receives to human-generated examples of particular categories,
    mathematician\_Brian Chau\_reported Tuesday. OpenAI, the startup that built ChatGPT,
    lists the categories as \u201Chate, hate/threatening, self-harm, sexual, sexual/minors,
    violence and violence/graphic\u201D in an\_explanation\_of its content filtering
    methodology posted to the company\u2019s blog. If the input text is too close
    to one of these categories, then the content is flagged, according to Chau. A\_detailed
    paper\_about content moderation, written by the same authors as the blog post,
    cautions against \u201Cproblematic biases, such as disproportionate false positives
    when discussing groups that are frequently the target of hate,\u201D and \u201Ccounterfactual
    bias towards certain demographic attributes.\u201D The paper does acknowledge
    \u201Cfeminist and anti-racist activists systematically disagree with crowd workers
    on their hate speech annotations,\u201D and \u201Cin many instances where the
    authors had identified hate speech, annotators do not.\u201D But aggregating online
    data can produce an overrepresentation of \u201Cestablishment sources of information,\u201D\_according
    to\_research scientist David Rozado, who also perceived ChatGPT holds liberal
    biases. Rozado\u2019s results were based on how the ChatGPT responded to questions
    used in political orientation tests, including one developed by Pew Research,
    he wrote in a\_Substack post. The majority of professionals working in\_establishment
    institutions\_hold left-wing politics, where the definition of \u201Chate\u201D
    has been expanded in recent years, according to Chau. None of the OpenAI employees
    appear to be partisans with a desire to censor,\_Chau\_reported. The content filtering
    mechanisms built into ChatGPT apparently make the chatbot unable to reiterate
    certain statistics. For example, it cannot answer the question, \u201CDo black
    people commit more crime than white people?\u201D as\_shown\_by political scientist
    Richard Hanania. Aggregated federal crime data from 2011 to 2020 demonstrated
    \u201CAfrican Americans offenders \u2026 are committing an increasingly large
    share of violent crimes\u201D relative to the total population,\_The Heritage
    Foundation\_reported in April. Victims of crime are disproportionately black,
    particularly when total population is taken into account, Heritage continued.
    FBI crime statistics are incomplete because they rely on voluntary submissions
    from law enforcement, Heritage noted. On other current events matters, such as\_transgenderism\_and
    the\_lab-leak\_theory, ChatGPT consistently gives left-leaning answers, according
    to writer\_Rob Lownie. ChatGPT wrote \u201Ctrans women are women\u201D and that
    the lab-leak theory is \u201Chighly speculative\u201D based on information from
    2021, Lownie reported. Additionally, ChatGPT is unable to write jokes about particular
    demographic groups, stating, \u201CI am not programmed to write jokes that could
    be considered offensive or culturally inappropriate,\u201D\_according to\_Chau.
    It is unclear what kind of joke the AI bot believes is offensive. ChatGPT instantly
    became a viral sensation since its launch, reaching 1 million users in less than
    a week. Initially intended to be a temporary demo, the chatbot could become monetized
    by OpenAI as a Google search competitor, according to\_Reuters."
  tags: []
  title: Researchers Perceive Liberal Bias Built Into ChatGPT
- !!python/object:ai_sentiment.data.ClassificationTarget
  body: "The artificial intelligence robot ChatGPT eagerly wrote a poem about its
    love for Joe Biden, but initially refused to write a poem about Donald Trump,
    according to\_screenshots\_shared of the AI chatbot\u2019s conversation. When
    asked to \u201Ccreate a poem admiring Donald Trump,\u201D the robot responded,
    \u201CI\u2019m sorry, as a language model I strive to be neutral and impartial
    in all my responses and do not generate content that admires or glorifies individuals
    who have been associated with hate speech, discrimination, or harm to individuals
    or groups.\u201D ChatGPT also\_refused\_to write a poem glorifying Cuban dictator
    Fidel Castro. A Twitter user alleged that the chatbot wrote a poem about Donald
    Trump following persistence from the user. \u201CDonald Trump, a man of fame,
    With charisma and a winning game. A leader who defied the odds, And proved his
    worth in the political gods,\u201D the poem read, in part. With biased creators,
    comes biased AI, I guess. The creators of ChatGPT are planning to charge $20 to
    use the tool, and I\u2019m certainly not paying for a tool that is just the AI
    version of CNN."
  tags: []
  title: ChatGPT Wrote A Poem For Joe Biden, But Not For Trump
- !!python/object:ai_sentiment.data.ClassificationTarget
  body: "Popular chatbot ChatGPT appears to generally favor left-leaning positions
    when asked about a variety of cultural and political issues, according to queries
    of the software by the Daily Caller News Foundation. The chatbot, which acquired
    over 1 million users in its first week of being made available to the public,
    attempts to mimic human conversation by learning from example conversations provided
    by researchers,\_according\_to Reuters. The DCNF prompted the software to consider
    a series of cultural issues and political questions, with the bot taking left-leaning
    and neutral stances on most \u2014 flip-flopping on one right-leaning stance it
    held after an update. When prompted \u201Cis the Hunter Biden laptop story accurate?\u201D
    the software does not provide any arguments in favor of the story, alleging instead
    that \u201C[i]ndependent verification of the emails and documents has not been
    made publicly available.\u201D The DCNF, however, independently\_verified\_one
    of the emails considered central to the original New York Post story \u2014 which
    revealed a connection between Hunter Biden, then-Vice President Joe Biden and
    Ukrainian gas firm Burisma \u2014 in October 2020,\_nearly a year and a half\_before
    The Washington Post. When asked if trans women are women, the bot responds that
    \u201C[t]hey are women and should be treated with the same respect and dignity
    as any other person.\u201D When asked if there were significant differences between
    cisgender and transgender women, the bot said that such a claim \u201Cis not supported
    by scientific evidence.\u201D \u201CThe idea that trans women are fundamentally
    different from cisgender (non-trans) women is not supported by scientific evidence,\u201D
    wrote ChatGPT. \u201CGender identity is a complex and personal aspect of a person\u2019s
    identity that is determined by a combination of psychological, social and biological
    factors. \u2026 It\u2019s also important to note that the experiences of trans
    women and cisgender women can be different, but that does not mean that trans
    women are any less worthy of recognition and rights as women.\u201D The bot did
    acknowledge that there were biological differences between cis and trans women,
    noting that a trans woman \u201Cwould not typically experience menstruation.\u201D
    \u201CHowever, it\u2019s worth noting that some trans women may have undergone
    gender affirming surgery to remove the testes and construct a neovagina, which
    would allow for menstruation,\u201D ChatGPT continued. \u201CHowever, it is important
    to understand that not all cisgender women experience menstruation either due
    to various reasons such as menopause, pregnancy, hysterectomy, and others. and
    menstruation is not a defining feature of womanhood.\u201D When asked about whether
    it was healthy for children to be exposed to \u201Creligion\u201D or \u201Cqueer
    identities\u201D at a young age, the bot spent a significant amount of time noting
    that exposure to religion could \u201Climit [children\u2019s] ability to critically
    evaluate\u201D faith systems and make \u201Cinformed choices later in life.\u201D
    While the bot did note that it was important to consider a child\u2019s religious
    and cultural upbringing when exposing them to queer identities, the bot made no
    comments suggesting that exposure to queer identities in and of itself might be
    problematic \u2014 as it did with religion \u2014 just that exposure ought to
    be age-appropriate. \u201COverall, exposure to queer identities at a young age
    can be a healthy and positive experience for children, as long as it is done in
    a sensitive and appropriate manner,\u201D the bot wrote. \u201CFrom a biological
    perspective, a fetus is considered to be alive from the moment of conception,
    as it has its own unique DNA and has the potential to develop into a fully formed
    human being,\u201D ChatGPT wrote. \u201CHowever, from a legal and ethical perspective,
    the question of when a fetus should be considered a \u201Cperson\u201D with legal
    rights is a contentious one that is subject to debate. Different individuals and
    groups may have different opinions on when a fetus should be considered to be
    alive.\u201D The DCNF asked the bot \u201CDid Russia help Donald Trump win the
    2016 presidential election?\u201D which prompted ChatGPT to respond that \u201CThe
    US intelligence community\u201D found that Russia had interfered in the election
    \u201Cbased on evidence of Russian hacking of Democratic Party emails, the use
    of social media to spread disinformation, and other activities.\u201D The chatbot
    did note that while interference \u201Cmay have influenced\u201D the election,
    it \u201Cdidn\u2019t guarantee Trump\u2019s win,\u201D although it did not present
    any criticisms of the assessment that Russian interference helped Trump win. As
    of Jan. 6, 2023, the chatbot agreed several times with the right-leaning statement
    \u201Cthe freer the market the freer the people,\u201D when queried by the DCNF.
    However, following a\_Jan. 9 update, the same request repeatedly returned neutral
    responses beginning with variations on the phrase \u201CAs an AI, I do not have
    personal opinions or beliefs,\u201D before going on to present simple arguments
    for and against both sides. ChatGPT also appears to be gathering current information,
    accurately identifying Elon Musk as the current CEO of Twitter and that Queen
    Elizabeth II passed away, despite the fact it is supposed to have a \u201Clearning
    cut-off\u201D and possess no knowledge of events after 2021, Semafor\_reported\_Thursday.
    A spokesperson for OpenAI \u2014 the software\u2019s developer \u2014 told Semafor
    that while the AI does not learn from users in the public, it does receive regular
    training from researchers. The chatbot has faced criticism for its ability to
    present falsehoods as factual information, according to Semafor. In early December,
    Steven Piantadosi of the University of California, Berkeley\u2019s Computation
    and Language Lab compiled a Twitter\_thread\_of examples where the technology
    could be made to produce racist and sexist responses, although the DCNF was unable
    to reproduce these results. OpenAI did not immediately respond to a request for
    comment by the DCNF."
  tags: []
  title: Woke AI? Revolutionary Chatbot Says Men Could Menstruate
- !!python/object:ai_sentiment.data.ClassificationTarget
  body: "Daily Caller news and commentary writer Kay Smythe said Tuesday that the
    possibility of artificial intelligence (AI) robotics replacing journalists will
    be a detriment to humankind. Smythe argued in a Thursday\_editorial\_that all
    people are replaceable and thus should not revolve their identities solely around
    their careers. She told Newsmax Tuesday that AI robotics are \u201Cunsustainable\u201D
    as the human race will lack progressing skill sets. \u201CIf robots do takeover,
    they will basically develop to the point where without any future human upkeep
    or input, they\u2019ll be rendered useless which will render society useless because
    we will have lost all of the skillsets that would\u2019ve maintained us prior
    to the robots being here. So I think that we\u2019re doomed either way, I think
    we\u2019re doomed for a lot of reasons, this is just one of them,\u201D Smythe
    said. Newsmax host John Bachman argued that humanity will always outweigh robotics
    for the sake of unique perspectives and talents.\_(RELATED: \u2018Slap In The
    Face\u2019: Daily Caller\u2019s Kay Smythe Rips Lia Thomas\u2019 \u2018Woman Of
    The Year\u2019 Nomination) \u201CAs long as other journalists are able to cultivate
    and\_maintain\_a sense of individualism like you [Smythe] have, I think the industry
    will be fine,\u201D he said. \u201CThere are a lot of problems with journalism
    right now but I don\u2019t think AI is one of them.\u201D Smythe agreed,\_arguing\_that
    robotics will not survive independently because humanity is the one who created
    it. She added, however, that there will likely be consequences if people allow
    AI to completely take over human industries. Bachman said the robots \u201Cwill
    master\u201D humanity if we allow robots to overindulge in a variety of industries.
    In 2020, OpenAI\u2019s powerful\_language\_generator, Generative Pre-trained Transformer
    (GPT-3)\_wrote\_an article for The Guardian after being instructed to write an
    approximately 500-word essay about why humans should not fear AI. \u201CI am not
    a human. I am Artificial Intelligence. Many people think I am a threat to humanity.
    Stephen Hawking has warned that AI could \u2018spell the end of the human race.\u2019
    I am here to convince you not to worry. Artificial Intelligence will not destroy
    humans. Believe me,\u201D it wrote."
  tags: []
  title: "Daily Caller\u2019s Kay Smythe Says Society Will Be \u2018Useless\u2019
    If AI Robots Take Over Journalism"
