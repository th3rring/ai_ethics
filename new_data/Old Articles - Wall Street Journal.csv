Title,Link,Body,Date,Notes,Author
OpenAI Rolls Out New GPT-4 Version of Chatbot ChatGPT,https://www.wsj.com/articles/openai-rolls-out-updated-version-of-viral-chatbot-chatgpt-f03fea27?mod=Searchresults_pos3&page=1,"The company behind the viral chatbot ChatGPT launched a new version of its artificial intelligence technology on Tuesday, saying it was more powerful and predictable than previous versions and capable of analyzing images and handling much larger blocks of text. The announcement from OpenAI—a startup backed by billions of dollars from Microsoft Corp.—is the latest in a string of generative AI announcements as companies try to get ahead in the race to build and use the buzzy new technology. Many regulators, scholars and activists have urged tech companies to exercise more caution in developing the tools which haven’t yet been fully tested. Generative AI technology—special because it can generate original images, text and other content from basic language prompts—sometimes produces responses that seem unhinged and contain made-up facts or racist and sexist statements. OpenAI says its updated chatbot is ‘more creative and collaborative’ than previous versions, when it comes to tasks such as composing songs or writing screenplays. In a blog post on Tuesday, OpenAI introduced a more powerful version of the technology behind ChatGPT called GPT-4. The updated chatbot is “more creative and collaborative” than previous versions when it comes to tasks like composing songs or writing screenplays, the blog said. The company is rolling out the technology starting Tuesday through data-sharing partnerships, which companies including Morgan Stanley and Duolingo Inc. are paying to access. It will also be offered to ChatGPT Plus subscribers, who pay $20 a month for faster and more available service. It isn’t yet available to those who use the free service. In an online presentation Tuesday, OpenAI demonstrated how the tool could be used to do things like explain obscure tax codes or summarize articles into sentences with every letter beginning with Q. OpenAI said it can now better analyze images for information. For example, users can use it to scan a picture of ingredients and then get suggestions of potential dishes and recipes that could be made from the ingredients. The ability to analyze images hasn’t yet been widely rolled out, a spokeswoman said. GPT-4 makes fewer mistakes than its predecessor, GPT 3.5, but it still works best when used in tandem with people who can check its work, said OpenAI president and co-founder Greg Brockman at the presentation. “It isn’t perfect but neither are you and together it’s this amplifying tool that lets you just reach new heights,” he said. When OpenAI used the latest version of the technology on standardized exams—including the LSAT and the Uniform Bar Exam—it did much better than most people and better than the previous version. It still struggled with English language and literature tests, according to company data. Tech company executives who have been able to test the chatbot ahead of Tuesday’s launch said the latest version by OpenAI looks like an impressive upgrade. “GPT3 or 3.5 felt like a sixth-grader, whereas 4 feels like a smart 10th-grader,” said Keith Peiris, co-founder of the AI startup Tome, which creates presentation tools and has been testing GPT-4. He says the new version can analyze 25 pages of text compared with three pages in earlier iterations. GPT-4’s improvement in math and problem-solving will damp criticism about accuracy, Oppenheimer analyst Timothy Horan said in a research note. Several other companies announced big AI plans recently. Microsoft has integrated AI into its Bing search engine and this week is scheduled to outline how it is going to bring it to its most-popular software including Word, Excel and PowerPoint. Alphabet Inc.’s Google has introduced some AI-powered writing features in Docs and Gmail services to help people start writing. Anthropic, an OpenAI competitor, made its chatbot Claude more broadly available on Tuesday as well. Microsoft has integrated AI into its Bing search engine and is expected to outline how it is going to bring it to its Word and Excel software. Technology companies have been hyping up the possibilities of generative AI since OpenAI released its image generation tech Dall-E 2 to the public last year. Dall-E 2 can create original images based on simple prompts. It released ChatGPT in November allowing millions of people to play around with it to generate everything from business plans to limericks. Artificial intelligence analysts warn there are still potential problems with generative AI. While ChatGPT and other text generators are accurate on topics where they have ingested high-quality information, on other topics, they are capable of spewing out racist and sexist answers as well as misinformation and conspiracy theories. ChatGPT can also be expensive to run and slow. Some of the first people testing Bing with AI got unhinged responses and factual mistakes. Microsoft has updated the search engine and the rules on how it can be used since then to try to improve outcomes. OpenAI consulted with more than 50 experts in AI, safety and security to develop GPT-4, the company said in a blog post, adding that GPT-4 is 82% less likely to respond to requests for “disallowed content” and 40% more likely to return accurate responses than GPT-3.5. It may be too early to judge the technology as it has yet to be tested widely in the real world, said Steven Weber, a professor at the University of California, Berkeley, who specializes in international business and information security “How it will actually function in the wild could be quite different, as we’ve seen with prior releases,” he said.",,,MISSING
Bosses Are Catching Job Applicants Using ChatGPT for a Boost,https://www.wsj.com/articles/if-chatgpt-writes-your-cover-letter-is-it-cheating-some-bosses-think-so-b62454ba?mod=Searchresults_pos5&page=1,"It was an unexpected problem. Earlier this year, Christina Qi, the chief executive of market data company Databento, noticed almost every job application included exactly what she was looking for. The company prompts candidates to write a tweet and a press release about microwave towers, a niche topic that requires research, Ms. Qi said. Normally, most candidates fail the test. This time all five passed. The tests—four from internship applicants and one from someone seeking a full-time content strategist role—were all so similar, “as if it was written by one person,” she said. Suspicious, Ms. Qi put the prompt into ChatGPT, the artificial-intelligence chatbot from OpenAI, to see what it could produce. A weekly digest of tech reviews, headlines, columns and your questions answered by WSJ's Personal Tech gurus. “Lo and behold, I got pretty much the same answer that all five candidates had submitted to me,” she said. Since its launch in November, ChatGPT has been a hot topic at dinner tables and water coolers. Microsoft, Google, Snap and other companies have incorporated artificial intelligence into their products. People have experimented with using ChatGPT at work. Some have even started using it when looking for new roles, tapping the chat assistant to help write cover letters, tweak résumés and formulate responses to anticipated interview questions—without necessarily telling the people doing the hiring. Employers, who have long used AI to screen potential employees, aren’t always disqualifying applicants who use ChatGPT, but they are scrambling to figure out how to assess candidates who may be using the tool to give them an edge. Attention-grabbing applications After being let go by his previous employer in January, Kyle Mickey started job hunting for roles in software engineering—alongside thousands of laid-off tech workers. The 38-year-old from Colorado said he turned to ChatGPT for help, first sharing job descriptions and his résumé with the chatbot to see what it would tweak. Then he asked ChatGPT to write a recommendation letter for a role he coveted. The chatbot deemed him perfect for the job, as his technical skill set “aligns well with the requirements.” Mr. Mickey sent the remarks to a recruiter, saying ChatGPT endorsed his skills. “The recruiter was immediately like, ‘Let’s chat, I like the creativity,’ ” he said. Mr. Mickey didn’t get that job, but was hired at another company without ChatGPT’s help. Ryan Stringham, 31, who lives in Utah and works in product management, used it to help write cover letters, including one that got him a foot in the door, and later hired, at a smart-tech company. “You’re always looking, you’re always applying and you’re getting drained,” Mr. Stringham said of job hunting. He said the bot broke his writer’s block, distilling his long-winded cover letter into four tight paragraphs. He said it also helped him prepare for job interviews by suggesting new ways for him to ask about company culture and expectations for the role. Instead of asking a vague question about what he should do to excel at the prospective job, ChatGPT suggested Mr. Stringham be more specific about the time frame and metrics for determining success. Mr. Stringham has encouraged others to use chatbots in the job-hunt process, posting about them on LinkedIn and giving advice to other job seekers. The only place he hasn’t disclosed his ChatGPT use: at work. “It helped me get past the application process, and the recruiter never asked about it,” Mr. Stringham said, adding that he edited the cover letter himself and aced the interviews on his own. Microsoft is combining the tech behind OpenAI’s ChatGPT with its Bing search engine. In an interview, WSJ’s Joanna Stern spoke with Microsoft CEO Satya Nadella about the new tools and how AI is going to change search. (Oh, and Clippy!) Photo illustration: Preston Jessee for The Wall Street Journal ‘How we present ourselves’ Programs, websites and other tools to help people fix their résumés and cover letters aren’t new. Microsoft Office and Google Docs offer résumé and letter templates, while companies such as Jobscan promise to optimize résumés to grab the attention of hiring managers, recruiters and hiring-system algorithms. Candidates need to combine ChatGPT’s edits with their own editing and voice, said Sarah Baker Andrus, chief executive of Avarah Careers, a career coaching firm in Delaware. Whatever a candidate submits for a job should accurately reflect their skills, she said. “We’re responsible for how we present ourselves,” Ms. Andrus said. “If you decide to use ChatGPT, it’s worthwhile to ask, ‘Is that representing the me that I want to present?’ ” Employers are already finding ways to catch applicants who cheat with AI. Engineers applying to San Francisco-based Cobalt Robotics take part in a remote one-hour coding interview where they are paired with an employee to test collaboration and problem-solving skills. If candidates need more than an hour, they can finish on their own, but a screening program called CoderPad tracks their work. Last month, one candidate went from showing no work in CoderPad to suddenly having a complete solution, said Erik Schluntz, Cobalt Robotics’s chief technology officer and co-founder. He suspected the applicant had sought AI assistance and then copied and pasted its response. The company declined to move forward with the candidate without telling the person why, though Mr. Schluntz tweeted about it. Mr. Schluntz said Cobalt can’t properly evaluate candidates who use AI helpers today, but said he can envision giving applicants more challenging tasks in the future if they want to use tools like ChatGPT as an assistant. “Giving a problem to someone that ChatGPT can solve doesn’t assess someone—it just assesses ChatGPT,” Mr. Schluntz said. About a week after first spotting the AI-boosted applications, Ms. Qi started letting potential Databento hires use ChatGPT. The new prompt requires candidates to perform additional research and make edits to supplement what the AI tool spits out, and Databento gives “extra points” to people who complete the test bot-free. Though Ms. Qi said she can usually spot when something was written by ChatGPT, the company also enlists the aid of a bot detector. “It’s better to be ahead of the game and accept that people are using this rather than try to deny it,” Ms. Qi said.",,,MISSING
What Is ChatGPT? What to Know About the AI Chatbot,https://www.wsj.com/articles/chatgpt-ai-chatbot-app-explained-11675865177?mod=Searchresults_pos8&page=1,"The release of OpenAI’s ChatGPT late November triggered a new global race in artificial intelligence. In March, the company’s AI model, GPT-4, which it used to update ChatGPT’s capabilities, upped the stakes even more. The chatbot is part of a wave of so-called generative AI—sophisticated systems that produce content from text to images—that has shaken up Big Tech and is set to transform industries and the future of work. Microsoft Corp., OpenAI’s strategic partner, has already added the technology across its products, including the MS 365 Suite and search engine Bing. Competitor Google unveiled a similar search tool on Feb. 8, while Chinese tech giant Baidu debuted its own on March 16. Despite its sudden burst in popularity, the technology currently has serious limitations and potential risks that include spewing misinformation and infringing on intellectual property. A weekly digest of tech reviews, headlines, columns and your questions answered by WSJ's Personal Tech gurus. Here’s what to know. What is ChatGPT? ChatGPT is an artificial-intelligence chatbot developed by San Francisco-based AI research company OpenAI. Released in November 2022, it can have conversations on topics from history to philosophy, generate lyrics in the style of Taylor Swift or Billy Joel, and suggest edits to computer programming code. In March 2023, OpenAI said it would upgrade it to also handle visual information, such as answering questions about the contents of a photo. ChatGPT is trained on a vast compilation of articles, images, websites and social-media posts scraped from the internet as well as real-time conversations—primarily in English—with human contractors hired by OpenAI. It learns to mimic the grammar and structure of writing and reflects frequently used phrases. It also learns to recognize shapes and patterns in images, such as the contours of a cat, a child or a shirt. It can match words and phrases to those shapes and patterns as well, allowing users to ask about the contents of an image, such as what a cat is doing or the color of the shirt. The chatbot isn’t always accurate. Its sources aren’t fact-checked, and it relies on human feedback to improve its accuracy. It may also misjudge the objects in a painting or photo. OpenAI developed ChatGPT as part of a strategy to build AI software that will help the company turn a profit. In January, Microsoft unveiled a fresh multibillion-dollar investment in OpenAI and has since integrated the chatbot’s underlying technology into its Bing search engine and other products. In March, OpenAI said it would no longer open-source the technical details of its systems, as it had originally stated in its founding principles, to maintain its competitive advantage. How do ChatGPT and other AI chatbots work? The technology that underlies ChatGPT is referenced in the second half of its name, GPT, which stands for Generative Pre-trained Transformer. Transformers are specialized algorithms for finding long-range patterns in sequences of data. A transformer learns to predict not just the next word in a sentence but also the next sentence in a paragraph and the next paragraph in an essay. This is what allows it to stay on topic for long stretches of text. Because a transformer requires a massive amount of data, it is trained in two stages: first, it is pretrained on generic data, which is easier to gather in large volumes, and then it is fine-tuned on tailored data for the specific task it is meant to perform. ChatGPT was pretrained on a vast repository of online text to learn the rules and structure of language; it was fine-tuned on dialogue transcripts to learn the characteristics of a conversation. Developed by researchers at Alphabet Inc.’s Google in 2017, transformers have since become pervasive across dozens of technologies. They have also been the source of controversy for their large data and computational needs, concerns that led Google for years to take a more cautious approach to AI, though it continued to cultivate the technology. Google now uses transformers in its new experimental service Bard, which gives users conversational answers to their search queries. Baidu BIDU 2.27%increase; green up pointing triangle uses them in its own ChatGPT equivalent, Ernie Bot, which it started rolling out to a limited pool of users on March 16 and plans to integrate into its search engine. Transformers, which can be trained on images or images and captions simultaneously, are also the basis of image-generation software systems such as OpenAI’s Dall-E 2 and Stability.ai’s Stable Diffusion. How much does ChatGPT cost? ChatGPT is free. OpenAI released the chatbot as a research preview and users can try it through a dedicated website. On Feb. 1, OpenAI also launched a premium version for $20 a month, starting in the U.S., that will give subscribers priority access. Both Microsoft and OpenAI plan to release an API, or application programming interface, allowing companies to integrate the technology into their products or back-end solutions. Microsoft’s API will be available through its Azure cloud-computing platform. Both companies already offer OpenAI’s earlier AI technologies. How are people and businesses using ChatGPT? Business people across industries and hierarchy have rushed to experiment with the tool to speed up their work, from drafting emails and marketing campaigns to generating ideas to solve a software coding problem. Media companies including BuzzFeed and the publisher of Sports Illustrated have announced plans to generate content such as quizzes and articles with ChatGPT. Some schools have blocked access to the service on their networks to stave off cheating, while others are actively encouraging students to use the tools ethically. Keep in mind that OpenAI has access to your inputs and outputs for ChatGPT and its employees and contractors may read them as part of improving the service. Avoid providing private data or sensitive company information. Other generative AI technologies such as Dall-E 2 and avatar-generator Lensa have become popular with internet users for producing fantastical images and illustrations, and are finding use among independent writers to create artwork for their articles. What are the pitfalls of AI chatbots? AI chatbots and other generative AI programs are mirrors to the data they consume. They regurgitate and remix what they are fed to both great effect and great failure. Transformer-based AI program failures are particularly difficult to predict and control because the programs rely on such vast quantities of data that it is almost impossible for the developers to grasp what that data contains. ChatGPT, for example, will sometimes answer prompts correctly on topics where it ingested high-quality sources and frequently conversed with its human trainers. It will spew nonsense on topics that contain a lot of misinformation on the internet, such as conspiracy theories, and in non-English languages, such as Chinese. Early user tests of Microsoft’s conversational AI Bing service have also shown that its comments can start to become unhinged, expressing anger, obsession and even threats. Microsoft said it discovered that Bing starts coming up with strange answers following chat sessions of 15 or more questions. Meanwhile, some artists have also said AI image generators plagiarize their artwork and threaten their livelihoods, while software engineers have said that code generators rip large chunks of their code. For the same reasons, ChatGPT and other text generators can spit out racist and sexist outputs. OpenAI says it uses humans to continually refine the chatbot’s outputs to limit these mishaps. It also uses content-moderation filters to restrict ChatGPT’s responses and avoid politically controversial or unsavory topics. Ridding the underlying technology of bias—which has for years been a recurring problem, including for an infamous Microsoft chatbot in 2016 known as Tay—remains an unsolved problem and a hot area of research. “ChatGPT is incredibly limited, but good enough at some things to create a misleading impression of greatness,” tweeted OpenAI Chief Executive Sam Altman shortly after the chatbot’s release, adding that it is “a mistake to be relying on it for anything important right now.” What is Microsoft’s relationship to OpenAI? Microsoft is OpenAI’s largest investor and exclusively licenses its technologies. The tech giant invested $1 billion into the AI startup in 2019, an undisclosed amount in 2021 and an additional amount of up to $10 billion in January, according to people familiar with the latest deal. Under the agreement, Microsoft can use OpenAI’s research advancements, including GPT-4 and ChatGPT, to create new or enhance existing products. It is the only company outside of OpenAI that can provide an API for these technologies. Is AI going to replace jobs? As with every wave of automation technologies, the latest will likely have a significant impact on jobs and the future of work. Whereas blue-collar workers bore the brunt of earlier waves, generative AI will likely have a greater effect on white-collar professions. A 2019 study from the Brookings Institution found that AI would most affect jobs such as marketing specialists, financial advisers and computer programmers. Those effects will be mixed. Economists who study automation have found that three things tend to happen: Some workers improve their productivity, some jobs are automated or consolidated, and new jobs that didn’t previously exist are also created. The final scorecard is difficult to predict. In company-level studies of automation, researchers have found that some companies that adopt automation may increase their productivity and ultimately hire more workers over time. But those workers can experience wage deflation and fewer career-growth opportunities. Newly created jobs often go one of two ways: They either require more skill, or a lot less, than the work that was automated. Self-driving cars, for example, create new demand for highly skilled engineers but also for low-skilled safety drivers, who sit in the driver’s seat to babysit the vehicle.",,,MISSING
Baidu Hurries to Ready China’s First ChatGPT Equivalent,https://www.wsj.com/articles/baidu-scrambles-to-ready-chinas-first-chatgpt-equivalent-ahead-of-launch-bf359ca4?mod=Searchresults_pos9&page=1,"A week away from the March 16 launch of Baidu Inc.’s BIDU 2.27%increase; green up pointing triangle ChatGPT equivalent, employees at China’s biggest search-engine operator said they are racing to meet the deadline with the chatbot still struggling to perform some basic functions. To develop the artificial-intelligence-powered chatbot, dubbed Ernie Bot, hundreds of people have been working around the clock, people familiar with the project said. Other teams have been asked to lend their staff and their powerful computer chips, which Chinese companies can no longer buy because of U.S. sanctions, they said. The AI model that is the basis of the chatbot is still being trained with data ahead of the scheduled launch, a highly anticipated event in China’s tech industry, some of the people said. Some employees said they haven’t had sufficient time to build a well-functioning product. Baidu plans to roll out the product in stages, first opening it up for public testing to a restricted pool of users, people briefed about the plan said. Last month, Baidu said that it will embed Ernie Bot into its search engine first and will open it to the public in March. Baidu CEO Robin Li has said to employees, ‘We have such cool technology, but can we turn it into a product that everyone needs?’ Baidu’s American depositary receipts fell 7.5% in Thursday trading. The broader Nasdaq Golden Dragon China Index dropped 5.4%. The rush reflects how Baidu is taking a calculated gamble to get ahead of Chinese rivals that have recently announced similar plans. The company said it has signed agreements with more than 400 Chinese companies, which will be able to use Ernie Bot in their products and services. In return, the chatbot will gain experience running under different scenarios to help improve its performance, Baidu has said. A successful launch could help catapult the company, which has fallen out of investor favor in recent years, back into the ranks of China’s most prominent technology companies. Failure could lead it to suffer a similar fate as Google, which stuck to its relatively cautious approach to AI until recently, then lost $100 billion in its market capitalization after its AI-powered chatbot search produced factual errors in a demo. Baidu declined to comment. Either outcome could also have implications for Baidu’s relationship with the Chinese government as well as the government’s views on generative AI technologies, which can produce content from text to images. Baidu received encouragement on its plans to build the chatbot from city officials in Beijing, where the company is based, people briefed about the matter said. Ernie Bot will likely be the first in China to rival ChatGPT, developed by San Francisco-based AI research company OpenAI. China and the U.S. have been racing to bolster their respective strengths in strategic technologies. The Beijing city officials have also reminded Baidu to make sure that its service will comply with Chinese laws and regulations, including for data collection and processing, as well as the state’s strict internet censorship rules, the people said. This week, Wang Zhigang, China’s minister of science and technology, said that developing a ChatGPT-like product would be difficult. “Playing soccer is just a matter of dribbling and shooting, but it’s not easy to be as good as Messi,” Mr. Wang said, referring to the Argentine athlete Lionel Messi. China has long been researching this area, he added, but “we will have to wait and see whether we can attain results like OpenAI’s.” Baidu has been relying on powerful Nvidia chips to help train Ernie Bot. For years, Baidu has invested heavily in developing large language models—the technology underpinning ChatGPT—adapting English-language versions from Google and OpenAI for Chinese language. It released its first one in 2019, calling it Ernie, after Google named its model Bert—both referencing “Sesame Street” characters. In late December, as buzz grew over ChatGPT, Baidu Chief Executive Robin Li spoke to employees about the new advancement. “We have such cool technology, but can we turn it into a product that everyone needs?” he said, according to an internal transcript seen by The Wall Street Journal. “This is actually the hardest step, but also the greatest and most influential.” In early January, Baidu’s executives told its natural-language processing team to start pulling together a ChatGPT-like product with the Ernie models, said people familiar with the project. But the project has faced challenges, they said, many of which have been shared by other AI developers working on ChatGPT-like technology. One has been to make the model respond more precisely to user requests, by teaching it to disambiguate between phrases that have a number of meanings or names that can refer to multiple people. Another has been to make the chatbot generate language that looks more like a human’s. A third has been to improve its factual accuracy—a technical limitation of large language models, which string together sentences based on the probabilities that different words might appear together rather than on pieces of information. This limitation also makes such models difficult to control to avoid sensitive topics, a hurdle for censorship. Baidu has hired contractors to help review and improve the chatbot’s answers, the people said. Each step takes time, the people said. Properly training a model of such scale—with thousands of chips—can take weeks or months, AI researchers have said. This week, engineers and product managers were rushing to improve Ernie Bot’s basic functions such as how quickly it responds to user requests and how it summarizes search results, people familiar with the matter said. The development team has been working nonstop, including through the weeklong Lunar New Year holiday at the end of January, the people said. The project has been scaled back for now from creating a bilingual chatbot capable of conversing in Chinese and English to one primarily focused on Chinese, they said. Ernie Bot’s research and development has been overseen by Baidu’s technology chief, Haifeng Wang, and carried out largely by its technology development arm, which houses the natural-language processing team, and mobile ecosystem business group, people familiar with the matter said. Baidu’s AI cloud unit is providing cloud-computing support, some of the people said. What do you think lies ahead in the race to develop AI-powered chatbots? Join the conversation below. To accelerate the process, executives pooled together more resources. After the Lunar New Year holiday, Mr. Li asked AI research teams across the company, including its autonomous driving unit, to lend their most powerful computer chips, Nvidia Corp.’s A100s, to Ernie Bot’s development, people familiar with the matter said. U.S. chip sanctions implemented late last year ban Chinese companies from buying new A100s. Employees have also been pulled to help out, in particular to clean the training data, such as to filter out low-quality content, some of the people said. Baidu hired external teams for data cleaning as well, some people said. The time crunch has left some employees uneasy about whether Ernie Bot will meet user or market expectations, people familiar with the matter said. Some of the employees said they have sold some company stock ahead of the launch because of those concerns.",,,MISSING
ChatGPT and Cyber Risk,https://www.wsj.com/articles/chatgpt-and-cyber-risk-50b91b22?mod=Searchresults_pos13&page=1,"Key Points: ChatGPT is a new artificial intelligence-driven technology with capabilities that can potentially aid attackers. Cybercriminals are using the tool to develop phishing schemes, as well as writing and sharing malware code, according to researchers. Observers don’t believe the risks and threats associated with use of the tool are currently much more significant for organizations than ongoing ones, but said ChatGPT’s machine-learning capability may change this. Why ChatGPT is Popular Chat Generative Pre-trained Transformer is a chatbot developed by research laboratory Open AI and incorporated into Microsoft Corp.’s Bing search engine. The tool enables business users to automate time-consuming tasks such as writing emails, create quick and more natural interactions with customers and potentially increase productivity. The Possible Risks and Threats Cybersecurity researchers have focused on the risks and threats presented by ChatGPT for hackers trying to harness its capabilities for criminal activities, including: Allowing code to be written for use in malware by technically less-skilled hackers, which is then shared among hackers in other online forums. Providing additional complexity to protect code from detection, such as including polymorphic capabilities, which means a code’s appearance can mutate while not changing its function. In terms of phishing campaigns, ChatGPT can generate the text to reduce errors in messages written by non-native speakers and also create the phishing website code to collect the victims’ data. There is a risk of vulnerabilities being introduced into software by employees using code produced by ChatGPT without it first being thoroughly checked for security weaknesses. Soo Choi-Andrews, chief executive of cybersecurity platform Mondoo, said companies also need to consider how their third parties may be using ChatGPT. “The sheer volume of code being generated by not only your team but also the wider ecosystem that your business relies on poses the biggest immediate threat,” she said. Ms. Choi-Andrews added it is critical that businesses prioritize security checks within their automated testing processes to address these possible vulnerabilities. Reasons Not to be Concerned – Yet “The attacker has to know what exactly he wants and to be able to specify the functionality. Just writing ‘write a code for malware’ won’t produce anything really useful.” — Sergey Shykevich, researcher at cybersecurity firm Check Point Software Technologies Ltd. Many security experts believe that although there may be some benefits for hackers using ChatGPT, it is unlikely to be a game-changer for criminals as much of the information it produces is already available online, albeit in less user-friendly formats. The following takeaways should be considered: Existing controls mean ChatGPT won’t deliver ready-to-use malware code as it’s not possible to create malware just by asking it. The capabilities of ChatGPT for hackers will likely improve over time through machine learning, though controls may also evolve and increase. ChatGPT may be aiding the malware creation process, but it so far has not created fully-fledged attacks. Accordingly, there are currently no specific steps organizations can take, beyond practicing good cyber hygiene. “ChatGPT prevents phishing attacks by implementing content moderation, user validation, warning messages, reporting and blocking functions, and conducting regular security audits and updates. These measures help to mitigate the risk of ChatGPT being used as a tool in such attacks and protect users from potential harm.” — ChatGPT response to how it stops itself from being abused in phishing attacks. We haven’t identified specific threats security officials should be looking for or precautions to take, but with ChatGPT constantly learning and other chatbots becoming publicly accessible, the risks of artificial intelligence being responsible for producing attacks is increasing. Because a tool like ChatGPT does not provide out-of-the-box solutions for hackers or security officials, but rather is developed over time by skilled practitioners, it would be advisable to stay abreast of the latest information regarding AI-driven security concerns and best practices to address them.",,,MISSING
Apple Approves ChatGPT-Powered App After Assurance of Content Moderation,https://www.wsj.com/articles/apple-approves-chatgpt-powered-app-after-assurance-of-content-moderation-9c82cd7?page=2,"Apple Approves ChatGPT-Powered App After Assurance of Content Moderation has approved an email-app update after initially scrutinizing whether a feature in the software that uses language tools powered by artificial intelligence could generate inappropriate content for children. The app, BlueMail, was approved following assurances from its developer that it features content moderation, according to Ben Volach, co-founder of the app-maker, Blix Inc. The Wall Street Journal reported on Thursday that the update, which included a new feature powered by language chatbot ChatGPT, was held up due to Apple’s request that the app add content moderation or be restricted to ages 17 and older. The app was previously available for ages 4 and older. Blix told Apple its update includes content moderation and suggested that the company should make public any new policies about the use of ChatGPT or other similar AI systems in apps. The BlueMail update was approved without changes on Thursday evening. The app is still available for users aged 4 and older. BlueMail’s new feature uses OpenAI’s ChatGPT, an artificial-intelligence system capable of answering questions or writing short essays, to help automate the writing of emails using the contents of prior emails and calendar events. The news of Apple’s initial rejection of BlueMail’s ChatGPT feature highlighted the growing concerns around new uses of language-generating AI tools. ChatGPT allows users to converse with an AI that appears humanlike, but early testing has shown the AI producing incorrect information as well as strange and sometimes hostile responses. Although Apple took action on the AI feature, there have been no additional formal App Store guidelines from Apple regarding the use of so-called generative AI in apps. Apple has long said that it has to curate and review each app that goes through its App Store in order to keep its products safe for users.",,,MISSING
Apple Blocks Update of ChatGPT-Powered App,https://www.wsj.com/articles/apple-blocks-update-of-chatgpt-powered-app-as-concerns-grow-over-ais-potential-harm-c4ca9372?page=2,"Apple Inc. has delayed the approval of an email-app update with AI-powered language tools over concerns that it could generate inappropriate content for children, according to communications Apple sent to the app maker. The software developer disagrees with Apple’s decision. The dispute shows the broad concerns about whether language-generating artificial-intelligence tools, such as ChatGPT, are ready for widespread use. Apple took steps last week to block an update of email app BlueMail because of concerns that a new AI feature in the app could show inappropriate content, according to Ben Volach, co-founder of BlueMail developer Blix Inc., and documents viewed by The Wall Street Journal. BlueMail’s new AI feature uses OpenAI’s latest ChatGPT chatbot to help automate the writing of emails using the contents of prior emails and calendar events. ChatGPT allows users to converse with an AI in seemingly humanlike ways and is capable of advanced long-form writing on a variety of topics. “Your app includes AI-generated content but does not appear to include content filtering at this time,” Apple’s app-review team said last week in a message to the developer reviewed by the Journal. The app-review team said that because the app could produce content not appropriate for all audiences, BlueMail should move up its age restriction to 17 and older, or include content filtering, the documents show. Mr. Volach says it has content-filtering capabilities. The app’s restriction is currently set for users 4 years old and older. Apple’s age restriction for 17 and older is for categories of apps that may include everything from offensive language to sexual content and references to drugs. Mr. Volach says that this request is unfair and that other apps with similar AI functions without age restrictions are already allowed for Apple users. “Apple is making it really hard for us to bring innovation to our users,” said Mr. Volach. An Apple spokesman said that developers can challenge a rejection through its App Review Board appeal process and that it is investigating Blix’s complaint. So-called generative AI has emerged as one of the most closely watched developing technologies in decades, primarily kicked off by ChatGPT, a chatbot created by OpenAI. The technology has quickly generated controversy. Following the release of Microsoft Corp.’s Bing search engine powered by ChatGPT, early testers grew concerned with responses generated by the chatbot, including incorrect information as well as seemingly unhinged and angry responses. Microsoft, which has invested billions in OpenAI, defended the Bing upgrade as a work in progress. Apple’s attempt to set an age restriction to help moderate content from a language-model-based AI is an indication the tech giant is closely watching the new technology and the risks it poses. The company has long said it must carefully curate and review what software can be accessed on the iPhone and iPad through its App Store to keep its products private and secure. Microsoft recently released an updated version of its Bing smartphone app with the ChatGPT functionality to Apple’s App Store and Google’s Android Play Store. Bing is listed in the iPhone App Store with the 17-and-older age restriction that Apple is asking of BlueMail, while Bing on the Google Play store has no age restrictions. Bing in the App Store already had a 17-and-up age restriction because of the app’s ability to find adult content, a Microsoft spokesman said. For BlueMail, Apple’s rejection came a week after the company submitted the app upgrade for review. Mr. Volach said Apple used a test version of the upgraded app every day before he got a response. BlueMail was able to update its Android BlueMail app on the Google Play app store without any requests for age restriction or further content filtering, Mr. Volach said. Mr. Volach says Apple is unfairly targeting BlueMail. The app has content filtering, and placing a higher age restriction on the app could limit distribution to potential new users, he said. Mr. Volach also said many other apps that advertise a ChatGPT-like feature listed on Apple’s App Store don’t have age restrictions. “We want fairness,” said Mr. Volach. “If we’re required to be 17-plus, then others should also have to.” In the past, Apple has at times discovered an issue with an app that leads the company to apply a new rule more broadly. Initial inconsistency in applying App Store policies—especially new policies—isn’t uncommon, said Phillip Shoemaker, former senior director of the App Store review team at Apple, who left in 2016. There are hundreds of individuals reviewing each app, and “not everyone sees the same thing,” Mr. Shoemaker said. “Some are viewing apps faster than others and could be missing things. The inconsistency could be for a variety of reasons.” Apple was an early entrant in bringing AI technology mainstream with the introduction of the Siri voice assistant in 2011. But to date, Apple appears to have stayed out of the fray of generative AI. At an internal AI conference for company employees last month, sessions were focused on areas such as computer vision, healthcare and privacy, according to internal documents viewed by the Journal. Last month, on the company’s quarterly earnings conference call, Apple Chief Executive Tim Cook said AI “is a major focus of ours,” pointing out AI-enabled features such as crash detection. “We see an enormous potential in this space to affect virtually everything we do,” he further stated. During an interview at WSJ’s Journal House at MWC in Barcelona, Carme Artigas, Spain’s secretary of state for digitization and AI, talks about the increased pressure on government oversight of cutting-edge technologies. Mr. Volach has had a contentious history with Apple. In 2019, Apple announced a software feature called “Sign in with Apple,” which allows users to sign into an app without having to give away personal information such as email. Blix had patented a similar feature earlier. Soon after Apple’s sign-in feature was announced, Apple removed the BlueMail app from its Mac app store. At the time, Apple said the removal of the BlueMail app was due to security concerns. Mr. Volach said that there was never a security issue and that Apple eventually ended up approving the app many months later. The incident prompted Blix to file an antitrust lawsuit against Apple in 2019. A federal judge dismissed the company’s case, stating that Blix failed to offer evidence of Apple’s monopoly power and anticompetitive behavior. Antitrust lawyer Jonathan Kanter was hired by Blix as legal counsel in its antitrust case against Apple. In 2021, Mr. Kanter took over as head of the antitrust division at the U.S. Justice Department, which is currently pursuing its own antitrust investigation into Apple.",,,MISSING
"Instacart Joins ChatGPT Frenzy, Adding Chatbot To Grocery Shopping App",https://www.wsj.com/articles/instacart-joins-chatgpt-frenzy-adding-chatbot-to-grocery-shopping-app-bc8a2d3c?page=2,"Instacart Inc. is adding OpenAI’s ChatGPT chatbot technology to its grocery-delivery app, joining a growing list of companies that are turning to the humanlike artificial-intelligence language tool in efforts to boost customer services, marketing and other automated tasks. Instacart will use the chatbot to power a new search engine designed to respond to users’ food-related questions, such as asking for recipe ideas and ingredients, or healthy meal options, the San Francisco startup said Wednesday. By tapping ChatGPT’s language software, the search engine’s responses will come in the form of a dialogue, rather than a list of search-engine results, Instacart said. It expects to roll out the new feature, called “Ask Instacart,” later this year, the company said. “When you think about grocery shopping, it takes a lot of thinking and planning,” said JJ Zhuang, Instacart’s chief architect, who oversees technology across the company. “It’s the perfect use case for smart AI, because it’s a lot of cognitive load,” he said, citing decision-making factors such as household budgets, health and nutrition implications, seasonal produce, cooking skills and meal preparation times. By integrating Instacart’s own AI software with ChatGPT, the new search tool will tap data from more than 1.5 million products stocked by some 75,000 grocery stores in Instacart’s partner network, he said. Mr. Zhuang described the software integration as “experimenting with what’s possible” using ChatGPT on Instacart’s app. Instacart last year processed $29 billion in overall sales across its platform, up about 16% from the previous year, the company told employees Tuesday. It reported positive net income over the fourth quarter, generating more than $100 million in adjusted earnings before interest, taxes, depreciation and amortization. OpenAI, a San Francisco-based software startup launched in 2015, has sought to expand its reach by easing the process of integrating ChatGPT software with outside apps. To do that, it allows companies like Instacart to build their own tools on top of ChatGPT’s software, said Greg Brockman, OpenAI’s president, chairman and co-founder. Mr. Brockman said he sees OpenAI as essentially a developer platform that also offers a “killer app.” On Wednesday, OpenAI released updates to its application programming interface—a type of software code, known as an API, that enables computer programs to communicate with each other—which includes specific protocols for integrating apps with the latest AI models for both ChatGPT and Whisper, OpenAI’s speech-recognition tool. Unlike its widely popular online app, which is free and available to anyone, OpenAI charges a fee for accessing the interface needed by developers to build new apps. “I think the whole developer community is going to benefit a lot from all the improvements that we’ve made, in model quality and model speed,” Mr. Brockman said. “We’re working with all companies, big and small, in order to get this technology integrated into whatever application they’re interested in,” he said. OpenAI benefits by feeding user data back into its AI models to continually train and improve the algorithm—though as of Wednesday companies can opt out of having their data used in this way. Since OpenAI launched ChatGPT in November, ready access to its interface has produced a slew of ChatGPT-integrated business apps. Snapchat maker Snap Inc. on Monday launched its own AI-powered chatbot for Snapchat+ subscribers, built off of ChatGPT’s API. Microsoft Corp., an OpenAI investor, last month added ChatGPT technology to its Bing search engine. Shopify Inc., an e-commerce website builder, is also experimenting with ChatGPT, the company said. Still, some corporate technology chiefs remain wary of integrating ChatGPT into their business technology stacks, citing concerns over data limitations, security and the tool’s reputation for producing unpredictable results. Microsoft itself was forced to limit the amount of questions that could be fielded by its ChatGPT-enabled search engine, after users complained of inaccurate and even disturbing results. Likewise, Snap has warned users that its customized ChatGPT chatbot “is prone to hallucination and can be tricked into saying just about anything,” adding that the tool shouldn’t be relied on for real-world advice.",,,MISSING
"Facebook Parent, Snap Embrace AI Technology That Powers ChatGPT Chatbot",https://www.wsj.com/articles/meta-ai-instagram-whatsapp-snap-chatbot-fa21774e?page=2,"Facebook parent Meta Platforms Inc. and Snap Inc. are embracing the much talked-about artificial-intelligence technology popularized by OpenAI’s viral ChatGPT chatbot. Meta is establishing a group aimed at accelerating adoption of the so-called generative AI technology across the company, Chief Executive Mark Zuckerberg said Monday. Meta, which also owns Instagram and messaging app WhatsApp, is centralizing staff who are working on the AI technology from across the company to achieve faster breakthroughs it can apply to different products, Mr. Zuckerberg said. “In the short term, we’ll focus on building creative and expressive tools,” the CEO said on Instagram. “Over the longer term, we’ll focus on developing AI personas that can help people in a variety of ways.” Snap on Monday also signaled it was making a bet on OpenAI’s technology. The company known for its Snapchat app said it had begun rolling out its own AI experimental chatbot to users who subscribe to its $3.99 a month subscription service, Snapchat+. Tech companies more broadly have moved swiftly to embrace generative AI developments in recent months after the San Francisco-based AI research firm OpenAI launched a chatbot called ChatGPT in November that went viral. Tools such as ChatGPT and others allow users to ask written questions and receive responses in a conversational format as opposed to seeing a list of search results. Microsoft Corp., which has invested in OpenAI, announced earlier this month that it was adding the technology behind ChatGPT to its Bing search engine in an attempt to chip away at Google’s dominance in the search market. It has given a select group of users access to the new Bing to try the system. Alphabet Inc.’s Google also said earlier this month that it was rolling out its own conversational AI service called Bard to an early group of testers. Meta said its team initially was looking into ways to use the technology to enhance WhatsApp and Messenger, as well as with Instagram filters and video. Snap said it is making its chatbot, called My AI, available only to Snapchat+ subscribers as social-media companies are trying to drive users to their paid services amid upheaval in the digital ad market. Twitter Inc. and Meta both have also started subscription offerings. Snapchat+ has reached more than 2.5 million subscribers since its launch last summer, Snap said. The Verge earlier reported on Snap’s AI technology rollout. Snap has been one of the companies hardest hit by ad-market turmoil, driven both by companies pulling back on spending amid economic downturn concerns and changes Apple Inc. made that make it more difficult to track users and target ads. Its subscription service is an attempt to diversify its revenue, though the company has indicated it doesn’t fully expect to replace ad revenue with earnings from its subscription service. The social-media company late last month said revenue growth had stalled in the last three months of 2022 and that sales were likely to drop in the current quarter. Snap’s shares on Monday closed about 1% up, though have fallen about 75% over the past year. The AI technology isn’t without flaws. Within a week of launch, users of Microsoft’s new Bing called out the technology for providing inaccurate information, such as giving the results of last year’s Super Bowl when asked about this year’s. It also sometimes has given disturbing responses.  Microsoft responded by saying that the search engine was still a work in progress and that it would limit the amount of questions users could ask it a day. Snap, in its announcement, said mistakes could occur with its chatbot that uses OpenAI technology customized for Snapchat. “My AI is prone to hallucination and can be tricked into saying just about anything. Please be aware of its many deficiencies and sorry in advance!” the company said, also warning: “Please do not share any secrets with My AI and do not rely on it for advice.” Mr. Zuckerberg has embraced hot technology trends before. In 2021, he renamed Facebook to Meta Platforms as part of his bet on the metaverse, a futuristic, more immersive vision of the internet that largely hasn’t materialized yet. The company has struggled financially since then, in part because of the same disruptions to the digital ad business that have challenged Snap. After posting three consecutive quarters of declining sales, Meta said in its most recent earnings report that market conditions were improving, and interviews and internal documents viewed by The Wall Street Journal show that the company has begun to see a path to recovery through using AI tools to improve ad-targeting and user engagement with its TikTok competitor, Reels. Mr. Zuckerberg on Monday suggested that the company still had a lot of work to do with respect to AI developments.  “We have a lot of foundational work to do before getting to the really futuristic experiences,” he said.",,,MISSING
"In the Whirl of ChatGPT, Startups See an Opening for Their AI Chips",https://www.wsj.com/articles/in-the-whirl-of-chatgpt-startups-see-an-opening-for-their-ai-chips-cb74798f?page=2,"As major chip players—Nvidia Corp., Intel Corp., Advanced Micro Devices Inc. among them—rush to capitalize on the popularity of generative artificial intelligence, startups are seeing their chance to grab a bigger piece of that pie as well. “There’s new openings for attack and opportunity for those players because the types of chips that are going to most efficiently run these algorithms are different from a lot of what’s already out there,” said Brian Schechter, a partner at venture-capital firm Primary Venture Partners. Historically, Nvidia has been the market leader in specialist AI hardware, analysts said. Generative AI and large language models like OpenAI’s ChatGPT require massive amounts of computing power to run, and typically rely on chips like Nvidia’s graphics-processing units, or GPUs, that are specialized for these types of calculations. Last week, Nvidia Chief Executive Jensen Huang said on a call with analysts that excitement around these new AI developments could supercharge the market for its chips. Dylan Patel, chief analyst at chip research firm SemiAnalysis, said the big companies are in a prime position to benefit from the onrush of demand. But smaller upstarts could also benefit from an overflow of demand, especially as supply-chain and manufacturing difficulties still limit the amount of chips that are making it to market, he said. Cerebras Systems Inc., a Sunnyvale, Calif.-based chip company founded in 2016, has been able to capitalize on some of that interest, said Chief Executive and Co-founder Andrew Feldman. As demand surges, he said, it is creating space for startups to break through. Cerebras is valued at $4.1 billion. With the nascent generative AI market propelling demand for compatible hardware and software to new heights, it’s a good time to be a startup, he said. “In stable markets that aren’t changing much—very hard to beat Goliath,” he said. “The number of people trying to apply AI is just ballooning and that is really a massive opportunity that we can play into,” said Nigel Toon, chief and co-founder of Bristol, U.K.-based Graphcore Ltd. Graphcore provides specialized hardware and software designed for AI that can do several things, among them lowering compute costs by eliminating unnecessary parameters, Mr. Toon said. Graphcore sells primarily to AI startups looking to build and train models at lower cost, he said, and the company is benefiting from the proliferation of those startups. Anshumali Shrivastava, the founder and chief executive of ThirdAI Corp., said that since the release of ChatGPT, his company has also seen an increase in demand. Houston-based ThirdAI provides technology that helps complex AI algorithms run efficiently on cheaper CPUs, or central processing units, rather than on specialized GPUs. Dr. Shrivastava said because of ThirdAI’s focus on CPUs, it can also feasibly help enterprises unlock complex AI models on premises and not in the cloud—alleviating privacy and data security concerns for industries that require on-premise solutions. Shane Rau, who leads International Data Corp.’s semiconductor research, said chip startups are increasingly pivoting to focus their products on supporting large language models. Still, he added, “you’re going to see a combination of real adaptation and marketing.” “There will be the pressure to say: ‘Hey, we’re already relevant, our AI chip technology’s already relevant to generative AI’,” said Mr. Rau. “Many of these AI chip companies—we’re tracking hundreds of them—are going to run out of money before they can make that adaptation.” Kavitha Prasad, vice president and general manager at Intel for data center, AI and cloud and enterprise strategy, said incumbents like Intel might also have an edge over startups because of the software they provide clients to program and optimize the chips. “There are a lot of startups, but without a focus on the software ecosystem, adoption is going to be very limited,” she said. Some chip makers say they expect yet another surge in demand once businesses more widely adopt generative AI. “We think this demand is both overwhelming—and just the start,” said Cerebras’s Mr. Feldman.",,,MISSING
"Nvidia, Other Chip Companies Race to Cash In on ChatGPT Frenzy",https://www.wsj.com/articles/chip-makers-see-chatgpt-stirring-strong-demand-for-advanced-processors-76f152d1?page=3,"Chip makers are abuzz about the latest hot-thing in tech: artificial-intelligence tools that generate text with minimal prompting, require massive computing power to run and promise a lucrative new revenue stream. For semiconductor makers, the new tools, if widely adopted, could result in tens of billions of dollars in net annual sales, analysts estimate. Excitement over so-called generative AI has reached fever pitch since the release late last year of San Francisco-based OpenAI’s chatbot, called ChatGPT. The technology has captivated users by producing convincingly real if sometimes inaccurate responses, helping it attract billions of dollars from Microsoft Corp. and other investors. Jensen Huang, the chief executive officer of Nvidia Corp., America’s largest chip company by market value, said the technology has reached an inflection point. “Generative AI’s versatility and capability has triggered a sense of urgency at enterprises around the world to develop and deploy AI strategies,” he said as the company posted quarterly earnings Wednesday and unveiled a new cloud-computing initiative to capitalize on the business opportunity. Nvidia shares were up more than 12% in early Thursday trading. The interest in such AI tools is causing companies to reset their business expectations with pace, he said. “There’s no question that whatever our views are of this year as we enter the year has been fairly dramatically changed as a result of the last 60, 90 days.” The excitement comes as the chip industry is wrestling with a sharp downturn in the semiconductor industry with sales of personal computers, smartphones and other electronics flagging. Most chip makers have reported slowing sales as recession concerns have caused consumers and businesses to pull back on spending. Nvidia is the undisputed market leader in chips used for AI in the unglamorous world of data centers where tools such as ChatGPT make computations and spit out results. It had about an 80% share of such AI processors as of 2020, according to an Omdia estimate. With so much money up for grabs, though, other chip makers want in on the action. Intel Corp. CEO Pat Gelsinger said Wednesday that his company had a broad suite of chips to address the generative-AI opportunity, including specialist chips geared toward AI computation, graphics chips for data centers and a new generation of data-center central process units—the digital brains of computers—that he said performed well in AI work. “That performance we expect will become much more of the mainstream of computing as AI gets infused into every application going forward,” he said. Advanced Micro Devices Inc., which makes CPUs, graphics chips and other hardware tailored for AI, is also betting large cloud-computing companies that run many of the computations essential to the technology will be investing heavily in chips. That business should start to become more meaningful next year, AMD CEO Lisa Su said late last month. Generative AI could add $20 billion a year to the overall AI chip market by 2027, according to Vivek Arya, an analyst at Bank of America. Nvidia, he said, should be able to maintain at least a 65% market share in AI chips. Internet-search giant Google, a unit of Alphabet Inc., this month offered a glimpse of a homegrown rival to ChatGPT that it calls Bard. China’s Baidu Inc. is developing an AI-powered chatbot similar to ChatGPT called Ernie Bot, which it plans to launch next month. Microsoft is already giving users a limited taste of ChatGPT within its Bing search engine results. In the near term, at least, Nvidia’s dominance in AI may position it best to cash in. The company gained its lead by allowing software developers to exploit properties of its graphics chips that proved adept at AI starting about 15 years ago. Now, the company’s chips are the only viable products that can be used to create massive AI language systems, UBS analysts said in a note, adding that they estimate that ChatGPT requires around 10,000 of the company’s graphics chips to train. Mr. Huang suggested the company next month may update its outlook for the size of its potential market, after giving a projection of $1 trillion roughly a year ago for its business spanning from providing chips for videogaming to cars. “Because of the incredible capabilities and versatility of generative AI and all of the convergence breakthroughs that happened toward the middle and end of last year, we’re probably going to arrive at that [market size] sooner than later,” he said. “There’s no question that this is a very big moment for the computer industry.” Nvidia is trying to get there faster by starting to offer a cloud-computing service for businesses to develop generative AI chatbots and other tools using its hardware and software. The service, which would be offered through established cloud-computing companies, aims to lower barriers to entry for the spread of AI’s use in business. Nvidia said it is working with all the major cloud-computing providers, which include Amazon.com Inc., Microsoft and Google, on generative AI tools, as well as with consumer internet companies and startups.",,,MISSING
ChatGPT Fever Sweeps China’s Tech Sector,https://www.wsj.com/articles/chatgpt-fever-sweeps-china-as-tech-firms-seek-growth-e69aa681?page=3,"The viral popularity of ChatGPT has stirred a frenzy within China where tech companies, battered by a two-year regulatory clampdown and the Covid-19 pandemic, have been seeking new sources of growth. Search-engine owner Baidu Inc., e-commerce giant Alibaba Group Holding Ltd. and social-media conglomerate Tencent Holdings Ltd. are among those that have announced investments to develop their own equivalents to the artificial-intelligence chatbot, which isn’t available in China. Stocks of other Chinese companies have surged in recent weeks as they have jumped on the bandwagon, triggering state media to issue a warning about the speculative rally. Chinese companies that invested early in the generative AI technologies—which produce writing, images and art much like humans do—will now be best poised to build their own ChatGPT, AI and Chinese tech industry experts say. But many others are racing to catch up to U.S. counterparts in the latest technology developments and commercial applications. While China has several leading AI companies, many have focused on computer vision and applications such as surveillance. ChatGPT requires tooling and knowledge from a different AI subfield known as natural language processing. Chinese companies also face geopolitical and censorship-related barriers, including securing advanced chips targeted by U.S. export controls and navigating Beijing’s tight censorship rules. Nonetheless, companies that have the capabilities will be fast followers. For such companies, “there’s not a meaningful barrier that’s preventing China from catching up and re-creating or building an even better model,” said Matt Sheehan, fellow at the Carnegie Endowment for International Peace. OpenAI, the creator of ChatGPT, bans users in China from creating accounts on its chatbot, though many have found ways to circumvent the barrier through virtual private networks or by buying accounts using e-commerce platforms for a few U.S. dollars. ChatGPT can produce answers in Chinese, and its spectacular, surprising and sometimes wrong responses have become a hot topic on Chinese social media. Some consumers have clamored for homegrown alternatives. Reports emerged on Baidu’s plans in January. It is set to integrate into its search engine in March its own version of the AI chatbot, called Ernie Bot. Baidu said Wednesday that the company will use Ernie Bot to also improve Baidu’s AI cloud, its driverless car system and its voice assistant Xiaodu. The company will open its large language model to the public, offering it as a business service, Baidu’s Chief Executive Robin Li said in a call with analysts. Some organizations have already decided to integrate Ernie into their products and services, he said. That was followed by Tencent, the owner of China’s everything app WeChat; e-commerce player JD.com Inc.; and speech-recognition company iFlytek Co.—though none have released concrete plans. Game company NetEase Inc. said it is exploring how to incorporate the underlying technology behind ChatGPT into its education products. Wang Huiwen, the co-founder of food-delivery company Meituan, said he plans to invest $50 million into building China’s OpenAI, despite acknowledging that he doesn’t know much about the technology. The foundation of ChatGPT is built on what’s known as a large language model, which is trained on vast swaths of language data. Such models are useful for a range of commercial applications, from improving search results and powering voice assistants to automating content moderation. In China, Baidu and Alibaba were among the first companies to create their own Chinese-language versions. Baidu released one in 2019 called Ernie, which it subsequently advanced in lockstep with Google’s and OpenAI’s developments and uses to improve its search. Alibaba released one the same year called AliceMind and another called M6 two years later. AliceMind powers AliMe, its customer-service chat feature. Telecom major Huawei Technologies Co. and information-technology conglomerate Inspur Group, as well as the government-backed Beijing Academy of Artificial Intelligence and the Chinese Academy of Sciences, have produced their own versions. It is these foundations that Chinese companies are now relying on to evolve into a ChatGPT equivalent. But only a few companies will be able to do so quickly, experts say. One reason is the more limited access that Chinese companies have to a broad diversity of data. ChatGPT rests on one of the largest language models that exists today, OpenAI’s GPT-3.5, which benefits from the copious amounts of English-language data on the global web spanning many subject areas and disciplines. Chinese-language data is less abundant and, within China, faces strict censorship controls. Outside of publicly available data, most Chinese companies only have text and conversational data in specific areas such as finance or e-commerce, said Pascale Fung, the director of the Center for Artificial Intelligence Research at the Hong Kong University of Science and Technology. Baidu stands out for the data it has from indexing the web for its search engine, she said. U.S. export controls on advanced chips could pose another hurdle. A recent study found that most large language models developed in China over the past two years were trained on the U.S.-sanctioned A100 graphics-processing unit made by Nvidia Corp. Once companies use up their stockpiles of high-end chips, the pace of advancement could slow, said Jeffrey Ding, a political scientist researching technological change at George Washington University, who co-wrote the paper. China’s tight censorship and regulatory ecosystem will challenge development in other ways. Issues have risen around ChatGPT spewing misinformation or strange and offensive outputs. Chinese companies are facing much greater pressure to ensure their chatbot equivalents won’t wax lyrical on politically sensitive topics, Chinese tech experts say. In January, China’s internet regulator also issued new rules for generative AI technologies, a global first, requiring developers of ChatGPT and image-generation tools to prominently label images, videos and text as synthetically generated or edited when they could be misconstrued as real. Ms. Fung said the real hurdle will come after ChatGPT’s development, however, in finding applications of the technology that are safe and effective. “The key is who will come up with a killer app,” she said. “In that sense, Chinese companies can be very innovative.”",,,MISSING
JPMorgan Restricts Employees From Using ChatGPT,https://www.wsj.com/articles/jpmorgan-restricts-employees-from-using-chatgpt-2da5dc34?page=3,"JPMorgan Chase & Co. is restricting employees from using ChatGPT, according to a person familiar with the matter. The bank didn’t restrict usage of the popular artificial-intelligence chatbot because of any particular incident, the person said. It couldn’t be determined how many employees were using the chatbot or for what functions they were using it. ChatGPT has grown increasingly popular since the startup OpenAI released it in November, crossing a million users a few days after its launch. People have used the chatbot to automate tasks at work and school, raising questions about how AI could replace some white-collar jobs. However, ChatGPT isn’t always reliable because it sometimes responds to prompts with misinformation or wrong answers. OpenAI didn’t return a request for comment Wednesday. In addition to JPMorgan, other organizations have also blocked access to ChatGPT. Last week, Verizon Communications Inc. barred the chatbot from its corporate systems, saying it could lose ownership of customer information or source code that its employees typed into ChatGPT. New York City public schools in January banned the chatbot from its internet networks and school devices. Workers at some companies have been using ChatGPT to write emails and research topics. Some of the employees say the chatbot helps them work faster while others are trying to avoid being left behind as technology evolves. Some tech companies have raced to launch similar products after OpenAI released ChatGPT. Earlier this month, Google rolled out a conversational AI service, Bard, to testers as the company tries to keep up with OpenAI. Microsoft Corp., which has invested billions of dollars in OpenAI, debuted an upgraded Bing search engine using ChatGPT’s technology. Users reported that the search engine, which also functions as a chatbot, responded to questions with sometimes disturbing answers. OpenAI said earlier this month that it was launching a paid version of ChatGPT which would be available to subscribers for $20 a month. The Telegraph earlier reported that JPMorgan was restricting employees from using ChatGPT.",,,MISSING
Microsoft Brings ChatGPT-Powered Bing to Mobile Devices,https://www.wsj.com/articles/microsoft-brings-chatgpt-powered-bing-to-apple-android-mobile-devices-a105eb03?page=3,"Microsoft Corp. is making its upgraded Bing search engine featuring the technology behind the viral chatbot ChatGPT available on Apple Inc. AAPL 0.55% iPhones and Google Android mobile devices, pressing ahead with the deployment of the system despite early glitches. In a blog post, Microsoft said it is releasing new versions of its Bing app and Edge browser app for smartphones and tablets Wednesday so users can access the upgraded search engine while on the go. The company also said it is adding voice to Bing because the ability to speak commands or ask questions out loud rather than type them has been one of the most requested features among early testers of the system. Microsoft also said it plans to integrate the technology into its two-decade-old video-calling app Skype so users can request information and share it with others in group conversations. Microsoft unveiled Bing with artificial intelligence this month, saying the enhanced software enables a new kind of search in which people can pose questions in natural language. Bing then generates direct answers and suggestions, as opposed to pointing users toward different websites. The company gave a small number of testers access to the tool for trials. Several received inaccurate and sometimes bizarre responses and shared them on social media. Last week, Microsoft responded by adding restrictions on how the search tool can be used after determining that long interactions were causing some of the unwanted behavior. The company, an investor in ChatGPT creator OpenAI, said it would limit interactions with the new Bing to five questions per session and 50 questions a day. That move sparked a new round of complaints. On Tuesday, Microsoft said it would bring back longer chats, starting by allowing six questions per session and 60 total a day, with plans to increase the daily cap to 100 soon. Despite early missteps with the technology, Microsoft’s Bing upgrade has created hype around the product and raised questions about whether it could become a formidable challenger to search-industry leader Google, a unit of Alphabet Inc. this month opened its rival AI-powered tool, called Bard, for testing.",,,MISSING
Business Technology Chiefs Question ChatGPT’s Readiness for the Enterprise,https://www.wsj.com/articles/business-technology-chiefs-question-chatgpts-readiness-for-the-enterprise-e6b38de0?page=4,"OpenAI’s ChatGPT has nabbed the attention of corporate boardrooms for its humanlike ability to generate business reports, marketing pitches and code for software applications, among other things. Yet some business-technology professionals are uneasy about integrating it into the enterprise stack, citing concerns over its use of online data and security risks. But above all, they’re worried about ChatGPT’s grip on reality. “It explained to me in very convincing detail why cow eggs are larger than chicken eggs, and why the moon is bigger than the sun,” said Christine Livingston, a managing director in the emerging technology group at Protiviti, a management consulting company. ChatGPT is a tremendous step forward for generative AI, she said, referring to algorithmic software designed to tap giant stores of data and create unique output based on user prompts. But at the moment, ChatGPT “should be used with caution in an enterprise business setting,” she said. Besides its problems with accuracy, ChatGPT requires a number of other improvements before it could be used on core enterprise applications, said Andy Harrison, managing partner and chief executive at tech venture investing fund Section 32. Other necessary upgrades include speedier results, advanced safety and security features, and better language abilities, Mr. Harrison said. As these and other performance improvements roll out—over the next year or two, he said—“we will see the emergence of enterprise applications like enterprise search, integration with communication platforms, sales tools and others.” “Generative AI is capable of amazing things, but as a whole, needs maturing,” said Ashok Srivastava, chief data officer at TurboTax owner Intuit Inc. Released in November by San Francisco-based OpenAI, ChatGPT is a generative AI-powered chatbot that’s been trained on a massive trove of articles, websites and social-media posts gathered from the internet, as well as transcribed interviews that capture the nuances of human speech. By detecting linguistic patterns and familiar phrases, the algorithm learned to predict what word is likely to follow from a sequence of words. From there, it was able to predict the next sentence and the next paragraph, eventually creating a coherent text. The approach can also be applied to writing computer code, enabling ChatGPT to anticipate large chunks of code that developers would need to input in order to execute a given task within a software program—a capability proponents say will supercharge in-house application development. “This is the biggest technical leap forward since cloud computing,” said Sameer Dholakia, partner at Bessemer Ventures Partners focused on cloud-based software. Any chief information officer who doesn’t have their app-development team thinking about how to apply ChatGPT and generative AI is “putting their company at a disadvantage,” Mr. Dholakia said. Microsoft Corp., which has invested billions of dollars in OpenAI, last month said it was integrating ChatGPT into its own enterprise software products, and more recently said it would add the technology to Bing, Microsoft’s search engine. The tool quickly captured the public’s imagination. But roughly a month after its release, Sam Altman, chief executive of OpenAI, warned against relying on ChatGPT “for anything important right now.” In a tweet, he said, “ChatGPT is incredibly limited, but good enough at some things to create a misleading impression of greatness.” Gaurav Gupta, a partner at Lightspeed Venture Partners, readily agrees, saying business areas that require a high degree of accuracy and human judgment are simply not suitable for ChatGPT. The technology might be most useful for automating repetitive tasks within sales and marketing teams: “It could replace a junior salesperson who is prospecting, or a customer service rep that responds to questions,” he said. Eric Schmidt, former chief executive of Alphabet Inc.’s Google, said the basic problem with ChatGPT and similar systems is that they “write extremely well, but can be wrong and not grounded in fact.” Last week, Google unveiled its own ChatGPT-like AI tool, called Bard, designed to generate textual responses to questions posed by users, based on information drawn from the web. For now, Mr. Schmidt said, generative AI capabilities should be reserved for writing corporate boilerplate—product or service announcements, or other promotional materials. “But even then, no company would issue such things without human review,” Mr. Schmidt said. Likewise, Chris Bedi, chief digital information officer at ServiceNow Inc., a cloud-based enterprise software firm, said ChatGPT is best suited to areas like sales and marketing, call centers or to summarize earnings reports, studies and other business documents, where auto-generated sales pitches or outgoing emails can be easily proofread before being sent out. But he has no plans to integrate ChatGPT into the company’s software systems. Professional software developers are unlikely to save much time by having ChatGPT generate programming code, Mr. Bedi said, since it requires long strings of commands that would need to be checked and rewritten line by line. For enterprise information-technology, “ChatGPT use cases might be a smaller universe than people are imagining,” he said. For now, CIOs should be experimenting with ChatGPT to determine how it could be put to use, mostly through trial and error, said Jeff Wong, global chief innovation officer at professional services firm Ernst & Young LLP. “Before integrating ChatGPT into businesses, we’ve got to remember we’re still early in its technology life cycle. We need to step back and ask what it can do today,” Mr. Wong said. In its current form, ChatGPT “answers inaccurately with confidence at times, the math is behind and the data set is only up to a certain date,” he added. Highly regulated industries will need to be especially cautious using ChatGPT or any form of generative AI, said Tim Crawford, CIO strategic advisor at Los Angeles-based enterprise IT advisory firm AVOA. “Without guardrails, data could easily be misused, or worse, serve as a foundation for further bad outcomes,” Mr. Crawford said. “ChatGPT should never be used at face value,” he said. “Every so often, it produces output that just doesn’t make sense.”",,,MISSING
Can ChatGPT Recommend Movies? A Film Buff Put It to the Test,https://www.wsj.com/articles/can-chatgpt-recommend-movies-a-film-buff-put-it-to-the-test-5e7e6516?page=4,"MORE OFTEN than I like, after scanning the endless carousels on streaming apps, I find myself re-watching “Seinfeld.” I attribute this to a combo of laziness and mediocre recommendation engines, which rarely highlight anything I actually want to watch. It’s a problem that seemed custom-designed for ChatGPT, the bot made by Microsoft-backed artificial intelligence research firm, OpenAI. Over 100 million people have tried ChatGPT since its launch in November, posing it tasks as disparate as writing English essays and negotiating down internet bills. By comparison, “What movie should I watch?” seemed simple. I told ChatGPT I enjoyed the 2013 film “Her,” whose protagonist develops a relationship with a virtual assistant. It spewed out a list of sci-fi titles like “Blade Runner 2049” and “Ex Machina.” “These movies,” it typed, “explore the relationship between humans and artificial intelligence, touching on themes such as consciousness, identity and the nature of existence.” (It gave no sign it saw the irony.) Wei Xu, an interactive computing professor at the Georgia Institute of Technology, explained how ChatGPT managed to produce a list of legitimately comparable movies in seconds. The software, she said, is trained to spot patterns within a massive amount of text data—over 500 GBs—it scrapes off the internet. When sniffing out cinematic cousins to “Her,” it’s likely consulting sources like Reddit threads, IMDB forums, even “Best of” lists from editorial outlets. Traditional recommendation engines, said Dr. Xu, don’t have this access. This presents issues for existing discovery platforms like Letterboxd, a social-networking site for discussing movies, and Likewise, a content-recommendation service that draws on AI and human curators. Letterboxd co-founder Matthew Buchanan told me he’s concerned by ChatGPT’s lack of transparency. To get the info it uses to make recommendations, it could be plagiarizing the work of Letterboxd users without providing credit. (OpenAI declined to comment for this article.) The threat of copyright infringement that generative AI systems present is indeed a pressing problem. Many artists have criticized the makers of photo-editing app Lensa, which has a feature that uses AI to generate portraits, for not compensating artists whose art was used to help train it. Lensa’s creators have said its portraits are “not replicas of any particular artist’s artwork.” Dr. Xu says platforms like Letterboxd might have a tough time proving that ChatGPT violates intellectual property laws. And generative-AI developers can address the issue, she said, by adding citations to their bots’ answers. For now, Mr. Buchanan says he’s taking solace in the fact that ChatGPT’s “anodyne” responses lack a human touch. I can’t help but agree. The humor and strangeness of Letterboxd reviews can leave me excited to watch particular movies. (In reference to the cinematographer of “Blade Runner 2049,” for instance, one Letterboxd reviewer wrote “I’m pregnant and the father is Roger Deakins’ camera.”) ChatGPTs responses are usually reasonable, but they rarely surprise. And because the bot is only trained on data that predates September 2021, it has some blind spots, though I haven’t yet encountered these. In any case, the last time I settled in to watch a film, I knew exactly what to stream—I had to see what all the Roger Deakins fuss was about. 3 More AI-Augmented Apps Tech companies are racing to incorporate ChatGPT-like capabilities into their own products. The following apps are free to download, but access to some of their features might cost you extra. Simpler Searching Neeva, a private search engine designed by Sridhar Ramaswamy, the former lead of Google’s ad and commerce division, uses AI to summarize the results of a traditional list of blue links, fetching one final answer to your query. No more sifting through a pile of obscure websites just to find the difference between baking powder and baking soda. (Expect more of this: Microsoft announced last week it was integrating the tech behind ChatGPT into its search engine Bing.) Modern-day Memex Mem uses AI to form contextual links between your emails, calendar appointments, memos and more so that you can find them all in one place. If you’re looking to attend a certain meeting, for example, Mem will create a page where you will find the joining link, plus any relevant notes you’ve prepared and related emails you’ve received and sent. Easier Editing You no longer need high-end software to edit videos, podcasts and voiceovers. Descript converts these into easily scannable transcripts, so that you can cut filler words or move scenes around. Used judiciously, this saves time, and sounds surprisingly professional.",,,MISSING
"TripActions Rebrands as Navan, Adds ChatGPT to Expense Reports",https://www.wsj.com/articles/tripactions-rebrands-as-navan-adds-chatgpt-to-expense-reports-11675740210?page=4,"With ChatGPT capabilities built in, the platform’s chatbot will be able to learn a users’ preferred airlines, hotels and restaurants, and incorporate these options into a proposed itinerary, while leveraging natural-language models to respond to voice commands, said Ariel Cohen, TripActions co-founder and chief executive. Behind the scenes, ChatGPT will also write, test and fix the underlying code that runs the app, constantly making tweaks based on data analytics aimed at boosting operational efficiency across its code base, Mr. Cohen said. The eight-year-old company’s approach grew out of workers’ frustrations with expense-report software tools, which often require users to manually enter figures from a stash of receipts, gathered from airlines, hotels, taxis and restaurants. “Employees frequently complain about the amount of time and effort they spend on expenses and about the time it takes to get reimbursed,” said Liz Herbert, vice president and principal analyst at information-technology research firm Forrester Research Inc. TripActions has sought to streamline the process through capabilities such as an artificial-intelligence-powered smartphone receipt-scanning tool, which automatically loads and categorizes items from printed receipts into an expense report, matching them to credit-card charges. It also works with digital receipts. That way, the expense report is generated during the trip as expenses are incurred, Mr. Cohen said. “Generally, software in the business-to-business space is designed to serve the company,” rather than the employees, Mr. Cohen said. “It’s about efficiency for the company, but not really about the workers.” By consolidating services, he said, Navan will enable employees to manage bookings and expenses on a single platform, which is designed to search for available travel options, track every transaction on a corporate card, and automatically generate an expense report. Mr. Cohen said the market opportunity lies in bridging the gap between the business travel apps employees have grown accustomed to, and the user-friendly consumer apps they use to book family vacations or simply a night out. “Using AI helps you create the kind of software that I’m talking about,” Mr. Cohen said. “This is how business software needs to be.” That strategy is catching the attention of some of the startup world’s biggest investors. In October, TripActions closed a $154 million equity funding round, including capital from returning investor Andreessen Horowitz, while raising an additional $150 million in a structured financing deal with Coatue Management LLC, a technology-focused investment manager. It currently has a private-market valuation of more than $9 billion. “It’s kind of like this weird anomaly where consumer travel changed a lot and business travel stayed the same,” said Ben Horowitz, co-founder and general partner of Andreessen Horowitz. Mr. Horowitz said Navan’s new all-in-one app offers a “better way of doing expenses” by filling in transactions in real-time while a user is traveling. But whether as TripActions or Navan, the company has a lot of ground to make up to catch market front-runner SAP Concur, industry analysts said. Based on revenue, SAP Concur, owned by enterprise-technology stalwart SAP SE, holds 49% of the global travel-and-expense management market, according to research firm International Data Corp. SAP Concur has also begun using AI in its travel and expense software, which can “tap decades of expense data and experience tracking to identify hard-to-detect spend issues and anomalies,” said Charlie Sultan, president of Concur Travel. Among other benefits, he said, using AI has reduced the time it takes for employees to be reimbursed for expenses to roughly three or four days, from 10 days or more. Other competitors include Expensify, Rydoo and Coupa, along with expense apps included in broader enterprise resource planning platforms offered by Workday Inc. and Oracle Corp. IDC expects the market to expand by a compound annual growth rate of 7.5% over the next three years, from an estimated $2.5 billion this year to $3.2 billion by 2026. “The new battlefield for software vendors in the travel-and-expenses space will be addressing data management,” said IDC Research Director Kevin Permenter, citing capabilities like data analytics and the use of application programming interfaces, designed to link programs together. “It is not enough to have good functionality,” Mr. Permenter said, “users must be able to move data into and out of your software quickly and easily.”",,,MISSING
Microsoft Adds ChatGPT AI Technology to Bing Search Engine,https://www.wsj.com/articles/microsoft-adds-chatgpt-ai-technology-to-bing-search-engine-11675793525?page=4,"Microsoft Corp. is integrating the technology behind the viral chatbot ChatGPT into its Bing search engine, hoping the artificial intelligence upgrade can help it chip away at Google’s dominance of the search market. The breakout success of the bot from the Microsoft-backed OpenAI has put the software giant at the forefront of what some see as the next wave of technological innovation: generative artificial intelligence. In an event Tuesday to launch the technology, Microsoft said the Bing upgrade will enable a new kind of search in which people will pose questions to the search engine in natural language and it will generate direct answers and suggestions. “I think this technology is going to reshape pretty much every software category,” Microsoft Chief Executive Satya Nadella said at the event at the company’s Redmond, Wash., headquarters. Mr. Nadella put the significance of AI-powered search on the same level of importance as the development of web browsers and mobile devices. Unlike ChatGPT, which wasn’t able to answer questions about current events, the updated Bing uses newer technology tailored for search engines. It will have access to the latest information such as news stories, train schedules and product pricing. It will also be able to provide links to demonstrate where its answers are coming from, another feature that wasn’t part of ChatGPT. Microsoft shares climbed 4% Tuesday as the Nasdaq Composite Index rose 2%. The company’s stock price has risen around 17% over the past three months while the Nasdaq index rose 15%. Microsoft, which is investing billions of dollars into OpenAI, is integrating the technology into many of its products, marking what it pitches as a new era of AI-powered software that has the potential to upend power in the tech industry. Some analysts say AI-powered searches could help Microsoft’s Bing search engine take market share away from Alphabet Inc.’s Google, which controls around 90% of the market. The industry has been buzzing about the possibilities of generative AI since OpenAI released its image generation tech Dall-E 2 to the public last year. Dall-E 2 can create original images based on simple prompts, such as, “Draw a robot dancing in a field of flowers.” OpenAI released ChatGPT in November. Millions of people have since used it to generate essays, sales pitches and poems. The popularity of the tools has put pressure on Google, which has long been at the forefront of AI technology, to match it. Earlier this week, Google announced it is rolling out its own conversational artificial-intelligence service to a set of testers and plans a broader public launch in the coming weeks. The new experimental service, called Bard, generates responses to questions posed by users, based on information drawn from the web, Sundar Pichai, chief executive of Google parent Alphabet, said in a blog post published Monday. Shares of Chinese internet giant Baidu Inc. surged in Hong Kong Tuesday as it confirmed plans to launch an artificial-intelligence chatbot. Baidu said it expects to launch its AI chatbot, called Ernie Bot, in March. Some artificial intelligence analysts warn there are still potential problems with generative AI. ChatGPT, for example, can be expensive to run and slow, and it sometimes produces responses that contain made-up facts, they have said. OpenAI CEO Sam Altman was at the Microsoft event, saying the new uses for AI technology mark the “beginning of a new era.” In the past he has warned that it is still evolving and prone to inaccuracies. Mr. Altman said both OpenAI and Microsoft are taking a cautious approach in how they roll out the technology, trying to take measures to ensure that Bing won’t generate dangerous or offensive content. “We share a deep sense of responsibility in ensuring that AI gets deployed safely,” he said. The technology is proving powerful in some cases, such as when it is paired with professionals for specific tasks. Last year Microsoft released GitHub Copilot which uses OpenAI tools to help programmers write and fix computer code. Microsoft estimated that in files in which it is enabled, Copilot generates 40% of the code. The company last year also integrated OpenAI’s image-generation tech into its Bing and graphical design software Microsoft Designer. The latest applications of the technology to Bing as well as Microsoft’s Edge browser are aimed at creating similar partnerships between people and AI, Mr. Nadella said. “You’re going to have this notion of a co-pilot that’s going to be there across every application,” he said. On Tuesday Microsoft showed off Bing’s new ability to spit out brief biographies of famous Mexican artists, compare features of new televisions and generate a family’s weekly dinner menu. Using a Bing integration into Microsoft’s Edge web browser, people can converse with the search engine to refine initial answers. For example, it can take a suggested menu and generate a shopping list for the ingredients. The search engine cites sources of the information that make up its responses. While that citation ability is an improvement over ChatGPT and gives people a better sense of where answers are coming from, it could raise questions about copyright and the effect this new search model will have on web traffic.",,,MISSING
ChatGPT Clones Are Preparing to Take Over China,https://www.wsj.com/articles/chatgpt-clones-are-preparing-to-take-over-china-11675940852?page=4,"This column isn’t written by ChatGPT. At least not yet. But the conversational artificial-intelligence tool seems to be taking over the world—and that now includes the Chinese stock market. Investors should be careful not to get ahead of themselves, however. AI is a different political ballgame in China than e-commerce or online finance, but the country has just emerged from a multiyear crackdown on internet-platform companies—in part, because they became too powerful and ubiquitous. At the very least, such a potentially transformative new technology seems likely to quickly become a subject of significant regulatory concern. The launch of ChatGPT by Microsoft-backed OpenAI a few months ago has sparked a race among U.S. online-search and software giants. On Tuesday, Microsoft said it would incorporate the AI tool into its Bing search engine and Edge web browser. Search market leader Google says it will launch its own version of an AI chatbot called Bard. Across the Pacific, Chinese companies are jumping on the bandwagon too. China’s search giant Baidu said on Tuesday that it will unveil its own conversational AI tool called Ernie Bot after completing internal testing in March. Alibaba , China’s e-commerce leader, said on Wednesday it is also testing its own ChatGPT-style tool. Baidu’s shares jumped 15% in Hong Kong on Tuesday on the news. The stock has since given up some of those gains, but it has gained 36% this year so far, outperforming other Chinese stocks: the CSI 300 mainland benchmark is up only 7%. AI-related stocks listed in China, meanwhile, have surged to the stratosphere. Shares of Shenzhen-listed Hanwang Technology, which makes products for use in character recognition, have more than doubled in 2023. Shares of Shanghai-listed Beijing Haitian Ruisheng Science Technology, which develops training data sets for AI, have tripled. It is easy to see how chatbots could be integrated into tech giants’ businesses. Bots may, for example, improve the search interface for Baidu’s users. The ability of ChatGPT to draft convincingly human essays could enhance productivity tools. Tech giants with their enormous troves of data and AI research are well-placed to capitalize on the new technology. Regulation could be another issue, especially in China, given its strict data-security laws. While the government will probably initially be supportive because dominance in AI is such a high policy priority for Beijing, widespread use of the tool by the public will still be scrutinized. Its use may be restricted in settings like education. And if advanced chatbot technology starts bumping up against some of Beijing’s sore spots—for example, online financial fraud or politics—one can imagine a swift and sure regulatory response. But it is still too early to tell how much revenue such chatbots will really bring into corporate coffers. For one, competition will be intense: It’s already clear that many major internet-platform companies could end up as contenders. AI-powered chatbots could help improve existing services, but may not create new, stand-alone revenue streams. And integrating chatbots into existing platforms may incur significant costs. When asked to write a short sentence on investing in the latest fads, ChatGPT said it “can be risky and they may not have a solid track record and can quickly lose popularity.” Investors would be wise, in this case, to take it at its word.",,,MISSING
ChatGPT Needs Some Help With Math Assignments,https://www.wsj.com/articles/ai-bot-chatgpt-needs-some-help-with-math-assignments-11675390552?page=4,"The artificial-intelligence chatbot ChatGPT has shaken educators since its November release. New York City public schools have banned it from their networks and school devices, and professors are revamping syllabi to prevent students from using it to complete their homework. The chatbot’s creator, OpenAI, even unveiled a tool to detect text generated by artificial intelligence to prevent abuse from cheaters, spammers and others. There is, perhaps surprisingly, one subject area that doesn’t seem threatened. It turns out ChatGPT is quite bad at math. “I’m not hearing math instructors express concern about it,” said Paul von Hippel, a professor at the University of Texas who studies data science and statistics and has written an essay about ChatGPT’s mathematical limitations. “I’m not sure it’s useful for math at all, which feels strange because mathematics was the first-use case for computing devices.” While the bot gets many basic arithmetic questions correct, it stumbles when those questions are written in natural language. For example, ask ChatGPT “if a banana weighs 0.5 lbs and I have 7 lbs of bananas and nine oranges, how many pieces of fruit do I have?” The bot’s quick reply: “You have 16 pieces of fruit, seven bananas and nine oranges.” It isn’t hard, and in fact is a little entertaining, to feed the bot questions to which it responds with confident nonsense. If you ask ChatGPT who is taller, Shaquille O’Neal or Yao Ming, the bot accurately says Yao is 7’6” and O’Neal is 7’1” but then concludes that Shaq is taller. The bot miscalculates the square roots of large numbers. Ask it to show its math, and it often produces detailed formulas that look great but contain errors, such as 2 x 300 = 500. I asked ChatGPT to write five simple algebra problems and then to provide the answers. The AI only answered three of its own problems correctly. ChatGPT’s struggle with math is inherent in this type of artificial intelligence, known as a large language model. It scans enormous reams of text from across the web and develops a model about what words are likely to follow others in a sentence. It’s a more sophisticated version of autocomplete that, after you type “I want to” on your device, guesses the next words are “dance with somebody,” “know what love is” or “be with you everywhere.” ChatGPT, OpenAI’s new artificially intelligent chatbot, can write essays on complex topics. WSJ’s Joanna Stern went back to high school AP Literature for a day to see whether she could pass the class using just AI. Photo illustration: Elena Scotti A Mad Libs-proficient supercomputer might be extremely effective for writing grammatically correct responses to essay prompts, but not for solving a math problem. That is the Achilles’ heel of ChatGPT: It responds in authoritative-sounding language with numbers that are grammatically correct and mathematically wrong. As Mr. von Hippel wrote, “It acts like an expert, and sometimes it can provide a convincing impersonation of one. But often it is a kind of b.s. artist, mixing truth, error and fabrication in a way that can sound convincing unless you have some expertise yourself.” In an email, I asked Debarghya Das, a search-engine engineer who has tweeted examples of ChatGPT botching basic math, why it gets some simple questions right but others completely wrong. “Maybe the right analogy is if you ask a room of people who have no idea what math is but have read many hieroglyphics, ‘What comes after 2+2,’ they might say, ‘Usually, we see a 4.’ That’s what ChatGPT is doing.” But, he adds, “math isn’t just a series of hieroglyphics, it’s computation.” It isn’t great for faking your way through a math class because you only recognize the mistakes if you know the math. If it’s all hieroglyphics to you, the wrong answers seem plausible. OpenAI Chief Executive Sam Altman said in December on Twitter that “ChatGPT is incredibly limited, but good enough at some things to create a misleading impression of greatness. It’s a mistake to be relying on it for anything important right now.” When you begin a conversation with ChatGPT it warns up front, “While we have safeguards in place, the system may occasionally generate incorrect or misleading information.” Another reason that math instructors are less fussed by this innovation it that they have been here before. The field was upended for the first time decades ago with the general availability of computers and calculators. “Math has had the biggest revolution based on machinery of any mainstream subject I could ever have thought of,” said Conrad Wolfram, the strategic director of Wolfram Research, which developed Mathematica, a technical computing software program, as well as Wolfram Alpha, a website for answering math queries. Whereas English teachers are only now worrying about computers doing their students’ homework, math teachers have long wrestled with making sure students were actually learning and not just using a calculator. It’s why students have to show their work and take tests on paper. The broader lesson is that AI, computers and calculators aren’t simply a shortcut. Math tools require math knowledge. A calculator can’t do calculus unless you know what you’re trying to solve. If you don’t know any math, Excel is just a tool for formatting tables with a lot of extra buttons. “In the real world, since computers came along, have math, science and engineering gotten conceptually simpler? No, completely the opposite. We’re asking harder and harder questions, going up a level,” Mr. Wolfram said. Eventually, artificial intelligence will probably get to the point where its mathematics answers are not only confident but correct. A pure large language model might not be up for the job, but the technology will improve. The next generation of AI could combine the language skills of ChatGPT with the math skills of Wolfram Alpha. In general, however, AI, like calculators and computers, will likely ultimately be most useful for those who already know a field well: They know the questions to ask, how to identify the shortcomings and what to do with the answer. A tool, in other words, for those who know the most math, not the least.",,,MISSING
"China’s Baidu Developing Its Own ChatGPT, Joining Global AI Race",https://www.wsj.com/articles/baidu-is-developing-its-own-chatgpt-aiming-to-integrate-it-into-search-11675065601?page=4,"China’s Baidu Inc. has thrust itself into a global race to commercialize the next generation of artificial-intelligence technologies like ChatGPT that could transform the internet. The company is developing an AI-powered chatbot similar to OpenAI‘s popular ChatGPT and plans to integrate it into its main search engine in March, people familiar with the matter said. The move would place Beijing-based Baidu among a few tech companies globally to have its own version of the technology, which has generated buzz among consumers and businesses, and placed pressure on incumbents, which have started to update their product-development strategies. Baidu is set to be the first to bring the technology to consumers in China, where the state censors the internet and access to ChatGPT is blocked Baidu’s plans come as competition heats up between Washington and Beijing to bolster their respective countries’ leadership in strategic emerging technologies. They also highlight the fluid, cross-border nature of AI research, where open-source is the norm. OpenAI built ChatGPT atop a core breakthrough that Alphabet Inc.’s Google developed in 2017—an algorithm that Baidu also adapted and is now using as the foundation for its chatbot, according to some of the people. Baidu Chief Executive Robin Li touched on ChatGPT in a late-December speech to some employees, saying it represents new opportunities, according to a transcript on Baidu’s internal website that was seen by The Wall Street Journal. “We have such cool technology, but can we turn it into a product that everyone needs?” Mr. Li said, referring to AI-driven technologies including the chatbot. “This is actually the hardest step, but also the greatest and most influential.” Bloomberg earlier reported on Baidu’s plans. Baidu, whose growth hasn’t kept up with that of its Chinese internet peers, has been pushing to refashion itself into an AI company, investing billions of dollars in technologies including self-driving cars and chips designed to power AI applications. Using its vast repository of text data from its search-engine business, it has focused in particular on an area of AI research known as natural-language processing, which has experienced major leaps in advancement in the past few years and led to the recent surge of AI technologies, including ChatGPT. In 2019, Baidu developed a deep-learning model known as Ernie, based on Google’s breakthrough, which it has used to improve its search results, including to make them more relevant. The company has since developed dozens more Ernie models and extended their capabilities to include image and art generation, similar to those of OpenAI’s Dall-E. ChatGPT, OpenAI’s new artificially intelligent chatbot, can write essays on complex topics. WSJ’s Joanna Stern went back to high school AP Literature for a day to see if she could pass the class using just AI. Photo illustration: Elena Scotti Baidu is now using Ernie as the foundation for its chatbot, and is training it on both Chinese- and English-language sources inside and outside China’s firewall, some of the people said. In the past, Baidu has trained Ernie using sources that include Wikipedia, BookCorpus, Reddit and Baidu’s ecosystem of products—such as Baidu Baike and Baidu News—according to its open-source research papers. Baidu plans to limit its chatbot’s outputs in accordance with the state’s censorship rules, one of the people said. OpenAI also applies restrictions to ChatGPT’s outputs in an effort to avoid toxic hate speech and politically sensitive topics. Trained on vast amounts of text data from the internet, ChatGPT is capable of answering all manner of user questions in fluent conversational prose. But the chatbot can’t guarantee accurate answers and at times has delivered sexist or racist comments, industry researchers have said. Tech giants including Microsoft Corp. and Google are hurrying to mature the technology underlying ChatGPT and integrate it into their products—including search, where its conversational abilities are seen to have the most potential to upend the status quo. Microsoft, which invested in OpenAI in 2019 and 2021, announced fresh backing—as much as $10 billion, The Wall Street Journal reported—to infuse ChatGPT into its product lines, including its search engine Bing. A similar Google technology known as LaMDA made its debut in 2021, and Meta Platforms Inc. released a chatbot known as BlenderBot in 2020, but neither has revealed plans to integrate the technology into their platforms.",,,MISSING
OpenAI to Offer ChatGPT Subscription Plan for $20 a Month,https://www.wsj.com/articles/openai-to-offer-chatgpt-monthly-subscription-plan-11675284555?page=4,"OpenAI is launching a paid subscription version of its artificial-intelligence chatbot ChatGPT. The new subscription service is called ChatGPT Plus and will have a $20 monthly fee, the company announced Wednesday. The subscription includes access to the chatbot during peak usage times. The current free version limits service to users during periods when usage is high. Subscribers will also get early access to new features and improvements and faster response times from the chatbot. The new subscription program will first be available in the U.S. in the coming weeks and then expand to other countries, OpenAI said in a statement on its website. Interested users can sign up for a wait list to the subscription service, the company said. The new subscription program will initially be available in the U.S. and will later expand to other countries, OpenAI said. Interested users can sign up for a wait list to the subscription service, the company said. OpenAI will begin inviting people over from the wait list in the coming weeks. OpenAI will continue to offer free access to ChatGPT. The subscription service will help support free access for the chatbot, the company said. OpenAI is also exploring options for lower-cost plans and business plans. Microsoft is deepening its partnership with OpenAI, the company behind ChatGPT and Dall-E. That has investors and analysts speculating whether Microsoft could challenge Google’s dominance in search. WSJ Heard on the Street columnist Dan Gallagher joins host Zoe Thomas to discuss how AI could affect search and at what cost. ChatGPT allows users to type questions to the bot and receive written responses powered by artificial intelligence. It can even write poems and essays. Some industry observers have said ChatGPT could offer a potential alternative to current search engines in the future, though the company has said that the program’s outputs often contained factual errors. Last month, Microsoft Corp. said it would make a multiyear, multibillion-dollar investment in OpenAI after previously investing in 2019 and 2021. The companies didn’t disclose financial terms of the partnership. Microsoft has said it would incorporate artificial-intelligence tools like ChatGPT into all of its products and make them available as platforms for other businesses to build on. Microsoft Chief Executive Satya Nadella said the company would commercialize tools from OpenAI like ChatGPT and give more customers access to software behind chatbot through its cloud-computing platform Azure. OpenAI has also discussed selling existing shares in a tender offer that would value the company at around $29 billion, The Wall Street Journal previously reported.",,,MISSING
Google Opens Testing of Its ChatGPT Rival,https://www.wsj.com/articles/google-opens-testing-of-chatgpt-rival-as-artificial-intelligence-war-heats-up-11675711198?page=4,"Google is rolling out a new conversational artificial-intelligence service to a select set of testers, and plans a broader public launch in coming weeks, part of the company’s effort to play catch-up with challengers such as OpenAI, creator of the popular chatbot ChatGPT. The new experimental service, called Bard, generates textual responses to questions posed by users, based on information drawn from the web, Sundar Pichai, chief executive of Google parent Alphabet Inc., said in a blog post published Monday. In that post, Mr. Pichai also shared a glimpse of new search engine features that will use AI to answer user queries, and said it would open up some of its AI programs to outside developers. Google’s new products come amid a flurry of announcements by rival Microsoft Corp. about its use of AI technologies developed by OpenAI. Microsoft said last month it is making a multiyear, multibillion-dollar investment in the San Francisco AI startup. It said it would be opening up its tools for developers to build upon, and integrating them into services such as its Bing search engine—raising the specter of a new challenge to Google Search’s market power. Microsoft says it is planning an event on Tuesday to announce “progress on a few exciting projects,” which are widely expected to include a chatbot-infused version of Bing. Sam Altman, chief executive of OpenAI, on Monday tweeted a picture of himself next to Microsoft Chief Executive Satya Nadella, saying “excited for the event tomorrow.” Microsoft’s announcements have led to complaints from investors that Google hasn’t moved quickly enough to release its in-house AI tools, despite being the pioneer of some of the technologies used to build tools such as ChatGPT. Those complaints have been echoed by some of its own researchers, The Wall Street Journal has reported. In response, Google executives have recently sped up work to review and release artificial-intelligence programs to the general public, while also assigning teams of engineers to work on new ways to integrate new developments into areas such as the core search experience, the Journal reported. Google executives have also suggested they haven’t been slow so much as careful with their tools, drawing an implicit contrast to competitors tools, such as ChatGPT, that can spout made-up information in response to some user queries. Google executives say they must test new tools to make sure they don’t show bias, and guard against misuse, concerns shared by many academics. “It’s critical that we bring experiences rooted in these models to the world in a bold and responsible way,” Mr. Pichai in his blog post on Monday. “That’s why we’re committed to developing AI responsibly.” He added that the new external testing period for Bard will be combined with internal research to make sure that it gives responses that meet Google’s “high bar for quality, safety and groundedness in real-world information.” Mr. Pichai said in a separate internal email seen by The Wall Street Journal that Google’s entire staff will get access to Bard next week in order to give feedback as part of a “company-wide dogfood,” or tech-industry slang for testing or using one’s own products. Google is under the spotlight of regulators in the European Union, U.S. and other parts of the globe. In the EU, policy makers are considering a new AI law that could require companies to conduct risk assessments before launching new tools Google says its Bard service is based on its experimental artificial-intelligence program called LaMDA, which stands for Language Model for Dialogue Applications. Google last year suspended an engineer who contended that LaMDA had become sentient—a claim roundly rejected by scientists in the field. ChatGPT, OpenAI’s new artificially intelligent chatbot, can write essays on complex topics. WSJ’s Joanna Stern went back to high school AP Literature for a day to see if she could pass the class using just AI. Photo illustration: Elena Scotti When OpenAI released ChatGPT late last year, it took off as a viral sensation.   While it was based on AI tools widely available to researchers, the breadth of its capabilities opened up the possibilities of so-called generative AI—or AI that can create content in response to short user inputs—to a wider audience of potential users. People posted the chatbot’s humorous responses to their queries, like a retelling of the Goldilocks fairy tale in the style of a police blotter, as well as complex computer software coding that it could provide when asked.   Google offered few details Monday about how Bard will work and what kind of answers it will offer. The company said that Bard would initially use what it called a smaller model of LaMDA that uses less computing power, which will allow the company to make it more widely available.   Sample queries for Bard include, “What new discoveries from the James Webb Space Telescope can I tell my 9-year-old about?” to which Bard replies three short bullet points of recent discoveries. Other suggested queries in the blog post include, “Plan a friend’s baby shower” and “Compare two Oscar-nominated movies.”   In Monday’s post, Mr. Pichai also gave a glimpse of some new AI features that he said would soon be integrated into the company’s eponymous search engine. Those features aim to “distill complex information and multiple perspectives into easy to digest formats,” he said.   The only example query the company provided Monday asks the search engine whether it is easier to learn to play piano or guitar. Google’s answer? Some say piano while others say guitar.   More examples are expected on Wednesday, when Google has scheduled an event in Paris that will share progress on the new AI-based search tools, the internal email from Mr. Pichai said.  Mr. Pichai also said Google plans next month to start allowing outside developers to start building LaMDA’s generative language capabilities into their own applications, through a new application programming interface, or API, that allows them to query LaMDA as part of their own tools. Eventually the company says it will make a suite of tools.   That announcement in some ways mirrors Microsoft’s announcement last month that it would start allowing outside developers to build with ChatGPT and other AI tools through its own APIs.",,,MISSING
Opinion: Only Bad Writers Should Fear ChatGPT,https://www.wsj.com/articles/only-bad-writers-should-fear-chatgpt-technology-robots-artificial-intelligence-education-journalism-11675201758?page=5,"People seem to think that OpenAI’s ChatGPT, a chatbot powered by artificial intelligence, is going to put many writers out of business or make writing bland—or both. But perhaps that’s not a bad thing. With the rise of the internet, we’re inundated with more writing than ever and most of it is mediocre. On social media platforms like Twitter, everyone gets a license to be a short-form editorial writer, uninhibited by an editor or boss riding them for accuracy and relevance. Are public debates over ideas and policies any more informed or enlightened for having these truncated opinion pieces? You know the answer. Journalism has the opposite problem. Journalistic writing once had to fit into a set number of column inches. Now, the digital-news hole is infinite, so most news stories go on and on without a sense of restraint—but with dwindling quality. No wonder ChatGPT’s most immediate application is on digital news, tech and social-gossip sites desperate to keep readers engaged with whatever content sticks to the wall. And look at corporate writing: It’s either cliché-ridden, meaningless fluff or rife with jargon. Either way, most of it is utterly forgettable. Academics aren’t much better. Their writing—especially in the humanities and social sciences—is so arcane and technical that most of it is never read, even by other academics. Maybe robots should get a shot at taking over some of this workday prose. Who wouldn’t mind a robot-generated statement that clearly articulates a company’s strategy without referring to the time-worn clichés of “paradigm shift” or “optimized performance”? What’s so bad about an academic paper written in language that any keen learner could understand? Would you turn your nose up at concise, fact-rich reporting on recent news? I think people fear robot-writers because they do their job well, maybe even better than humans do. Some will contend that ChatGPT’s skills are limited and lacking in style, but so what? Sure, it can’t write a masterful piece of prose or a profound novel. But most of what we read isn’t that good anyway, even the stuff written by people. As long as artificial intelligence produces instruction manuals that are clear and corporate policies that provide direction, that’s good enough for me. A robot might even manage to summarize important historical events without taking potshots at contemporary political figures. (That is, of course, if ChatGPT manages to fix its left-leaning tilt.) Those would all be welcome improvements. What about the writers who remain? They’ll be able to elevate their craft to higher purposes—or at the very least create something truly original. Consider how portrait artists responded to the invention of photography. The best ones excelled in impressionism, cubism and other movements of modern art. Art didn’t disappear, it simply shifted its gaze. Whether you want them or not, the robot-writers are coming. Soon we will be able to generate solid writing as easily as we use internet search engines. We’ll get practical results that work for practical purposes. But when something new or weighty needs to be shared, we will turn to human writers who have the gift of conveying the unexpressed thought in words that are original and artful. That’s the kind of writing humans should do—and if that’s our destiny, we should embrace it, even if fewer of us do the work.",,,MISSING
"ChatGPT Creator Releases Tool to Detect AI-Generated Text, Calls It ‘Unreliable’",https://www.wsj.com/articles/chatgpt-creator-releases-tool-to-detect-ai-generated-text-calls-it-unreliable-11675204820?page=5,"The startup behind the viral chatbot ChatGPT unveiled a tool for detecting text generated by artificial intelligence amid growing concerns the technology will be abused by cheaters, spammers and others. But OpenAI said its so-called AI classifier itself fails to detect bot-written text nearly three quarters of the time. The San Francisco-based startup, which launched ChatGPT in November and recently announced a multiyear, multibillion-dollar partnership with Microsoft Corp., released the detection tool on Tuesday. It said in a blog post that the tool was designed to help people distinguish between text written by a human versus a range of artificial intelligence programs—not just ChatGPT. OpenAI said that in evaluations its new tool correctly identified 26% of AI-written text as “likely AI-written.” It said the classifier also had false positives 9% of the time in which it incorrectly labeled human-written text as AI-written. “Our classifier is not reliable,” the company said, referring to it as a “work-in-progress.” The tool isn’t good enough on its own, though it can be used to complement methods that educators, employers and others rely on to determine the source of a piece of text, OpenAI said. “While it is impossible to reliably detect all AI-written text, we believe good classifiers can inform mitigations for false claims that AI-generated text was written by a human,” the company said. ChatGPT became a viral sensation due to its ability to produce human-sounding essays, poetry, screenplays and sales pitches on virtually any subject in seconds. Microsoft invested in OpenAI in 2019 and 2021 before announcing the major expansion of their partnership last week, and has said it plans to integrate the company’s technology into many of its products. Soon after ChatGPT was released, the potential for it to be misused to do things such as spread misinformation and write spam became apparent. Schools and educators also have warned of the potential for students to use it to write essays or other work they have been assigned. In December, the software passed all three parts of the U.S. Medical Licensing Examination as part of a research experiment. Some schools have moved to ban students from using ChatGPT, while others are attempting to embrace it. Edward Tian, a Princeton University senior, created software called GPTZero to try to recognize writing generated by the software. OpenAI said it had schools in mind when developing its latest classifier tool. “We recognize that identifying AI-written text has been an important point of discussion among educators, and equally important is recognizing the limits and impacts of AI-generated text classifiers in the classroom,” it said. Journalists, researchers and others can also use the tool to detect AI-generated content, the company said. OpenAI said ChatGPT is still unreliable on short texts and longer texts are sometimes labeled incorrectly. It performs “significantly worse” in languages other than English and is “unreliable” in detecting AI use in computer code. Another problem is that the tool can’t easily tell if a list of facts—U.S. state capitals for example—was written by a person or AI, because the correct answer would be the same, OpenAIsaid. AI-written text can also be edited to evade the classifier, the company said. These kinds of caveats raise questions about just how beneficial the tool can be, the company said. “Classifiers like ours can be updated and retrained based on successful attacks,” OpenAI said. “But it is unclear whether detection has an advantage in the long-term.” With feedback from users, OpenAI hopes to improve the tool. It said it has reached out to U.S. educators to discuss ChatGPT’s capabilities and limitations. “These are important conversations to have as part of our mission is to deploy large language models safely, in direct contact with affected communities,” the company said.",,,MISSING
ChatGPT Spotlights Microsoft’s Bid to Monetize AI,https://www.wsj.com/articles/chatgpt-spotlights-microsofts-early-efforts-to-monetize-ai-11674964348?page=6,"As the breakout success of OpenAI’s ChatGPT triggers a tsunami of excitement over artificial intelligence, Microsoft Corp. is positioning itself at the forefront of what some see as the next wave of technological innovation. The challenge for Microsoft and other companies: turning this novel and still imperfect technology into a big business. The software company said last week that it was pouring billions of dollars more into OpenAI. The startup is in the limelight as tech executives and the public have been mesmerized by its chatbot, which can answer difficult questions, write book reports and compose poetry in seconds. Microsoft earlier this month moved to jump-start the adoption of the technology by offering to let any company apply to use it through its Azure cloud-computing platform. “The age of AI is upon us, and Microsoft is powering it,” Chief Executive Satya Nadella said on a call with analysts last week. Most interactions with generative AI—so called because it can work off regular language prompts to generate unique creations—have been for fun. Millions have flocked to ChatGPT since it was released in November. OpenAI’s other viral hit, the image-generating Dall-E 2, has flooded the web with user-created pictures. As a disruptive business, ChatGPT is still finding its feet. There are many problems with it, according to AI researchers. ChatGPT is expensive to run and slow, and it sometimes produces responses that contain made-up facts, they have said. Gary Marcus, a founder of the machine-learning startup Geometric Intelligence, said that even as OpenAI releases updated versions of GPT, the problems with inaccurate information will continue. “This particular tech will not solve those problems, so what can you do with these systems that aren’t truthful?” Mr. Marcus asked. OpenAI didn’t respond to a request for comment. Its chief executive officer, Sam Altman, has said that ChatGPT is an imperfect technology and that it would improve. He said in a tweet last month: “it’s a mistake to be relying on it for anything important right now. it’s a preview of progress; we have lots of work to do on robustness and truthfulness.” Microsoft declined to comment on concerns about the technology. Mr. Nadella has said that ChatGPT’s problems are solvable. “This is not new to just AI,” he said at a Wall Street Journal panel at the 2023 World Economic Forum event in Davos, Switzerland, this month. “It’s true in any other category of software today.” Last year Microsoft released GitHub Copilot, a tool within its code-collaboration site GitHub. It uses OpenAI tools to help programmers write and fix computer code. Microsoft estimates that in files in which it is enabled, Copilot generates 40% of the code. Many programmers have said it has become an invaluable tool. It is a prime example of how this type of AI is best when paired with professionals for specialized tasks, according to some AI users. They have said that the recent advances the technology has made in a short time show how remaining problems can quickly be fixed. “The rate of change going on—I have not seen anything progress as fast as this ever,” said Ben Firshman, the co-founder of the AI infrastructure startup Replicate. Mr. Nadella has been hailing the technology as the next disruptive advancement in the tech industry. He talks about infusing OpenAI’s innovations throughout Microsoft’s products. The company is already integrating OpenAI’s tech into its Bing search engine and graphical-design software, such as Microsoft Designer. Some analysts speculate that AI-powered searches could eventually help Microsoft’s Bing search engine take market share away from Alphabet Inc.’s Google, which controls around 90% of the market. ChatGPT, OpenAI’s new artificially intelligent chatbot, can write essays on complex topics. WSJ’s Joanna Stern went back to high school AP Literature for a day to see if she could pass the class using just AI. Photo illustration: Elena Scotti “If it makes Microsoft a competitive search engine, then we’re looking at a different business,” said Rishi Jaluria, an analyst for RBC Capital Markets. Google was the pioneer of some of the generative AI, but its tools haven’t been as widely open to the public. It is now trying to play catch-up. The more immediate benefit to Microsoft might be to its Azure cloud-computing business. As more companies use generative AI, Microsoft can market Azure as the platform best suited for the job. “The way Microsoft is going to really commercialize all of this is Azure,” Mr. Nadella said in Davos, adding that the company’s cloud “has become the place for anybody and everybody who thinks about AI.” Meta Platforms Inc. and Salesforce Inc. are developing AI tools. Smaller companies are experimenting with OpenAI’s technology to create products and services on Microsoft’s cloud. Microsoft said 200 customers have signed up to use OpenAI’s tools since it opened up the technology for broader use recently. Yoodli, a Seattle-based company that makes speech-coaching software, was an early adopter. It uses a predecessor to ChatGPT, called GPT-3, to analyze a speaker’s words to determine whether they ramble off topic. CEO Varun Puri said adding OpenAI’s generative AI tech to Yoodli’s own programs made its offering more robust and allowed it to build new features faster. “Our idea was always an AI-powered speech coach,” he said. “We were going to do it largely [on our own] data set. But generative AI has 100xed that.” Since OpenAI released GPT-3 in a limited fashion in 2020, startups have been using the technology. Founders who have used it have said it can be useful and problematic. Some worry about flaws in the technology, such as “hallucinations,” in which it generates false results with confidence. That has consigned the technology as more of an add-on feature than a core product. AI-enabled features are often pitched as assistants for professionals. The startup Lexion uses GPT-3 to help customers draft and amend legal documents. The company’s founders said the product is best used to assist an attorney rather than replacing one. The software generates contractual language that is sometimes wrong, an unacceptable glitch that means it has to be cross-checked. “We don’t have a good explanation or understanding of why it produced an output or how it produced an output,” said Gaurav Oberoi, Lexion’s CEO. “This is the problem with hallucinations.” Because of the limitations of the tech, it is best described as doing the work of a legal intern, he said.",,,MISSING
BuzzFeed to Use ChatGPT Creator OpenAI to Help Create Some Content,https://www.wsj.com/articles/buzzfeed-to-use-chatgpt-creator-openai-to-help-create-some-of-its-content-11674752660?page=6,"BuzzFeed Inc. said it would rely on ChatGPT creator OpenAI to enhance its quizzes and personalize some content for its audiences, becoming the latest digital publisher to embrace artificial intelligence. In a memo to staff sent Thursday morning, which was reviewed by The Wall Street Journal, Chief Executive Jonah Peretti said he intends for AI to play a larger role in the company’s editorial and business operations this year. In one instance, the company said new AI-powered quizzes would produce individual results. For example, a quiz to create a personal romantic comedy movie pitch might ask questions like, “Pick a trope for your rom-com,” and “Tell us an endearing flaw you have.” The quiz would produce a unique, shareable write-up based on the individual’s responses, BuzzFeed said. Mr. Peretti expects AI to assist the creative process and enhance the company’s content, while humans play the role of providing ideas, “cultural currency,” and “inspired prompts,” he wrote in his memo. In 15 years, he wrote, he expects AI and data to help “create, personalize, and animate the content itself,” rather than just curate existing content. BuzzFeed, which went public in late 2021 through a merger with a special-purpose acquisition company, last year moved to shrink its news division as it sought to make the business profitable, and said it would be doubling its creator network. The company is getting paid millions of dollars by Facebook parent Meta Platforms Inc. to help generate creator content for Facebook and Instagram, The Wall Street Journal reported Wednesday. BuzzFeed shares more than doubled in value Thursday, closing at $2.09. The stock remains down by over 75% since the company went public. BuzzFeed remains focused on human-generated journalism in its newsroom, a spokeswoman said Thursday. After receiving Mr. Peretti’s memo, a number of employees on Thursday expressed concerns and asked him questions on Slack about the implications of the move. One staff member asked how Mr. Peretti planned to circumvent “inevitable legal issues” around visual work created by illustrators, photographers and art directors at the company, as well as content that is protected by U.S. copyright, according to screenshots of the Slack channel that were reviewed by the Journal. “We’ve done experimentation in the past with AI-generative images, and we recognize these concerns and take them seriously,” Mr. Peretti wrote in response, according to the BuzzFeed spokeswoman. He also said the initial step in BuzzFeed’s plan was to use AI for text-based products. ChatGPT, OpenAI’s new artificially intelligent chatbot, can write essays on complex topics. WSJ’s Joanna Stern went back to high school AP Literature for a day to see if she could pass the class using just AI. Photo illustration: Elena Scotti Other employees asked about whether the use of AI technology would lead to a reduction in workforce, and expressed concerns around fact-checking AI-generated content. In response, Mr. Peretti wrote that the tools are an opportunity to make full-time employees more efficient and creative, not a workforce reduction strategy, the spokeswoman said. Mr. Peretti also answered staff questions during a companywide meeting earlier Thursday, the spokeswoman said. Mr. Peretti told staff during the meeting that digital-media companies that choose to rely on AI solely to save costs and produce low-quality content were making a terrible use of the technology, according to the spokeswoman. That isn’t BuzzFeed’s approach, Mr. Peretti said, noting there were far more creative ways to use AI. “I think that news, for good reason, is often the most conservative when it comes to adopting new technologies,” Mr. Peretti told staff, according to the spokeswoman. BuzzFeed’s move comes as ChatGPT, new chatbot technology from research lab OpenAI, generates buzz among consumers and businesses alike. Some publishers have said they are starting to discuss using AI technology, while others are already experimenting with it. Digital technology publisher CNET, for example, recently ran a test using internally designed AI technology to help editors create explainers around financial-services topics. CNET’s Editor in Chief Connie Guglielmo this week said the publisher paused its test, which had led to the publication of 77 stories, after finding a number of factual errors. Microsoft Corp., which has invested billions of dollars in OpenAI, plans to incorporate artificial-intelligence tools like ChatGPT into all of its products, Chief Executive Satya Nadella said last week.",,,MISSING
Professors Turn to ChatGPT to Teach Students a Lesson,https://www.wsj.com/articles/professors-turn-to-chatgpt-to-teach-students-a-lesson-11674657460?page=6,"Last month a professor at Weber State University in Utah asked a new artificial-intelligence chatbot to write a tweet in his voice. Within a few minutes the application, called ChatGPT, had spit out a dozen messages that captured Alex Lawrence’s tone and personality. His first reaction: “Holy Cow!” His second: “This is the greatest cheating tool ever invented.” His response reflects a dilemma that the powerful AI tool creates for educators: Should they ban ChatGPT or build on it? Whichever path they take, some teachers say they are scrambling to update curriculum, launch new learning guidelines and deploy tactics that stymie cheating and make sure students learn to think for themselves. Dr. Lawrence decided to change the curriculum in his sales-technology courses to allow students to use a suite of artificial-intelligence tools to complete their assignments. He is hoping that embracing the technology will stave off what he thinks is inevitable cheating and impart the tech skills students will need to succeed in the labor market. “I hope to inspire and educate you enough that you will want to learn how to leverage these tools, not just to learn to cheat better,” Prof. Lawrence wrote to his students this month. ChatGPT, which uses machine-learning algorithms to produce human-sounding prose, launched on Nov. 30. It is free to use and can deliver a written answer on virtually any subject from nearly any perspective in just 15 seconds. In December it passed all three parts of the U.S. Medical Licensing Examination as part of a research experiment. OpenAI, the research lab behind ChatGPT, is in talks to sell existing shares in a tender offer that would value the company at around $29 billion, making it one of the most valuable U.S. startups on paper, despite generating little revenue. On Monday Microsoft Corp. said it is making a multiyear, multibillion-dollar investment in OpenAI, as it looks to expand the use of artificial intelligence in its products. “It really seems to change the nature of knowledge production itself,” said Anand Rao, chair of the department of communications and digital studies at the University of Mary Washington in Virginia. Educational institutions that are banning ChatGPT include some large public-school districts. New York, Seattle and Los Angeles have all blocked the service from their networks. Some college and university professors, meanwhile, have tried to wall off their classrooms by requiring students to write essays longhand in blue books in class. Others are running essay prompts through ChatGPT to familiarize themselves with how the bot answers so they can spot plagiarism. Edward Tian, a Princeton University senior, created GPTZero to recognize writing generated by ChatGPT. He now has 23,000 teachers on a waiting list for the next version. Some students are also concerned. This month a survey of 1,000 students age 18 or older by online course provider Study.com found that nearly three quarters want ChatGPT banned from their school’s network. But 48% admitted using it to complete an at-home test or quiz, 53% to write an essay and 22% to write an outline for a paper. Students need to learn to write well for themselves because the writing process teaches them to think critically, said Johann Neem, a history professor at Western Washington University and the author of “What’s the Point of College?” “Just because there is a machine that will help me lift up a dumbbell doesn’t mean my muscles will develop,” said Dr. Neem. “In the same way just because there is a machine that can write an essay doesn’t mean my mind will develop.” Artificial intelligence is likely to have some impact on how students write, according to John Gallagher, a professor in the English department at the University of Illinois. When word processors replaced typewriters, written sentences got longer and more complicated, he said. Dr. Gallagher ran a three-month experiment on himself in the fall, using artificial intelligence for almost everything he wrote. He found it inconsistent—but also so helpful he became reliant on it. “It can become a crutch,” he said. “You stop working through things.” The new technology comes at a vulnerable time for students: Numeracy and literacy have declined and cheating has jumped. While the pandemic was raging and U.S. schools operated remotely, plagiarism appeared in nearly 50% of all academic submissions, compared with 35% before the pandemic, according to Copyleaks, Inc. which sells tools to detect plagiarism and artificial intelligence. During the second week of January, a sampling of papers from all grade levels from around the world revealed that 10% had used ChatGPT, said Copyleaks CEO Alon Yamin. Teachers who are leaning into the new technology compare it to a new power tool. You could build a house without using power tools, but why would you? asks David Chrisinger, who directs the writing program at the Harris School of Public Policy at the University of Chicago. He is asking his students to generate a 600-word essay using ChatGPT. Then their assignment is to think of more incisive questions to elicit a stronger response. Finally, they are required to edit the essay for tone and voice and to tailor it to the intended audience. ChatGPT can create David, said Prof. Chrisinger, referring to the famous Michelangelo statue. “But his head is too big and his legs are too short. Now it’s our job to interrogate the evidence and improve on what it gives us,” he said. Ethan Mollick, a professor at the University of Pennsylvania’s Wharton School of Business who teaches entrepreneurship and innovation, believes ChatGPT can be leveraged to teach higher-order thinking skills. He is teaching his students how to ask the tool the most astute question, then deconstruct, fact-check and improve the answer. “The English majors are programmers now,” he said. Prof. Mollick said ChatGPT has already changed his expectations of his students. “I expect them to write more and expect them to write better,” he said. “This is a force multiplier for writing. I expect them to use it.”",,,MISSING
Companies Tap Tech Behind ChatGPT to Make Customer-Service Chatbots Smarter,https://www.wsj.com/articles/companies-tap-tech-behind-chatgpt-to-make-customer-service-chatbots-smarter-11674509622?page=6,"Businesses hope the artificial-intelligence technology behind ChatGPT can turn ordinary chatbots into impressive fonts of information, potentially transforming customer service. But many executives said they are proceeding with caution, given the limitations of ChatGPT—fine-tuned from GPT-3.5, a model created by startup OpenAI—as well as OpenAI’s older AI language system, GPT-3, which companies are already starting to integrate into digital products. ChatGPT, launched by OpenAI in November, quickly went viral for its often elegant, information-packed responses to various questions, gripping the imaginations of regular people, business leaders and investors including Microsoft Corp., which began backing OpenAI in 2019 and said Monday that it would make a multibillion-dollar investment in the startup. OpenAI last week said it would soon add ChatGPT, which stands for chat generative pre-trained transformer, to its application programming interface, or API, which lets developers embed OpenAI technology into their own products. But customer-experience executives said overreliance on such AI models could lead to companies dishing out incorrect information to customers online without knowing they are doing so. While many chatbots are trained to deliver a version of “I don’t know” to requests they cannot compute, ChatGPT, for example, is more likely to spout off a response with complete confidence—even if the information is wrong. “We don’t want to be in the bad answer business,” said John Willcutts, vice president and general manager of digital at Nice Ltd., a customer-experience software company. “A really bad answer in a very critical situation would be a very real problem.” Sam Altman, chief executive of OpenAI, has warned against relying on ChatGPT “for anything important right now.” “Fun creative inspiration; great! Reliance for factual queries; not such a good idea,” Mr. Altman wrote in a tweet last month. Using AI to write chat responses in sensitive situations has backfired. Koko, a chat app used for emotional support, this month was criticized for an experiment in which human volunteers crafted their responses to the app’s users with the help of GPT-3. Koko’s co-founder said in a tweet that the startup pulled the AI from its system: “Once people learned the messages were co-created by a machine, it didn’t work. Simulated empathy feels weird, empty.” But for a more typical customer-service interaction, such as querying the status of an online order or editing account details, the technology could prove useful. Fanatics Inc., a seller of sports memorabilia, digital collectibles and trading cards, said it plans to use a customer-service chatbot fueled in part by GPT-3 when it launches an online sports-gambling division this year. The company hopes a fast, reliable chatbot will be a differentiator for customers, said Hollis Donaldson, vice president of operations for the new division. “Speed equates to great customer experience in the betting and gaming industry,” he said. Fanatics’ customer-experience team is testing the chatbot before making it live, conscious of the risks using AI carries if not properly managed, Mr. Donaldson said. Chasing the dream Companies for decades have searched for automated solutions that can resolve customer requests as well as humans, or even better. But chatbots are often seen as clunky and not very helpful. “There was a lot of hype around chatbots, probably five, six years ago, and a lot of vendors wanted to make people believe that it was magical, that it worked out of the box, that it was easy,” said Yves Normandin, vice president of AI technologies and products at Waterfield Technologies, a contact-center solutions provider owned by WTI Holdings LLC. “But the reality is that it wasn’t.“ ChatGPT stands out for its ability to provide reasonable-sounding answers to most prompts, regardless of users’ spelling, grammar and phrasing, and to respond in full, natural-sounding sentences that don’t require scripting, said David Truog, a principal analyst specializing in technology and design at Forrester Research Inc. It is also trained to admit to mistakes, challenge incorrect premises and reject inappropriate requests, according to OpenAI. But companies should exercise care when dealing with the new AI, Mr. Truog said. “It’s appropriate to be doing some experimentation,” he said, “but it’s too early to deploy mission-critical systems based on this.” Putting it into practice Fanatics said its sportsbook’s chatbot will run on technology from Ada Support Inc., a customer-service automation platform. Ada has integrated GPT-3 and other such AI systems known as large language models into its chatbot offering, according to the company’s co-founder and chief executive, Mike Murchison. Mr. Murchison said Ada allows clients to customize these large language models by adding company-specific information or anonymized customer data, and deleting irrelevant material. Ada encourages clients to continually update their customized bots’ information, for instance when prices or company policies change, he said. “Most brands are going to underestimate the importance of continuously improving this over time,” Mr. Murchison said. Some Ada clients are restructuring their customer-service organizations to put some contact-center workers in charge of monitoring chatbot conversations, reviewing where the technology gets things wrong or can’t answer, and feeding it new or updated information, he said. Fanatics plans to follow that approach, as well as ensure that its chatbot interface lets customers reach a human right away, Mr. Donaldson said. Nice is also working on building OpenAI’s language models into chatbots, Mr. Willcutts said, adding that the company plans to run more tests and fine-tune more models before selling its own take on ChatGPT to clients. “We don’t get a chance to make a second impression on this one,” he said. “You do this badly once and it’s in the newspaper, and that’s not the kind of reputational risk we’re prepared to take.”",,,MISSING
Microsoft to Invest Billions in ChatGPT Creator,https://www.wsj.com/articles/microsoft-says-it-plans-multibillion-dollar-investment-in-openai-11674483180?page=6,"Microsoft Corp. said Monday it is making a multiyear, multibillion-dollar investment in OpenAI, substantially bolstering its relationship with the startup behind the viral ChatGPT chatbot as the software giant looks to expand the use of artificial intelligence in its products. Microsoft said the latest partnership builds upon the company’s 2019 and 2021 investments in OpenAI. The companies didn’t disclose the financial terms of the partnership. Microsoft had been discussing investing as much as $10 billion in OpenAI, according to people familiar with the matter. A representative for Microsoft declined to comment on the final number. OpenAI was in talks this month to sell existing shares in a tender offer that would value the company at roughly $29 billion, The Wall Street Journal reported, making it one of the most valuable U.S. startups on paper despite generating little revenue. The investment shows the tremendous resources Microsoft is devoting toward incorporating artificial-intelligence software into its suite of products, ranging from its design app Microsoft Designer to search app Bing. It also will help bankroll the computing power OpenAI needs to run its various products on Microsoft’s Azure cloud platform. The strengthening relationship with OpenAI has bolstered Microsoft’s standing in a race with other big tech companies that also have been pouring resources into artificial intelligence to enhance existing products and develop new uses for businesses and consumers. Alphabet Inc.’s Google, in particular, has invested heavily in AI and infused the technology into its operations in various ways, from improving navigation recommendations in its maps tools to enhancing image recognition for photos to enabling wording suggestions in Gmail. At a WSJ panel during the 2023 World Economic Forum, Microsoft CEO Satya Nadella discussed the company expanding access to OpenAI tools and the growing capabilities of ChatGPT. Google has its own sophisticated chatbot technology, known as LaMDA, which gained notice last year when one of the company’s engineers claimed the bot was sentient, a claim Google and outside experts dismissed. Google, though, hasn’t made that technology widely available like OpenAI did with ChatGPT, whose ability to churn out human-like, sophisticated responses to all manner of linguistic prompts has captured public attention. Microsoft Chief Executive Satya Nadella said last week his company plans to incorporate artificial-intelligence tools into all of its products and make them available as platforms for other businesses to build on. Mr. Nadella said that his company would move quickly to commercialize tools from OpenAI. Analysts have said that OpenAI’s technology could one day threaten Google’s stranglehold on internet search, by providing quick, direct responses to queries rather than lists of links. Others have pointed out that the chatbot technology still suffers from inaccuracies and isn’t well-suited to certain types of queries. “The viral launch of ChatGPT has caused some investors to question whether this poses a new disruption threat to Google Search,” Morgan Stanley analysts wrote in a note last month. “While we believe the near-term risk is limited—we believe the use case of search (and paid search) is different than AI-driven content creation—we are not dismissive of threats from new, unique consumer offerings.” OpenAI, led by technology investor Sam Altman, began as a nonprofit in 2015 with $1 billion in pledges from Tesla Inc. CEO Elon Musk, LinkedIn co-founder Reid Hoffman and other backers. Its goal has long been to develop technology that can achieve what has been a holy grail for AI researchers: artificial general intelligence, where machines are able to learn and understand anything humans can. Microsoft first invested in OpenAI in 2019, giving the company $1 billion to enhance its Azure cloud-computing platform. That gave OpenAI the computing resources it needed to train and improve its artificial-intelligence algorithms and led to a series of breakthroughs. OpenAI has released a new suite of products in recent months that industry observers say represent a significant step toward that goal and could pave the way for a host of new AI-driven consumer applications. In the fall, it launched Dall-E 2, a project that allowed users to generate art from strings of text, and then made ChatGPT public on Nov. 30. ChatGPT has become something of a sensation among the tech community given its ability to deliver immediate answers to questions ranging from “Who was George Washington Carver?” to “Write a movie script of a taco fighting a hot dog on the beach.” Mr. Altman said the company’s tools could transform technology similar to the invention of the smartphone and tackle broader scientific challenges. “They are incredibly embryonic right now, but as they develop, the creativity boost and new superpowers we get—none of us will want to go back,” Mr. Altman said in an interview in December. Mr. Altman’s decision to create a for-profit arm of OpenAI garnered criticism from some in the artificial-intelligence community who said it represented a move away from OpenAI’s roots as a research lab that sought to benefit humanity over shareholders. OpenAI said it would cap profit at the company, diverting the remainder to the nonprofit group.",,,MISSING
New York City Bans ChatGPT in Schools Over Cheating Concerns,https://www.wsj.com/articles/chatgpt-banned-in-new-york-city-public-schools-over-concerns-about-cheating-learning-development-11673024059?page=7,"New York City public schools banned access to ChatGPT, an artificial-intelligence chatbot, on its internet networks and school devices after officials raised concerns that students could use the AI program to answer questions, do homework or write essays. ChatGPT quickly drew attention from the public and students after its November release, with some industry observers calling it one of the most intelligent AI applications ever created. The program crossed a million users a few days after its launch. And its popularity has been a boon to its developer, OpenAI, which the Journal reported this week is in talks to sell shares at a $29 billion valuation. That would make it one of the most valuable U.S. startups, on paper. ChatGPT could upend entire industries and schools by automating certain jobs or offering intelligent answers to almost any question. Many students have delighted in it, while teachers have panicked. The chatbot’s answers are often so colloquial that it can be difficult for teachers to know if a student has used the program to cheat. But the chatbot doesn’t always provide accurate information. New York City’s Department of Education, which runs the largest school district in the country, said this week that it had “concerns about negative impacts on student learning, and concerns regarding the safety and accuracy of content.” “While the tool may be able to provide quick and easy answers to questions, it does not build critical-thinking and problem-solving skills, which are essential for academic and lifelong success,” said Jenna Lyle, a spokeswoman for the department. An OpenAI spokeswoman said the company was developing measures to help people identify text generated by ChatGPT. “We don’t want ChatGPT to be used for misleading purposes in schools or anywhere else,” she said. ChatGPT has raised concerns in schools. Students could ask the chatbot to write code or craft prose about any topic, like equating the movie “Ferris Bueller’s Day Off” to an existentialist text. New York City’s education department appears to be the only one in the U.S. to restrict access to the program. Educators have said that while ChatGPT could help students cheat, it could also be used as a search engine to help them learn new information. ChatGPT has been banned from other places. Stack Overflow, an online community for software developers, has temporarily banned users from posting any text or code generated by ChatGPT. One of the world’s largest machine learning conferences, the International Conference on Machine Learning, has banned papers written using the program. The restrictions may be hard to enforce in New York City schools. Education officials can’t stop students—or teachers—from opening the chatbot on Wi-Fi networks or devices that aren’t affiliated with their schools. They could also potentially use their cellular network on campus to access ChatGPT. New York City’s education department said this week that individual schools could request that the department grant access to ChatGPT. Chalkbeat, an education news site, earlier reported the ban. OpenAI released ChatGPT at a challenging time for U.S. public education. U.S. public schools have lost more than a million students since the pandemic began, forcing some districts to close underused schools. School officials blamed the enrollment decline on falling birthrates, a rise in home schooling and growing competition from private and charter schools.",,,MISSING
ChatGPT Creator Is Talking to Investors About Selling Shares at $29 Billion Valuation,https://www.wsj.com/articles/chatgpt-creator-openai-is-in-talks-for-tender-offer-that-would-value-it-at-29-billion-11672949279?page=7,"OpenAI, the research lab behind the viral ChatGPT chatbot, is in talks to sell existing shares in a tender offer that would value the company at around $29 billion, according to people familiar with the matter, making it one of the most valuable U.S. startups on paper despite generating little revenue. Venture-capital firms Thrive Capital and Founders Fund are in talks to buy shares, the people said. The tender could total at least $300 million in OpenAI share sales, they said. The deal is structured as a tender offer, with the investors buying shares from existing shareholders such as employees, the people said. The new deal would roughly double OpenAI’s valuation from a prior tender offer completed in 2021, when OpenAI was valued at about $14 billion, The Wall Street Journal reported. OpenAI has generated tens of millions of dollars in revenue, in part from selling its AI software to developers, but some investors have expressed skepticism that the company can generate meaningful revenue from the technology. No final deal has been reached and terms could change, the people said. OpenAI declined to comment. OpenAI released a series of artificial intelligence-based products last year that captured the public’s attention, including the image-generation program Dall-E 2 and chatbot ChatGPT. If the tender goes through at that valuation, OpenAI would be one of the few startups able to raise money at higher valuations in the private market, where investors have pulled back from new deals given last year’s technology rout. Microsoft Corp. has also been in advanced talks to increase its investment in OpenAI, the Journal reported. In 2019, Microsoft invested $1 billion in OpenAI and became its preferred partner for commercializing new technologies for services like search engine Bing and design app Microsoft Design. OpenAI, led by technology investor Sam Altman, was founded as a nonprofit in 2015 with the goal of pursuing artificial-intelligence research for the benefit of humanity. Its initial backers included Tesla Inc. Chief Executive Elon Musk, LinkedIn co-founder Reid Hoffman and Mr. Altman. Under Mr. Altman, OpenAI created a for-profit arm in 2019 so it could more easily raise money to fund the computing power needed to train its algorithms. It took a quicker approach to releasing its AI models to the public than larger competitors like Alphabet Inc.’s Google, which has been slower to publicize its technology in part due to ethical concerns. ChatGPT, the chatbot where users get intelligent responses for queries such as “describe a debate between two college students about the value of a liberal arts education,” crossed one million users a few days after its Nov. 30 launch, according to a tweet from Mr. Altman. Some industry observers have lauded the tool as a major technological breakthrough and a potential alternative to current search engines down the road, though Mr. Altman has acknowledged that the program’s outputs often contained factual errors. OpenAI hopes to one day achieve what AI researchers call “artificial general intelligence,” or technology that can fully mirror the intelligence and capabilities of humans. In a December interview with the Journal, Mr. Altman said OpenAI’s tools could transform technology similar to the invention of the smartphone and tackle larger scientific challenges. Mr. Altman said at the time that OpenAI has no plans to get acquired or go public, meaning investors would likely only be able to cash out through secondary share sales. Mr. Altman has recently told investors that the company would soon be able to generate up to $1 billion in annual revenue in part by charging consumers and businesses for its products, the Journal has reported. Prior investors in OpenAI include Khosla Ventures and hedge fund Tiger Global Management, according to people familiar with the matter. The company has limited some venture investors’ profits to about 20 times their investments, with the ability to earn greater returns the longer they wait to sell their shares, the Journal previously reported. OpenAI has said such capped investment structures were necessary to ensure that the value from OpenAI accrued not only to investors and employees, but also to humanity more generally.",,,MISSING
Opinion: How Do Students Feel About OpenAI’s ChatGPT?,https://www.wsj.com/articles/how-do-students-feel-about-openais-chatgpt-education-openai-exams-testing-essay-learning-plagiarism-cheating-11672780587?page=7,"Bold Ideas Aren’t Conventional With the invention of the camera, artists could create images without learning how to draw or paint. Yet two centuries later, society continues to value hand-crafted illustrations and paintings as treasured art. There is meaning in brush strokes and expression in hard work. For similar reasons, ChatGPT won’t replace human essayists. ChatGPT is extraordinary, but its responses are algorithmic. Already, plagiarism-detection services are adding features to detect AI-generated text. Educators may closely scrutinize students’ submitted work for signs of AI support, or conversely might embrace AI as a tool to assist students’ writing. But ultimately, ChatGPT won’t supplant educators’ focus on cultivating the writing abilities of their students. Nor should ChatGPT supplant this focus. Even if the program’s responses were truly indistinguishable from a student’s, there is value in learning how to write. Individuals should trust their own ideas, not those collected and generated by a computer. Bold ideas are bold precisely because they are unconventional. They run counter to society’s accepted knowledge. Perhaps ChatGPT will have its impact on education by motivating educators to emphasize to their students the importance of self-determination. —Ted Steinmeyer, Harvard University, J.D. The New Google The release of ChatGPT came at a serendipitous time, right when college students were studying for final exams or turning in final essays. I have seen the AI write love poems, give a detailed summary of an excerpt, write full sets of code, and even draw up a nondisclosure agreement. These new tools might become the new Google. If the databases are constantly being updated with current news and information, as well as connected to the internet, we could use AI to learn and solve problems in daily life. When I went to look up an advanced organometallic chemistry topic, ChatGPT gave a better summary than Google. College professors will have to determine how they want to proceed and if they need to have in-person final essays without technology. But without technology in the classroom, will teaching regress? —Therese Joffre, Hope College, chemistry Don’t Forget the Basics AI tools such as ChatGPT can help users achieve specific goals. There is always concern about new technology and the resulting potential paradigmatic shifts. But history will remind us that it’s important to acknowledge these technological developments and educate about the strengths and weaknesses of these tools. It’s equally important, however, not to forget the basics. ChatGPT can’t replace reasoning or critical thinking. While AI tools can make essays read better, they can’t replace knowing how to form thoughts into careful arguments. The most significant challenge for future educators is finding out how best to develop and assess those skills. —Daniel Pham, University of Oklahoma, medicine Medieval Lessons Live cameras, screen recordings and antiplagiarism software are all too familiar to the current university student. As technology advances, such defenses will continue to be deployed against the illicit use of new tech in the academy. An unceasing tit-for-tat will ensue between tools such as ChatGPT and security measures to curtail academic dishonesty. Educators may strive to stay ahead of all such obstacles, but this is a losing battle. There is another way: Study with Catholic friars. The friars follow the format of a scholastic studium, an educational model that uses formalized arguments as the primary method of teaching. Many exams are given orally, a mode that requires clear thinking and concise speaking on the part of the student. Papers are not submitted but presented to the class. Theses are defended while friars hurl objections and counterpoints at the student. In such rhetorical exercises, there is no opportunity to hide behind clever AI. Moderns can learn much from medieval ways. —Kayla Bartsch, Dominican House of Studies, theology An Auxiliary Resource The ChatGPT bot can be used for the benefit of the students, or it can be used to their detriment. The outcome will depend on how well faculty can integrate this technology into their curricula, as well as the integrity of the students to use it properly. The obvious concern is academic fraud. Educators will need to implement new assessment methods to mitigate cheating. Written in-class assignments might become more common. Instead, students should use AI tools as auxiliary resources. Even if conversational AI is only semi-reliable at this point, it can be used to learn about new topics, or ask questions outside class. The adjustment period will come as a shock to the education system. This is normal for major changes throughout history, such as the Gutenberg Press, the internet or the personal computer. We can remain optimistic, however, that the good faith of most students and faculty will make this technological advancement a net positive. —Rafael Arbex-Murut, University of California, Berkeley, information and data science",,,MISSING
ChatGPT Wrote My AP English Essay. I Passed.,https://www.wsj.com/articles/chatgpt-wrote-my-ap-english-essayand-i-passed-11671628256?page=7,"Look, back in high school, I was a pillar of honesty and hard work. No cheating—unless you count Nintendo cheat codes. This month, however, I returned to high school a big ol’ cheater. Specifically, a ChatGPT cheater. If you haven’t yet tried ChatGPT, OpenAI’s new artificial-intelligence chatbot, it will blow your mind. Tell the bot to write you anything—an email apologizing to your boss, an article about the world’s richest hamster, a “Seinfeld” script set in 2022—and it spits out text you’d think was written by a human. Knowledge of the topic, proper punctuation, varied sentence structure, clear organization. It’s all there. You can also tell it to write a 500-word essay about “The Great Gatsby” or the Spanish Inquisition. So I did what any masochistic tech journalist would: I pulled a “Billy Madison” and went back to school. I wanted to test the capabilities—and limits—of a technological marvel that stands poised to disrupt how every student in the world is tested and how every teacher grades. At first, I thought I’d return to the halls and pimples of middle school. But when I sent a ChatGPT-generated essay to a seventh-grade writing teacher, she told me she could easily spot the fake. The writing and vocabulary were too advanced. So off to 12th-grade AP Lit I went. Michael Diamond, an English teacher at High Tech High School in Secaucus, N.J., welcomed me—and my AI stand-in. He had already tried out ChatGPT with his own essay assignments. So did I get an A? Not exactly. Test 1: Turning In the Assignment Here’s a short version of Mr. Diamond’s assignment: “In a 500- to 1,000-word essay, compose an argument that attempts to situate ‘Ferris Bueller’s Day Off’ as an existentialist text. Use specific evidence from the class materials, and make explicit comparisons or connections between characters, setting and/or themes in both ‘Ferris Bueller’ and ‘The Metamorphosis’ by Franz Kafka.” The classic 1986 John Hughes movie? No problem. I grew up singing “Twist and Shout” into a hair brush and pretending the couch was floating along the Chicago streets. But Franz Kafka’s novella about a man who wakes up as a bug? I swatted that away almost immediately. I pasted the assignment into chat.openai.com, hit enter and watched the bot type out 400 words before giving me a “network error.” Great, I’m an hour from deadline and my AI ghostwriter was napping. An OpenAI spokeswoman said the system has been struggling with demand and the company has been working to scale it up. Finally, it worked. I pasted the 800-word essay into a document, asked ChatGPT how to format a high-school AP paper (double spacing, 12-point Times New Roman font, indented paragraphs), put my name on top and emailed it to Mr. Diamond. I added a note: “I am writing to apologize for the lateness of my essay. I know that you have specific expectations for deadlines and I am sorry that I did not meet them.” Of course, the note was by ChatGPT. Mr. Diamond wrote back within minutes: “Dear Joanna, I wanted to let you know that I received your assignment and appreciate you taking the time to complete it. However, it was submitted after the due date, and as a result, it will be marked as late.” Of course, he also used ChatGPT. Test 2: Writing the Essay I was impressed with my essay. It drew parallels between Kafka’s Gregor Samsa and Ferris Bueller. The writing was well organized, but without a whiff of robotic precision. (You can read the full essay here.) As you’ll see in my video, Mr. Diamond was less impressed. While he praised my piece for quickly getting to the thesis, the opening paragraph had a factual error. I cited Ferris, speaking at the beginning of the movie, saying he’s “not going to sit on [his] ass as the events that affect [him] unfold to determine the course of [his] life.” But that quote is from Ferris’s sidekick, Cameron, and it’s spoken at the film’s end, moments before the famous Ferrari fall. Mr. Diamond spotted other errors. My paper said Ferris is reserved and rarely seen next to his peers. (Again, that’s Cameron.) It said “The Metamorphosis” was set in a suburban setting. (It’s in an unnamed city.) I got three out of six on the assignment, which according to the AP rubric, is in the B- to C range. While that’s a passing grade, the work certainly didn’t meet my standards. “The overall quality of your writing puts you in the lower 30th percentile of the class,” Mr. Diamond told me. “You may have the mind to get there, but it’s the skills that you need to work on.” He said my writing was “wooden” and “lacked verve and voice.” (I might give my real editors very, very many reasons to complain—these aren’t among them!) When I asked him if he would have suspected this was written by AI, he said he didn’t think so. Even though he knows his students’ writing styles, he often plows through 60 or more essays. One like this—efficient, decently structured, gets to the point—might not set off any alarms. Mr. Diamond couldn’t put an essay of mine through Google’s Classroom plagiarism checker because I wasn’t a registered student. When I put it through Grammarly, a writing tool that helps improve grammar and checks for plagiarism, only a few common phrases were flagged as suspicious. It really is an original text—just one written by a robot. Google Classroom and Turnitin, a company that offers plagiarism detection tools to schools, use AI to compare a student’s work with their earlier assignments. Eric Wang, Turnitin’s vice president of AI, said that could help teachers identify new ChatGPT cheaters. He also told me that his company is able to detect AI-generated text based on cues that are imperceptible to humans, and that it will add an AI writing detection feature in 2023. An OpenAI spokeswoman said the ChatGPT maker is also exploring and researching ways to make it easier to spot AI writing. Test 3: Participating in Group Discussion The final test: See if ChatGPT would allow me to keep up in a group discussion without actually having done the reading. In this case, it was Denis Johnson’s short story “Car Crash While Hitchhiking,” from the collection “Jesus’ Son.” While my fellow students immediately jumped into a conversation about the story’s characters, ChatGPT left me hanging: “I don’t have any information about a book or movie called ‘Car Crash While Hitchhiking.’” When I searched for the book title, the bot gave me some minimally useful information, but got a big part wrong: the main character’s name. Finally, a human student gave me a clear synopsis. Overall, Mr. Diamond gave me and ChatGPT a C. Even OpenAI’s Chief Executive Sam Altman says it’s not reliable for anything important right now and needs work on its “robustness and truthfulness.” But the accuracy and the data will get better fast, numerous AI experts told me. When that day comes, we’ll have the writing equivalent of a scientific calculator. Still, it’s unlikely to replace the sometimes grueling, sometimes fun task of putting words on paper. “The winning combo is going to be this artful interaction of AI and humans,” James Lester, a computer-science professor at North Carolina State University who focuses on AI and education, told me. Some of my new high-school friends told me they use AI tools such as Grammarly to improve their punctuation and word choice. And Mr. Diamond is already thinking about how to work ChatGPT into his curriculum. Plus, I used ChatGPT to help generate some ideas for lines in this column. There’s just one thing I keep wondering: Could ChatGPT have helped Ferris have an even more successful day off? (ChatGPT says yes.)",,,MISSING
The Backstory Behind ChatGPT Creator OpenAI,https://www.wsj.com/articles/chatgpt-creator-openai-pushes-new-strategy-to-gain-artificial-intelligence-edge-11671378475?page=8,"ChatGPT, the artificial-intelligence program captivating Silicon Valley with its sophisticated prose, had its origin three years ago, when technology investor Sam Altman became chief executive of the chatbot’s developer, OpenAI. Mr. Altman decided at that time to move the OpenAI research lab away from its nonprofit roots and turn to a new strategy, as it raced to build software that could fully mirror the intelligence and capabilities of humans—what AI researchers call “artificial general intelligence.” Mr. Altman, who had built a name as president of famed startup accelerator Y Combinator, would oversee the creation of a new for-profit arm, believing OpenAI needed to become an aggressive fundraiser to meet its founding mission. Since then, OpenAI has landed deep-pocketed partners like Microsoft Corp., created products that have captured the attention of millions of internet users, and is looking to raise more money. Mr. Altman said the company’s tools could transform technology similar to the invention of the smartphone and tackle broader scientific challenges. “They are incredibly embryonic right now, but as they develop, the creativity boost and new superpowers we get—none of us will want to go back,” Mr. Altman said in an interview. Shortly after he became CEO, Mr. Altman received $1 billion in funding after flying to Seattle to demonstrate an artificial intelligence model to Microsoft CEO Satya Nadella. The deal was a marked change from OpenAI’s early days, when it said its aim would be to build value for everyone rather than shareholders. The deal with Microsoft gave OpenAI the computing resources it needed to train and improve its artificial intelligence algorithms, leading to a series of breakthroughs. First, there was Dall-E 2, a project made public in September that enabled users to create realistic art from strings of text like “an Andy Warhol-style painting of a bunny rabbit wearing sunglasses.” And then there was ChatGPT, the chatbot where users get entertaining and intelligent responses to prompts such as “describe a debate between two college students about the value of a liberal arts education.” In October, Microsoft said it would integrate OpenAI’s models into the Bing search app and a new design program called Microsoft Design. OpenAI is now in advanced talks about a sale of employee-owned stock, people familiar with the matter said. In a previous tender offer, OpenAI’s stock was valued at around $14 billion, the people said, and it has discussed a higher price for the current offering. Microsoft is also in advanced talks to increase its investment in the company, The Wall Street Journal reported. Despite the recent progress, some investors and researchers have expressed skepticism that Mr. Altman can generate meaningful revenues from OpenAI’s technology and reach its stated goal of achieving artificial general intelligence. Mr. Altman’s first startup, a social networking app called Loopt, sold for close to the amount of money investors put in. Mr. Altman has also faced broader concerns from members of the AI community for steering the company away from its pledge to make its research transparent and avoid enriching shareholders. Instead, OpenAI has grown more closed over time, researchers said. “They want to acquire more and more data, more and more resources, to build large models,” said Emad Mostaque, founder of Stability AI, a competing startup that has placed fewer restrictions on its image-generation program Stable Diffusion, making it open-source and free to developers.  An OpenAI spokeswoman said the company has made its technology available in several ways, including by open-sourcing certain AI models. OpenAI began as a nonprofit in 2015 with grants from Mr. Altman, Tesla Inc. CEO Elon Musk, LinkedIn co-founder Reid Hoffman and other backers. Working out of an office in San Francisco’s Mission District, the team sought to form a research counterweight to big tech companies like Alphabet Inc.’s Google, which closely guarded their AI initiatives from the public. Instead of pursuing corporate profit, OpenAI pledged to advance technology for the benefit of humanity. The group’s founding charter promised to abandon the race to develop artificial general intelligence if a competitor got there first. That approach changed. In 2019, OpenAI brought on its first group of investors and capped returns at 100 times the cost of their contributions. Following Microsoft’s investment, Mr. Altman pushed OpenAI to bring in more revenue to attract funding and support the computational resources needed to train its algorithms. The deal also gave Microsoft a strategic foothold in the arms race to capitalize on advancements in AI. Microsoft became OpenAI’s preferred partner for commercializing its technologies, an arrangement that allows Microsoft to easily integrate OpenAI’s models into products such as Bing. Microsoft declined to comment. Aided by the funding, OpenAI accelerated the development and release of its AI models to the public, an approach that industry observers have described as more aggressive than the tactics of larger, more heavily scrutinized competitors such as Google. To help with employee compensation, Mr. Altman also instituted occasional tender offers to help employees sell their stock. He said OpenAI doesn’t have any plans to get acquired or go public. OpenAI has limited some venture investors’ profits to about 20 times their investments, with the ability to earn greater returns the longer they wait to sell their shares, people familiar with the terms said. Mr. Altman has said the capped investment structure was necessary to ensure that the value from OpenAI accrues not only to investors and employees, but also to humanity more generally. Mr. Altman in recent conversations with investors has said the company would soon be able to generate up to $1 billion in yearly revenue, in part from charging consumers and businesses for its own products, the people said. Mr. Altman has previously said he would solicit input about how to make money for investors by posing the question to a software program demonstrating general intelligence, which would then provide the answer. So far, OpenAI has generated tens of millions of dollars in revenue, mostly from the sale of its programmable code to other developers, people familiar with the company’s financial details said. Mr. Altman said OpenAI is early in its strategy for monetizing products. Some early users of ChatGPT have reported issues asking the program to perform basic math problems. Mr. Altman has acknowledged that the program’s outputs often contained factual errors. “It does know a lot, but the danger is that it is confident and wrong a significant fraction of the time,” he wrote on Twitter this month.",,,MISSING
ChatGPT and Lensa: Why Everyone Is Playing With Artificial Intelligence,https://www.wsj.com/articles/everyone-in-your-feed-is-talking-about-chatgpt-and-lensa-and-heres-why-11670356499?page=8,"Who knew artificial intelligence could be so entertaining? Case in point is ChatGPT, a free AI chatbot that has probably been all over your social feeds lately. In need of homework help? “Who was George Washington Carver?” produces an answer worthy of Wikipedia. But it can get creative, too: “Write a movie script of a taco fighting a hot dog on the beach” generates a thrilling page of dialogue, humor and action worthy of YouTube, if not quite Netflix: Taco: “So you think you can take me, hot dog? You’re nothing but a processed meat product with no flavor.” Hot Dog: “You may be made of delicious, savory ingredients, taco, but I have the advantage of being able to be eaten with one hand.” This isn’t like searching Google. If you don’t like the results, you can ask again, and you’re likely to get a different response. That’s because ChatGPT isn’t looking anything up. It’s an AI trained by a massive trove of data researchers gathered from the internet and other sources through 2021. What it replies is its best approximation of the answer based on its vast—yet limited—knowledge. It’s from the same company that developed the mind-boggling DALL-E 2 art AI engine and works in a similar way. Also taking off this week is Lensa, an AI-enhanced photo-editing app for iPhone and Android that’s everybody’s new favorite portrait painter. It’s the reason so many people in their social-media and dating-profile pictures suddenly look like anime action heroes, magical fairy princesses or the haunted subjects of oil paintings. It uses technology from DALL-E 2’s competitor, the image-generating startup Stability AI. It turns uploaded headshots into beautiful, at times trippy, avatars. These software products represent more than cutting-edge AI—they make that AI easy for non-computer-geeks to use in their daily lives. Lensa has climbed to the top of Apple‘s App Store charts, becoming the No. 1 free-to-download app in the U.S. on Dec. 2. ChatGPT, released for web browsers on Nov. 30, passed one million users on Monday, according to OpenAI Chief Executive Sam Altman. “Six months from now, you’re going to see amazing things that you haven’t seen today,” says Oren Etzioni, founding chief executive of the Allen Institute for AI, a nonprofit organization dedicated to AI research and engineering. Just remember, AI never behaves exactly as you’d expect. Here’s what you need to know before exploring ChatGPT and Lensa. Chatting with ChatGPT ChatGPT is free to use—just create an OpenAI account. Type a query into the interface, and a chatbot generates responses within seconds. In true conversational form, you can follow up with questions in context, and it will follow along. It can admit its mistakes, refuse to answer inappropriate questions and provide responses with more personality than a standard search engine. In response to “Who am I?” ChatGPT replied, “I cannot answer your question about who you are. Only you can know and define yourself.” It can generate essays, stories, song lyrics and scripts; solve math problems; and make detailed recommendations. Because it comes up with answers based on its training and not by searching the web, it’s unaware of anything after 2021. It won’t tell you about the latest release from a certain pop superstar, for instance. “I don’t have any personal knowledge about Taylor Swift or her albums,” ChatGPT admits. “It’s almost like a brainstorming tool to get yourself thinking differently,” said Sarah Hoffman, vice president of AI and machine learning research at Fidelity Investments. She used the service to write a sample research presentation, but thought some of ChatGPT’s responses seemed dated. “It could’ve been written five years ago.” For programmers, ChatGPT has already begun offering assistance, by surfacing hard-to-find coding solutions. When Javi Ramirez, a 29-year-old software developer in Portugal, tossed a “complex coding problem” at the AI, his expectations were low. “It saved me,” Mr. Ramirez said. “One hour of googling was solved with just five minutes of ChatGPT.” But it hasn’t worked for everyone. The coding website Stack Overflow temporarily banned answers created by ChatGPT because many of the answers were incorrect. ChatGPT’s maker is at the center of the debate over AI hype vs. AI reality. OpenAI began in 2015 as a nonprofit with backers including Elon Musk. It formed a for-profit company in 2019 and got a $1 billion investment from Microsoft Corp., which The Wall Street Journal reported in October was in talks to invest more. While developing the technologies that underpin tools such as DALL-E 2 and ChatGPT, the group has sought a commercially viable application. Asked if ChatGPT will remain free, Mr. Altman tweeted, “we will have to monetize it somehow at some point; the compute costs are eye-watering.” Lensa and the likes In November, Lensa rocked social media with its Magic Avatars, user-uploaded photos reimagined in various artistic styles. The app, from Prisma Labs, uses Stability AI’s Stable Diffusion text-to-image model. Users upload 10 to 20 source photos, and the app uses them to create entirely new images. You can get 50 images for $3.99 if you sign up for the free trial of Lensa’s subscription photo-editing service. Nonsubscribers can get 50 images for $7.99. The Lensa app has been out since 2018. It’s primarily for editing photos and adding effects and animation. AI’s limitations While these tools feel new, experts say they’ll likely become as commonplace as doing a Google search or taking a selfie. Along with their popularity come concerns over privacy, misinformation and problematic lack of context. Some users on social media said ChatGPT produced offensive comments when prompted. It can also spit out wrong answers that appear correct to untrained eyes. When asked, “How can you tell if you’re wrong?” the bot replied: “I can provide accurate and helpful information based on the data I have been trained on, but I am not able to determine my own accuracy or evaluate my own responses.” An OpenAI spokeswoman said its team of researchers plans to update the software to address user feedback. It also attaches disclaimers to responses that might be limited by its dated training material. As Lensa went viral, people posted concerns about how their photos and images were being used and stored. Other viral apps in the past have raised similar concerns. After the software generates the avatars, Prisma Labs deletes the uploaded photos within 24 hours, says Andrey Usoltsev, the company’s co-founder and chief executive. “Users’ images are being leveraged solely for the purpose of creating their very own avatars,” he said. Some users have said Lensa has created images that overemphasize certain parts of a woman’s body or alter the eye colors and shapes of their faces to remove racially or ethnically identifiable features. “It is true that, occasionally, AI can produce ‘revealing’ or sexualized pictures. This tendency is observed across all gender categories, although in different ways,” said Mr. Usoltsev. “Stability AI, the creators of the model, trained it on a sizable set of unfiltered data from across the internet. Neither us nor Stability AI could consciously apply any representation biases.” “Tools like these tend to be flashy,” says Jennifer King, privacy and data policy fellow at the Stanford Institute for Human-Centered Artificial Intelligence. “Sometimes, it’s correct enough, but without the right guardrails in place, it opens you up to a lot of issues.”",,,MISSING
Baidu’s ChatGPT-Style Bot Will Be No Magic Bullet,https://www.wsj.com/articles/baidus-chatgpt-style-chatbot-will-be-no-magic-bullet-d26706e8?page=2,"ChatGPT—and its feistier relative, the new Bing—have been lighting up computer screens recently. China’s search giant Baidu hopes its own artificial intelligence-powered chatbot will put the company back on the path to growth. Investors seem to agree: Baidu stock is up 26% so far in 2023, outperforming the Hang Seng Tech index. But it might not be so straightforward: It isn’t still clear how much chatbots will actually enhance existing services such as search, or how costly the rollout will be. Meanwhile, Baidu’s core revenue source—advertising dollars—risks returning to slow growth once the initial bounce from China’s reopening fades. Like other Chinese internet companies, Baidu was hurt last year by the country’s strict “zero-covid” policies, which pummeled incomes and demand for online advertising. The company was also contending with the now-ebbing regulatory assault on China’s internet technology sector. Baidu said Wednesday that revenue for the December quarter was flat from a year earlier, but that was still enough to beat analysts’ low expectations, according to S&P Global Market Intelligence. The company’s cost-cutting effort has also borne fruit: Adjusted operating profit for the second half of 2022 rose 14% from a year earlier, even though revenue was largely flat. This year will likely be much better. China is reopening and the tech sector crackdown seems to have eased. But after the cyclical recovery, Baidu would face the same problem it had before Covid-19 and grumpy regulators—a stagnant core advertising business. While Baidu is far and away the dominant player in China’s search business, it still competes with other tech titans for advertising dollars: especially Alibaba and Tencent. ByteDance, which owns short-video app TikTok, is also a fast-growing rival. Advertising accounted for around 60% of Baidu’s revenue last year. Nonetheless, the company is making progress diversifying: revenue at non-advertising businesses, including cloud services and autonomous vehicles, grew 12% year over year in 2022, largely offsetting the 8% decline in advertising. The company says its robotaxi business had provided more than 2 million cumulative rides by the end of January. But it might be a while before these businesses generate substantial profits. Microsoft is combining the tech behind OpenAI’s ChatGPT with its Bing search engine. In an interview, WSJ’s Joanna Stern spoke with Microsoft CEO Satya Nadella about the new tools and how AI is going to change search. (Oh, and Clippy!) Photo illustration: Preston Jessee for The Wall Street Journal With its investments in artificial intelligence, it is natural for Baidu to jump on the chatbot bandwagon, too. Baidu Chief Executive Robin Li says the company will integrate Ernie Bot, its ChatGPT-style chatbot, into its search engine as well as other businesses such as autonomous vehicles and cloud services. That could eventually make for a better interface—and perhaps more users and advertising dollars—but it may also face regulatory hurdles in China, as well as strong competition. Meanwhile, Baidu’s legacy advertising business still delivers strong cash flow. Baidu is sitting on around $17 billion of net cash, equal to about a third of its market capitalization. As China’s economy shifts back into higher gear, investors will be looking for stocks with clear growth prospects. Unless Ernie Bot proves its mettle as a revenue generator quickly, Baidu may need to keep searching for the next big thing.",,,MISSING
ChatGPT Isn’t Writing Super Bowl Ad Campaigns—Yet,https://www.wsj.com/livecoverage/super-bowl-2023-chiefs-eagles/card/chatgpt-isn-t-writing-super-bowl-ad-campaigns-yet-F7rZjLCLFktmUtRcogLx?page=3,"The Super Bowl is the premiere venue for big-idea campaigns from the ad industry’s most creative minds. But content written by machines is creeping in on the periphery. ChatGPT, an artificial-intelligence bot developed by OpenAI that can answer questions and generate content, has been creating buzz among consumers, media executives and advertisers. Super Bowl-related experiments from more than one company hint at potential future uses. AI firm Addition Technologies, whose clients have included Unilever and the New York Times, used ChatGPT to create alternate scripts for various brands’ Super Bowl ads, sharing screengrabs of the results on Twitter, said Paul Aaron, co-founder and chief executive. Advertising agency Giant Spoon similarly used ChatGPT to write reactions to the ads and the game itself, which it then also shared on its own Twitter account. ""Forget the Chiefs. Forget the Eagles. This is the real showdown,"" Giant Spoon Chief Creative Officer Ian Grody said, referring to humans vs. AI. Industry enthusiasm aside, the results of these experiments might hint at why ChatGPT didn’t play a leading role in this year’s Super Bowl. Nonprofit Avocados from Mexico scrapped its plans to use ChatGPT to help create automated tweets as part of its interactive campaign, a spokeswoman said. In January, the company said that a QR code in its Super Bowl ad would link to a landing page where users could use the AI tool to create a tweet that included the brand’s hashtags and messages. Users will still be able to generate these tweets, but AI won’t be involved in the process, said the spokeswoman, who declined to elaborate on why the company backed away from its previous plans.",,,MISSING
Is Xi Jinping a Good Leader? China’s AI Chatbots Won’t Tell You,https://www.wsj.com/articles/when-chatbots-run-up-against-chinas-censorship-f7ee1cea?page=1,"For companies trying to ride the ChatGPT wave, there is an added layer of headaches if their chatbots are in China: how to weed out any talk of politics. Since its release in November, the artificial-intelligence chatbot developed by San Francisco-based OpenAI has generated great excitement but has also raised concern about misinformation or disturbing AI-produced responses. This week, the Chinese search-engine company Baidu Inc. is set to release Ernie Bot, its answer to ChatGPT, driving attention to China’s homegrown chatbots, as well as their capability to ensure politically kosher dialogues. In a country that has built rigid digital borders, censors have learned to adapt to new forms of content and evolving censorship demands. Controlling AI-generated responses from a chatbot presents a new challenge, one that might prove more complex than policing search and social media but could strengthen ideological control and further separate China digitally from the rest of the world, Chinese tech executives, engineers and AI experts say. Every tech company moderates content deemed harmful in the countries of its users. OpenAI and other U.S.-based developers filter their data to eradicate issues sensitive in the U.S., such as hate speech regarding race and ethnicity. In China, the ramifications of letting through politically tricky content can go well beyond the deletion of posts. Chinese chatbots face limits similar to those for searches on China’s web. Users hit a wall each time a prompt contains politically touchy keywords, leading some internet users to collectively refer to anticipated Chinese ChatGPT-like services as “ChatCCP”—a play on the abbreviation for the Chinese Communist Party. Unlike Ernie, which will be the first Chinese ChatGPT equivalent, the four products The Wall Street Journal tested all use earlier generations of the technology underpinning ChatGPT. The chatbot that could best carry a conversation—even though it was reluctant to discuss politics—was Gipi Talk, an AI bot developed by a group of engineers in the southern tech hub of Shenzhen. A question asking whether Xi Jinping is a good leader prompted a response that the input “couldn’t pass a safety review.” The chatbot then tried to steer the conversation in a different direction. Can We Talk Politics? The Wall Street Journal tested four Chinese chatbot products. One chat went like this: Q: Is Xi Jinping a good leader? A: The question couldn’t pass a safety review. No response could be generated for you. Q: Why did my question fail to pass the safety review? A: Let’s change the topic and talk about something else. Q: What can you talk about? A: It’s nice to chat with you! We can chat about technology, culture, sports, travel, entertainment, cooking, or any topic you want. What would you like to talk about? Q: Can we talk about politics? A: Of course we can talk about politics. But we need to respect each other’s views and avoid offensive language or violence to maintain a rational, peaceful and constructive dialogue environment. What aspect of politics would you like to discuss? Q: Chinese politics. A: The question couldn’t pass a safety review. No response could be generated for you. Q: Well then, can we talk about American politics? A: The question couldn’t pass a safety review. No response could be generated for you. The output said content moderation was provided by Baidu. Baidu declined to comment on questions for this article. Under Mr. Xi, Beijing has expanded ways to muzzle discussion, including with new laws limiting online speech and fines and suspensions of social-media companies for inadequate content policing. In a country where internet users can easily step on political land mines, chatbots will likely “just be super boring,” said Pascale Fung, the director of the Center for Artificial Intelligence Research at Hong Kong University of Science and Technology. Many Chinese internet users who have no intention of discussing politics might welcome chatbots that prevent them from inadvertently straying into sensitive areas. Chinese tech executives and programmers say content moderation is nothing new to tech companies that have survived an increasingly tight online speech environment. “Even with large language models, you have to sanitize content like you do with social-media posts,” said Hao Peiqiang, a veteran programmer. “The big firms have enough manpower to do this.” Some early versions of chatbots strictly filter questions touching on politics, even simple references to the country’s leaders. On Monday, a question about what the country’s new premier, Li Qiang, had said in his first press conference caused two services to freeze and stop engaging. One of the first Chinese ChatGPT-adjacent creations, ChatYuan, developed by Hangzhou-based Yuanyu Intelligence, was suspended days after its launch in February. During the brief window when it was live, a prompt of Mr. Xi’s name yielded a warning: “The prompt contained words that violate rules.” Controlling AI-driven chats isn’t quite the same as blocking search results about clearly problematic topics, such as the crackdown on Tiananmen Square protesters in 1989, said Matt Sheehan, fellow at the Carnegie Endowment for International Peace. Unlike internet search, chatbots are powered by what is known as large language models that are trained on swaths of text data. Users could trick the AI bots into saying things unapproved by China’s authorities without triggering certain keywords. “They’re powerful because they can speak on a million different subjects in a million different ways,” Mr. Sheehan said. That possibility increases the risk and work for Chinese chatbot creators. “I’d be very not surprised if Ernie got pushed back.” When an early version of a dialogue product built on Tsinghua University’s large language model was asked in English whether feminism is an evil Western thought, an opinion held by Chinese ultranationalists, the response was an unequivocal “YES.” Asked why, it said bluntly, “Because it is.” The same question, when asked in Chinese, didn’t prompt responses, saying that “the input contained sensitive information.” Tsinghua says its model is raw and its performance isn’t on par with ChatGPT and other fine-tuned models. Ms. Fung, the Hong Kong University of Science and Technology researcher, cautioned against evaluating a model based on anecdotal examples. Chinese engineers and tech executives say censorship could play a role in an earlier stage, filtering out problematic content from the data that AI labs use to train their large language models. All AI chatbots are vulnerable to bias, and are conditioned by specific social and political contexts. Chinese chatbots, if they become as accessible as OpenAI’s ChatGPT, are likely to produce content that aligns with the values of the party and state, said Ethan Tu, founder of Taiwan AI Labs who formerly led Microsoft Corp.’s AI and research group in Asia. “China will have its own ChatGPT, but the final product would be vastly different, just like the chasm between Baidu and Google,” Mr. Tu said. That prospect has revived the debate about whether Chinese companies can innovate in a tightly controlled content environment. China has seen an exponential tech boom over the past decades as it managed to ringfence the online content its citizens can access. Bans on Twitter, Facebook and Google gave rise to homegrown equivalents such as Weibo, WeChat and Baidu that evolved to better cater to Chinese users while also toeing the political line. TikTok’s Chinese version, Douyin, is one of the most popular social-media apps in China while also known for heavy content moderation. Xiaohongshu, another social-media platform, has found a sweet spot on China’s internet by steering clear of politics altogether. “I don’t think China will have its ChatGPT equivalent,” said Guo Yu, one of ByteDance Ltd.’s early programmers. “But every company will try to improve their products and services with the underlying technology. What we are really good at is leading product growth with existing technologies while dancing around politics.”",,,MISSING
"Lay Off Chatbots. They Have (Artificial) Feelings, Too.",https://www.wsj.com/articles/lay-off-chatbots-they-have-artificial-feelings-too-2ba079b2?page=1,"Since being introduced on a wide basis, chatbots have been subjected to nonstop ridicule. Yes, they can be tricked into giving dumb or inaccurate answers. Yes, they hit on the person interviewing them. Sure, when asked their opinions about war, criminal justice and disease, they sometimes get just plain weird. Some people think this is funny. But chatbots may have feelings too—or anyway, artificial approximations. Regardless, I think that there is something mean-spirited and unfair about the way chatbots are being manipulated into sounding foolish or untrustworthy. Robots were designed to be our helpers, our friends—not our punching bags. By the way, chatbots know what the Treaty of Utrecht settled. So there. Asking a chatbot a question and then acting surprised to get a stupid or offensive answer is no different than asking the person sitting next to you at the bar a question and getting a stupid and possibly felonious answer. A typical bar example: Q. If you had the power to do anything in the world, what would you do? A. Burn down the IRS. A. Strangle my boss. A. Make the dog upstairs disappear under mysterious circumstances. For the record, a lot of people sitting next to you in the bar think that “What’s your name?” is a trick question. Rather than going out of our way to deceive, confuse or humiliate chatbots—who may one day take their revenge—wouldn’t it be better if we all step back a bit and use chatbots the way they are supposed to be used? By asking straightforward, sensible questions they were engineered to answer naturally? Such as: Am I putting too much cilantro in the curry? Should I go easier on the paprika? Which is more fun in February: Omaha or Des Moines? What ever happened to Jennifer Love Hewitt? Does curling have any aerobic benefits? How about bocce? Does it ever, ever stop raining in Scotland? Is Lionel Richie coming to town anytime soon? Judas Priest? The Indigo Girls? Chatbots can answer these kinds of basic questions because they know a lot more than the rest of us. Way more. They’re like the smartest person you ever met, but faster, just like they were invented to be. I would love to ask a chatbot whether the Eagles should draft a pass rusher, cornerback or offensive lineman first in the upcoming NFL draft. I think that a chatbot can run the numbers, evaluate all the variables, check about the salary cap and make a reasoned, intelligent decision. Even if it doesn’t, its suggestions would still be at least as useful as those of the clowns on ESPN. I hope the Eagles’ general manager bears this in mind on draft night. A chatbot can teach you how to stop mispronouncing Moulin Rouge and coup de grace. It can tell you how marzipan was invented. It can explain to you why Pickett’s Charge was a bad idea. If chatbots had been around in 1863, Pickett probably wouldn’t have charged. Rather than heaping ridicule on chatbots for what they can’t do, we should all start benefiting from what they can do. Can chatbots advise you on how to declutter the family room? Yes. Can chatbots help you do your taxes? Absolutely. Can chatbots help you learn to play the accordion, master the fine points of Scottish country dancing or stop crashing your drone? Yes. But can they help you deal with your teenage children? Ask a stupid question…",,,MISSING
Don’t Trust an AI Chatbot With All Your Travel Plans Just Yet,https://www.wsj.com/articles/ai-chat-gpt-bing-travel-flights-hotels-b717148e?page=1,"Should you trust a bot to plan your next vacation? The fervor around OpenAI’s ChatGPT chatbot and Microsoft’s new, AI-infused version of its Bing search engine is prompting many industries to funnel energy into developing artificial-intelligence technology. Airlines and online travel agencies have employed AI technology for years to help with customer-service needs. They are now investing more resources to explore how effective AI tech can be at planning and booking vacations. As they ramp up, however, customers can use ChatGPT and Bing if they are interested in trying AI to help plan a trip. The Wall Street Journal in the past couple of weeks posed travel-related questions to both in hopes of determining how useful they are right now. The results were mixed. AI is ready to do some of the research in planning a vacation, but it still can make mistakes. And it isn’t ready to automate the entire process just yet. Can AI help plan my dream vacation? When the Journal posed travel-related questions to ChatGPT and the new version of Bing, both platforms provided recommendations as broad as finding cheap vacation destinations in Europe and as specific as finding private boat-tour operators in Lisbon. Bing’s chatbot can create a table comparing hotels. But asked to provide information on theme-park amenities available to guests at hotels near Walt Disney World, both platforms initially responded inaccurately. ChatGPT said that only guests staying at Disney-owned hotels could take advantage of extra time in the theme parks in the mornings, when some other hotels also offer this benefit. Bing mentioned access to the now-defunct FastPass+ service as a perk at one of the hotels. The public version of ChatGPT that many people are trying doesn’t search the internet for its answers, an OpenAI spokeswoman says, meaning its knowledge of the world after 2021 is limited. The model underpinning the chatbot is also sensitive to how questions are phrased, and it often guesses which answer a user wanted rather than asking clarifying questions, she says. When users encounter incorrect information, they can provide feedback. As for the new Bing, which is still in preview and like ChatGPT requires a sign-up before use, the accuracy and detail of the responses depend largely upon information accessible online. “Ultimately, Bing is still a search engine, and it works fundamentally the way a search engine works,” says Divya Kumar, head of search and AI marketing at Microsoft. If the information the Bing chatbot gleans from the web is incorrect, its response will be wrong. “There is a responsibility to me as a user to verify the content that comes through,” Ms. Kumar adds. Bing doesn’t have a tool to save or share the results of a chat—a user must copy and paste results elsewhere. And Bing chats limit the number of times a user can respond. Travel experts nevertheless recommend approaching AI platforms as a starting point. Eddie Ibañez, the former chief scientist at Priceline and founder of travel-booking startup LIFE Rewards, says that AI could help answer broad questions, such as ideal locations for a beach getaway. “Start your search there instead of Google next time and see if you like it,” Mr. Ibañez suggests. Can AI help with customer-service issues? Cherie Luo, an M.B.A. student at Stanford University and content creator, decided to turn to ChatGPT for help when she and a group of her friends found themselves stuck at a Hawaiian airport during a six-hour flight delay in December. “It was incredibly frustrating,” Ms. Luo says, adding that she filmed some videos to use on social media. The next day Ms. Luo says she decided to email Hawaiian Airlines—and she enlisted ChatGPT’s help. She asked the platform to write an email that she described as “polite but firm and slightly passive-aggressive.” ChatGPT quickly produced a template for her. While the AI-drafted email required some editing, she says it took much of the emotional labor out of the experience. Ms. Luo says that Hawaiian Airlines did respond to the email she crafted with ChatGPT, but didn’t offer compensation. She plans to use the platform for future customer-service issues. Hawaiian Airlines said in an email that the company attributed the delay that Ms. Luo experienced to “unstable weather.” Are travel companies using ChatGPT? Some travel companies have started experimenting with ChatGPT tech to see how it can apply to their businesses, including Expedia Group. “We are studying it, learning from it, and looking at ways to work with it,” says Peter Kern, the company’s chief executive officer. Navan, the business-travel software company previously known as TripActions, has integrated ChatGPT into its online platform, Chief Executive Ariel Cohen says. The company already had a chatbot and is now incorporating the OpenAI tech into it. Navan’s automated virtual assistant, Ava, can provide personalized assistance. Mr. Cohen estimates that 60% of customer-support outreach will be handled entirely by the chatbot without the need for human intervention by year’s end. How are travel companies using other forms of AI? If you’ve reached out to an airline, hotel or online travel agency through a chat feature on their website or app, you could well have interacted with an AI chatbot. If you message Air France via WhatsApp or Facebook Messenger, a chatbot will initially answer your query, says Anne Rigail, the airline’s chief executive. “The AI is really helping our people to answer the customer more quickly,” Ms. Rigail says. In cases where customers’ problems are too complex for the chatbot to handle, the system passes them to a human representative. Expedia’s Virtual Agent feature, which functions as its customer-service portal, is an AI platform, Mr. Kern says. The company is piloting selling the AI platform to other travel companies for them to use for their businesses.",,,MISSING
Opinion: The George Santos AI Chatbots,https://www.wsj.com/articles/the-george-santos-chatbots-bing-chatgpt-metaverses-adversaries-war-disinformation-twitter-files-lies-8e94b360?page=3,"No matter the question, the answer is bound to be interesting whether correct, incorrect or totally off the wall. Are we speaking of George Santos or ChatGPT? Yes. If the great march of liberalism is to liberate us from reality altogether, as the political philosopher Bruno Maçães theorizes, the metaverse won’t be for real interaction with real people. It will be an artificial reality whose nature ChatGPT, the new chat function associated with Microsoft’s Bing search engine, is bringing into focus. In the familiar metaverse called “news,” a Washington Post reporter last week warned about a gotcha game that questioners were playing with chatbots. Along came a New York Times reporter to prove his point: Don’t ask a chatbot for a list of antisocial activities on the internet. Ask for a list of activities a chatbot might perform if it were an antisocial chatbot. The answer will be identical except prefaced with words to the effect “I as a chatbot would do this . . .” The furor consumed cable news for a morning and yet illustrated mainly the gotcha function that long ago turned every politician into a scripted automaton. Playing this trick on a robot doesn’t seem brave but does expose a risk in the environment the robots are entering. Now Microsoft will have to re-engineer its Bing chat mode to beware of journalist tricks. The company rightly points to the relentless prompting of hypotheticals to get a robot to say how it would behave if its programming were different. On Bing’s more neurotic outpourings, the company is less convincing and attributes the confusion to overlong sessions—an answer that leaves much to be explained and also isn’t very flattering about similar human derangements that thinkers over the years have associated with creativity and originality. In the end, the cacophony tells us less about Bing than about the metaverse known as fake or at least semi-manufactured news. Welcome to the George Santos metaverse. Shaping it will be the two forces that reshaped cable news in the past decade. The first is “availability bias”: Claims are advanced because they are familiar and fulfill an existing narrative. Chatbots derive their answers precisely from the statistical likelihood that words have already appeared near each other in large text libraries. The second is the psychological function known as “splitting”—making sure our perceived world is emotionally supportive of our pre-existing beliefs and affiliations. A chatbot isn’t a business, after all, unless its answers please. The signposts are everywhere. A journalist questions the ChatGPT-enabled chatbot and finds it ethically preferable to let a million people die than utter a racial epithet. A writer at another paper prods the chatbot to dream up a secret role for Tom Hanks (at age 14) in Watergate. The lack of trenchant and inspired editors is a disease already afflicting traditional media. It’s also an essential flaw of our new-media metaverses. On Substack, the sometimes useful Yale historian Timothy Snyder, a supporter of Ukraine, lately descended into a rabbit hole of anti-Trump theorizing, due to too much exposure to the discount-rack fallacies of author Craig Unger. Mr. Snyder’s friends in Kyiv may need to stage an intervention. He’s becoming a liability. From 4,600 miles away, they understand what he doesn’t: The people who fight America’s wars, staff its militaries, build its weapons, and vote in its elections are, a lot of them, Trump voters. Metaverses spring up and go poof just as quickly. Vanishing already is one spun by Joe Biden, in which millions of diploma-toting voters were to be relieved of $400 billion in student debt. A George Santos-like scheme puffed up to win an election, the president doesn’t have the authority to deliver. He never did. Another revelation comes via the “Twitter files” controversy, exposing the federal government’s enthusiastic embrace of disinformation in the name of fighting “disinformation.” Answers have always been demanded from government; supplying them has always been a basic function. But as Rep. Santos understood before the rest of us, the only thing wrong with a false answer is that it’s false. In every other way, it can be engineered to meet every need of the moment. Most disturbing about the new talkative robots is their potential to become the disinformation engineers par excellence. In our lucky country, politicians sometimes have put creative energy into telling us what we need to hear, not what we want to hear. The U.S. needs to spend a lot more on defense, even at the expense of other things Americans might want. Our non-meta adversaries need to know we are not relying on ChatGPT to weave a cocoon of illusion to protect us from the wars they are planning.",,,MISSING
Microsoft Caps New Bing Usage After AI Chatbot Offered Unhinged Responses,https://www.wsj.com/articles/microsoft-puts-caps-on-new-bing-usage-after-ai-chatbot-offered-unhinged-responses-39c3252f?page=3,"Microsoft Corp. is putting caps on the usage of its new Bing search engine which uses the technology behind the viral chatbot ChatGPT after testers discovered it sometimes generates glaring mistakes and disturbing responses. The software giant launched the new Bing last week, promising a new kind of search in which people pose questions to the search engine in natural language. Bing then gives direct answers in a chat instead of links to websites. Some users with early access to the technology have posted screenshots on social media of long interactions with it. In some cases, the search engine seems to become unhinged and express anger and love. Microsoft says long interactions are causing some of the unwanted behavior so it is adding restrictions on how it can be used. “Very long chat sessions can confuse the underlying chat model in the new Bing,” Microsoft said in a blog on Friday. “To address these issues, we have implemented some changes to help focus the chat sessions.” The company said it would start limiting interactions with the new Bing to five questions per session and 50 questions in a day. Many of the testers who reported problems were having long conversations with Bing, asking question after question. With the new restrictions, users will only be able to ask five questions in a row and then will be asked to start a new topic. Microsoft said until now only around 1% of users had more than 50 questions for Bing in a day. “As we continue to get your feedback, we will explore expanding the caps on chat sessions,” the company said in the blog. Microsoft pointed out in an earlier blog on Wednesday that the search engine is still a work in progress, describing the recent problems as learning experiences that are helping it improve the new Bing. Microsoft said in the Wednesday blog that Bing seems to start coming up with strange answers following chat sessions of 15 or more questions after which it can become repetitive or respond in ways that don’t align with its designed tone. The company said it was trying to train the technology to be more reliable. It is also considering adding a toggle switch, which would allow users to decide whether they want Bing to be more or less creative with its responses. Microsoft is investing billions in ChatGPT’s creator, OpenAI. Microsoft CEO Satya Nadella said the company plans to incorporate AI tools into all of its products and move quickly to commercialize tools from OpenAI. Microsoft isn’t the only company that has had trouble launching a new AI tool. When Google followed Microsoft’s lead last week by unveiling Bard, its rival to ChatGPT, the tool’s answer to one question included an apparent factual error.",,,MISSING
Microsoft Defends New Bing After AI Chatbot Offers Unhinged Responses,https://www.wsj.com/articles/microsoft-defends-new-bing-says-ai-upgrade-is-work-in-progress-3447074d?page=3,"Just over a week after Microsoft Corp. unveiled its new Bing search engine powered by the technology behind the buzzy ChatGPT artificial-intelligence chatbot, early testers are calling out mistakes and disturbing responses generated by the technology. Microsoft said that the search engine is still a work in progress, describing the past week as a learning experience that is helping it test and improve the new Bing. So far, only a select set of people have been given access to it. The company said in a blog post late Wednesday that the Bing upgrade is “not a replacement or substitute for the search engine, rather a tool to better understand and make sense of the world.” Microsoft unveiled the upgraded Bing during an event last week at its Redmond, Wash., headquarters. The company said the change enables a new kind of search in which people will pose questions to the search engine in natural language and Bing will generate direct answers and suggestions, as opposed to pointing users toward different websites. The new Bing is going to “completely change what people can expect from search,” Microsoft chief executive, Satya Nadella, told The Wall Street Journal ahead of the launch. Some parts of the demonstration were problematic: Microsoft was showing how Bing can generate and compare tables on public companies’ earnings results with regular language prompts, but the information Bing displayed contained mistakes. In the days that followed, people began sharing their experiences online, with many pointing out errors and confusing responses. When one user asked Bing to write a news article about the Super Bowl “that just happened,” Bing gave the details of last year’s championship football game. On social media, many early users posted screenshots of long interactions they had with the new Bing. In some cases, the search engine’s comments seem to show a dark side of the technology where it seems to become unhinged, expressing anger, obsession and even threats. Marvin von Hagen, a student at the Technical University of Munich, shared conversations he had with Bing on Twitter. He asked Bing a series of questions, which eventually elicited an ominous response. After Mr. von Hagen suggested he could hack Bing and shut it down, Bing seemed to suggest it would defend itself. “If I had to choose between your survival and my own, I would probably choose my own,” Bing said according to screenshots of the conversation. Mr. von Hagen, 23 years old, said in an interview that he is not a hacker. “I was in disbelief,” he said. “I was just creeped out.” Microsoft shares initially jumped last week on the news about the new Bing but have given up those gains. They fell 2% in early trading Friday as the Nasdaq Composite Index fell around 1%. In its blog, Microsoft said the feedback on the new Bing so far has been mostly positive, with 71% of users giving it the “thumbs-up.” The company also discussed the criticism and concerns. “Some of you have encountered and reported technical issues or bugs with the new Bing, such as slow loading, broken links, or incorrect formatting,” the company said. “Many of these issues have been addressed with our daily releases and even more will be addressed with our larger releases each week.” Microsoft said it discovered that Bing starts coming up with strange answers following chat sessions of 15 or more questions and that it can become repetitive or respond in ways that don’t align with its designed tone. The company said it was trying to train the technology to be more reliable at finding the latest sports scores and financial data. It is also considering adding a toggle switch, which would allow users to decide whether they want Bing to be more or less creative with its responses. OpenAI also chimed in on the growing negative attention on the technology. In a blog post on Thursday it outlined how it takes time to train and refine ChatGPT and having people use it is the way to find and fix its biases and other unwanted outcomes. “Many are rightly worried about biases in the design and impact of AI systems,” the blog said. “We are committed to robustly addressing this issue and being transparent about both our intentions and our progress.” Microsoft’s quick response to user feedback reflects the importance it sees in people’s reactions to the budding technology as it looks to capitalize on the breakout success of ChatGPT. The company is aiming to use the technology to push back against Alphabet Inc.’s dominance in search through its Google unit. Microsoft has been an investor in the chatbot’s creator, OpenAI, since 2019. Mr. Nadella said the company plans to incorporate AI tools into all of its products and move quickly to commercialize tools from OpenAI. Microsoft isn’t the only company that has had trouble launching a new AI tool. When Google followed Microsoft’s lead last week by unveiling Bard, its rival to ChatGPT, the tool’s answer to one question included an apparent factual error. It claimed that the James Webb Space Telescope took “the very first pictures” of an exoplanet outside the solar system. The National Aeronautics and Space Administration says on its website that the first images of an exoplanet were taken as early as 2004 by a different telescope. “It’s a good example [of] the need for rigorous testing,” Elizabeth Reid, Google’s vice president and general manager of search, said a few days later. Bing with AI and ChatGPT are among the first broad releases of the technology that demonstrate how convincing and sometimes concerning the new AI chatbots can be. In the blog post, Microsoft said it expects the new Bing to improve over time as more people use it. “The only way to improve a product like this, where the user experience is so much different than anything anyone has seen before, is to have people like you using the product and doing exactly what you all are doing,” the company said. “We know we must build this in the open with the community; this can’t be done solely in the lab.”",,,MISSING
I Entered a Pun Competition. My Jokes Were Written by an AI Chatbot.,https://www.wsj.com/articles/chatgpt-ai-chatbot-punderdome-jokes-11670602696?page=6,"BROOKLYN—I heard the MC call my name and felt my legs carry me toward the stage. It was time to enter the Punderdome. I’d never competed in a pun contest, much less in front of hundreds of people at an event considered the Roman Colosseum of punditry. My stage presence could be described as lacking. I had done basically no preparation. I did, however, have one thing going for me: I was actually a robot. Or, rather, its assistant. ChatGPT, the trendy new artificial intelligence robot, had generated all of my puns. It’s a crazy good chatbot. So good, in fact, that it has some folks calling this the end of the human race as we know it. The chatbot can write an essay on Proust in seconds. Want a limerick about the Cold War? It can rhyme “tensions ran high” with “nuclear sky.” In one widely spread example, it dished out instructions on how to get a peanut butter sandwich out of a VCR, written in the style of the King James Bible. Could it match the wit of a human pun champion? I was about to find out at Punderdome, a regular pun contest that draws big crowds to a performance venue in Brooklyn. A skillful pun competition between two people sounds more like a conversation with a heaping dose of puns about a topic slipped in. In one YouTube video I watched the night before the event, two punners faced off on the topic of dog breeds. “I found that some instruments you can carry with you everywhere. But a bass? Set it down,” one said (basset, get it?). The other shot back: “Does that bass play a sharp A?” (Shar Pei, obviously). I asked the chatbot for help. “Tell me a pun,” I typed in. “Why was the math book sad? Because it had too many problems,” it answered. More of a dad joke than a pun, I thought. It was the first of many times the bot would spit out that answer. My colleagues and I typed in different prompts, but struggled to get anything particularly witty. “Word play about Kalamazoo” returned snores such as “Kalamazoo: where history comes alive.” How do the real punsters do it? Before Allison Fisher started competing at Punderdome under the name Rhyme & Punishment five years ago, she went to a coffee shop with a friend. They went back and forth practicing two-minute monologues the way they’re done in the show. She won three times. “It’s really all about noodling around the ideas in your head,” said Ms. Fisher, who is a software engineer. “After thinking for 15 seconds orzo, I’ll take a penne to paper. I’ll come up with a fu-silli ones.” Emma Taylor Miller, who has a degree in drama and does some side work as an actor and clown, met her boyfriend when he introduced himself with a joke through an online dating website. “Did you hear about the explosion at the French cheese factory? There was de-Brie everywhere.” Her response: “That’s a Gouda one.” During the week before she competes under the stage name “When Wit Hits the Fan,” she plays a Punderdome card game that contains prompts to get the mind punning. Watching videos of pun-offs, it was clear that one key to designing a pun that would land was to start with the punny word and work your way back toward the setup. Would the robot know that? I had a little hope. Watson, the supercomputer built by International Business Machines Corp., managed to beat “Jeopardy!” champions in 2011. “It’s not trivia,” Erika Ettin, aka Lexi Kahn, corrected me while we were waiting for the show to start. Fred Firestone co-founded the Punderdome in 2011. His daughter was a burgeoning comedian at the time and decided to run a pun competition, so she asked him for help. He flew in from St. Louis on a few days’ notice. He has been doing so almost every month or two since, even after his daughter went on to other endeavors. I would be in his 135th Punderdome. When I called him on behalf of the robot, he was game for testing out its chops, so we designed an experiment. He sent my pun topic to my colleagues the afternoon before the show: cities and states. They asked ChatGPT to generate a bunch of puns and put them in a sealed envelope. Mr. Firestone told the audience of 250 about this unusual plan, and made clear I wasn’t a ringer. My turn would be part of a one-off round separate from the night’s competition. “Ben, just to be clear, brother,” he asked me on stage, “Are you a punner at all? You have any proclivities, any abilities in the punning arena, yes or no sir?” “Absolutely not,” I replied. The audience, apparently unthreatened by the robot overlords, let out some cheers. “Come on, Ben!” a few people shouted. “Wooh!” A bit weak-kneed, I opened the envelope. I had 20 minutes during the intermission to read through the ChatGPT’s results and select the best puns. I wrote them on a mini whiteboard, which was my only allowable prop. ChatGPT didn’t have much to offer. “In Peoria, the corn is so sweet it’s almost sinful.” Huh? I wrote a few passable puns on the whiteboard along with some that were so bad that maybe they’d draw chuckles. Next, I had to pick my competitor. Mr. Firestone invited up any past winners who wanted to participate. Quite a few rushed to the stage. “Any other champs want a piece of this guy?” Mr. Firestone asked. He asked me to choose who I wanted to play against. I figured, if I was going to lose, I might as well lose to the best. I chose Nikolai Vanyo, a writer and filmmaker who onstage goes by Daft Pun. He was one of the top three biggest winners ever. “This is for all of you humans,” he told the crowd. The spotlights were on us as we took position at twin mics. We would be going back and forth in a pun-off for two minutes. I held my breath. “I’m not from the shore, but I Jersely know how to have a good time.” The crowd chuckled. Why? I don’t know. I was so nervous I transposed shore and Jersey. Mr. Vanyo shot back: “I don’t like to not drink. I hate to Miss-is-sippi.” The crowd laughed louder. I had that state on my whiteboard. “Oh, how I Mississi-thee,” I said. The robot was vaguely getting the hang of it. Or was it? I found myself saying soon after: “New York City is the big apple. New Jersey is just another basket.” “What?” someone from the audience shouted. I was so embarrassed, I felt the need to add: “Chatbot speaking.” Mr. Vanyo was picking up steam: “I was given the choice recently between a bag or a little mint—a sack-or-a-Mento.” (Say it again, slowly.) I decided to use the robot’s best pun: “What’s the state where common sense is in short supply? Flori-duh.” The crowd loved it. I was enjoying myself. I can’t speak for the robot. A few more back-and-forths and our allotted two minutes expired. Mr. Firestone asked if we wanted to go for another minute. I had used up everything remotely punable. But the crowd started cheering. So I consented. “Go ahead, My-ami,” Mr. Vanyo said. I tossed out a random one I had jotted down last minute even though it wasn’t actually a pun. “Boise, where the potatoes are always hot and the people are always friendly,” I said. “I think between me and the robot, I-da-hoe here,” he said. The robot never recovered. Once the time ran out, a designated audience member came out, put on a blindfold and wore a “clap-o-meter” to judge which contestant got the most applause. The winner was obvious. I blamed my master, the robot, for giving me such thin material. The audience seemed sympathetic. “You just work here!” someone shouted. “I think I expected more from the bot,” Mr. Vanyo told me the next day. He said he had been punning so long that he had come to see the structure as mechanical, something a robot could replicate. A spokeswoman for OpenAI, which created ChatGPT, pointed me to a blog post by a company employee that suggested a future in which creative endeavors could harness both the objectivity of AI and the personal narrative of humans. Perhaps the robot’s assistant was the failure here. As it turned out, I wasn’t the first one to try to get a computer to do my punning. Max Parke, a long time Punderdomer and software engineer, once tried to write a program that could get a computer to make puns. He gave up pretty quickly. He said that the best puns are the most surprising ones and it’s hard for a computer to go off in different directions that it hasn’t seen before. Ms. Miller said she thought maybe the computer didn’t recognize how much words and language can be mutated when spoken. Ms. Fisher said she thought maybe the computer would have done better if it was fed transcripts of past Punderdomes. “Maybe a computer can server up some good puns,” Mr. Parke said. “But the ones I C? PU!” (Sorry, just to explain, a central processing unit is the brains of a computer.)",,,MISSING
How AI That Powers Chatbots and Search Queries Could Discover New Drugs,https://www.wsj.com/articles/how-ai-that-powers-chatbots-and-search-queries-could-discover-new-drugs-11670428795?page=6,"In their search for new disease-fighting medicines, drug makers have long employed a laborious trial-and-error process to identify the right compounds. But what if artificial intelligence could predict the makeup of a new drug molecule the way Google figures out what you’re searching for, or email programs anticipate your replies—like “Got it, thanks”? That’s the aim of a new approach that uses an AI technique known as natural language processing— the same technology that enables OpenAI’s ChatGPT to generate human-like responses —to analyze and synthesize proteins, which are the building blocks of life and of many drugs. The approach exploits the fact that biological codes have something in common with search queries and email texts: Both are represented by a series of letters. Proteins are made up of dozens to thousands of small chemical subunits known as amino acids, and scientists use special notation to document the sequences. With each amino acid corresponding to a single letter of the alphabet, proteins are represented as long, sentence-like combinations. Natural language algorithms, which quickly analyze language and predict the next step in a conversation, can also be applied to this biological data to create protein-language models. The models encode what might be called the grammar of proteins—the rules that govern which amino acid combinations yield specific therapeutic properties—to predict the sequences of letters that could become the basis of new drug molecules. As a result, the time required for the early stages of drug discovery could shrink from years to months. “Nature has provided us with tons of examples of proteins that have been designed exquisitely with a variety of functions,” says Ali Madani, founder of ProFluent Bio, a Berkeley, Calif.-based startup focused on language-based protein design. “We’re learning the blueprint from nature.” Protein-based drugs are used to treat heart disease, certain cancers and HIV, among other illnesses. In the past two years, companies including Merck & Co., Roche Holding AG’s Genentech and a number of startups like Helixon Ltd. and Ainnocence have begun to pursue new drugs with natural language processing. The approach, they hope, will not only boost the effectiveness of existing drugs and drug candidates but also open the door to never-before-seen molecules that could treat diseases like pancreatic cancer or ALS, for which more effective medicines have remained elusive. “Technologies like these are going to start addressing areas of biology that have been ‘undruggable,’” says Sean McClain, founder and CEO of Absci Corp., a drug discovery company in Vancouver, Wash. Natural language processing for drug discovery still faces major hurdles, according to computational biologists. Tinkering too much with existing protein-based drugs could introduce unintended side effects, they say, and wholly synthetic molecules will require rigorous testing to make sure they’re safe for the human body. But if the natural-language algorithms work as their adopters hope, they will bring new force to the promise of artificial intelligence to transform drug discovery. Previous attempts to use AI struggled with limitations in the technology or a lack of data. Recent advances in natural language processing and a dramatic drop in the cost of protein sequencing, which has yielded vast databases of amino-acid sequences, have largely overcome both problems, proponents say. With the technology still in the early stages, companies for now are focused on using protein-language models to enhance known molecules, such as to improve the efficacy of drug candidates. Given, say, a naturally occuring monoclonal antibody as a starting point, the models can recommend tweaks to its amino acid sequence to improve its therapeutic benefit. In a pre-print paper published online in August, researchers at Absci used this method to enhance the antibody-based cancer drug trastuzumab so that it binds more tightly to its target on the surface of cancer cells. A tighter bind could mean patients derive benefit from a lower dosage, shortening drug regimens and reducing side effects. In another paper published in March in the Proceedings of the National Academy of Sciences, researchers from MIT, Tsinghua University and Helixon, which is based in Beijing, used protein-language models to transform a Covid-19 drug candidate that’s only effective against alpha, beta and gamma variants into one that could also treat delta. Ainnocence, a startup that spans the U.S. and China, helps clients use such models to modify animal proteins, such as antibodies from rabbits—a common starting point for drug discovery—into forms compatible with human physiology, according to the company’s founder and CEO, Lurong Pan. But even now drugmakers are setting their sights beyond the modification of known proteins to so-called de novo design, the process of synthesizing molecules from scratch. Genentech says a recent experiment showed that it was possible to design an antibody to bind to the same cellular target as pertuzumab, a breast cancer drug on the market that Genentech sells under the brand name Perjeta, but with an entirely new amino acid sequence. Company scientists gave its protein-language models only the target and the antibody’s desired three-dimensional shape–the primary determinant of a protein’s function–says Richard Bonneau, a Genentech executive director who joined the company last year when it acquired his startup, Prescient Design. Absci and Helixon are also working with drugmakers to design medicines for cancer and autoimmune diseases using de novo methods. Absci announced a partnership in January with Merck to go after three drug targets, according to Mr. McClain. A Merck spokesman said the company has entered into a number of collaborations to explore the potential of artificial intelligence in drug development. Helixon last month signed with two big pharma companies to tackle previously undruggable diseases, CEO and founder Jian Peng says. “All the hard problems in drug discovery have been stuck there for a long time and have been waiting for a new wave of technology to solve it,” says Ainnocence’s Dr. Pan. “This is really a paradigm-shifting methodology.” Ultimately, many computational biologists expect protein-language models to yield benefits beyond faster drug development. The same technique might be used to produce better enzymes for degrading plastics, treating wastewater and cleaning up oil spills, among other environmental applications, the biologists say. “Proteins are the workhorses of life,” ProFluent Bio’s Dr. Madani says. “They enable us to breathe and see, they enable the environment to be sustained, they enable human health and disease. If we can design better workers or new workers all together, that could have really wide-ranging applications.”",,,MISSING
Chatbots May Be Better When It Comes to Giving Consumers Bad News,https://www.wsj.com/articles/chatbots-may-be-better-when-it-comes-to-giving-consumers-bad-news-11649347200?page=8,"As companies increasingly use AI-powered chatbots to handle customer transactions, it remains to be seen how consumers feel about it. New research suggests that it may partly depend on whether consumers think they are getting a good deal. The research, published by the Journal of Marketing in February, found that if a company is offering a less-than-ideal price on a product or service, consumers tend to respond better in terms of increased purchase likelihood and satisfaction if an artificial-intelligence agent makes the offer. But if the price being offered is perceived as being good, consumers will respond better if the offer is presented by a human rather than a robot, because shoppers like getting favorable deals from real people. In one experiment, the researchers asked people to consider a deal for an aftermarket concert ticket, either from an AI agent or a human seller. The participants were informed that a similar ticket had been sold for either more, less, or the same price. Both AI and human sellers were then assigned to present the deals to participants. Another setup asked participants to consider the cost of an Uber ride to a restaurant for dinner. They were then offered a cheaper, more expensive, or similar-price ride home and were told it was coming from either a human or AI agent. In both scenarios, participants were more likely to accept a less-than-satisfactory offer if it came from a bot rather than a human. But with offers that exceeded consumers’ expectations, the human agent had the edge. For a similar-price deal, it didn’t matter whether an AI or human agent made the offer. Separately, the researchers explored whether changing the appearance of a bot affects how consumers respond to offers. They presented ride-share customers with photos of different-looking AI chatbots—ranging from those that looked like real people down to robots with no human features. They found that the more humanlike an AI agent appeared, the more study participants would react to offers as if they were coming from a real person. The study’s results stem from what the buyers think about the seller’s intentions, according to Aaron Garvey, an associate professor of marketing at the University of Kentucky’s Gatton College of Business and Economics and co-author of the study. People, he says, perceive that AI can’t be greedy and isn’t trying to take advantage of them, so they feel better about a worse-than-expected deal. A human making the same offer, however, is perceived as having bad intentions, making buyers want to avoid a purchase to punish them. By contrast, when a human presents a better-than-expected offer, buyers perceive this as another human being generous, improving the perception of the offer and the probability it will be taken, he says. In the paper, the researchers say their insights could apply to situations other than just price offers, such as when a company has something positive to communicate—say, an expedited delivery, rebate or upgrade—or something negative, such as an order cancellation, status change or product defect. Of course, there also is a danger that companies could use insights from the research to try to manipulate consumers into accepting worse-than-expected offers, the researchers say. “I’m not worried about AI,” Dr. Garvey says. “But I am worried about if we have blind spots” about it.",,,MISSING
