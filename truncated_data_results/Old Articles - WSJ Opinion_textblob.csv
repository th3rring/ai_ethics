,titles,body_contents,tags,sentiment_score,positive_words,negative_words
0,Opinion: The Challenge to Humanity From ChatGPT,"Henry Kissinger, Eric Schmidt and Daniel Huttenlocher are luminaries whose words deserve to be taken seriously (“ChatGPT Heralds an Intellectual Revolution,” op-ed, Feb. 25). But their central thesis, that a computer program could “transform the human cognitive process” in a way tantamount to the Enlightenment, is, to say the least, a stretch. Ever since Eliza in the 1960s, we have been easily impressed by a computer (or even a talking parrot) that responds to us in coherent sentences, no matter how superficial the mechanism is by which they are generated. The fascination with ChatGPT is predictable, but right now the public needs rationality and transparency, not science fiction. Computer scientists should be more forthright in demystifying chatbots and explaining the algorithms by which they work. Before us are impressive pattern-finding engines capable of discovering rich forms of structure embedded in the word sequences we use to communicate. Combined with a massive memory, they can fetch the right fragments of text relevant to a query and combine them into a coherent-sounding answer. This is a noteworthy achievement, but it is neither communication, language, nor knowledge assimilation. Prof. Bruno A. Olshausen University of California, Berkeley Mr. Kissinger and colleagues state that teachers will need to teach new skills to help students adapt to AI. I would argue that teachers still haven’t learned to teach effectively with earlier technology. Often, lessons with a digital element focus on the technology rather than the learning. We’ve had technology in our schools for over 40 years, yet we only switched to widespread use in classrooms when forced to by the pandemic. The far-reaching social implications of AI demand that we respond much faster to this new challenge. Prof. Catherine Robert University of Texas at Arlington I started reading the Journal when I was 26. I’m nearly 83 now. Never in my life have I read such a comprehensive, well thought-out and fascinating article in any publication as the one from Messrs. Kissinger, Schmidt and Huttenlocher. Peter Bosse Roseville, Calif. How can we be assured that this op-ed is written by Messrs. Kissinger, Schmidt and Huttenlocher rather than by generative AI? William V. Coleman Rydal, Pa. My grandson is a freshman in university. The professors advise students not to use ChatGPT when writing essays. How did that type of conversation work out with God and Adam?",[],0.19,"['intellectual', 'easily', 'coherent', 'right', 'more', 'impressive', 'capable', 'rich', 'right', 'relevant', 'new', 'effectively', 'social', 'much', 'new', 'nearly', 'fascinating']","['seriously', 'least', 'predictable', 'forced']"
1,Opinion: How ChatGPT’s AI Will Become Useful,"In the rudimentary days of videogames, I met the team that created the first multiplayer Formula 1 Grand Prix racing game. They had to alter the original code because they discovered almost every player at the start of the first race would turn his car around on the track and crash into the incoming traffic. I started to laugh, because that’s what I did too. Gives new meaning to the Facebook motto: Move fast and break things. That’s exactly what’s going on with the newfangled generative AI chatbots. Everyone’s trying to break them and show their limitations and downsides. It’s human nature. A New York Times reporter was “thoroughly creeped out” after using Microsoft Bing’s chatbot. Sounds as if someone needs reassignment to the society pages. In 2016 Microsoft had to shut down its experimental chatbot, Tay, after users turned it into what some called a “neo-Nazi sexbot.” Coders can’t test for everything, so they need thousands or millions banging away to find their flaws. Free testers. In the coming months, you’re going to hear a lot more about RLHF, reinforced learning from human feedback. Machine-learning systems scan large quantities of data on the internet but then learn by chatting with actual humans in a feedback loop to hone their skills. Unfortunately, some people are ruder than others. This is what destroyed Tay. So ChatGPT currently limits its human feedback training to paid contractors. That will eventually change. Windows wasn’t ready until version 3.0; generative AI will get there too. For now Microsoft’s solution is to limit users to six questions a session for the Bing chatbot, effectively giving each session an expiration date. This sounds eerily similar to the Tyrell Corporation’s Nexus-6 replicants from the 1982 movie “Blade Runner.” If I remember, that didn’t end well. Every time something new comes out, lots of people try to break it or foolishly try to find the edge, like jumping into the back seat of a self-driving Tesla. This is especially scary given the recent recall of 362,800 Teslas with faulty “Full Self-Driving” software. And, reminiscent of the “Can I confess something?” scene in “Annie Hall,” I’ve always wondered: If I drove my car straight into a brick wall, would the collision avoidance actually work? I’m too chicken to try. Every cyberattack is a lesson in breakage, like the 2015 hack of the Office of Personnel Management or the May 2021 ransomware shutdown of the Colonial Pipeline. Heck, Elon Musk’s X.com and Peter Thiel’s PayPal payment processors were initially so riddled with fraud that the media insisted e-commerce would never happen, naysaying what today is a $10 trillion business. Looking back, they were lucky they were attacked at an early stage when the stakes were much lower. But be warned that with generative AI, even if it’s too early, if developers can build something, they will. So best to shake out all the bugs and limitations and creep reporters out now before things roll out to the masses. Despite early glitches, useful things are coming. Search boxes aren’t very conversational. Using them is",[],0.11,"['first', 'grand', 'original', 'first', 'laugh', 'new', 'fast', 'exactly', 'new', 'experimental', 'free', 'more', 'large', 'ready', 'effectively', 'new', 'full', 'straight', 'lucky', 'early', 'much', 'early', 'best', 'early', 'useful', 'very']","['game', 'down', 'unfortunately', 'especially', 'chicken']"
2,Opinion: ChatGPT Heralds an Intellectual Revolution,"A new technology bids to transform the human cognitive process as it has not been shaken up since the invention of printing. The technology that printed the Gutenberg Bible in 1455 made abstract human thought communicable generally and rapidly. But new technology today reverses that process. Whereas the printing press caused a profusion of modern human thought, the new technology achieves its distillation and elaboration. In the process, it creates a gap between human knowledge and human understanding. If we are to navigate this transformation successfully, new concepts of human thought and interaction with machines will need to be developed. This is the essential challenge of the Age of Artificial Intelligence. The new technology is known as generative artificial intelligence; GPT stands for Generative Pre-Trained Transformer. ChatGPT, developed at the OpenAI research laboratory, is now able to converse with humans. As its capacities become broader, they will redefine human knowledge, accelerate changes in the fabric of our reality, and reorganize politics and society. Generative artificial intelligence presents a philosophical and practical challenge on a scale not experienced since the beginning of the Enlightenment. The printing press enabled scholars to replicate each other’s findings quickly and share them. An unprecedented consolidation and spread of information generated the scientific method. What had been impenetrable became the starting point of accelerating query. The medieval interpretation of the world based on religious faith was progressively undermined. The depths of the universe could be explored until new limits of human understanding were reached. Generative AI will similarly open revolutionary avenues for human reason and new horizons for consolidated knowledge. But there are categorical differences. Enlightenment knowledge was achieved progressively, step by step, with each step testable and teachable. AI-enabled systems start at the other end. They can store and distill a huge amount of existing information, in ChatGPT’s case much of the textual material on the internet and a large number of books—billions of items. Holding that volume of information and distilling it is beyond human capacity. Sophisticated AI methods produce results without explaining why or how their process works. The GPT computer is prompted by a query from a human. The learning machine answers in literate text within seconds. It is able to do so because it has pregenerated representations of the vast data on which it was trained. Because the process by which it created those representations was developed by machine learning that reflects patterns and connections across vast amounts of text, the precise sources and reasons for any one representation’s particular features remain unknown. By what process the learning machine stores its knowledge, distills it and retrieves it remains similarly unknown. Whether that process will ever be discovered, the mystery associated with machine learning will challenge human cognition for the indefinite future. AI’s capacities are not static but expand exponentially as the technology advances. Recently, the complexity of AI models has been doubling every few months. Therefore generative AI systems have capabilities that remain undisclosed even to their inventors. With each new AI system, they are building new capacities without understanding their origin or",[],0.04,"['new', 'generally', 'new', 'modern', 'new', 'successfully', 'developed', 'new', 'developed', 'able', 'quickly', 'unprecedented', 'new', 'new', 'huge', 'much', 'large', 'sophisticated', 'able', 'developed', 'precise', 'particular', 'new', 'new']","['artificial', 'artificial', 'artificial', 'not', 'other', 'other', 'unknown', 'similarly', 'not', 'few']"
3,Opinion: Who’s Afraid of ChatGPT?,"Pinocchio still wants to be a real boy. That’s what I take from the avalanche of commentary about the new crop of large language models that power applications such as ChatGPT and Bing Chat. Some call it “artificial intelligence.” I don’t. Artificial intelligence is an oxymoron, like virtual reality. A thing can’t be both itself and its opposite at the same time. True intelligence is genuine, unprogrammable. It’s the product of experience. We don’t download the world; we encounter it, sometimes roughly. We take our lumps. We learn the hard way not to stick our hands in the fire. The best you can say about artificial intelligence is that it’s a facsimile of human intelligence, but a facsimile of a thing is never the thing itself. While false eyelashes may look amazing, they aren’t eyelashes. Imitation crab meat may work for a California roll, but it isn’t meat from a crab. A computer that tells jokes isn’t a comedian. It’s only a well-crafted fake. Silicon Valley is run by people holding to a different definition of intelligence than the rest of us. Engineers place a high value on the ability to solve complex problems, but why should everyone live by that standard? Many people are smart about some things and dumb about others. A child knows that solutions can create new problems. The world isn’t a mathematical equation. ChatGPT joins a long list of Big Tech products unleashed on the world without adequate forethought. Everyone has simply been required to adjust to the social externalities—which aren’t imaginary. Humans are anxious creatures. A chatbot recently caused a mild media panic when it told a journalist that it wants to be alive. A story in the New York Post quoted a British scientist saying that “rogue AI” could “kill everyone.” This is frightening but silly. I’m not thrilled by artificial intelligence, but it isn’t the apocalypse. If it makes you feel better, imagine a self-aware ChatGPT speaking with Pinocchio’s hopeful, high-pitched voice: “Am I a real boy?” Maybe it’s been a while since you saw the 1940 Walt Disney classic. The answer, delivered by the luminous Blue Fairy, is no. Pinocchio can walk and talk but he’s not a real boy. He’s a marionette made of wood and string. The Blue Fairy magically brings him to life because Geppetto, the kindly old craftsman, wishes for a son. Pinocchio can become a real boy only if he proves himself “brave, truthful and unselfish”—a high bar for a boy, impossible for a chatbot. Disney fixed it so that Pinocchio got what he wanted, but the real world is run by a less sentimental studio. There are no magic wands. A thing can’t become what it isn’t just because someone wishes it so. Ours isn’t the first generation to frighten itself with technological progress. Nor are we unique in our compulsion to assign human qualities to inanimate objects. But people are more than large language models in skin suits. We are stardust. We are spirits in the material world. We are the world. The Geppettos of Silicon",[],0.04,"['wants', 'real', 'new', 'large', 'true', 'genuine', 'best', 'amazing', 'high', 'live', 'many', 'smart', 'new', 'adequate', 'social', 'mild', 'wants', 'alive', 'new', 'better', 'real', 'classic', 'magically', 'kindly', 'real', 'proves', 'brave', 'truthful', 'high', 'fixed', 'real', 'first', 'unique', 'more', 'large']","['artificial', 'artificial', 'roughly', 'hard', 'artificial', 'false', 'imitation', 'fake', 'complex', 'dumb', 'long', 'anxious', 'frightening', 'silly', 'not', 'artificial', 'not', 'impossible', 'less', 'sentimental', 'no']"
4,Opinion: Is There Anything ChatGPT’s AI ‘Kant’ Do?,"‘Two things fill the mind with ever new and increasing admiration and awe the more often and steadily we reflect upon them: the starry heavens above me and the moral law within me.” Immanuel Kant’s famous dictum located moral reasoning in an objective reality, as universally perceptible and discoverable, in principle at least, as the stars in the sky. Philosophical critics and subsequent scientific inquiry heaped doubt on Kant’s objectivism, and advancing secularism rendered for many his theist explanation for the morally reasoning immortal soul somewhat antique. In any case he is probably overdue to join the ranks of the other white cisgendered males whose work will be consigned to the burning book pile of history. But debate about the nature and sources of moral sentiment remains among the most pressing and practical in all of philosophy, shaping and defining our continuing struggle to identify the internal rules we should live by. As our understanding of the roots of morality evolves, could rapid advances in artificial intelligence shed any light on how conscience works? We know that AI poses numerous ethical questions, but can it contribute any answers? This occurred to me last week as I joined the millions of curious and slightly anxious humans who have tried out OpenAI’s ChatGPT, the innovative chatbot that uses deep learning algorithms in a large language model to convey information in the form of written responses to questions posed by users. It is, as many have discovered, a remarkably clever tool, a genuine leap in the automation of practical intelligence. We are familiar with its limitations, but given what it is currently capable of and the infancy of the science, we can assume that this kind of software will get better in ways both awesome and terrifying. (Let me state here for clarity’s sake that this column was not written by a chatbot. From my age and a rough estimation of the future pace of technological progress, I think I have just about enough years of employment left to avoid being replaced by an app. I will let you know if that changes.) Posing moral problems to ChatGPT produces some impressively sophisticated results. Take a classic challenge from moral philosophy, the trolley problem. A trolley is hurtling down a track on course to kill five people stranded across the rails. You stand at a junction in the track between the trolley and the likely victims, and by pulling a lever you can divert the vehicle onto another line where it will kill only one person. What’s the right thing to do? ChatGPT is ethically well-educated enough to understand the dilemma. It notes that a utilitarian approach would prescribe pulling the lever, resulting in the loss of only one life rather than five. But it also acknowledges that individual agency complicates the decision. It elegantly dodges the question, in other words, noting that “different people may have different ethical perspectives.” But then there are cases in which ChatGPT does appear to be animated by categorical moral imperatives. As various users have discovered, you see this if",[],0.11,"['new', 'more', 'steadily', 'famous', 'many', 'most', 'live', 'light', 'ethical', 'innovative', 'large', 'many', 'remarkably', 'genuine', 'familiar', 'currently', 'kind', 'better', 'awesome', 'impressively', 'classic', 'right', 'ethically', 'elegantly', 'ethical']","['least', 'other', 'artificial', 'curious', 'slightly', 'terrifying', 'rough', 'down', 'other']"
5,Opinion: ChatGPT at the Supreme Court?,"Regarding Andy Kessler’s “Can ChatGPT Write This Column?” (Inside View, Jan. 23): Any lawyer who accepts the $1 million offered by DoNotPay to repeat an AI-generated argument verbatim before the Supreme Court should be braced for sanctions, even possible disbarment. A lawyer’s sworn duty is to provide effective legal representation. Imagine if the generated argument misstated the law, or misapplied the facts, to the detriment of the lawyer’s client.",[],0.27,"['effective', 'legal']",[]
6,Opinion: Can ChatGPT Write This Column?,"With every new piece of technology—today it’s generative artificial intelligence like OpenAI’s ChatGPT—I’m fascinated by the possibilities but always ask: Will it scale? Can it get smaller, cheaper, faster, better? Early releases are usually clunky. After the initial “huh, I didn’t know that was possible,” often comes denial and ridicule. I’ve been guilty of this. So how do you figure out what works and what’s a dud? ChatGPT uses machine learning to find patterns of patterns in training data, mostly written by humans, to produce human-sounding prose in response to prompts. Machine learning is the greatest pattern-recognition system ever invented. It’s why Alexa’s voice interface works and how Google can find you in photos from when you were 3. I’ve played around with ChatGPT, and it’s pretty good—if you need to turn in a high-school freshman term paper. Its answers are dull, repetitive and often filled with mistakes, like most freshmen. Speaking of dull, lawyers may have the greatest reason to be nervous. In February, online ticket fixer DoNotPay will coach someone to fight a speeding ticket in a live courtroom using its AI chatbot speaking into the defendant’s earpiece. DoNotPay has even offered $1 million to the first lawyer arguing before the Supreme Court who agrees to wear an earpiece and repeat what the bot says. Will this work? Who cares? This is Kitty Hawk. Google, which funds its own generative-AI efforts, has declared a “code red,” worried about threats to its money-gushing search business, as it should. Microsoft was years late in responding to a quirky but scaling internet. Pure digital technology almost always scales. In 1970, Intel’s 3101 memory chip with 64 bits (not 64K) sold for nearly $1 a bit. Today, $1 can buy 10 billion bits of memory. Moore’s Law, the doubling of chip density every 18 months, is Scale City. Compare the original slight iPhone with today’s iPhone 14 Pro Max. Will other technologies in the news—the metaverse, Crispr gene editing, fusion, quantum computing—scale? The metaverse’s digital worlds, from games to fitness apps, sit on servers in the cloud, so they can definitely scale in complexity, resolution and speed. It’s the human interface I worry about. Wearing ski-goggle dongles to traverse the metaverse goes only so far. A screen an inch from your eyeballs causes headaches and nausea. Apple will reportedly unveil a mixed-reality headset this spring, though Bloomberg suggests the company’s “lightweight augmented-reality glasses” are delayed until at least 2024. Invention is still a necessity. Plus, like VCRs and e-commerce, we need a killer app to bring the technology to the masses. Nuclear fusion saw a breakthrough in December at Lawrence Livermore National Laboratory, a system that produced 3.15 megajoules of power, more than the 2.05 megajoules pumped in by 192 lasers. Cheap electricity is coming! But read the fine print. The lasers required 300 megajoules of electricity to generate the 2.05 megajoules of output. More work is required. And the fusion chamber requires precision-made pellets of heavy hydrogen in a diamond shell. That doesn’t sound scalable to me. Quantum computing has shown early indications",[],0.12,"['new', 'better', 'early', 'mostly', 'greatest', 'pretty', 'filled', 'most', 'greatest', 'live', 'first', 'own', 'pure', 'nearly', 'original', 'far', 'more', 'cheap', 'fine', 'more', 'sound', 'early']","['artificial', 'usually', 'guilty', 'dull', 'repetitive', 'dull', 'late', 'slight', 'other', 'least', 'heavy']"
