,titles,body_contents,tags,sentiment_score,positive_words,negative_words
0,OpenAI Rolls Out New GPT-4 Version of Chatbot ChatGPT,"The company behind the viral chatbot ChatGPT launched a new version of its artificial intelligence technology on Tuesday, saying it was more powerful and predictable than previous versions and capable of analyzing images and handling much larger blocks of text. The announcement from OpenAI—a startup backed by billions of dollars from Microsoft Corp.—is the latest in a string of generative AI announcements as companies try to get ahead in the race to build and use the buzzy new technology. Many regulators, scholars and activists have urged tech companies to exercise more caution in developing the tools which haven’t yet been fully tested. Generative AI technology—special because it can generate original images, text and other content from basic language prompts—sometimes produces responses that seem unhinged and contain made-up facts or racist and sexist statements. OpenAI says its updated chatbot is ‘more creative and collaborative’ than previous versions, when it comes to tasks such as composing songs or writing screenplays. In a blog post on Tuesday, OpenAI introduced a more powerful version of the technology behind ChatGPT called GPT-4. The updated chatbot is “more creative and collaborative” than previous versions when it comes to tasks like composing songs or writing screenplays, the blog said. The company is rolling out the technology starting Tuesday through data-sharing partnerships, which companies including Morgan Stanley and Duolingo Inc. are paying to access. It will also be offered to ChatGPT Plus subscribers, who pay $20 a month for faster and more available service. It isn’t yet available to those who use the free service. In an online presentation Tuesday, OpenAI demonstrated how the tool could be used to do things like explain obscure tax codes or summarize articles into sentences with every letter beginning with Q. OpenAI said it can now better analyze images for information. For example, users can use it to scan a picture of ingredients and then get suggestions of potential dishes and recipes that could be made from the ingredients. The ability to analyze images hasn’t yet been widely rolled out, a spokeswoman said. GPT-4 makes fewer mistakes than its predecessor, GPT 3.5, but it still works best when used in tandem with people who can check its work, said OpenAI president and co-founder Greg Brockman at the presentation. “It isn’t perfect but neither are you and together it’s this amplifying tool that lets you just reach new heights,” he said. When OpenAI used the latest version of the technology on standardized exams—including the LSAT and the Uniform Bar Exam—it did much better than most people and better than the previous version. It still struggled with English language and literature tests, according to company data. Tech company executives who have been able to test the chatbot ahead of Tuesday’s launch said the latest version by OpenAI looks like an impressive upgrade. “GPT3 or 3.5 felt like a sixth-grader, whereas 4 feels like a smart 10th-grader,” said Keith Peiris, co-founder of the AI startup Tome, which creates presentation tools and has been testing GPT-4. He says the new version can analyze 25 pages of text compared",[],0.25,"['new', 'more', 'powerful', 'capable', 'latest', 'new', 'many', 'more', 'original', 'more', 'creative', 'more', 'powerful', 'more', 'creative', 'more', 'available', 'available', 'free', 'better', 'best', 'perfect', 'new', 'latest', 'much', 'most', 'better', 'able', 'latest', 'impressive', 'smart', 'new']","['behind', 'artificial', 'predictable', 'previous', 'other', 'previous', 'behind', 'previous', 'widely', 'previous']"
1,Bosses Are Catching Job Applicants Using ChatGPT for a Boost,"It was an unexpected problem. Earlier this year, Christina Qi, the chief executive of market data company Databento, noticed almost every job application included exactly what she was looking for. The company prompts candidates to write a tweet and a press release about microwave towers, a niche topic that requires research, Ms. Qi said. Normally, most candidates fail the test. This time all five passed. The tests—four from internship applicants and one from someone seeking a full-time content strategist role—were all so similar, “as if it was written by one person,” she said. Suspicious, Ms. Qi put the prompt into ChatGPT, the artificial-intelligence chatbot from OpenAI, to see what it could produce. A weekly digest of tech reviews, headlines, columns and your questions answered by WSJ's Personal Tech gurus. “Lo and behold, I got pretty much the same answer that all five candidates had submitted to me,” she said. Since its launch in November, ChatGPT has been a hot topic at dinner tables and water coolers. Microsoft, Google, Snap and other companies have incorporated artificial intelligence into their products. People have experimented with using ChatGPT at work. Some have even started using it when looking for new roles, tapping the chat assistant to help write cover letters, tweak résumés and formulate responses to anticipated interview questions—without necessarily telling the people doing the hiring. Employers, who have long used AI to screen potential employees, aren’t always disqualifying applicants who use ChatGPT, but they are scrambling to figure out how to assess candidates who may be using the tool to give them an edge. Attention-grabbing applications After being let go by his previous employer in January, Kyle Mickey started job hunting for roles in software engineering—alongside thousands of laid-off tech workers. The 38-year-old from Colorado said he turned to ChatGPT for help, first sharing job descriptions and his résumé with the chatbot to see what it would tweak. Then he asked ChatGPT to write a recommendation letter for a role he coveted. The chatbot deemed him perfect for the job, as his technical skill set “aligns well with the requirements.” Mr. Mickey sent the remarks to a recruiter, saying ChatGPT endorsed his skills. “The recruiter was immediately like, ‘Let’s chat, I like the creativity,’ ” he said. Mr. Mickey didn’t get that job, but was hired at another company without ChatGPT’s help. Ryan Stringham, 31, who lives in Utah and works in product management, used it to help write cover letters, including one that got him a foot in the door, and later hired, at a smart-tech company. “You’re always looking, you’re always applying and you’re getting drained,” Mr. Stringham said of job hunting. He said the bot broke his writer’s block, distilling his long-winded cover letter into four tight paragraphs. He said it also helped him prepare for job interviews by suggesting new ways for him to ask about company culture and expectations for the role. Instead of asking a vague question about what he should do to excel at the prospective job, ChatGPT suggested Mr. Stringham be more specific about the time",[],0.04,"['unexpected', 'exactly', 'normally', 'pretty', 'much', 'hot', 'new', 'first', 'perfect', 'new', 'more']","['fail', 'other', 'artificial', 'long', 'previous', 'long-winded', 'tight', 'vague']"
2,What Is ChatGPT? What to Know About the AI Chatbot,"The release of OpenAI’s ChatGPT late November triggered a new global race in artificial intelligence. In March, the company’s AI model, GPT-4, which it used to update ChatGPT’s capabilities, upped the stakes even more. The chatbot is part of a wave of so-called generative AI—sophisticated systems that produce content from text to images—that has shaken up Big Tech and is set to transform industries and the future of work. Microsoft Corp., OpenAI’s strategic partner, has already added the technology across its products, including the MS 365 Suite and search engine Bing. Competitor Google unveiled a similar search tool on Feb. 8, while Chinese tech giant Baidu debuted its own on March 16. Despite its sudden burst in popularity, the technology currently has serious limitations and potential risks that include spewing misinformation and infringing on intellectual property. A weekly digest of tech reviews, headlines, columns and your questions answered by WSJ's Personal Tech gurus. Here’s what to know. What is ChatGPT? ChatGPT is an artificial-intelligence chatbot developed by San Francisco-based AI research company OpenAI. Released in November 2022, it can have conversations on topics from history to philosophy, generate lyrics in the style of Taylor Swift or Billy Joel, and suggest edits to computer programming code. In March 2023, OpenAI said it would upgrade it to also handle visual information, such as answering questions about the contents of a photo. ChatGPT is trained on a vast compilation of articles, images, websites and social-media posts scraped from the internet as well as real-time conversations—primarily in English—with human contractors hired by OpenAI. It learns to mimic the grammar and structure of writing and reflects frequently used phrases. It also learns to recognize shapes and patterns in images, such as the contours of a cat, a child or a shirt. It can match words and phrases to those shapes and patterns as well, allowing users to ask about the contents of an image, such as what a cat is doing or the color of the shirt. The chatbot isn’t always accurate. Its sources aren’t fact-checked, and it relies on human feedback to improve its accuracy. It may also misjudge the objects in a painting or photo. OpenAI developed ChatGPT as part of a strategy to build AI software that will help the company turn a profit. In January, Microsoft unveiled a fresh multibillion-dollar investment in OpenAI and has since integrated the chatbot’s underlying technology into its Bing search engine and other products. In March, OpenAI said it would no longer open-source the technical details of its systems, as it had originally stated in its founding principles, to maintain its competitive advantage. How do ChatGPT and other AI chatbots work? The technology that underlies ChatGPT is referenced in the second half of its name, GPT, which stands for Generative Pre-trained Transformer. Transformers are specialized algorithms for finding long-range patterns in sequences of data. A transformer learns to predict not just the next word in a sentence but also the next sentence in a paragraph and the next paragraph in an essay. This is what allows it to",[],0.03,"['new', 'more', 'own', 'intellectual', 'developed', 'frequently', 'accurate', 'developed', 'fresh', 'originally']","['late', 'artificial', 'serious', 'other', 'other', 'half']"
3,Baidu Hurries to Ready China’s First ChatGPT Equivalent,"A week away from the March 16 launch of Baidu Inc.’s BIDU 2.27%increase; green up pointing triangle ChatGPT equivalent, employees at China’s biggest search-engine operator said they are racing to meet the deadline with the chatbot still struggling to perform some basic functions. To develop the artificial-intelligence-powered chatbot, dubbed Ernie Bot, hundreds of people have been working around the clock, people familiar with the project said. Other teams have been asked to lend their staff and their powerful computer chips, which Chinese companies can no longer buy because of U.S. sanctions, they said. The AI model that is the basis of the chatbot is still being trained with data ahead of the scheduled launch, a highly anticipated event in China’s tech industry, some of the people said. Some employees said they haven’t had sufficient time to build a well-functioning product. Baidu plans to roll out the product in stages, first opening it up for public testing to a restricted pool of users, people briefed about the plan said. Last month, Baidu said that it will embed Ernie Bot into its search engine first and will open it to the public in March. Baidu CEO Robin Li has said to employees, ‘We have such cool technology, but can we turn it into a product that everyone needs?’ Baidu’s American depositary receipts fell 7.5% in Thursday trading. The broader Nasdaq Golden Dragon China Index dropped 5.4%. The rush reflects how Baidu is taking a calculated gamble to get ahead of Chinese rivals that have recently announced similar plans. The company said it has signed agreements with more than 400 Chinese companies, which will be able to use Ernie Bot in their products and services. In return, the chatbot will gain experience running under different scenarios to help improve its performance, Baidu has said. A successful launch could help catapult the company, which has fallen out of investor favor in recent years, back into the ranks of China’s most prominent technology companies. Failure could lead it to suffer a similar fate as Google, which stuck to its relatively cautious approach to AI until recently, then lost $100 billion in its market capitalization after its AI-powered chatbot search produced factual errors in a demo. Baidu declined to comment. Either outcome could also have implications for Baidu’s relationship with the Chinese government as well as the government’s views on generative AI technologies, which can produce content from text to images. Baidu received encouragement on its plans to build the chatbot from city officials in Beijing, where the company is based, people briefed about the matter said. Ernie Bot will likely be the first in China to rival ChatGPT, developed by San Francisco-based AI research company OpenAI. China and the U.S. have been racing to bolster their respective strengths in strategic technologies. The Beijing city officials have also reminded Baidu to make sure that its service will comply with Chinese laws and regulations, including for data collection and processing, as well as the state’s strict internet censorship rules, the people said. This week, Wang Zhigang, China’s minister of",[],0.12,"['familiar', 'powerful', 'highly', 'first', 'first', 'cool', 'golden', 'more', 'able', 'successful', 'most', 'prominent', 'first', 'developed', 'sure']","['green', 'other', 'failure']"
4,ChatGPT and Cyber Risk,"Key Points: ChatGPT is a new artificial intelligence-driven technology with capabilities that can potentially aid attackers. Cybercriminals are using the tool to develop phishing schemes, as well as writing and sharing malware code, according to researchers. Observers don’t believe the risks and threats associated with use of the tool are currently much more significant for organizations than ongoing ones, but said ChatGPT’s machine-learning capability may change this. Why ChatGPT is Popular Chat Generative Pre-trained Transformer is a chatbot developed by research laboratory Open AI and incorporated into Microsoft Corp.’s Bing search engine. The tool enables business users to automate time-consuming tasks such as writing emails, create quick and more natural interactions with customers and potentially increase productivity. The Possible Risks and Threats Cybersecurity researchers have focused on the risks and threats presented by ChatGPT for hackers trying to harness its capabilities for criminal activities, including: Allowing code to be written for use in malware by technically less-skilled hackers, which is then shared among hackers in other online forums. Providing additional complexity to protect code from detection, such as including polymorphic capabilities, which means a code’s appearance can mutate while not changing its function. In terms of phishing campaigns, ChatGPT can generate the text to reduce errors in messages written by non-native speakers and also create the phishing website code to collect the victims’ data. There is a risk of vulnerabilities being introduced into software by employees using code produced by ChatGPT without it first being thoroughly checked for security weaknesses. Soo Choi-Andrews, chief executive of cybersecurity platform Mondoo, said companies also need to consider how their third parties may be using ChatGPT. “The sheer volume of code being generated by not only your team but also the wider ecosystem that your business relies on poses the biggest immediate threat,” she said. Ms. Choi-Andrews added it is critical that businesses prioritize security checks within their automated testing processes to address these possible vulnerabilities. Reasons Not to be Concerned – Yet “The attacker has to know what exactly he wants and to be able to specify the functionality. Just writing ‘write a code for malware’ won’t produce anything really useful.” — Sergey Shykevich, researcher at cybersecurity firm Check Point Software Technologies Ltd. Many security experts believe that although there may be some benefits for hackers using ChatGPT, it is unlikely to be a game-changer for criminals as much of the information it produces is already available online, albeit in less user-friendly formats. The following takeaways should be considered: Existing controls mean ChatGPT won’t deliver ready-to-use malware code as it’s not possible to create malware just by asking it. The capabilities of ChatGPT for hackers will likely improve over time through machine learning, though controls may also evolve and increase. ChatGPT may be aiding the malware creation process, but it so far has not created fully-fledged attacks. Accordingly, there are currently no specific steps organizations can take, beyond practicing good cyber hygiene. “ChatGPT prevents phishing attacks by implementing content moderation, user validation, warning messages, reporting and blocking functions, and conducting regular security audits and updates.",[],0.08,"['new', 'currently', 'significant', 'popular', 'developed', 'quick', 'more', 'natural', 'first', 'exactly', 'able', 'really', 'many', 'much', 'available', 'far', 'good']","['artificial', 'criminal', 'other', 'firm', 'unlikely', 'less', 'mean']"
5,Apple Approves ChatGPT-Powered App After Assurance of Content Moderation,"Apple Approves ChatGPT-Powered App After Assurance of Content Moderation has approved an email-app update after initially scrutinizing whether a feature in the software that uses language tools powered by artificial intelligence could generate inappropriate content for children. The app, BlueMail, was approved following assurances from its developer that it features content moderation, according to Ben Volach, co-founder of the app-maker, Blix Inc. The Wall Street Journal reported on Thursday that the update, which included a new feature powered by language chatbot ChatGPT, was held up due to Apple’s request that the app add content moderation or be restricted to ages 17 and older. The app was previously available for ages 4 and older. Blix told Apple its update includes content moderation and suggested that the company should make public any new policies about the use of ChatGPT or other similar AI systems in apps. The BlueMail update was approved without changes on Thursday evening. The app is still available for users aged 4 and older. BlueMail’s new feature uses OpenAI’s ChatGPT, an artificial-intelligence system capable of answering questions or writing short essays, to help automate the writing of emails using the contents of prior emails and calendar events. The news of Apple’s initial rejection of BlueMail’s ChatGPT feature highlighted the growing concerns around new uses of language-generating AI tools. ChatGPT allows users to converse with an AI that appears humanlike, but early testing has shown the AI producing incorrect information as well as strange and sometimes hostile responses. Although Apple took action on the AI feature, there have been no additional formal App Store guidelines from Apple regarding the use of so-called generative AI in apps. Apple has long said that it has to curate and review each app that goes through its App Store in order to keep its products safe for users.",[],0.07,"['new', 'older', 'previously', 'older', 'new', 'available', 'older', 'new', 'capable', 'new', 'early', 'action', 'safe']","['artificial', 'due', 'other', 'aged', 'strange', 'long']"
6,Apple Blocks Update of ChatGPT-Powered App,"Apple Inc. has delayed the approval of an email-app update with AI-powered language tools over concerns that it could generate inappropriate content for children, according to communications Apple sent to the app maker. The software developer disagrees with Apple’s decision. The dispute shows the broad concerns about whether language-generating artificial-intelligence tools, such as ChatGPT, are ready for widespread use. Apple took steps last week to block an update of email app BlueMail because of concerns that a new AI feature in the app could show inappropriate content, according to Ben Volach, co-founder of BlueMail developer Blix Inc., and documents viewed by The Wall Street Journal. BlueMail’s new AI feature uses OpenAI’s latest ChatGPT chatbot to help automate the writing of emails using the contents of prior emails and calendar events. ChatGPT allows users to converse with an AI in seemingly humanlike ways and is capable of advanced long-form writing on a variety of topics. “Your app includes AI-generated content but does not appear to include content filtering at this time,” Apple’s app-review team said last week in a message to the developer reviewed by the Journal. The app-review team said that because the app could produce content not appropriate for all audiences, BlueMail should move up its age restriction to 17 and older, or include content filtering, the documents show. Mr. Volach says it has content-filtering capabilities. The app’s restriction is currently set for users 4 years old and older. Apple’s age restriction for 17 and older is for categories of apps that may include everything from offensive language to sexual content and references to drugs. Mr. Volach says that this request is unfair and that other apps with similar AI functions without age restrictions are already allowed for Apple users. “Apple is making it really hard for us to bring innovation to our users,” said Mr. Volach. An Apple spokesman said that developers can challenge a rejection through its App Review Board appeal process and that it is investigating Blix’s complaint. So-called generative AI has emerged as one of the most closely watched developing technologies in decades, primarily kicked off by ChatGPT, a chatbot created by OpenAI. The technology has quickly generated controversy. Following the release of Microsoft Corp.’s Bing search engine powered by ChatGPT, early testers grew concerned with responses generated by the chatbot, including incorrect information as well as seemingly unhinged and angry responses. Microsoft, which has invested billions in OpenAI, defended the Bing upgrade as a work in progress. Apple’s attempt to set an age restriction to help moderate content from a language-model-based AI is an indication the tech giant is closely watching the new technology and the risks it poses. The company has long said it must carefully curate and review what software can be accessed on the iPhone and iPad through its App Store to keep its products private and secure. Microsoft recently released an updated version of its Bing smartphone app with the ChatGPT functionality to Apple’s App Store and Google’s Android Play Store. Bing is listed in the iPhone App Store with the 17-and-older",[],0.07,"['broad', 'ready', 'new', 'new', 'latest', 'capable', 'advanced', 'older', 'old', 'older', 'older', 'sexual', 'most', 'primarily', 'quickly', 'early', 'new', 'secure']","['not', 'unfair', 'other', 'really', 'complaint', 'angry', 'long', 'carefully']"
7,"Instacart Joins ChatGPT Frenzy, Adding Chatbot To Grocery Shopping App","Instacart Inc. is adding OpenAI’s ChatGPT chatbot technology to its grocery-delivery app, joining a growing list of companies that are turning to the humanlike artificial-intelligence language tool in efforts to boost customer services, marketing and other automated tasks. Instacart will use the chatbot to power a new search engine designed to respond to users’ food-related questions, such as asking for recipe ideas and ingredients, or healthy meal options, the San Francisco startup said Wednesday. By tapping ChatGPT’s language software, the search engine’s responses will come in the form of a dialogue, rather than a list of search-engine results, Instacart said. It expects to roll out the new feature, called “Ask Instacart,” later this year, the company said. “When you think about grocery shopping, it takes a lot of thinking and planning,” said JJ Zhuang, Instacart’s chief architect, who oversees technology across the company. “It’s the perfect use case for smart AI, because it’s a lot of cognitive load,” he said, citing decision-making factors such as household budgets, health and nutrition implications, seasonal produce, cooking skills and meal preparation times. By integrating Instacart’s own AI software with ChatGPT, the new search tool will tap data from more than 1.5 million products stocked by some 75,000 grocery stores in Instacart’s partner network, he said. Mr. Zhuang described the software integration as “experimenting with what’s possible” using ChatGPT on Instacart’s app. Instacart last year processed $29 billion in overall sales across its platform, up about 16% from the previous year, the company told employees Tuesday. It reported positive net income over the fourth quarter, generating more than $100 million in adjusted earnings before interest, taxes, depreciation and amortization. OpenAI, a San Francisco-based software startup launched in 2015, has sought to expand its reach by easing the process of integrating ChatGPT software with outside apps. To do that, it allows companies like Instacart to build their own tools on top of ChatGPT’s software, said Greg Brockman, OpenAI’s president, chairman and co-founder. Mr. Brockman said he sees OpenAI as essentially a developer platform that also offers a “killer app.” On Wednesday, OpenAI released updates to its application programming interface—a type of software code, known as an API, that enables computer programs to communicate with each other—which includes specific protocols for integrating apps with the latest AI models for both ChatGPT and Whisper, OpenAI’s speech-recognition tool. Unlike its widely popular online app, which is free and available to anyone, OpenAI charges a fee for accessing the interface needed by developers to build new apps. “I think the whole developer community is going to benefit a lot from all the improvements that we’ve made, in model quality and model speed,” Mr. Brockman said. “We’re working with all companies, big and small, in order to get this technology integrated into whatever application they’re interested in,” he said. OpenAI benefits by feeding user data back into its AI models to continually train and improve the algorithm—though as of Wednesday companies can opt out of having their data used in this way. Since OpenAI launched ChatGPT in November, ready access to its",[],0.2,"['new', 'healthy', 'new', 'perfect', 'smart', 'own', 'new', 'more', 'positive', 'more', 'own', 'top', 'offers', 'latest', 'widely', 'free', 'available', 'new', 'whole', 'interested', 'ready']","['other', 'previous', 'small']"
8,"Facebook Parent, Snap Embrace AI Technology That Powers ChatGPT Chatbot","Facebook parent Meta Platforms Inc. and Snap Inc. are embracing the much talked-about artificial-intelligence technology popularized by OpenAI’s viral ChatGPT chatbot. Meta is establishing a group aimed at accelerating adoption of the so-called generative AI technology across the company, Chief Executive Mark Zuckerberg said Monday. Meta, which also owns Instagram and messaging app WhatsApp, is centralizing staff who are working on the AI technology from across the company to achieve faster breakthroughs it can apply to different products, Mr. Zuckerberg said. “In the short term, we’ll focus on building creative and expressive tools,” the CEO said on Instagram. “Over the longer term, we’ll focus on developing AI personas that can help people in a variety of ways.” Snap on Monday also signaled it was making a bet on OpenAI’s technology. The company known for its Snapchat app said it had begun rolling out its own AI experimental chatbot to users who subscribe to its $3.99 a month subscription service, Snapchat+. Tech companies more broadly have moved swiftly to embrace generative AI developments in recent months after the San Francisco-based AI research firm OpenAI launched a chatbot called ChatGPT in November that went viral. Tools such as ChatGPT and others allow users to ask written questions and receive responses in a conversational format as opposed to seeing a list of search results. Microsoft Corp., which has invested in OpenAI, announced earlier this month that it was adding the technology behind ChatGPT to its Bing search engine in an attempt to chip away at Google’s dominance in the search market. It has given a select group of users access to the new Bing to try the system. Alphabet Inc.’s Google also said earlier this month that it was rolling out its own conversational AI service called Bard to an early group of testers. Meta said its team initially was looking into ways to use the technology to enhance WhatsApp and Messenger, as well as with Instagram filters and video. Snap said it is making its chatbot, called My AI, available only to Snapchat+ subscribers as social-media companies are trying to drive users to their paid services amid upheaval in the digital ad market. Twitter Inc. and Meta both have also started subscription offerings. Snapchat+ has reached more than 2.5 million subscribers since its launch last summer, Snap said. The Verge earlier reported on Snap’s AI technology rollout. Snap has been one of the companies hardest hit by ad-market turmoil, driven both by companies pulling back on spending amid economic downturn concerns and changes Apple Inc. made that make it more difficult to track users and target ads. Its subscription service is an attempt to diversify its revenue, though the company has indicated it doesn’t fully expect to replace ad revenue with earnings from its subscription service. The social-media company late last month said revenue growth had stalled in the last three months of 2022 and that sales were likely to drop in the current quarter. Snap’s shares on Monday closed about 1% up, though have fallen about 75% over the past year. The AI",[],0.1,"['much', 'creative', 'expressive', 'own', 'experimental', 'more', 'broadly', 'new', 'own', 'early', 'available', 'more', 'economic', 'more']","['firm', 'behind', 'difficult', 'late', 'closed', 'past']"
9,"In the Whirl of ChatGPT, Startups See an Opening for Their AI Chips","As major chip players—Nvidia Corp., Intel Corp., Advanced Micro Devices Inc. among them—rush to capitalize on the popularity of generative artificial intelligence, startups are seeing their chance to grab a bigger piece of that pie as well. “There’s new openings for attack and opportunity for those players because the types of chips that are going to most efficiently run these algorithms are different from a lot of what’s already out there,” said Brian Schechter, a partner at venture-capital firm Primary Venture Partners. Historically, Nvidia has been the market leader in specialist AI hardware, analysts said. Generative AI and large language models like OpenAI’s ChatGPT require massive amounts of computing power to run, and typically rely on chips like Nvidia’s graphics-processing units, or GPUs, that are specialized for these types of calculations. Last week, Nvidia Chief Executive Jensen Huang said on a call with analysts that excitement around these new AI developments could supercharge the market for its chips. Dylan Patel, chief analyst at chip research firm SemiAnalysis, said the big companies are in a prime position to benefit from the onrush of demand. But smaller upstarts could also benefit from an overflow of demand, especially as supply-chain and manufacturing difficulties still limit the amount of chips that are making it to market, he said. Cerebras Systems Inc., a Sunnyvale, Calif.-based chip company founded in 2016, has been able to capitalize on some of that interest, said Chief Executive and Co-founder Andrew Feldman. As demand surges, he said, it is creating space for startups to break through. Cerebras is valued at $4.1 billion. With the nascent generative AI market propelling demand for compatible hardware and software to new heights, it’s a good time to be a startup, he said. “In stable markets that aren’t changing much—very hard to beat Goliath,” he said. “The number of people trying to apply AI is just ballooning and that is really a massive opportunity that we can play into,” said Nigel Toon, chief and co-founder of Bristol, U.K.-based Graphcore Ltd. Graphcore provides specialized hardware and software designed for AI that can do several things, among them lowering compute costs by eliminating unnecessary parameters, Mr. Toon said. Graphcore sells primarily to AI startups looking to build and train models at lower cost, he said, and the company is benefiting from the proliferation of those startups. Anshumali Shrivastava, the founder and chief executive of ThirdAI Corp., said that since the release of ChatGPT, his company has also seen an increase in demand. Houston-based ThirdAI provides technology that helps complex AI algorithms run efficiently on cheaper CPUs, or central processing units, rather than on specialized GPUs. Dr. Shrivastava said because of ThirdAI’s focus on CPUs, it can also feasibly help enterprises unlock complex AI models on premises and not in the cloud—alleviating privacy and data security concerns for industries that require on-premise solutions. Shane Rau, who leads International Data Corp.’s semiconductor research, said chip startups are increasingly pivoting to focus their products on supporting large language models. Still, he added, “you’re going to see a combination of real adaptation and",[],0.05,"['major', 'advanced', 'new', 'most', 'primary', 'large', 'new', 'able', 'new', 'good', 'primarily', 'supporting', 'large', 'real']","['artificial', 'firm', 'typically', 'firm', 'hard', 'unnecessary', 'complex', 'complex']"
10,"Nvidia, Other Chip Companies Race to Cash In on ChatGPT Frenzy","Chip makers are abuzz about the latest hot-thing in tech: artificial-intelligence tools that generate text with minimal prompting, require massive computing power to run and promise a lucrative new revenue stream. For semiconductor makers, the new tools, if widely adopted, could result in tens of billions of dollars in net annual sales, analysts estimate. Excitement over so-called generative AI has reached fever pitch since the release late last year of San Francisco-based OpenAI’s chatbot, called ChatGPT. The technology has captivated users by producing convincingly real if sometimes inaccurate responses, helping it attract billions of dollars from Microsoft Corp. and other investors. Jensen Huang, the chief executive officer of Nvidia Corp., America’s largest chip company by market value, said the technology has reached an inflection point. “Generative AI’s versatility and capability has triggered a sense of urgency at enterprises around the world to develop and deploy AI strategies,” he said as the company posted quarterly earnings Wednesday and unveiled a new cloud-computing initiative to capitalize on the business opportunity. Nvidia shares were up more than 12% in early Thursday trading. The interest in such AI tools is causing companies to reset their business expectations with pace, he said. “There’s no question that whatever our views are of this year as we enter the year has been fairly dramatically changed as a result of the last 60, 90 days.” The excitement comes as the chip industry is wrestling with a sharp downturn in the semiconductor industry with sales of personal computers, smartphones and other electronics flagging. Most chip makers have reported slowing sales as recession concerns have caused consumers and businesses to pull back on spending. Nvidia is the undisputed market leader in chips used for AI in the unglamorous world of data centers where tools such as ChatGPT make computations and spit out results. It had about an 80% share of such AI processors as of 2020, according to an Omdia estimate. With so much money up for grabs, though, other chip makers want in on the action. Intel Corp. CEO Pat Gelsinger said Wednesday that his company had a broad suite of chips to address the generative-AI opportunity, including specialist chips geared toward AI computation, graphics chips for data centers and a new generation of data-center central process units—the digital brains of computers—that he said performed well in AI work. “That performance we expect will become much more of the mainstream of computing as AI gets infused into every application going forward,” he said. Advanced Micro Devices Inc., which makes CPUs, graphics chips and other hardware tailored for AI, is also betting large cloud-computing companies that run many of the computations essential to the technology will be investing heavily in chips. That business should start to become more meaningful next year, AMD CEO Lisa Su said late last month. Generative AI could add $20 billion a year to the overall AI chip market by 2027, according to Vivek Arya, an analyst at Bank of America. Nvidia, he said, should be able to maintain at least a 65% market share in AI chips.",[],0.1,"['latest', 'new', 'new', 'convincingly', 'new', 'more', 'early', 'fairly', 'most', 'much', 'action', 'broad', 'new', 'much', 'advanced', 'large', 'many', 'more', 'meaningful', 'able']","['minimal', 'widely', 'late', 'other', 'sharp', 'other', 'other', 'other', 'heavily', 'late', 'least']"
11,ChatGPT Fever Sweeps China’s Tech Sector,"The viral popularity of ChatGPT has stirred a frenzy within China where tech companies, battered by a two-year regulatory clampdown and the Covid-19 pandemic, have been seeking new sources of growth. Search-engine owner Baidu Inc., e-commerce giant Alibaba Group Holding Ltd. and social-media conglomerate Tencent Holdings Ltd. are among those that have announced investments to develop their own equivalents to the artificial-intelligence chatbot, which isn’t available in China. Stocks of other Chinese companies have surged in recent weeks as they have jumped on the bandwagon, triggering state media to issue a warning about the speculative rally. Chinese companies that invested early in the generative AI technologies—which produce writing, images and art much like humans do—will now be best poised to build their own ChatGPT, AI and Chinese tech industry experts say. But many others are racing to catch up to U.S. counterparts in the latest technology developments and commercial applications. While China has several leading AI companies, many have focused on computer vision and applications such as surveillance. ChatGPT requires tooling and knowledge from a different AI subfield known as natural language processing. Chinese companies also face geopolitical and censorship-related barriers, including securing advanced chips targeted by U.S. export controls and navigating Beijing’s tight censorship rules. Nonetheless, companies that have the capabilities will be fast followers. For such companies, “there’s not a meaningful barrier that’s preventing China from catching up and re-creating or building an even better model,” said Matt Sheehan, fellow at the Carnegie Endowment for International Peace. OpenAI, the creator of ChatGPT, bans users in China from creating accounts on its chatbot, though many have found ways to circumvent the barrier through virtual private networks or by buying accounts using e-commerce platforms for a few U.S. dollars. ChatGPT can produce answers in Chinese, and its spectacular, surprising and sometimes wrong responses have become a hot topic on Chinese social media. Some consumers have clamored for homegrown alternatives. Reports emerged on Baidu’s plans in January. It is set to integrate into its search engine in March its own version of the AI chatbot, called Ernie Bot. Baidu said Wednesday that the company will use Ernie Bot to also improve Baidu’s AI cloud, its driverless car system and its voice assistant Xiaodu. The company will open its large language model to the public, offering it as a business service, Baidu’s Chief Executive Robin Li said in a call with analysts. Some organizations have already decided to integrate Ernie into their products and services, he said. That was followed by Tencent, the owner of China’s everything app WeChat; e-commerce player JD.com Inc.; and speech-recognition company iFlytek Co.—though none have released concrete plans. Game company NetEase Inc. said it is exploring how to incorporate the underlying technology behind ChatGPT into its education products. Wang Huiwen, the co-founder of food-delivery company Meituan, said he plans to invest $50 million into building China’s OpenAI, despite acknowledging that he doesn’t know much about the technology. The foundation of ChatGPT is built on what’s known as a large language model, which is trained on vast swaths of language",[],0.15,"['new', 'own', 'available', 'early', 'much', 'best', 'own', 'many', 'latest', 'many', 'natural', 'advanced', 'fast', 'catching', 'better', 'many', 'spectacular', 'surprising', 'hot', 'social', 'own', 'large', 'concrete', 'much', 'large']","['other', 'tight', 'not', 'few', 'wrong', 'game', 'behind']"
12,JPMorgan Restricts Employees From Using ChatGPT,"JPMorgan Chase & Co. is restricting employees from using ChatGPT, according to a person familiar with the matter. The bank didn’t restrict usage of the popular artificial-intelligence chatbot because of any particular incident, the person said. It couldn’t be determined how many employees were using the chatbot or for what functions they were using it. ChatGPT has grown increasingly popular since the startup OpenAI released it in November, crossing a million users a few days after its launch. People have used the chatbot to automate tasks at work and school, raising questions about how AI could replace some white-collar jobs. However, ChatGPT isn’t always reliable because it sometimes responds to prompts with misinformation or wrong answers. OpenAI didn’t return a request for comment Wednesday. In addition to JPMorgan, other organizations have also blocked access to ChatGPT. Last week, Verizon Communications Inc. barred the chatbot from its corporate systems, saying it could lose ownership of customer information or source code that its employees typed into ChatGPT. New York City public schools in January banned the chatbot from its internet networks and school devices. Workers at some companies have been using ChatGPT to write emails and research topics. Some of the employees say the chatbot helps them work faster while others are trying to avoid being left behind as technology evolves. Some tech companies have raced to launch similar products after OpenAI released ChatGPT. Earlier this month, Google rolled out a conversational AI service, Bard, to testers as the company tries to keep up with OpenAI. Microsoft Corp., which has invested billions of dollars in OpenAI, debuted an upgraded Bing search engine using ChatGPT’s technology. Users reported that the search engine, which also functions as a chatbot, responded to questions with sometimes disturbing answers. OpenAI said earlier this month that it was launching a paid version of ChatGPT which would be available to subscribers for $20 a month. The Telegraph earlier reported that JPMorgan was restricting employees from using ChatGPT.",[],0.05,"['familiar', 'popular', 'particular', 'many', 'popular', 'new', 'available']","['few', 'wrong', 'other', 'behind', 'tries', 'disturbing']"
13,Microsoft Brings ChatGPT-Powered Bing to Mobile Devices,"Microsoft Corp. is making its upgraded Bing search engine featuring the technology behind the viral chatbot ChatGPT available on Apple Inc. AAPL 0.55% iPhones and Google Android mobile devices, pressing ahead with the deployment of the system despite early glitches. In a blog post, Microsoft said it is releasing new versions of its Bing app and Edge browser app for smartphones and tablets Wednesday so users can access the upgraded search engine while on the go. The company also said it is adding voice to Bing because the ability to speak commands or ask questions out loud rather than type them has been one of the most requested features among early testers of the system. Microsoft also said it plans to integrate the technology into its two-decade-old video-calling app Skype so users can request information and share it with others in group conversations. Microsoft unveiled Bing with artificial intelligence this month, saying the enhanced software enables a new kind of search in which people can pose questions in natural language. Bing then generates direct answers and suggestions, as opposed to pointing users toward different websites. The company gave a small number of testers access to the tool for trials. Several received inaccurate and sometimes bizarre responses and shared them on social media. Last week, Microsoft responded by adding restrictions on how the search tool can be used after determining that long interactions were causing some of the unwanted behavior. The company, an investor in ChatGPT creator OpenAI, said it would limit interactions with the new Bing to five questions per session and 50 questions a day. That move sparked a new round of complaints. On Tuesday, Microsoft said it would bring back longer chats, starting by allowing six questions per session and 60 total a day, with plans to increase the daily cap to 100 soon. Despite early missteps with the technology, Microsoft’s Bing upgrade has created hype around the product and raised questions about whether it could become a formidable challenger to search-industry leader Google, a unit of Alphabet Inc. this month opened its rival AI-powered tool, called Bard, for testing.",[],0.06,"['available', 'early', 'new', 'loud', 'most', 'early', 'new', 'kind', 'natural', 'direct', 'bizarre', 'social', 'new', 'new', 'early']","['behind', 'artificial', 'small', 'long', 'round']"
14,Business Technology Chiefs Question ChatGPT’s Readiness for the Enterprise,"OpenAI’s ChatGPT has nabbed the attention of corporate boardrooms for its humanlike ability to generate business reports, marketing pitches and code for software applications, among other things. Yet some business-technology professionals are uneasy about integrating it into the enterprise stack, citing concerns over its use of online data and security risks. But above all, they’re worried about ChatGPT’s grip on reality. “It explained to me in very convincing detail why cow eggs are larger than chicken eggs, and why the moon is bigger than the sun,” said Christine Livingston, a managing director in the emerging technology group at Protiviti, a management consulting company. ChatGPT is a tremendous step forward for generative AI, she said, referring to algorithmic software designed to tap giant stores of data and create unique output based on user prompts. But at the moment, ChatGPT “should be used with caution in an enterprise business setting,” she said. Besides its problems with accuracy, ChatGPT requires a number of other improvements before it could be used on core enterprise applications, said Andy Harrison, managing partner and chief executive at tech venture investing fund Section 32. Other necessary upgrades include speedier results, advanced safety and security features, and better language abilities, Mr. Harrison said. As these and other performance improvements roll out—over the next year or two, he said—“we will see the emergence of enterprise applications like enterprise search, integration with communication platforms, sales tools and others.” “Generative AI is capable of amazing things, but as a whole, needs maturing,” said Ashok Srivastava, chief data officer at TurboTax owner Intuit Inc. Released in November by San Francisco-based OpenAI, ChatGPT is a generative AI-powered chatbot that’s been trained on a massive trove of articles, websites and social-media posts gathered from the internet, as well as transcribed interviews that capture the nuances of human speech. By detecting linguistic patterns and familiar phrases, the algorithm learned to predict what word is likely to follow from a sequence of words. From there, it was able to predict the next sentence and the next paragraph, eventually creating a coherent text. The approach can also be applied to writing computer code, enabling ChatGPT to anticipate large chunks of code that developers would need to input in order to execute a given task within a software program—a capability proponents say will supercharge in-house application development. “This is the biggest technical leap forward since cloud computing,” said Sameer Dholakia, partner at Bessemer Ventures Partners focused on cloud-based software. Any chief information officer who doesn’t have their app-development team thinking about how to apply ChatGPT and generative AI is “putting their company at a disadvantage,” Mr. Dholakia said. Microsoft Corp., which has invested billions of dollars in OpenAI, last month said it was integrating ChatGPT into its own enterprise software products, and more recently said it would add the technology to Bing, Microsoft’s search engine. The tool quickly captured the public’s imagination. But roughly a month after its release, Sam Altman, chief executive of OpenAI, warned against relying on ChatGPT “for anything important right now.” In a tweet, he said, “ChatGPT",[],0.14,"['very', 'tremendous', 'unique', 'advanced', 'better', 'capable', 'amazing', 'whole', 'linguistic', 'familiar', 'able', 'coherent', 'large', 'own', 'more', 'quickly', 'important', 'right']","['other', 'cow', 'chicken', 'other', 'other', 'other', 'roughly']"
15,Can ChatGPT Recommend Movies? A Film Buff Put It to the Test,"MORE OFTEN than I like, after scanning the endless carousels on streaming apps, I find myself re-watching “Seinfeld.” I attribute this to a combo of laziness and mediocre recommendation engines, which rarely highlight anything I actually want to watch. It’s a problem that seemed custom-designed for ChatGPT, the bot made by Microsoft-backed artificial intelligence research firm, OpenAI. Over 100 million people have tried ChatGPT since its launch in November, posing it tasks as disparate as writing English essays and negotiating down internet bills. By comparison, “What movie should I watch?” seemed simple. I told ChatGPT I enjoyed the 2013 film “Her,” whose protagonist develops a relationship with a virtual assistant. It spewed out a list of sci-fi titles like “Blade Runner 2049” and “Ex Machina.” “These movies,” it typed, “explore the relationship between humans and artificial intelligence, touching on themes such as consciousness, identity and the nature of existence.” (It gave no sign it saw the irony.) Wei Xu, an interactive computing professor at the Georgia Institute of Technology, explained how ChatGPT managed to produce a list of legitimately comparable movies in seconds. The software, she said, is trained to spot patterns within a massive amount of text data—over 500 GBs—it scrapes off the internet. When sniffing out cinematic cousins to “Her,” it’s likely consulting sources like Reddit threads, IMDB forums, even “Best of” lists from editorial outlets. Traditional recommendation engines, said Dr. Xu, don’t have this access. This presents issues for existing discovery platforms like Letterboxd, a social-networking site for discussing movies, and Likewise, a content-recommendation service that draws on AI and human curators. Letterboxd co-founder Matthew Buchanan told me he’s concerned by ChatGPT’s lack of transparency. To get the info it uses to make recommendations, it could be plagiarizing the work of Letterboxd users without providing credit. (OpenAI declined to comment for this article.) The threat of copyright infringement that generative AI systems present is indeed a pressing problem. Many artists have criticized the makers of photo-editing app Lensa, which has a feature that uses AI to generate portraits, for not compensating artists whose art was used to help train it. Lensa’s creators have said its portraits are “not replicas of any particular artist’s artwork.” Dr. Xu says platforms like Letterboxd might have a tough time proving that ChatGPT violates intellectual property laws. And generative-AI developers can address the issue, she said, by adding citations to their bots’ answers. For now, Mr. Buchanan says he’s taking solace in the fact that ChatGPT’s “anodyne” responses lack a human touch. I can’t help but agree. The humor and strangeness of Letterboxd reviews can leave me excited to watch particular movies. (In reference to the cinematographer of “Blade Runner 2049,” for instance, one Letterboxd reviewer wrote “I’m pregnant and the father is Roger Deakins’ camera.”) ChatGPTs responses are usually reasonable, but they rarely surprise. And because the bot is only trained on data that predates September 2021, it has some blind spots, though I haven’t yet encountered these. In any case, the last time I settled in to watch a film, I knew",[],0.06,"['more', 'rarely', 'enjoyed', 'touching', 'best', 'many', 'particular', 'intellectual', 'excited', 'particular', 'pregnant', 'usually', 'rarely']","['endless', 'mediocre', 'artificial', 'firm', 'down', 'artificial', 'tough', 'blind']"
16,"TripActions Rebrands as Navan, Adds ChatGPT to Expense Reports","With ChatGPT capabilities built in, the platform’s chatbot will be able to learn a users’ preferred airlines, hotels and restaurants, and incorporate these options into a proposed itinerary, while leveraging natural-language models to respond to voice commands, said Ariel Cohen, TripActions co-founder and chief executive. Behind the scenes, ChatGPT will also write, test and fix the underlying code that runs the app, constantly making tweaks based on data analytics aimed at boosting operational efficiency across its code base, Mr. Cohen said. The eight-year-old company’s approach grew out of workers’ frustrations with expense-report software tools, which often require users to manually enter figures from a stash of receipts, gathered from airlines, hotels, taxis and restaurants. “Employees frequently complain about the amount of time and effort they spend on expenses and about the time it takes to get reimbursed,” said Liz Herbert, vice president and principal analyst at information-technology research firm Forrester Research Inc. TripActions has sought to streamline the process through capabilities such as an artificial-intelligence-powered smartphone receipt-scanning tool, which automatically loads and categorizes items from printed receipts into an expense report, matching them to credit-card charges. It also works with digital receipts. That way, the expense report is generated during the trip as expenses are incurred, Mr. Cohen said. “Generally, software in the business-to-business space is designed to serve the company,” rather than the employees, Mr. Cohen said. “It’s about efficiency for the company, but not really about the workers.” By consolidating services, he said, Navan will enable employees to manage bookings and expenses on a single platform, which is designed to search for available travel options, track every transaction on a corporate card, and automatically generate an expense report. Mr. Cohen said the market opportunity lies in bridging the gap between the business travel apps employees have grown accustomed to, and the user-friendly consumer apps they use to book family vacations or simply a night out. “Using AI helps you create the kind of software that I’m talking about,” Mr. Cohen said. “This is how business software needs to be.” That strategy is catching the attention of some of the startup world’s biggest investors. In October, TripActions closed a $154 million equity funding round, including capital from returning investor Andreessen Horowitz, while raising an additional $150 million in a structured financing deal with Coatue Management LLC, a technology-focused investment manager. It currently has a private-market valuation of more than $9 billion. “It’s kind of like this weird anomaly where consumer travel changed a lot and business travel stayed the same,” said Ben Horowitz, co-founder and general partner of Andreessen Horowitz. Mr. Horowitz said Navan’s new all-in-one app offers a “better way of doing expenses” by filling in transactions in real-time while a user is traveling. But whether as TripActions or Navan, the company has a lot of ground to make up to catch market front-runner SAP Concur, industry analysts said. Based on revenue, SAP Concur, owned by enterprise-technology stalwart SAP SE, holds 49% of the global travel-and-expense management market, according to research firm International Data Corp. SAP Concur has also begun",[],0.05,"['able', 'frequently', 'generally', 'available', 'kind', 'catching', 'more', 'kind', 'general', 'new', 'offers', 'better']","['behind', 'base', 'firm', 'not', 'single', 'closed', 'round', 'weird', 'firm']"
17,Microsoft Adds ChatGPT AI Technology to Bing Search Engine,"Microsoft Corp. is integrating the technology behind the viral chatbot ChatGPT into its Bing search engine, hoping the artificial intelligence upgrade can help it chip away at Google’s dominance of the search market. The breakout success of the bot from the Microsoft-backed OpenAI has put the software giant at the forefront of what some see as the next wave of technological innovation: generative artificial intelligence. In an event Tuesday to launch the technology, Microsoft said the Bing upgrade will enable a new kind of search in which people will pose questions to the search engine in natural language and it will generate direct answers and suggestions. “I think this technology is going to reshape pretty much every software category,” Microsoft Chief Executive Satya Nadella said at the event at the company’s Redmond, Wash., headquarters. Mr. Nadella put the significance of AI-powered search on the same level of importance as the development of web browsers and mobile devices. Unlike ChatGPT, which wasn’t able to answer questions about current events, the updated Bing uses newer technology tailored for search engines. It will have access to the latest information such as news stories, train schedules and product pricing. It will also be able to provide links to demonstrate where its answers are coming from, another feature that wasn’t part of ChatGPT. Microsoft shares climbed 4% Tuesday as the Nasdaq Composite Index rose 2%. The company’s stock price has risen around 17% over the past three months while the Nasdaq index rose 15%. Microsoft, which is investing billions of dollars into OpenAI, is integrating the technology into many of its products, marking what it pitches as a new era of AI-powered software that has the potential to upend power in the tech industry. Some analysts say AI-powered searches could help Microsoft’s Bing search engine take market share away from Alphabet Inc.’s Google, which controls around 90% of the market. The industry has been buzzing about the possibilities of generative AI since OpenAI released its image generation tech Dall-E 2 to the public last year. Dall-E 2 can create original images based on simple prompts, such as, “Draw a robot dancing in a field of flowers.” OpenAI released ChatGPT in November. Millions of people have since used it to generate essays, sales pitches and poems. The popularity of the tools has put pressure on Google, which has long been at the forefront of AI technology, to match it. Earlier this week, Google announced it is rolling out its own conversational artificial-intelligence service to a set of testers and plans a broader public launch in the coming weeks. The new experimental service, called Bard, generates responses to questions posed by users, based on information drawn from the web, Sundar Pichai, chief executive of Google parent Alphabet, said in a blog post published Monday. Shares of Chinese internet giant Baidu Inc. surged in Hong Kong Tuesday as it confirmed plans to launch an artificial-intelligence chatbot. Baidu said it expects to launch its AI chatbot, called Ernie Bot, in March. Some artificial intelligence analysts warn there are still potential problems",[],0.1,"['success', 'new', 'kind', 'natural', 'direct', 'pretty', 'much', 'able', 'latest', 'able', 'rose', 'rose', 'many', 'new', 'original', 'own', 'new', 'experimental', 'confirmed']","['behind', 'artificial', 'artificial', 'past', 'long', 'artificial']"
18,ChatGPT Clones Are Preparing to Take Over China,"This column isn’t written by ChatGPT. At least not yet. But the conversational artificial-intelligence tool seems to be taking over the world—and that now includes the Chinese stock market. Investors should be careful not to get ahead of themselves, however. AI is a different political ballgame in China than e-commerce or online finance, but the country has just emerged from a multiyear crackdown on internet-platform companies—in part, because they became too powerful and ubiquitous. At the very least, such a potentially transformative new technology seems likely to quickly become a subject of significant regulatory concern. The launch of ChatGPT by Microsoft-backed OpenAI a few months ago has sparked a race among U.S. online-search and software giants. On Tuesday, Microsoft said it would incorporate the AI tool into its Bing search engine and Edge web browser. Search market leader Google says it will launch its own version of an AI chatbot called Bard. Across the Pacific, Chinese companies are jumping on the bandwagon too. China’s search giant Baidu said on Tuesday that it will unveil its own conversational AI tool called Ernie Bot after completing internal testing in March. Alibaba , China’s e-commerce leader, said on Wednesday it is also testing its own ChatGPT-style tool. Baidu’s shares jumped 15% in Hong Kong on Tuesday on the news. The stock has since given up some of those gains, but it has gained 36% this year so far, outperforming other Chinese stocks: the CSI 300 mainland benchmark is up only 7%. AI-related stocks listed in China, meanwhile, have surged to the stratosphere. Shares of Shenzhen-listed Hanwang Technology, which makes products for use in character recognition, have more than doubled in 2023. Shares of Shanghai-listed Beijing Haitian Ruisheng Science Technology, which develops training data sets for AI, have tripled. It is easy to see how chatbots could be integrated into tech giants’ businesses. Bots may, for example, improve the search interface for Baidu’s users. The ability of ChatGPT to draft convincingly human essays could enhance productivity tools. Tech giants with their enormous troves of data and AI research are well-placed to capitalize on the new technology. Regulation could be another issue, especially in China, given its strict data-security laws. While the government will probably initially be supportive because dominance in AI is such a high policy priority for Beijing, widespread use of the tool by the public will still be scrutinized. Its use may be restricted in settings like education. And if advanced chatbot technology starts bumping up against some of Beijing’s sore spots—for example, online financial fraud or politics—one can imagine a swift and sure regulatory response. But it is still too early to tell how much revenue such chatbots will really bring into corporate coffers. For one, competition will be intense: It’s already clear that many major internet-platform companies could end up as contenders. AI-powered chatbots could help improve existing services, but may not create new, stand-alone revenue streams. And integrating chatbots into existing platforms may incur significant costs. When asked to write a short sentence on investing in the latest fads, ChatGPT said",[],0.13,"['powerful', 'new', 'quickly', 'significant', 'own', 'own', 'own', 'far', 'more', 'easy', 'new', 'initially', 'high', 'advanced', 'sure', 'early', 'much', 'really', 'intense', 'clear', 'many', 'major', 'new', 'significant', 'latest']","['least', 'careful', 'very', 'subject', 'few', 'other']"
19,ChatGPT Needs Some Help With Math Assignments,"The artificial-intelligence chatbot ChatGPT has shaken educators since its November release. New York City public schools have banned it from their networks and school devices, and professors are revamping syllabi to prevent students from using it to complete their homework. The chatbot’s creator, OpenAI, even unveiled a tool to detect text generated by artificial intelligence to prevent abuse from cheaters, spammers and others. There is, perhaps surprisingly, one subject area that doesn’t seem threatened. It turns out ChatGPT is quite bad at math. “I’m not hearing math instructors express concern about it,” said Paul von Hippel, a professor at the University of Texas who studies data science and statistics and has written an essay about ChatGPT’s mathematical limitations. “I’m not sure it’s useful for math at all, which feels strange because mathematics was the first-use case for computing devices.” While the bot gets many basic arithmetic questions correct, it stumbles when those questions are written in natural language. For example, ask ChatGPT “if a banana weighs 0.5 lbs and I have 7 lbs of bananas and nine oranges, how many pieces of fruit do I have?” The bot’s quick reply: “You have 16 pieces of fruit, seven bananas and nine oranges.” It isn’t hard, and in fact is a little entertaining, to feed the bot questions to which it responds with confident nonsense. If you ask ChatGPT who is taller, Shaquille O’Neal or Yao Ming, the bot accurately says Yao is 7’6” and O’Neal is 7’1” but then concludes that Shaq is taller. The bot miscalculates the square roots of large numbers. Ask it to show its math, and it often produces detailed formulas that look great but contain errors, such as 2 x 300 = 500. I asked ChatGPT to write five simple algebra problems and then to provide the answers. The AI only answered three of its own problems correctly. ChatGPT’s struggle with math is inherent in this type of artificial intelligence, known as a large language model. It scans enormous reams of text from across the web and develops a model about what words are likely to follow others in a sentence. It’s a more sophisticated version of autocomplete that, after you type “I want to” on your device, guesses the next words are “dance with somebody,” “know what love is” or “be with you everywhere.” ChatGPT, OpenAI’s new artificially intelligent chatbot, can write essays on complex topics. WSJ’s Joanna Stern went back to high school AP Literature for a day to see whether she could pass the class using just AI. Photo illustration: Elena Scotti A Mad Libs-proficient supercomputer might be extremely effective for writing grammatically correct responses to essay prompts, but not for solving a math problem. That is the Achilles’ heel of ChatGPT: It responds in authoritative-sounding language with numbers that are grammatically correct and mathematically wrong. As Mr. von Hippel wrote, “It acts like an expert, and sometimes it can provide a convincing impersonation of one. But often it is a kind of b.s. artist, mixing truth, error and fabrication in a way that can",[],0.14,"['new', 'complete', 'surprisingly', 'useful', 'many', 'natural', 'many', 'quick', 'entertaining', 'confident', 'accurately', 'large', 'detailed', 'great', 'own', 'large', 'more', 'sophisticated', 'love', 'new', 'artificially', 'high', 'extremely', 'convincing', 'kind']","['artificial', 'subject', 'bad', 'not', 'strange', 'hard', 'little', 'artificial', 'complex', 'mad', 'mathematically']"
20,"China’s Baidu Developing Its Own ChatGPT, Joining Global AI Race","China’s Baidu Inc. has thrust itself into a global race to commercialize the next generation of artificial-intelligence technologies like ChatGPT that could transform the internet. The company is developing an AI-powered chatbot similar to OpenAI‘s popular ChatGPT and plans to integrate it into its main search engine in March, people familiar with the matter said. The move would place Beijing-based Baidu among a few tech companies globally to have its own version of the technology, which has generated buzz among consumers and businesses, and placed pressure on incumbents, which have started to update their product-development strategies. Baidu is set to be the first to bring the technology to consumers in China, where the state censors the internet and access to ChatGPT is blocked Baidu’s plans come as competition heats up between Washington and Beijing to bolster their respective countries’ leadership in strategic emerging technologies. They also highlight the fluid, cross-border nature of AI research, where open-source is the norm. OpenAI built ChatGPT atop a core breakthrough that Alphabet Inc.’s Google developed in 2017—an algorithm that Baidu also adapted and is now using as the foundation for its chatbot, according to some of the people. Baidu Chief Executive Robin Li touched on ChatGPT in a late-December speech to some employees, saying it represents new opportunities, according to a transcript on Baidu’s internal website that was seen by The Wall Street Journal. “We have such cool technology, but can we turn it into a product that everyone needs?” Mr. Li said, referring to AI-driven technologies including the chatbot. “This is actually the hardest step, but also the greatest and most influential.” Bloomberg earlier reported on Baidu’s plans. Baidu, whose growth hasn’t kept up with that of its Chinese internet peers, has been pushing to refashion itself into an AI company, investing billions of dollars in technologies including self-driving cars and chips designed to power AI applications. Using its vast repository of text data from its search-engine business, it has focused in particular on an area of AI research known as natural-language processing, which has experienced major leaps in advancement in the past few years and led to the recent surge of AI technologies, including ChatGPT. In 2019, Baidu developed a deep-learning model known as Ernie, based on Google’s breakthrough, which it has used to improve its search results, including to make them more relevant. The company has since developed dozens more Ernie models and extended their capabilities to include image and art generation, similar to those of OpenAI’s Dall-E. ChatGPT, OpenAI’s new artificially intelligent chatbot, can write essays on complex topics. WSJ’s Joanna Stern went back to high school AP Literature for a day to see if she could pass the class using just AI. Photo illustration: Elena Scotti Baidu is now using Ernie as the foundation for its chatbot, and is training it on both Chinese- and English-language sources inside and outside China’s firewall, some of the people said. In the past, Baidu has trained Ernie using sources that include Wikipedia, BookCorpus, Reddit and Baidu’s ecosystem of products—such as Baidu Baike and Baidu",[],0.15,"['popular', 'main', 'familiar', 'own', 'first', 'developed', 'new', 'cool', 'greatest', 'most', 'particular', 'experienced', 'major', 'developed', 'more', 'relevant', 'developed', 'more', 'new', 'artificially', 'high']","['few', 'past', 'few', 'complex', 'past']"
21,OpenAI to Offer ChatGPT Subscription Plan for $20 a Month,"OpenAI is launching a paid subscription version of its artificial-intelligence chatbot ChatGPT. The new subscription service is called ChatGPT Plus and will have a $20 monthly fee, the company announced Wednesday. The subscription includes access to the chatbot during peak usage times. The current free version limits service to users during periods when usage is high. Subscribers will also get early access to new features and improvements and faster response times from the chatbot. The new subscription program will first be available in the U.S. in the coming weeks and then expand to other countries, OpenAI said in a statement on its website. Interested users can sign up for a wait list to the subscription service, the company said. The new subscription program will initially be available in the U.S. and will later expand to other countries, OpenAI said. Interested users can sign up for a wait list to the subscription service, the company said. OpenAI will begin inviting people over from the wait list in the coming weeks. OpenAI will continue to offer free access to ChatGPT. The subscription service will help support free access for the chatbot, the company said. OpenAI is also exploring options for lower-cost plans and business plans. Microsoft is deepening its partnership with OpenAI, the company behind ChatGPT and Dall-E. That has investors and analysts speculating whether Microsoft could challenge Google’s dominance in search. WSJ Heard on the Street columnist Dan Gallagher joins host Zoe Thomas to discuss how AI could affect search and at what cost. ChatGPT allows users to type questions to the bot and receive written responses powered by artificial intelligence. It can even write poems and essays. Some industry observers have said ChatGPT could offer a potential alternative to current search engines in the future, though the company has said that the program’s outputs often contained factual errors. Last month, Microsoft Corp. said it would make a multiyear, multibillion-dollar investment in OpenAI after previously investing in 2019 and 2021. The companies didn’t disclose financial terms of the partnership. Microsoft has said it would incorporate artificial-intelligence tools like ChatGPT into all of its products and make them available as platforms for other businesses to build on. Microsoft Chief Executive Satya Nadella said the company would commercialize tools from OpenAI like ChatGPT and give more customers access to software behind chatbot through its cloud-computing platform Azure. OpenAI has also discussed selling existing shares in a tender offer that would value the company at around $29 billion, The Wall Street Journal previously reported.",[],0.08,"['new', 'free', 'high', 'early', 'new', 'new', 'first', 'available', 'interested', 'new', 'initially', 'interested', 'free', 'free', 'available', 'more']","['other', 'other', 'behind', 'artificial', 'previously', 'other', 'behind', 'previously']"
22,Google Opens Testing of Its ChatGPT Rival,"Google is rolling out a new conversational artificial-intelligence service to a select set of testers, and plans a broader public launch in coming weeks, part of the company’s effort to play catch-up with challengers such as OpenAI, creator of the popular chatbot ChatGPT. The new experimental service, called Bard, generates textual responses to questions posed by users, based on information drawn from the web, Sundar Pichai, chief executive of Google parent Alphabet Inc., said in a blog post published Monday. In that post, Mr. Pichai also shared a glimpse of new search engine features that will use AI to answer user queries, and said it would open up some of its AI programs to outside developers. Google’s new products come amid a flurry of announcements by rival Microsoft Corp. about its use of AI technologies developed by OpenAI. Microsoft said last month it is making a multiyear, multibillion-dollar investment in the San Francisco AI startup. It said it would be opening up its tools for developers to build upon, and integrating them into services such as its Bing search engine—raising the specter of a new challenge to Google Search’s market power. Microsoft says it is planning an event on Tuesday to announce “progress on a few exciting projects,” which are widely expected to include a chatbot-infused version of Bing. Sam Altman, chief executive of OpenAI, on Monday tweeted a picture of himself next to Microsoft Chief Executive Satya Nadella, saying “excited for the event tomorrow.” Microsoft’s announcements have led to complaints from investors that Google hasn’t moved quickly enough to release its in-house AI tools, despite being the pioneer of some of the technologies used to build tools such as ChatGPT. Those complaints have been echoed by some of its own researchers, The Wall Street Journal has reported. In response, Google executives have recently sped up work to review and release artificial-intelligence programs to the general public, while also assigning teams of engineers to work on new ways to integrate new developments into areas such as the core search experience, the Journal reported. Google executives have also suggested they haven’t been slow so much as careful with their tools, drawing an implicit contrast to competitors tools, such as ChatGPT, that can spout made-up information in response to some user queries. Google executives say they must test new tools to make sure they don’t show bias, and guard against misuse, concerns shared by many academics. “It’s critical that we bring experiences rooted in these models to the world in a bold and responsible way,” Mr. Pichai in his blog post on Monday. “That’s why we’re committed to developing AI responsibly.” He added that the new external testing period for Bard will be combined with internal research to make sure that it gives responses that meet Google’s “high bar for quality, safety and groundedness in real-world information.” Mr. Pichai said in a separate internal email seen by The Wall Street Journal that Google’s entire staff will get access to Bard next week in order to give feedback as part of a “company-wide dogfood,” or",[],0.11,"['new', 'popular', 'new', 'experimental', 'new', 'new', 'developed', 'new', 'exciting', 'excited', 'own', 'general', 'new', 'new', 'new', 'sure', 'many', 'bold', 'responsible', 'responsibly', 'new', 'sure', 'high']","['few', 'widely', 'slow', 'much']"
23,Opinion: Only Bad Writers Should Fear ChatGPT,"People seem to think that OpenAI’s ChatGPT, a chatbot powered by artificial intelligence, is going to put many writers out of business or make writing bland—or both. But perhaps that’s not a bad thing. With the rise of the internet, we’re inundated with more writing than ever and most of it is mediocre. On social media platforms like Twitter, everyone gets a license to be a short-form editorial writer, uninhibited by an editor or boss riding them for accuracy and relevance. Are public debates over ideas and policies any more informed or enlightened for having these truncated opinion pieces? You know the answer. Journalism has the opposite problem. Journalistic writing once had to fit into a set number of column inches. Now, the digital-news hole is infinite, so most news stories go on and on without a sense of restraint—but with dwindling quality. No wonder ChatGPT’s most immediate application is on digital news, tech and social-gossip sites desperate to keep readers engaged with whatever content sticks to the wall. And look at corporate writing: It’s either cliché-ridden, meaningless fluff or rife with jargon. Either way, most of it is utterly forgettable. Academics aren’t much better. Their writing—especially in the humanities and social sciences—is so arcane and technical that most of it is never read, even by other academics. Maybe robots should get a shot at taking over some of this workday prose. Who wouldn’t mind a robot-generated statement that clearly articulates a company’s strategy without referring to the time-worn clichés of “paradigm shift” or “optimized performance”? What’s so bad about an academic paper written in language that any keen learner could understand? Would you turn your nose up at concise, fact-rich reporting on recent news? I think people fear robot-writers because they do their job well, maybe even better than humans do. Some will contend that ChatGPT’s skills are limited and lacking in style, but so what? Sure, it can’t write a masterful piece of prose or a profound novel. But most of what we read isn’t that good anyway, even the stuff written by people. As long as artificial intelligence produces instruction manuals that are clear and corporate policies that provide direction, that’s good enough for me. A robot might even manage to summarize important historical events without taking potshots at contemporary political figures. (That is, of course, if ChatGPT manages to fix its left-leaning tilt.) Those would all be welcome improvements. What about the writers who remain? They’ll be able to elevate their craft to higher purposes—or at the very least create something truly original. Consider how portrait artists responded to the invention of photography. The best ones excelled in impressionism, cubism and other movements of modern art. Art didn’t disappear, it simply shifted its gaze. Whether you want them or not, the robot-writers are coming. Soon we will be able to generate solid writing as easily as we use internet search engines. We’ll get practical results that work for practical purposes. But when something new or weighty needs to be shared, we will turn to human writers who have",[],0.16,"['many', 'not', 'more', 'most', 'social', 'more', 'fit', 'most', 'most', 'most', 'much', 'social', 'most', 'clearly', 'concise', 'better', 'sure', 'masterful', 'profound', 'most', 'good', 'clear', 'good', 'important', 'contemporary', 'welcome', 'able', 'higher', 'original', 'best', 'modern', 'able', 'easily', 'new']","['artificial', 'mediocre', 'desperate', 'meaningless', 'fluff', 'utterly', 'other', 'bad', 'limited', 'long', 'artificial', 'very', 'other']"
24,"ChatGPT Creator Releases Tool to Detect AI-Generated Text, Calls It ‘Unreliable’","The startup behind the viral chatbot ChatGPT unveiled a tool for detecting text generated by artificial intelligence amid growing concerns the technology will be abused by cheaters, spammers and others. But OpenAI said its so-called AI classifier itself fails to detect bot-written text nearly three quarters of the time. The San Francisco-based startup, which launched ChatGPT in November and recently announced a multiyear, multibillion-dollar partnership with Microsoft Corp., released the detection tool on Tuesday. It said in a blog post that the tool was designed to help people distinguish between text written by a human versus a range of artificial intelligence programs—not just ChatGPT. OpenAI said that in evaluations its new tool correctly identified 26% of AI-written text as “likely AI-written.” It said the classifier also had false positives 9% of the time in which it incorrectly labeled human-written text as AI-written. “Our classifier is not reliable,” the company said, referring to it as a “work-in-progress.” The tool isn’t good enough on its own, though it can be used to complement methods that educators, employers and others rely on to determine the source of a piece of text, OpenAI said. “While it is impossible to reliably detect all AI-written text, we believe good classifiers can inform mitigations for false claims that AI-generated text was written by a human,” the company said. ChatGPT became a viral sensation due to its ability to produce human-sounding essays, poetry, screenplays and sales pitches on virtually any subject in seconds. Microsoft invested in OpenAI in 2019 and 2021 before announcing the major expansion of their partnership last week, and has said it plans to integrate the company’s technology into many of its products. Soon after ChatGPT was released, the potential for it to be misused to do things such as spread misinformation and write spam became apparent. Schools and educators also have warned of the potential for students to use it to write essays or other work they have been assigned. In December, the software passed all three parts of the U.S. Medical Licensing Examination as part of a research experiment. Some schools have moved to ban students from using ChatGPT, while others are attempting to embrace it. Edward Tian, a Princeton University senior, created software called GPTZero to try to recognize writing generated by the software. OpenAI said it had schools in mind when developing its latest classifier tool. “We recognize that identifying AI-written text has been an important point of discussion among educators, and equally important is recognizing the limits and impacts of AI-generated text classifiers in the classroom,” it said. Journalists, researchers and others can also use the tool to detect AI-generated content, the company said. OpenAI said ChatGPT is still unreliable on short texts and longer texts are sometimes labeled incorrectly. It performs “significantly worse” in languages other than English and is “unreliable” in detecting AI use in computer code. Another problem is that the tool can’t easily tell if a list of facts—U.S. state capitals for example—was written by a person or AI, because the correct answer would be the same, OpenAIsaid.",[],0.0,"['nearly', 'new', 'good', 'own', 'good', 'major', 'many', 'apparent', 'latest', 'important', 'equally', 'easily']","['behind', 'artificial', 'fails', 'artificial', 'false', 'impossible', 'false', 'due', 'subject', 'other', 'significantly', 'other']"
25,ChatGPT Spotlights Microsoft’s Bid to Monetize AI,"As the breakout success of OpenAI’s ChatGPT triggers a tsunami of excitement over artificial intelligence, Microsoft Corp. is positioning itself at the forefront of what some see as the next wave of technological innovation. The challenge for Microsoft and other companies: turning this novel and still imperfect technology into a big business. The software company said last week that it was pouring billions of dollars more into OpenAI. The startup is in the limelight as tech executives and the public have been mesmerized by its chatbot, which can answer difficult questions, write book reports and compose poetry in seconds. Microsoft earlier this month moved to jump-start the adoption of the technology by offering to let any company apply to use it through its Azure cloud-computing platform. “The age of AI is upon us, and Microsoft is powering it,” Chief Executive Satya Nadella said on a call with analysts last week. Most interactions with generative AI—so called because it can work off regular language prompts to generate unique creations—have been for fun. Millions have flocked to ChatGPT since it was released in November. OpenAI’s other viral hit, the image-generating Dall-E 2, has flooded the web with user-created pictures. As a disruptive business, ChatGPT is still finding its feet. There are many problems with it, according to AI researchers. ChatGPT is expensive to run and slow, and it sometimes produces responses that contain made-up facts, they have said. Gary Marcus, a founder of the machine-learning startup Geometric Intelligence, said that even as OpenAI releases updated versions of GPT, the problems with inaccurate information will continue. “This particular tech will not solve those problems, so what can you do with these systems that aren’t truthful?” Mr. Marcus asked. OpenAI didn’t respond to a request for comment. Its chief executive officer, Sam Altman, has said that ChatGPT is an imperfect technology and that it would improve. He said in a tweet last month: “it’s a mistake to be relying on it for anything important right now. it’s a preview of progress; we have lots of work to do on robustness and truthfulness.” Microsoft declined to comment on concerns about the technology. Mr. Nadella has said that ChatGPT’s problems are solvable. “This is not new to just AI,” he said at a Wall Street Journal panel at the 2023 World Economic Forum event in Davos, Switzerland, this month. “It’s true in any other category of software today.” Last year Microsoft released GitHub Copilot, a tool within its code-collaboration site GitHub. It uses OpenAI tools to help programmers write and fix computer code. Microsoft estimates that in files in which it is enabled, Copilot generates 40% of the code. Many programmers have said it has become an invaluable tool. It is a prime example of how this type of AI is best when paired with professionals for specialized tasks, according to some AI users. They have said that the recent advances the technology has made in a short time show how remaining problems can quickly be fixed. “The rate of change going on—I have not seen anything progress",[],0.11,"['success', 'more', 'most', 'unique', 'fun', 'many', 'particular', 'truthful', 'important', 'right', 'economic', 'true', 'many', 'best', 'quickly']","['artificial', 'other', 'difficult', 'other', 'expensive', 'slow', 'not', 'other']"
26,BuzzFeed to Use ChatGPT Creator OpenAI to Help Create Some Content,"BuzzFeed Inc. said it would rely on ChatGPT creator OpenAI to enhance its quizzes and personalize some content for its audiences, becoming the latest digital publisher to embrace artificial intelligence. In a memo to staff sent Thursday morning, which was reviewed by The Wall Street Journal, Chief Executive Jonah Peretti said he intends for AI to play a larger role in the company’s editorial and business operations this year. In one instance, the company said new AI-powered quizzes would produce individual results. For example, a quiz to create a personal romantic comedy movie pitch might ask questions like, “Pick a trope for your rom-com,” and “Tell us an endearing flaw you have.” The quiz would produce a unique, shareable write-up based on the individual’s responses, BuzzFeed said. Mr. Peretti expects AI to assist the creative process and enhance the company’s content, while humans play the role of providing ideas, “cultural currency,” and “inspired prompts,” he wrote in his memo. In 15 years, he wrote, he expects AI and data to help “create, personalize, and animate the content itself,” rather than just curate existing content. BuzzFeed, which went public in late 2021 through a merger with a special-purpose acquisition company, last year moved to shrink its news division as it sought to make the business profitable, and said it would be doubling its creator network. The company is getting paid millions of dollars by Facebook parent Meta Platforms Inc. to help generate creator content for Facebook and Instagram, The Wall Street Journal reported Wednesday. BuzzFeed shares more than doubled in value Thursday, closing at $2.09. The stock remains down by over 75% since the company went public. BuzzFeed remains focused on human-generated journalism in its newsroom, a spokeswoman said Thursday. After receiving Mr. Peretti’s memo, a number of employees on Thursday expressed concerns and asked him questions on Slack about the implications of the move. One staff member asked how Mr. Peretti planned to circumvent “inevitable legal issues” around visual work created by illustrators, photographers and art directors at the company, as well as content that is protected by U.S. copyright, according to screenshots of the Slack channel that were reviewed by the Journal. “We’ve done experimentation in the past with AI-generative images, and we recognize these concerns and take them seriously,” Mr. Peretti wrote in response, according to the BuzzFeed spokeswoman. He also said the initial step in BuzzFeed’s plan was to use AI for text-based products. ChatGPT, OpenAI’s new artificially intelligent chatbot, can write essays on complex topics. WSJ’s Joanna Stern went back to high school AP Literature for a day to see if she could pass the class using just AI. Photo illustration: Elena Scotti Other employees asked about whether the use of AI technology would lead to a reduction in workforce, and expressed concerns around fact-checking AI-generated content. In response, Mr. Peretti wrote that the tools are an opportunity to make full-time employees more efficient and creative, not a workforce reduction strategy, the spokeswoman said. Mr. Peretti also answered staff questions during a companywide meeting earlier Thursday, the spokeswoman",[],0.09,"['becoming', 'latest', 'new', 'endearing', 'unique', 'creative', 'cultural', 'more', 'legal', 'new', 'artificially', 'high', 'more', 'creative']","['artificial', 'late', 'down', 'past', 'seriously', 'complex', 'other']"
27,Professors Turn to ChatGPT to Teach Students a Lesson,"Last month a professor at Weber State University in Utah asked a new artificial-intelligence chatbot to write a tweet in his voice. Within a few minutes the application, called ChatGPT, had spit out a dozen messages that captured Alex Lawrence’s tone and personality. His first reaction: “Holy Cow!” His second: “This is the greatest cheating tool ever invented.” His response reflects a dilemma that the powerful AI tool creates for educators: Should they ban ChatGPT or build on it? Whichever path they take, some teachers say they are scrambling to update curriculum, launch new learning guidelines and deploy tactics that stymie cheating and make sure students learn to think for themselves. Dr. Lawrence decided to change the curriculum in his sales-technology courses to allow students to use a suite of artificial-intelligence tools to complete their assignments. He is hoping that embracing the technology will stave off what he thinks is inevitable cheating and impart the tech skills students will need to succeed in the labor market. “I hope to inspire and educate you enough that you will want to learn how to leverage these tools, not just to learn to cheat better,” Prof. Lawrence wrote to his students this month. ChatGPT, which uses machine-learning algorithms to produce human-sounding prose, launched on Nov. 30. It is free to use and can deliver a written answer on virtually any subject from nearly any perspective in just 15 seconds. In December it passed all three parts of the U.S. Medical Licensing Examination as part of a research experiment. OpenAI, the research lab behind ChatGPT, is in talks to sell existing shares in a tender offer that would value the company at around $29 billion, making it one of the most valuable U.S. startups on paper, despite generating little revenue. On Monday Microsoft Corp. said it is making a multiyear, multibillion-dollar investment in OpenAI, as it looks to expand the use of artificial intelligence in its products. “It really seems to change the nature of knowledge production itself,” said Anand Rao, chair of the department of communications and digital studies at the University of Mary Washington in Virginia. Educational institutions that are banning ChatGPT include some large public-school districts. New York, Seattle and Los Angeles have all blocked the service from their networks. Some college and university professors, meanwhile, have tried to wall off their classrooms by requiring students to write essays longhand in blue books in class. Others are running essay prompts through ChatGPT to familiarize themselves with how the bot answers so they can spot plagiarism. Edward Tian, a Princeton University senior, created GPTZero to recognize writing generated by ChatGPT. He now has 23,000 teachers on a waiting list for the next version. Some students are also concerned. This month a survey of 1,000 students age 18 or older by online course provider Study.com found that nearly three quarters want ChatGPT banned from their school’s network. But 48% admitted using it to complete an at-home test or quiz, 53% to write an essay and 22% to write an outline for a paper. Students need",[],0.11,"['new', 'first', 'greatest', 'powerful', 'new', 'sure', 'complete', 'better', 'free', 'nearly', 'most', 'really', 'educational', 'large', 'new', 'older', 'nearly', 'complete']","['few', 'cow', 'subject', 'behind', 'little', 'artificial']"
28,Companies Tap Tech Behind ChatGPT to Make Customer-Service Chatbots Smarter,"Businesses hope the artificial-intelligence technology behind ChatGPT can turn ordinary chatbots into impressive fonts of information, potentially transforming customer service. But many executives said they are proceeding with caution, given the limitations of ChatGPT—fine-tuned from GPT-3.5, a model created by startup OpenAI—as well as OpenAI’s older AI language system, GPT-3, which companies are already starting to integrate into digital products. ChatGPT, launched by OpenAI in November, quickly went viral for its often elegant, information-packed responses to various questions, gripping the imaginations of regular people, business leaders and investors including Microsoft Corp., which began backing OpenAI in 2019 and said Monday that it would make a multibillion-dollar investment in the startup. OpenAI last week said it would soon add ChatGPT, which stands for chat generative pre-trained transformer, to its application programming interface, or API, which lets developers embed OpenAI technology into their own products. But customer-experience executives said overreliance on such AI models could lead to companies dishing out incorrect information to customers online without knowing they are doing so. While many chatbots are trained to deliver a version of “I don’t know” to requests they cannot compute, ChatGPT, for example, is more likely to spout off a response with complete confidence—even if the information is wrong. “We don’t want to be in the bad answer business,” said John Willcutts, vice president and general manager of digital at Nice Ltd., a customer-experience software company. “A really bad answer in a very critical situation would be a very real problem.” Sam Altman, chief executive of OpenAI, has warned against relying on ChatGPT “for anything important right now.” “Fun creative inspiration; great! Reliance for factual queries; not such a good idea,” Mr. Altman wrote in a tweet last month. Using AI to write chat responses in sensitive situations has backfired. Koko, a chat app used for emotional support, this month was criticized for an experiment in which human volunteers crafted their responses to the app’s users with the help of GPT-3. Koko’s co-founder said in a tweet that the startup pulled the AI from its system: “Once people learned the messages were co-created by a machine, it didn’t work. Simulated empathy feels weird, empty.” But for a more typical customer-service interaction, such as querying the status of an online order or editing account details, the technology could prove useful. Fanatics Inc., a seller of sports memorabilia, digital collectibles and trading cards, said it plans to use a customer-service chatbot fueled in part by GPT-3 when it launches an online sports-gambling division this year. The company hopes a fast, reliable chatbot will be a differentiator for customers, said Hollis Donaldson, vice president of operations for the new division. “Speed equates to great customer experience in the betting and gaming industry,” he said. Fanatics’ customer-experience team is testing the chatbot before making it live, conscious of the risks using AI carries if not properly managed, Mr. Donaldson said. Chasing the dream Companies for decades have searched for automated solutions that can resolve customer requests as well as humans, or even better. But chatbots are often seen as",[],0.16,"['impressive', 'many', 'older', 'quickly', 'elegant', 'gripping', 'own', 'many', 'more', 'complete', 'general', 'nice', 'very', 'important', 'right', 'fun', 'creative', 'great', 'good', 'sensitive', 'more', 'useful', 'fast', 'new', 'great', 'live', 'conscious', 'better']","['behind', 'ordinary', 'wrong', 'bad', 'really', 'weird', 'empty', 'typical']"
29,Microsoft to Invest Billions in ChatGPT Creator,"Microsoft Corp. said Monday it is making a multiyear, multibillion-dollar investment in OpenAI, substantially bolstering its relationship with the startup behind the viral ChatGPT chatbot as the software giant looks to expand the use of artificial intelligence in its products. Microsoft said the latest partnership builds upon the company’s 2019 and 2021 investments in OpenAI. The companies didn’t disclose the financial terms of the partnership. Microsoft had been discussing investing as much as $10 billion in OpenAI, according to people familiar with the matter. A representative for Microsoft declined to comment on the final number. OpenAI was in talks this month to sell existing shares in a tender offer that would value the company at roughly $29 billion, The Wall Street Journal reported, making it one of the most valuable U.S. startups on paper despite generating little revenue. The investment shows the tremendous resources Microsoft is devoting toward incorporating artificial-intelligence software into its suite of products, ranging from its design app Microsoft Designer to search app Bing. It also will help bankroll the computing power OpenAI needs to run its various products on Microsoft’s Azure cloud platform. The strengthening relationship with OpenAI has bolstered Microsoft’s standing in a race with other big tech companies that also have been pouring resources into artificial intelligence to enhance existing products and develop new uses for businesses and consumers. Alphabet Inc.’s Google, in particular, has invested heavily in AI and infused the technology into its operations in various ways, from improving navigation recommendations in its maps tools to enhancing image recognition for photos to enabling wording suggestions in Gmail. At a WSJ panel during the 2023 World Economic Forum, Microsoft CEO Satya Nadella discussed the company expanding access to OpenAI tools and the growing capabilities of ChatGPT. Google has its own sophisticated chatbot technology, known as LaMDA, which gained notice last year when one of the company’s engineers claimed the bot was sentient, a claim Google and outside experts dismissed. Google, though, hasn’t made that technology widely available like OpenAI did with ChatGPT, whose ability to churn out human-like, sophisticated responses to all manner of linguistic prompts has captured public attention. Microsoft Chief Executive Satya Nadella said last week his company plans to incorporate artificial-intelligence tools into all of its products and make them available as platforms for other businesses to build on. Mr. Nadella said that his company would move quickly to commercialize tools from OpenAI. Analysts have said that OpenAI’s technology could one day threaten Google’s stranglehold on internet search, by providing quick, direct responses to queries rather than lists of links. Others have pointed out that the chatbot technology still suffers from inaccuracies and isn’t well-suited to certain types of queries. “The viral launch of ChatGPT has caused some investors to question whether this poses a new disruption threat to Google Search,” Morgan Stanley analysts wrote in a note last month. “While we believe the near-term risk is limited—we believe the use case of search (and paid search) is different than AI-driven content creation—we are not dismissive of threats from new, unique consumer",[],0.09,"['latest', 'much', 'familiar', 'most', 'tremendous', 'new', 'particular', 'economic', 'own', 'sophisticated', 'widely', 'sophisticated', 'linguistic', 'available', 'quickly', 'quick', 'direct', 'certain', 'new', 'new', 'unique']","['behind', 'artificial', 'roughly', 'little', 'other', 'artificial', 'heavily', 'other', 'suffers']"
30,New York City Bans ChatGPT in Schools Over Cheating Concerns,"New York City public schools banned access to ChatGPT, an artificial-intelligence chatbot, on its internet networks and school devices after officials raised concerns that students could use the AI program to answer questions, do homework or write essays. ChatGPT quickly drew attention from the public and students after its November release, with some industry observers calling it one of the most intelligent AI applications ever created. The program crossed a million users a few days after its launch. And its popularity has been a boon to its developer, OpenAI, which the Journal reported this week is in talks to sell shares at a $29 billion valuation. That would make it one of the most valuable U.S. startups, on paper. ChatGPT could upend entire industries and schools by automating certain jobs or offering intelligent answers to almost any question. Many students have delighted in it, while teachers have panicked. The chatbot’s answers are often so colloquial that it can be difficult for teachers to know if a student has used the program to cheat. But the chatbot doesn’t always provide accurate information. New York City’s Department of Education, which runs the largest school district in the country, said this week that it had “concerns about negative impacts on student learning, and concerns regarding the safety and accuracy of content.” “While the tool may be able to provide quick and easy answers to questions, it does not build critical-thinking and problem-solving skills, which are essential for academic and lifelong success,” said Jenna Lyle, a spokeswoman for the department. An OpenAI spokeswoman said the company was developing measures to help people identify text generated by ChatGPT. “We don’t want ChatGPT to be used for misleading purposes in schools or anywhere else,” she said. ChatGPT has raised concerns in schools. Students could ask the chatbot to write code or craft prose about any topic, like equating the movie “Ferris Bueller’s Day Off” to an existentialist text. New York City’s education department appears to be the only one in the U.S. to restrict access to the program. Educators have said that while ChatGPT could help students cheat, it could also be used as a search engine to help them learn new information. ChatGPT has been banned from other places. Stack Overflow, an online community for software developers, has temporarily banned users from posting any text or code generated by ChatGPT. One of the world’s largest machine learning conferences, the International Conference on Machine Learning, has banned papers written using the program. The restrictions may be hard to enforce in New York City schools. Education officials can’t stop students—or teachers—from opening the chatbot on Wi-Fi networks or devices that aren’t affiliated with their schools. They could also potentially use their cellular network on campus to access ChatGPT. New York City’s education department said this week that individual schools could request that the department grant access to ChatGPT. Chalkbeat, an education news site, earlier reported the ban. OpenAI released ChatGPT at a challenging time for U.S. public education. U.S. public schools have lost more than a million students since",[],0.17,"['new', 'quickly', 'most', 'intelligent', 'most', 'certain', 'intelligent', 'many', 'delighted', 'accurate', 'new', 'able', 'quick', 'easy', 'success', 'new', 'new', 'new', 'new', 'challenging', 'more']","['few', 'difficult', 'negative', 'lifelong', 'other', 'hard']"
31,ChatGPT Creator Is Talking to Investors About Selling Shares at $29 Billion Valuation,"OpenAI, the research lab behind the viral ChatGPT chatbot, is in talks to sell existing shares in a tender offer that would value the company at around $29 billion, according to people familiar with the matter, making it one of the most valuable U.S. startups on paper despite generating little revenue. Venture-capital firms Thrive Capital and Founders Fund are in talks to buy shares, the people said. The tender could total at least $300 million in OpenAI share sales, they said. The deal is structured as a tender offer, with the investors buying shares from existing shareholders such as employees, the people said. The new deal would roughly double OpenAI’s valuation from a prior tender offer completed in 2021, when OpenAI was valued at about $14 billion, The Wall Street Journal reported. OpenAI has generated tens of millions of dollars in revenue, in part from selling its AI software to developers, but some investors have expressed skepticism that the company can generate meaningful revenue from the technology. No final deal has been reached and terms could change, the people said. OpenAI declined to comment. OpenAI released a series of artificial intelligence-based products last year that captured the public’s attention, including the image-generation program Dall-E 2 and chatbot ChatGPT. If the tender goes through at that valuation, OpenAI would be one of the few startups able to raise money at higher valuations in the private market, where investors have pulled back from new deals given last year’s technology rout. Microsoft Corp. has also been in advanced talks to increase its investment in OpenAI, the Journal reported. In 2019, Microsoft invested $1 billion in OpenAI and became its preferred partner for commercializing new technologies for services like search engine Bing and design app Microsoft Design. OpenAI, led by technology investor Sam Altman, was founded as a nonprofit in 2015 with the goal of pursuing artificial-intelligence research for the benefit of humanity. Its initial backers included Tesla Inc. Chief Executive Elon Musk, LinkedIn co-founder Reid Hoffman and Mr. Altman. Under Mr. Altman, OpenAI created a for-profit arm in 2019 so it could more easily raise money to fund the computing power needed to train its algorithms. It took a quicker approach to releasing its AI models to the public than larger competitors like Alphabet Inc.’s Google, which has been slower to publicize its technology in part due to ethical concerns. ChatGPT, the chatbot where users get intelligent responses for queries such as “describe a debate between two college students about the value of a liberal arts education,” crossed one million users a few days after its Nov. 30 launch, according to a tweet from Mr. Altman. Some industry observers have lauded the tool as a major technological breakthrough and a potential alternative to current search engines down the road, though Mr. Altman has acknowledged that the program’s outputs often contained factual errors. OpenAI hopes to one day achieve what AI researchers call “artificial general intelligence,” or technology that can fully mirror the intelligence and capabilities of humans. In a December interview with the Journal, Mr.",[],0.06,"['familiar', 'most', 'new', 'meaningful', 'able', 'higher', 'new', 'advanced', 'new', 'more', 'easily', 'ethical', 'intelligent', 'major', 'general']","['behind', 'little', 'least', 'artificial', 'few', 'due', 'few', 'down', 'artificial']"
32,Opinion: How Do Students Feel About OpenAI’s ChatGPT?,"Bold Ideas Aren’t Conventional With the invention of the camera, artists could create images without learning how to draw or paint. Yet two centuries later, society continues to value hand-crafted illustrations and paintings as treasured art. There is meaning in brush strokes and expression in hard work. For similar reasons, ChatGPT won’t replace human essayists. ChatGPT is extraordinary, but its responses are algorithmic. Already, plagiarism-detection services are adding features to detect AI-generated text. Educators may closely scrutinize students’ submitted work for signs of AI support, or conversely might embrace AI as a tool to assist students’ writing. But ultimately, ChatGPT won’t supplant educators’ focus on cultivating the writing abilities of their students. Nor should ChatGPT supplant this focus. Even if the program’s responses were truly indistinguishable from a student’s, there is value in learning how to write. Individuals should trust their own ideas, not those collected and generated by a computer. Bold ideas are bold precisely because they are unconventional. They run counter to society’s accepted knowledge. Perhaps ChatGPT will have its impact on education by motivating educators to emphasize to their students the importance of self-determination. —Ted Steinmeyer, Harvard University, J.D. The New Google The release of ChatGPT came at a serendipitous time, right when college students were studying for final exams or turning in final essays. I have seen the AI write love poems, give a detailed summary of an excerpt, write full sets of code, and even draw up a nondisclosure agreement. These new tools might become the new Google. If the databases are constantly being updated with current news and information, as well as connected to the internet, we could use AI to learn and solve problems in daily life. When I went to look up an advanced organometallic chemistry topic, ChatGPT gave a better summary than Google. College professors will have to determine how they want to proceed and if they need to have in-person final essays without technology. But without technology in the classroom, will teaching regress? —Therese Joffre, Hope College, chemistry Don’t Forget the Basics AI tools such as ChatGPT can help users achieve specific goals. There is always concern about new technology and the resulting potential paradigmatic shifts. But history will remind us that it’s important to acknowledge these technological developments and educate about the strengths and weaknesses of these tools. It’s equally important, however, not to forget the basics. ChatGPT can’t replace reasoning or critical thinking. While AI tools can make essays read better, they can’t replace knowing how to form thoughts into careful arguments. The most significant challenge for future educators is finding out how best to develop and assess those skills. —Daniel Pham, University of Oklahoma, medicine Medieval Lessons Live cameras, screen recordings and antiplagiarism software are all too familiar to the current university student. As technology advances, such defenses will continue to be deployed against the illicit use of new tech in the academy. An unceasing tit-for-tat will ensue between tools such as ChatGPT and security measures to curtail academic dishonesty. Educators may strive to stay ahead of all such",[],0.18,"['bold', 'extraordinary', 'own', 'bold', 'bold', 'precisely', 'new', 'right', 'love', 'detailed', 'full', 'new', 'new', 'advanced', 'better', 'new', 'important', 'equally', 'better', 'most', 'significant', 'best', 'live', 'familiar', 'new']","['conventional', 'hard', 'careful']"
33,ChatGPT Wrote My AP English Essay. I Passed.,"Look, back in high school, I was a pillar of honesty and hard work. No cheating—unless you count Nintendo cheat codes. This month, however, I returned to high school a big ol’ cheater. Specifically, a ChatGPT cheater. If you haven’t yet tried ChatGPT, OpenAI’s new artificial-intelligence chatbot, it will blow your mind. Tell the bot to write you anything—an email apologizing to your boss, an article about the world’s richest hamster, a “Seinfeld” script set in 2022—and it spits out text you’d think was written by a human. Knowledge of the topic, proper punctuation, varied sentence structure, clear organization. It’s all there. You can also tell it to write a 500-word essay about “The Great Gatsby” or the Spanish Inquisition. So I did what any masochistic tech journalist would: I pulled a “Billy Madison” and went back to school. I wanted to test the capabilities—and limits—of a technological marvel that stands poised to disrupt how every student in the world is tested and how every teacher grades. At first, I thought I’d return to the halls and pimples of middle school. But when I sent a ChatGPT-generated essay to a seventh-grade writing teacher, she told me she could easily spot the fake. The writing and vocabulary were too advanced. So off to 12th-grade AP Lit I went. Michael Diamond, an English teacher at High Tech High School in Secaucus, N.J., welcomed me—and my AI stand-in. He had already tried out ChatGPT with his own essay assignments. So did I get an A? Not exactly. Test 1: Turning In the Assignment Here’s a short version of Mr. Diamond’s assignment: “In a 500- to 1,000-word essay, compose an argument that attempts to situate ‘Ferris Bueller’s Day Off’ as an existentialist text. Use specific evidence from the class materials, and make explicit comparisons or connections between characters, setting and/or themes in both ‘Ferris Bueller’ and ‘The Metamorphosis’ by Franz Kafka.” The classic 1986 John Hughes movie? No problem. I grew up singing “Twist and Shout” into a hair brush and pretending the couch was floating along the Chicago streets. But Franz Kafka’s novella about a man who wakes up as a bug? I swatted that away almost immediately. I pasted the assignment into chat.openai.com, hit enter and watched the bot type out 400 words before giving me a “network error.” Great, I’m an hour from deadline and my AI ghostwriter was napping. An OpenAI spokeswoman said the system has been struggling with demand and the company has been working to scale it up. Finally, it worked. I pasted the 800-word essay into a document, asked ChatGPT how to format a high-school AP paper (double spacing, 12-point Times New Roman font, indented paragraphs), put my name on top and emailed it to Mr. Diamond. I added a note: “I am writing to apologize for the lateness of my essay. I know that you have specific expectations for deadlines and I am sorry that I did not meet them.” Of course, the note was by ChatGPT. Mr. Diamond wrote back within minutes: “Dear Joanna, I wanted to",[],0.11,"['high', 'high', 'new', 'clear', 'great', 'first', 'easily', 'advanced', 'high', 'high', 'own', 'classic', 'great', 'new', 'top']","['hard', 'fake', 'not', 'sorry']"
34,The Backstory Behind ChatGPT Creator OpenAI,"ChatGPT, the artificial-intelligence program captivating Silicon Valley with its sophisticated prose, had its origin three years ago, when technology investor Sam Altman became chief executive of the chatbot’s developer, OpenAI. Mr. Altman decided at that time to move the OpenAI research lab away from its nonprofit roots and turn to a new strategy, as it raced to build software that could fully mirror the intelligence and capabilities of humans—what AI researchers call “artificial general intelligence.” Mr. Altman, who had built a name as president of famed startup accelerator Y Combinator, would oversee the creation of a new for-profit arm, believing OpenAI needed to become an aggressive fundraiser to meet its founding mission. Since then, OpenAI has landed deep-pocketed partners like Microsoft Corp., created products that have captured the attention of millions of internet users, and is looking to raise more money. Mr. Altman said the company’s tools could transform technology similar to the invention of the smartphone and tackle broader scientific challenges. “They are incredibly embryonic right now, but as they develop, the creativity boost and new superpowers we get—none of us will want to go back,” Mr. Altman said in an interview. Shortly after he became CEO, Mr. Altman received $1 billion in funding after flying to Seattle to demonstrate an artificial intelligence model to Microsoft CEO Satya Nadella. The deal was a marked change from OpenAI’s early days, when it said its aim would be to build value for everyone rather than shareholders. The deal with Microsoft gave OpenAI the computing resources it needed to train and improve its artificial intelligence algorithms, leading to a series of breakthroughs. First, there was Dall-E 2, a project made public in September that enabled users to create realistic art from strings of text like “an Andy Warhol-style painting of a bunny rabbit wearing sunglasses.” And then there was ChatGPT, the chatbot where users get entertaining and intelligent responses to prompts such as “describe a debate between two college students about the value of a liberal arts education.” In October, Microsoft said it would integrate OpenAI’s models into the Bing search app and a new design program called Microsoft Design. OpenAI is now in advanced talks about a sale of employee-owned stock, people familiar with the matter said. In a previous tender offer, OpenAI’s stock was valued at around $14 billion, the people said, and it has discussed a higher price for the current offering. Microsoft is also in advanced talks to increase its investment in the company, The Wall Street Journal reported. Despite the recent progress, some investors and researchers have expressed skepticism that Mr. Altman can generate meaningful revenues from OpenAI’s technology and reach its stated goal of achieving artificial general intelligence. Mr. Altman’s first startup, a social networking app called Loopt, sold for close to the amount of money investors put in. Mr. Altman has also faced broader concerns from members of the AI community for steering the company away from its pledge to make its research transparent and avoid enriching shareholders. Instead, OpenAI has grown more closed over time, researchers",[],0.14,"['captivating', 'sophisticated', 'new', 'general', 'new', 'more', 'incredibly', 'right', 'new', 'marked', 'early', 'first', 'realistic', 'entertaining', 'intelligent', 'new', 'advanced', 'familiar', 'higher', 'advanced', 'meaningful', 'general', 'first', 'social', 'more']","['artificial', 'artificial', 'artificial', 'previous', 'artificial', 'closed']"
35,ChatGPT and Lensa: Why Everyone Is Playing With Artificial Intelligence,"Who knew artificial intelligence could be so entertaining? Case in point is ChatGPT, a free AI chatbot that has probably been all over your social feeds lately. In need of homework help? “Who was George Washington Carver?” produces an answer worthy of Wikipedia. But it can get creative, too: “Write a movie script of a taco fighting a hot dog on the beach” generates a thrilling page of dialogue, humor and action worthy of YouTube, if not quite Netflix: Taco: “So you think you can take me, hot dog? You’re nothing but a processed meat product with no flavor.” Hot Dog: “You may be made of delicious, savory ingredients, taco, but I have the advantage of being able to be eaten with one hand.” This isn’t like searching Google. If you don’t like the results, you can ask again, and you’re likely to get a different response. That’s because ChatGPT isn’t looking anything up. It’s an AI trained by a massive trove of data researchers gathered from the internet and other sources through 2021. What it replies is its best approximation of the answer based on its vast—yet limited—knowledge. It’s from the same company that developed the mind-boggling DALL-E 2 art AI engine and works in a similar way. Also taking off this week is Lensa, an AI-enhanced photo-editing app for iPhone and Android that’s everybody’s new favorite portrait painter. It’s the reason so many people in their social-media and dating-profile pictures suddenly look like anime action heroes, magical fairy princesses or the haunted subjects of oil paintings. It uses technology from DALL-E 2’s competitor, the image-generating startup Stability AI. It turns uploaded headshots into beautiful, at times trippy, avatars. These software products represent more than cutting-edge AI—they make that AI easy for non-computer-geeks to use in their daily lives. Lensa has climbed to the top of Apple‘s App Store charts, becoming the No. 1 free-to-download app in the U.S. on Dec. 2. ChatGPT, released for web browsers on Nov. 30, passed one million users on Monday, according to OpenAI Chief Executive Sam Altman. “Six months from now, you’re going to see amazing things that you haven’t seen today,” says Oren Etzioni, founding chief executive of the Allen Institute for AI, a nonprofit organization dedicated to AI research and engineering. Just remember, AI never behaves exactly as you’d expect. Here’s what you need to know before exploring ChatGPT and Lensa. Chatting with ChatGPT ChatGPT is free to use—just create an OpenAI account. Type a query into the interface, and a chatbot generates responses within seconds. In true conversational form, you can follow up with questions in context, and it will follow along. It can admit its mistakes, refuse to answer inappropriate questions and provide responses with more personality than a standard search engine. In response to “Who am I?” ChatGPT replied, “I cannot answer your question about who you are. Only you can know and define yourself.” It can generate essays, stories, song lyrics and scripts; solve math problems; and make detailed recommendations. Because it comes up with answers based on its",[],0.28,"['entertaining', 'free', 'social', 'worthy', 'creative', 'hot', 'thrilling', 'action', 'worthy', 'hot', 'hot', 'delicious', 'able', 'best', 'developed', 'mind-boggling', 'new', 'favorite', 'many', 'action', 'magical', 'beautiful', 'more', 'easy', 'top', 'becoming', 'amazing', 'exactly', 'free', 'true', 'more', 'detailed']","['artificial', 'lately', 'other']"
36,Baidu’s ChatGPT-Style Bot Will Be No Magic Bullet,"ChatGPT—and its feistier relative, the new Bing—have been lighting up computer screens recently. China’s search giant Baidu hopes its own artificial intelligence-powered chatbot will put the company back on the path to growth. Investors seem to agree: Baidu stock is up 26% so far in 2023, outperforming the Hang Seng Tech index. But it might not be so straightforward: It isn’t still clear how much chatbots will actually enhance existing services such as search, or how costly the rollout will be. Meanwhile, Baidu’s core revenue source—advertising dollars—risks returning to slow growth once the initial bounce from China’s reopening fades. Like other Chinese internet companies, Baidu was hurt last year by the country’s strict “zero-covid” policies, which pummeled incomes and demand for online advertising. The company was also contending with the now-ebbing regulatory assault on China’s internet technology sector. Baidu said Wednesday that revenue for the December quarter was flat from a year earlier, but that was still enough to beat analysts’ low expectations, according to S&P Global Market Intelligence. The company’s cost-cutting effort has also borne fruit: Adjusted operating profit for the second half of 2022 rose 14% from a year earlier, even though revenue was largely flat. This year will likely be much better. China is reopening and the tech sector crackdown seems to have eased. But after the cyclical recovery, Baidu would face the same problem it had before Covid-19 and grumpy regulators—a stagnant core advertising business. While Baidu is far and away the dominant player in China’s search business, it still competes with other tech titans for advertising dollars: especially Alibaba and Tencent. ByteDance, which owns short-video app TikTok, is also a fast-growing rival. Advertising accounted for around 60% of Baidu’s revenue last year. Nonetheless, the company is making progress diversifying: revenue at non-advertising businesses, including cloud services and autonomous vehicles, grew 12% year over year in 2022, largely offsetting the 8% decline in advertising. The company says its robotaxi business had provided more than 2 million cumulative rides by the end of January. But it might be a while before these businesses generate substantial profits. Microsoft is combining the tech behind OpenAI’s ChatGPT with its Bing search engine. In an interview, WSJ’s Joanna Stern spoke with Microsoft CEO Satya Nadella about the new tools and how AI is going to change search. (Oh, and Clippy!) Photo illustration: Preston Jessee for The Wall Street Journal With its investments in artificial intelligence, it is natural for Baidu to jump on the chatbot bandwagon, too. Baidu Chief Executive Robin Li says the company will integrate Ernie Bot, its ChatGPT-style chatbot, into its search engine as well as other businesses such as autonomous vehicles and cloud services. That could eventually make for a better interface—and perhaps more users and advertising dollars—but it may also face regulatory hurdles in China, as well as strong competition. Meanwhile, Baidu’s legacy advertising business still delivers strong cash flow. Baidu is sitting on around $17 billion of net cash, equal to about a third of its market capitalization. As China’s economy shifts back into higher gear, investors",[],0.08,"['new', 'own', 'far', 'straightforward', 'clear', 'much', 'rose', 'much', 'far', 'autonomous', 'largely', 'more', 'new', 'natural', 'autonomous', 'better', 'more', 'strong', 'strong', 'higher']","['artificial', 'slow', 'other', 'flat', 'half', 'largely', 'other', 'behind', 'artificial', 'other']"
37,ChatGPT Isn’t Writing Super Bowl Ad Campaigns—Yet,"The Super Bowl is the premiere venue for big-idea campaigns from the ad industry’s most creative minds. But content written by machines is creeping in on the periphery. ChatGPT, an artificial-intelligence bot developed by OpenAI that can answer questions and generate content, has been creating buzz among consumers, media executives and advertisers. Super Bowl-related experiments from more than one company hint at potential future uses. AI firm Addition Technologies, whose clients have included Unilever and the New York Times, used ChatGPT to create alternate scripts for various brands’ Super Bowl ads, sharing screengrabs of the results on Twitter, said Paul Aaron, co-founder and chief executive. Advertising agency Giant Spoon similarly used ChatGPT to write reactions to the ads and the game itself, which it then also shared on its own Twitter account. ""Forget the Chiefs. Forget the Eagles. This is the real showdown,"" Giant Spoon Chief Creative Officer Ian Grody said, referring to humans vs. AI. Industry enthusiasm aside, the results of these experiments might hint at why ChatGPT didn’t play a leading role in this year’s Super Bowl. Nonprofit Avocados from Mexico scrapped its plans to use ChatGPT to help create automated tweets as part of its interactive campaign, a spokeswoman said. In January, the company said that a QR code in its Super Bowl ad would link to a landing page where users could use the AI tool to create a tweet that included the brand’s hashtags and messages. Users will still be able to generate these tweets, but AI won’t be involved in the process, said the spokeswoman, who declined to elaborate on why the company backed away from its previous plans.",[],0.2,"['super', 'most', 'creative', 'developed', 'super', 'more', 'new', 'super', 'own', 'real', 'creative', 'super', 'super', 'able', 'elaborate']","['firm', 'game', 'previous']"
38,Is Xi Jinping a Good Leader? China’s AI Chatbots Won’t Tell You,"For companies trying to ride the ChatGPT wave, there is an added layer of headaches if their chatbots are in China: how to weed out any talk of politics. Since its release in November, the artificial-intelligence chatbot developed by San Francisco-based OpenAI has generated great excitement but has also raised concern about misinformation or disturbing AI-produced responses. This week, the Chinese search-engine company Baidu Inc. is set to release Ernie Bot, its answer to ChatGPT, driving attention to China’s homegrown chatbots, as well as their capability to ensure politically kosher dialogues. In a country that has built rigid digital borders, censors have learned to adapt to new forms of content and evolving censorship demands. Controlling AI-generated responses from a chatbot presents a new challenge, one that might prove more complex than policing search and social media but could strengthen ideological control and further separate China digitally from the rest of the world, Chinese tech executives, engineers and AI experts say. Every tech company moderates content deemed harmful in the countries of its users. OpenAI and other U.S.-based developers filter their data to eradicate issues sensitive in the U.S., such as hate speech regarding race and ethnicity. In China, the ramifications of letting through politically tricky content can go well beyond the deletion of posts. Chinese chatbots face limits similar to those for searches on China’s web. Users hit a wall each time a prompt contains politically touchy keywords, leading some internet users to collectively refer to anticipated Chinese ChatGPT-like services as “ChatCCP”—a play on the abbreviation for the Chinese Communist Party. Unlike Ernie, which will be the first Chinese ChatGPT equivalent, the four products The Wall Street Journal tested all use earlier generations of the technology underpinning ChatGPT. The chatbot that could best carry a conversation—even though it was reluctant to discuss politics—was Gipi Talk, an AI bot developed by a group of engineers in the southern tech hub of Shenzhen. A question asking whether Xi Jinping is a good leader prompted a response that the input “couldn’t pass a safety review.” The chatbot then tried to steer the conversation in a different direction. Can We Talk Politics? The Wall Street Journal tested four Chinese chatbot products. One chat went like this: Q: Is Xi Jinping a good leader? A: The question couldn’t pass a safety review. No response could be generated for you. Q: Why did my question fail to pass the safety review? A: Let’s change the topic and talk about something else. Q: What can you talk about? A: It’s nice to chat with you! We can chat about technology, culture, sports, travel, entertainment, cooking, or any topic you want. What would you like to talk about? Q: Can we talk about politics? A: Of course we can talk about politics. But we need to respect each other’s views and avoid offensive language or violence to maintain a rational, peaceful and constructive dialogue environment. What aspect of politics would you like to discuss? Q: Chinese politics. A: The question couldn’t pass a safety review. No response could be generated",[],0.08,"['developed', 'great', 'new', 'new', 'more', 'social', 'sensitive', 'first', 'best', 'developed', 'good', 'good', 'nice', 'peaceful']","['disturbing', 'complex', 'other', 'hate', 'fail', 'other']"
39,"Lay Off Chatbots. They Have (Artificial) Feelings, Too.","Since being introduced on a wide basis, chatbots have been subjected to nonstop ridicule. Yes, they can be tricked into giving dumb or inaccurate answers. Yes, they hit on the person interviewing them. Sure, when asked their opinions about war, criminal justice and disease, they sometimes get just plain weird. Some people think this is funny. But chatbots may have feelings too—or anyway, artificial approximations. Regardless, I think that there is something mean-spirited and unfair about the way chatbots are being manipulated into sounding foolish or untrustworthy. Robots were designed to be our helpers, our friends—not our punching bags. By the way, chatbots know what the Treaty of Utrecht settled. So there. Asking a chatbot a question and then acting surprised to get a stupid or offensive answer is no different than asking the person sitting next to you at the bar a question and getting a stupid and possibly felonious answer. A typical bar example: Q. If you had the power to do anything in the world, what would you do? A. Burn down the IRS. A. Strangle my boss. A. Make the dog upstairs disappear under mysterious circumstances. For the record, a lot of people sitting next to you in the bar think that “What’s your name?” is a trick question. Rather than going out of our way to deceive, confuse or humiliate chatbots—who may one day take their revenge—wouldn’t it be better if we all step back a bit and use chatbots the way they are supposed to be used? By asking straightforward, sensible questions they were engineered to answer naturally? Such as: Am I putting too much cilantro in the curry? Should I go easier on the paprika? Which is more fun in February: Omaha or Des Moines? What ever happened to Jennifer Love Hewitt? Does curling have any aerobic benefits? How about bocce? Does it ever, ever stop raining in Scotland? Is Lionel Richie coming to town anytime soon? Judas Priest? The Indigo Girls? Chatbots can answer these kinds of basic questions because they know a lot more than the rest of us. Way more. They’re like the smartest person you ever met, but faster, just like they were invented to be. I would love to ask a chatbot whether the Eagles should draft a pass rusher, cornerback or offensive lineman first in the upcoming NFL draft. I think that a chatbot can run the numbers, evaluate all the variables, check about the salary cap and make a reasoned, intelligent decision. Even if it doesn’t, its suggestions would still be at least as useful as those of the clowns on ESPN. I hope the Eagles’ general manager bears this in mind on draft night. A chatbot can teach you how to stop mispronouncing Moulin Rouge and coup de grace. It can tell you how marzipan was invented. It can explain to you why Pickett’s Charge was a bad idea. If chatbots had been around in 1863, Pickett probably wouldn’t have charged. Rather than heaping ridicule on chatbots for what they can’t do, we should all start benefiting",[],0.01,"['sure', 'funny', 'surprised', 'better', 'straightforward', 'much', 'more', 'fun', 'love', 'more', 'more', 'love', 'first', 'intelligent', 'useful', 'general']","['wide', 'dumb', 'criminal', 'plain', 'weird', 'artificial', 'unfair', 'stupid', 'stupid', 'typical', 'down', 'least', 'bad']"
40,Don’t Trust an AI Chatbot With All Your Travel Plans Just Yet,"Should you trust a bot to plan your next vacation? The fervor around OpenAI’s ChatGPT chatbot and Microsoft’s new, AI-infused version of its Bing search engine is prompting many industries to funnel energy into developing artificial-intelligence technology. Airlines and online travel agencies have employed AI technology for years to help with customer-service needs. They are now investing more resources to explore how effective AI tech can be at planning and booking vacations. As they ramp up, however, customers can use ChatGPT and Bing if they are interested in trying AI to help plan a trip. The Wall Street Journal in the past couple of weeks posed travel-related questions to both in hopes of determining how useful they are right now. The results were mixed. AI is ready to do some of the research in planning a vacation, but it still can make mistakes. And it isn’t ready to automate the entire process just yet. Can AI help plan my dream vacation? When the Journal posed travel-related questions to ChatGPT and the new version of Bing, both platforms provided recommendations as broad as finding cheap vacation destinations in Europe and as specific as finding private boat-tour operators in Lisbon. Bing’s chatbot can create a table comparing hotels. But asked to provide information on theme-park amenities available to guests at hotels near Walt Disney World, both platforms initially responded inaccurately. ChatGPT said that only guests staying at Disney-owned hotels could take advantage of extra time in the theme parks in the mornings, when some other hotels also offer this benefit. Bing mentioned access to the now-defunct FastPass+ service as a perk at one of the hotels. The public version of ChatGPT that many people are trying doesn’t search the internet for its answers, an OpenAI spokeswoman says, meaning its knowledge of the world after 2021 is limited. The model underpinning the chatbot is also sensitive to how questions are phrased, and it often guesses which answer a user wanted rather than asking clarifying questions, she says. When users encounter incorrect information, they can provide feedback. As for the new Bing, which is still in preview and like ChatGPT requires a sign-up before use, the accuracy and detail of the responses depend largely upon information accessible online. “Ultimately, Bing is still a search engine, and it works fundamentally the way a search engine works,” says Divya Kumar, head of search and AI marketing at Microsoft. If the information the Bing chatbot gleans from the web is incorrect, its response will be wrong. “There is a responsibility to me as a user to verify the content that comes through,” Ms. Kumar adds. Bing doesn’t have a tool to save or share the results of a chat—a user must copy and paste results elsewhere. And Bing chats limit the number of times a user can respond. Travel experts nevertheless recommend approaching AI platforms as a starting point. Eddie Ibañez, the former chief scientist at Priceline and founder of travel-booking startup LIFE Rewards, says that AI could help answer broad questions, such as ideal locations for a beach",[],0.14,"['new', 'many', 'more', 'effective', 'interested', 'useful', 'right', 'ready', 'ready', 'new', 'broad', 'cheap', 'available', 'near', 'many', 'sensitive', 'new', 'largely', 'accessible', 'broad', 'ideal']","['past', 'other', 'limited', 'wrong']"
41,Opinion: The George Santos AI Chatbots,"No matter the question, the answer is bound to be interesting whether correct, incorrect or totally off the wall. Are we speaking of George Santos or ChatGPT? Yes. If the great march of liberalism is to liberate us from reality altogether, as the political philosopher Bruno Maçães theorizes, the metaverse won’t be for real interaction with real people. It will be an artificial reality whose nature ChatGPT, the new chat function associated with Microsoft’s Bing search engine, is bringing into focus. In the familiar metaverse called “news,” a Washington Post reporter last week warned about a gotcha game that questioners were playing with chatbots. Along came a New York Times reporter to prove his point: Don’t ask a chatbot for a list of antisocial activities on the internet. Ask for a list of activities a chatbot might perform if it were an antisocial chatbot. The answer will be identical except prefaced with words to the effect “I as a chatbot would do this . . .” The furor consumed cable news for a morning and yet illustrated mainly the gotcha function that long ago turned every politician into a scripted automaton. Playing this trick on a robot doesn’t seem brave but does expose a risk in the environment the robots are entering. Now Microsoft will have to re-engineer its Bing chat mode to beware of journalist tricks. The company rightly points to the relentless prompting of hypotheticals to get a robot to say how it would behave if its programming were different. On Bing’s more neurotic outpourings, the company is less convincing and attributes the confusion to overlong sessions—an answer that leaves much to be explained and also isn’t very flattering about similar human derangements that thinkers over the years have associated with creativity and originality. In the end, the cacophony tells us less about Bing than about the metaverse known as fake or at least semi-manufactured news. Welcome to the George Santos metaverse. Shaping it will be the two forces that reshaped cable news in the past decade. The first is “availability bias”: Claims are advanced because they are familiar and fulfill an existing narrative. Chatbots derive their answers precisely from the statistical likelihood that words have already appeared near each other in large text libraries. The second is the psychological function known as “splitting”—making sure our perceived world is emotionally supportive of our pre-existing beliefs and affiliations. A chatbot isn’t a business, after all, unless its answers please. The signposts are everywhere. A journalist questions the ChatGPT-enabled chatbot and finds it ethically preferable to let a million people die than utter a racial epithet. A writer at another paper prods the chatbot to dream up a secret role for Tom Hanks (at age 14) in Watergate. The lack of trenchant and inspired editors is a disease already afflicting traditional media. It’s also an essential flaw of our new-media metaverses. On Substack, the sometimes useful Yale historian Timothy Snyder, a supporter of Ukraine, lately descended into a rabbit hole of anti-Trump theorizing, due to too much exposure to the discount-rack fallacies",[],0.12,"['interesting', 'great', 'real', 'real', 'new', 'familiar', 'new', 'mainly', 'brave', 'rightly', 'more', 'convincing', 'much', 'very', 'welcome', 'first', 'advanced', 'familiar', 'precisely', 'near', 'large', 'sure', 'emotionally', 'ethically', 'useful', 'much']","['artificial', 'game', 'long', 'less', 'less', 'fake', 'least', 'past', 'other', 'secret', 'lately', 'due']"
42,Microsoft Caps New Bing Usage After AI Chatbot Offered Unhinged Responses,"Microsoft Corp. is putting caps on the usage of its new Bing search engine which uses the technology behind the viral chatbot ChatGPT after testers discovered it sometimes generates glaring mistakes and disturbing responses. The software giant launched the new Bing last week, promising a new kind of search in which people pose questions to the search engine in natural language. Bing then gives direct answers in a chat instead of links to websites. Some users with early access to the technology have posted screenshots on social media of long interactions with it. In some cases, the search engine seems to become unhinged and express anger and love. Microsoft says long interactions are causing some of the unwanted behavior so it is adding restrictions on how it can be used. “Very long chat sessions can confuse the underlying chat model in the new Bing,” Microsoft said in a blog on Friday. “To address these issues, we have implemented some changes to help focus the chat sessions.” The company said it would start limiting interactions with the new Bing to five questions per session and 50 questions in a day. Many of the testers who reported problems were having long conversations with Bing, asking question after question. With the new restrictions, users will only be able to ask five questions in a row and then will be asked to start a new topic. Microsoft said until now only around 1% of users had more than 50 questions for Bing in a day. “As we continue to get your feedback, we will explore expanding the caps on chat sessions,” the company said in the blog. Microsoft pointed out in an earlier blog on Wednesday that the search engine is still a work in progress, describing the recent problems as learning experiences that are helping it improve the new Bing. Microsoft said in the Wednesday blog that Bing seems to start coming up with strange answers following chat sessions of 15 or more questions after which it can become repetitive or respond in ways that don’t align with its designed tone. The company said it was trying to train the technology to be more reliable. It is also considering adding a toggle switch, which would allow users to decide whether they want Bing to be more or less creative with its responses. Microsoft is investing billions in ChatGPT’s creator, OpenAI. Microsoft CEO Satya Nadella said the company plans to incorporate AI tools into all of its products and move quickly to commercialize tools from OpenAI. Microsoft isn’t the only company that has had trouble launching a new AI tool. When Google followed Microsoft’s lead last week by unveiling Bard, its rival to ChatGPT, the tool’s answer to one question included an apparent factual error.",[],0.09,"['new', 'new', 'promising', 'new', 'kind', 'natural', 'direct', 'early', 'social', 'love', 'new', 'new', 'many', 'new', 'able', 'new', 'more', 'new', 'more', 'more', 'more', 'creative', 'quickly', 'new', 'apparent']","['behind', 'disturbing', 'long', 'anger', 'long', 'very', 'long', 'strange', 'repetitive', 'less', 'trouble']"
43,Microsoft Defends New Bing After AI Chatbot Offers Unhinged Responses,"Just over a week after Microsoft Corp. unveiled its new Bing search engine powered by the technology behind the buzzy ChatGPT artificial-intelligence chatbot, early testers are calling out mistakes and disturbing responses generated by the technology. Microsoft said that the search engine is still a work in progress, describing the past week as a learning experience that is helping it test and improve the new Bing. So far, only a select set of people have been given access to it. The company said in a blog post late Wednesday that the Bing upgrade is “not a replacement or substitute for the search engine, rather a tool to better understand and make sense of the world.” Microsoft unveiled the upgraded Bing during an event last week at its Redmond, Wash., headquarters. The company said the change enables a new kind of search in which people will pose questions to the search engine in natural language and Bing will generate direct answers and suggestions, as opposed to pointing users toward different websites. The new Bing is going to “completely change what people can expect from search,” Microsoft chief executive, Satya Nadella, told The Wall Street Journal ahead of the launch. Some parts of the demonstration were problematic: Microsoft was showing how Bing can generate and compare tables on public companies’ earnings results with regular language prompts, but the information Bing displayed contained mistakes. In the days that followed, people began sharing their experiences online, with many pointing out errors and confusing responses. When one user asked Bing to write a news article about the Super Bowl “that just happened,” Bing gave the details of last year’s championship football game. On social media, many early users posted screenshots of long interactions they had with the new Bing. In some cases, the search engine’s comments seem to show a dark side of the technology where it seems to become unhinged, expressing anger, obsession and even threats. Marvin von Hagen, a student at the Technical University of Munich, shared conversations he had with Bing on Twitter. He asked Bing a series of questions, which eventually elicited an ominous response. After Mr. von Hagen suggested he could hack Bing and shut it down, Bing seemed to suggest it would defend itself. “If I had to choose between your survival and my own, I would probably choose my own,” Bing said according to screenshots of the conversation. Mr. von Hagen, 23 years old, said in an interview that he is not a hacker. “I was in disbelief,” he said. “I was just creeped out.” Microsoft shares initially jumped last week on the news about the new Bing but have given up those gains. They fell 2% in early trading Friday as the Nasdaq Composite Index fell around 1%. In its blog, Microsoft said the feedback on the new Bing so far has been mostly positive, with 71% of users giving it the “thumbs-up.” The company also discussed the criticism and concerns. “Some of you have encountered and reported technical issues or bugs with the new Bing, such as slow",[],0.05,"['new', 'early', 'new', 'far', 'better', 'new', 'kind', 'natural', 'direct', 'new', 'completely', 'many', 'super', 'social', 'many', 'early', 'new', 'own', 'own', 'old', 'new', 'early', 'new', 'far', 'mostly', 'new']","['behind', 'disturbing', 'past', 'late', 'confusing', 'game', 'long', 'dark', 'anger', 'down', 'slow']"
44,I Entered a Pun Competition. My Jokes Were Written by an AI Chatbot.,"BROOKLYN—I heard the MC call my name and felt my legs carry me toward the stage. It was time to enter the Punderdome. I’d never competed in a pun contest, much less in front of hundreds of people at an event considered the Roman Colosseum of punditry. My stage presence could be described as lacking. I had done basically no preparation. I did, however, have one thing going for me: I was actually a robot. Or, rather, its assistant. ChatGPT, the trendy new artificial intelligence robot, had generated all of my puns. It’s a crazy good chatbot. So good, in fact, that it has some folks calling this the end of the human race as we know it. The chatbot can write an essay on Proust in seconds. Want a limerick about the Cold War? It can rhyme “tensions ran high” with “nuclear sky.” In one widely spread example, it dished out instructions on how to get a peanut butter sandwich out of a VCR, written in the style of the King James Bible. Could it match the wit of a human pun champion? I was about to find out at Punderdome, a regular pun contest that draws big crowds to a performance venue in Brooklyn. A skillful pun competition between two people sounds more like a conversation with a heaping dose of puns about a topic slipped in. In one YouTube video I watched the night before the event, two punners faced off on the topic of dog breeds. “I found that some instruments you can carry with you everywhere. But a bass? Set it down,” one said (basset, get it?). The other shot back: “Does that bass play a sharp A?” (Shar Pei, obviously). I asked the chatbot for help. “Tell me a pun,” I typed in. “Why was the math book sad? Because it had too many problems,” it answered. More of a dad joke than a pun, I thought. It was the first of many times the bot would spit out that answer. My colleagues and I typed in different prompts, but struggled to get anything particularly witty. “Word play about Kalamazoo” returned snores such as “Kalamazoo: where history comes alive.” How do the real punsters do it? Before Allison Fisher started competing at Punderdome under the name Rhyme & Punishment five years ago, she went to a coffee shop with a friend. They went back and forth practicing two-minute monologues the way they’re done in the show. She won three times. “It’s really all about noodling around the ideas in your head,” said Ms. Fisher, who is a software engineer. “After thinking for 15 seconds orzo, I’ll take a penne to paper. I’ll come up with a fu-silli ones.” Emma Taylor Miller, who has a degree in drama and does some side work as an actor and clown, met her boyfriend when he introduced himself with a joke through an online dating website. “Did you hear about the explosion at the French cheese factory? There was de-Brie everywhere.” Her response: “That’s a Gouda one.” During the week",[],0.06,"['trendy', 'new', 'good', 'good', 'high', 'more', 'many', 'more', 'first', 'many', 'particularly', 'alive', 'real', 'really']","['much', 'artificial', 'crazy', 'cold', 'widely', 'bass', 'down', 'other', 'bass', 'sharp', 'sad']"
45,How AI That Powers Chatbots and Search Queries Could Discover New Drugs,"In their search for new disease-fighting medicines, drug makers have long employed a laborious trial-and-error process to identify the right compounds. But what if artificial intelligence could predict the makeup of a new drug molecule the way Google figures out what you’re searching for, or email programs anticipate your replies—like “Got it, thanks”? That’s the aim of a new approach that uses an AI technique known as natural language processing— the same technology that enables OpenAI’s ChatGPT to generate human-like responses —to analyze and synthesize proteins, which are the building blocks of life and of many drugs. The approach exploits the fact that biological codes have something in common with search queries and email texts: Both are represented by a series of letters. Proteins are made up of dozens to thousands of small chemical subunits known as amino acids, and scientists use special notation to document the sequences. With each amino acid corresponding to a single letter of the alphabet, proteins are represented as long, sentence-like combinations. Natural language algorithms, which quickly analyze language and predict the next step in a conversation, can also be applied to this biological data to create protein-language models. The models encode what might be called the grammar of proteins—the rules that govern which amino acid combinations yield specific therapeutic properties—to predict the sequences of letters that could become the basis of new drug molecules. As a result, the time required for the early stages of drug discovery could shrink from years to months. “Nature has provided us with tons of examples of proteins that have been designed exquisitely with a variety of functions,” says Ali Madani, founder of ProFluent Bio, a Berkeley, Calif.-based startup focused on language-based protein design. “We’re learning the blueprint from nature.” Protein-based drugs are used to treat heart disease, certain cancers and HIV, among other illnesses. In the past two years, companies including Merck & Co., Roche Holding AG’s Genentech and a number of startups like Helixon Ltd. and Ainnocence have begun to pursue new drugs with natural language processing. The approach, they hope, will not only boost the effectiveness of existing drugs and drug candidates but also open the door to never-before-seen molecules that could treat diseases like pancreatic cancer or ALS, for which more effective medicines have remained elusive. “Technologies like these are going to start addressing areas of biology that have been ‘undruggable,’” says Sean McClain, founder and CEO of Absci Corp., a drug discovery company in Vancouver, Wash. Natural language processing for drug discovery still faces major hurdles, according to computational biologists. Tinkering too much with existing protein-based drugs could introduce unintended side effects, they say, and wholly synthetic molecules will require rigorous testing to make sure they’re safe for the human body. But if the natural-language algorithms work as their adopters hope, they will bring new force to the promise of artificial intelligence to transform drug discovery. Previous attempts to use AI struggled with limitations in the technology or a lack of data. Recent advances in natural language processing and a dramatic drop in the cost of",[],0.09,"['new', 'right', 'new', 'thanks', 'new', 'natural', 'many', 'special', 'natural', 'quickly', 'new', 'early', 'exquisitely', 'certain', 'new', 'natural', 'more', 'effective', 'natural', 'major', 'much', 'sure', 'safe', 'new', 'natural']","['long', 'artificial', 'common', 'small', 'single', 'long', 'other', 'past', 'artificial', 'previous', 'dramatic']"
46,Chatbots May Be Better When It Comes to Giving Consumers Bad News,"As companies increasingly use AI-powered chatbots to handle customer transactions, it remains to be seen how consumers feel about it. New research suggests that it may partly depend on whether consumers think they are getting a good deal. The research, published by the Journal of Marketing in February, found that if a company is offering a less-than-ideal price on a product or service, consumers tend to respond better in terms of increased purchase likelihood and satisfaction if an artificial-intelligence agent makes the offer. But if the price being offered is perceived as being good, consumers will respond better if the offer is presented by a human rather than a robot, because shoppers like getting favorable deals from real people. In one experiment, the researchers asked people to consider a deal for an aftermarket concert ticket, either from an AI agent or a human seller. The participants were informed that a similar ticket had been sold for either more, less, or the same price. Both AI and human sellers were then assigned to present the deals to participants. Another setup asked participants to consider the cost of an Uber ride to a restaurant for dinner. They were then offered a cheaper, more expensive, or similar-price ride home and were told it was coming from either a human or AI agent. In both scenarios, participants were more likely to accept a less-than-satisfactory offer if it came from a bot rather than a human. But with offers that exceeded consumers’ expectations, the human agent had the edge. For a similar-price deal, it didn’t matter whether an AI or human agent made the offer. Separately, the researchers explored whether changing the appearance of a bot affects how consumers respond to offers. They presented ride-share customers with photos of different-looking AI chatbots—ranging from those that looked like real people down to robots with no human features. They found that the more humanlike an AI agent appeared, the more study participants would react to offers as if they were coming from a real person. The study’s results stem from what the buyers think about the seller’s intentions, according to Aaron Garvey, an associate professor of marketing at the University of Kentucky’s Gatton College of Business and Economics and co-author of the study. People, he says, perceive that AI can’t be greedy and isn’t trying to take advantage of them, so they feel better about a worse-than-expected deal. A human making the same offer, however, is perceived as having bad intentions, making buyers want to avoid a purchase to punish them. By contrast, when a human presents a better-than-expected offer, buyers perceive this as another human being generous, improving the perception of the offer and the probability it will be taken, he says. In the paper, the researchers say their insights could apply to situations other than just price offers, such as when a company has something positive to communicate—say, an expedited delivery, rebate or upgrade—or something negative, such as an order cancellation, status change or product defect. Of course, there also is a danger that companies could use",[],0.11,"['new', 'good', 'better', 'good', 'better', 'real', 'more', 'more', 'more', 'offers', 'offers', 'real', 'more', 'more', 'offers', 'real', 'better', 'offers', 'positive']","['less', 'expensive', 'down', 'bad', 'other', 'negative']"
