,titles,body_contents,tags,sentiment_score,positive_words,negative_words
0,"Alarmed by A.I. Chatbots, Universities Start Revamping How They Teach","While grading essays for his world religions course last month, Antony Aumann, a professor of philosophy at Northern Michigan University, read what he said was easily “the best paper in the class.” It explored the morality of burqa bans with clean paragraphs, fitting examples and rigorous arguments. A red flag instantly went up. Mr. Aumann confronted his student over whether he had written the essay himself. The student confessed to using ChatGPT, a chatbot that delivers information, explains concepts and generates ideas in simple sentences — and, in this case, had written the paper. Alarmed by his discovery, Mr. Aumann decided to transform essay writing for his courses this semester. He plans to require students to write first drafts in the classroom, using browsers that monitor and restrict computer activity. In later drafts, students have to explain each revision. Mr. Aumann, who may forgo essays in subsequent semesters, also plans to weave ChatGPT into lessons by asking students to evaluate the chatbot’s responses. “What’s happening in class is no longer going to be, ‘Here are some questions — let’s talk about it between us human beings,’” he said, but instead “it’s like, ‘What also does this alien robot think?’” Across the country, university professors like Mr. Aumann, department chairs and administrators are starting to overhaul classrooms in response to ChatGPT, prompting a potentially huge shift in teaching and learning. Some professors are redesigning their courses entirely, making changes that include more oral exams, group work and handwritten assessments in lieu of typed ones. The moves are part of a real-time grappling with a new technological wave known as generative artificial intelligence. ChatGPT, which was released in November by the artificial intelligence lab OpenAI, is at the forefront of the shift. The chatbot generates eerily articulate and nuanced text in response to short prompts, with people using it to write love letters, poetry, fan fiction — and their schoolwork. That has upended some middle and high schools, with teachers and administrators trying to discern whether students are using the chatbot to do their schoolwork. Some public school systems, including in New York City and Seattle, have since banned the tool on school Wi-Fi networks and devices to prevent cheating, though students can easily find workarounds to access ChatGPT. In higher education, colleges and universities have been reluctant to ban the A.I. tool because administrators doubt the move would be effective and they don’t want to infringe on academic freedom. That means the way people teach is changing instead. “We try to institute general policies that certainly back up the faculty member’s authority to run a class,” instead of targeting specific methods of cheating, said Joe Glover, provost of the University of Florida. “This isn’t going to be the last innovation we have to deal with. That’s especially true as generative A.I. is in its early days. OpenAI is expected to soon release another tool, GPT-4, which is better at generating text than previous versions. Google has built LaMDA, a rival chatbot, and Microsoft is discussing a $10 billion investment in OpenAI. Silicon Valley",[],0.14,"['easily', 'best', 'clean', 'fitting', 'first', 'potentially', 'more', 'new', 'love', 'high', 'new', 'easily', 'higher', 'effective', 'general', 'especially', 'early', 'better']","['alien', 'artificial', 'artificial', 'expected', 'previous']"
1,How ChatGPT Hijacks Democracy,"Launched just weeks ago, ChatGPT is already threatening to upend how we draft everyday communications like emails, college essays and myriad other forms of writing. Created by the company OpenAI, ChatGPT is a chatbot that can automatically respond to written prompts in a manner that is sometimes eerily close to human. But for all the consternation over the potential for humans to be replaced by machines in formats like poetry and sitcom scripts, a far greater threat looms: artificial intelligence replacing humans in the democratic processes — not through voting, but through lobbying. ChatGPT could automatically compose comments submitted in regulatory processes. It could write letters to the editor for publication in local newspapers. It could comment on news articles, blog entries and social media posts millions of times every day. It could mimic the work that the Russian Internet Research Agency did in its attempt to influence our 2016 elections, but without the agency’s reported multimillion-dollar budget and hundreds of employees. Automatically generated comments aren’t a new problem. For some time, we have struggled with bots, machines that automatically post content. Five years ago, at least a million automatically drafted comments were believed to have been submitted to the Federal Communications Commission regarding proposed regulations on net neutrality. In 2019, a Harvard undergraduate, as a test, used a text-generation program to submit 1,001 comments in response to a government request for public input on a Medicaid issue. Back then, submitting comments was just a game of overwhelming numbers. Platforms have gotten better at removing “coordinated inauthentic behavior.” Facebook, for example, has been removing over a billion fake accounts a year. But such messages are just the beginning. Rather than flooding legislators’ inboxes with supportive emails, or dominating the Capitol switchboard with synthetic voice calls, an A.I. system with the sophistication of ChatGPT but trained on relevant data could selectively target key legislators and influencers to identify the weakest points in the policymaking system and ruthlessly exploit them through direct communication, public relations campaigns, horse trading or other points of leverage. When we humans do these things, we call it lobbying. Successful agents in this sphere pair precision message writing with smart targeting strategies. Right now, the only thing stopping a ChatGPT-equipped lobbyist from executing something resembling a rhetorical drone warfare campaign is a lack of precision targeting. A.I. could provide techniques for that as well. A system that can understand political networks, if paired with the textual-generation capabilities of ChatGPT, could identify the member of Congress with the most leverage over a particular policy area — say, corporate taxation or military spending. Like human lobbyists, such a system could target undecided representatives sitting on committees controlling the policy of interest and then focus resources on members of the majority party when a bill moves toward a floor vote. Once individuals and strategies are identified, an A.I. chatbot like ChatGPT could craft written messages to be used in letters, comments — anywhere text is useful. Human lobbyists could also target those individuals directly. It’s the combination that’s important: Editorial and social media",[],0.05,"['far', 'greater', 'social', 'new', 'overwhelming', 'better', 'supportive', 'relevant', 'direct', 'successful', 'smart', 'right', 'most', 'particular', 'useful', 'directly', 'important', 'social']","['everyday', 'other', 'artificial', 'least', 'game', 'fake', 'ruthlessly', 'other', 'military']"
2,My So-So Encounters with ChatGPT,"A mountain man buys his first chain saw. He comes back to the store a week later complaining that it cuts down only two trees a day when he was told it would cut down 20. The service person says, “Well, let’s see what the trouble is,” and starts it up. The mountain man jumps back and asks, “What’s that noise?” (He’d been sawing without the engine on.) I feel like that mountain man when it comes to ChatGPT, the powerful new artificial intelligence chatbot that seemingly everyone is experimenting with. I got mediocre results from ChatGPT because I didn’t try very hard to use it properly. Other people have gotten amazing results because they’re smarter and more purposeful about how they use it — they yank its pull cord and get its engine going. I confess that my first idea was to figure out what ChatGPT could not do rather than what it could. It won’t offer opinions. It’s not up on anything that’s happened since it was trained last year. It doesn’t have a body so it has never been to Ireland. (One of my questions.) I somehow got into a conversation with ChatGPT about words that change their spelling when they’re Anglicized from French. ChatGPT gave “ballet” as an example. But “ballet” is spelled the same in both languages. Hah, it made a mistake! I felt as if I’d scored a win for the human race. But what a shallow win. Other people have done better because they’ve accentuated the positive. On YouTube I found a video of a computer guy, Jason Fleagle, asking ChatGPT, “Can you create a web app using HTML, CSS and Javascript that has a form that takes in a stock ticker symbol for a company and then on form submission displays the stock market performance of that particular company?” ChatGPT did that and more. The code wasn’t perfect — there was a bug somewhere — but Fleagle said, “As you can see, I just saved myself, like, a lot of time.” There are dozens of such examples. ChatGPT can even rewrite software into a different programming language. “I introduced my undergraduate entrepreneurship students to the new A.I. system, and before I was done talking, one of my students had used it to create the code for a start-up prototype using code libraries they had never seen before,” Ethan Mollick, an associate professor at the University of Pennsylvania’s Wharton School, wrote in Harvard Business Review on Wednesday. Mollick himself used ChatGPT to rough out a course syllabus, class assignments, grading criteria and lecture notes. ChatGPT strikes me as an example of what economists call “skill-biased technical change.” It is incredibly powerful in the hands of people who already have skills and ideas because they know what to ask it for. You have two options. You can do a better job than ChatGPT, whether it’s writing or coding, or you can admit your inferiority but figure out a way to make ChatGPT work for you. If you can’t do either, you may need to find a",[],0.12,"['first', 'powerful', 'new', 'amazing', 'more', 'first', 'win', 'win', 'better', 'positive', 'particular', 'more', 'perfect', 'new', 'incredibly', 'better']","['down', 'down', 'trouble', 'artificial', 'mediocre', 'very', 'properly', 'shallow', 'other', 'rough']"
3,ChatGPT Has a Devastating Sense of Humor,"ChatGPT makes an irresistible first impression. It’s got a devastating sense of humor, a stunning capacity for dead-on mimicry, and it can rhyme like nobody’s business. Then there is its overwhelming reasonableness. When ChatGPT fails the Turing test, it’s usually because it refuses to offer its own opinion on just about anything. When was the last time real people on the internet declined to tell you what they really think? I started talking to ChatGPT a couple of weeks ago, after the artificial intelligence company OpenAI released the bot as a “research preview” of its work on large language models. A language model is an A.I. system that has been trained on enormous troves of text to find the probabilistic connection between words; ChatGPT is a language model that has been optimized to create what’s long been the holy grail in artificial intelligence research — a computer with which you can hold a conversation. ChatGPT certainly achieves that. I have spoken to lots of computers in my lifetime (weird flex, I know), but ChatGPT is the first that I’ve found fun and interesting to talk to. I began by peppering it with simple trivia but it wasn’t long before we were holding surprisingly nuanced conversations about, among many other things, the role of the Federal Reserve in the American economy; the nature of consciousness; neologisms like “woke” and “Karen”; ethical quandaries in parenting; how to support one’s striking colleagues; climate change, abortion and vaccine safety; and whether or not a hot dog is a sandwich. This is where I’m supposed to tell you I am either in awe or afraid of ChatGPT, that it will revolutionize our world or ruin it. But while I do think ChatGPT illustrates some dangers of A.I., I’m reluctant to either strongly praise or condemn it. That’s because, like most cocktail party schmoozers, it has a potential for both harm and good that are, at least for now, quite limited. I have no doubt that something like ChatGPT could be misused — that it has the potential to contribute to confident-sounding viral misinformation, or that it could make it easier for students to cheat on essays. But OpenAI seems to be doing what you’d want in the release of potentially powerful technology: In an interview, Mira Murati, OpenAI’s chief technology officer, told me the company is carefully monitoring how people use and misuse it, quickly altering the system to address evident harms and iteratively improving it in response to user feedback. Indeed, ChatGPT’s recognition of its own limitations is one of its most interesting personality traits. Many conversations with ChatGPT go like this — when you try to pin it down it becomes as circumspect as a Supreme Court nominee at a confirmation hearing, usually cautioning you that there are different beliefs about the matter, that there may not be a definitive “correct” answer and that you should try to appreciate different perspectives. These answers seem wishy-washy, and the Electoral College response is just wrong — it should have said “a candidate who wins by a small",[],0.09,"['first', 'stunning', 'overwhelming', 'own', 'real', 'really', 'large', 'certainly', 'first', 'fun', 'interesting', 'surprisingly', 'many', 'ethical', 'striking', 'strongly', 'most', 'good', 'potentially', 'quickly', 'evident', 'own', 'most', 'interesting', 'many', 'wins']","['devastating', 'fails', 'usually', 'artificial', 'long', 'artificial', 'weird', 'long', 'other', 'not', 'afraid', 'least', 'limited', 'carefully', 'down', 'usually', 'wrong', 'small']"
4,Will ChatGPT Make Me Irrelevant?,"Like every other journalist I know, I often and unabashedly ask for help. Friends give me ideas. Colleagues give me phrases. Editors suggest what to keep, what to cut and where a key detail belongs. My field of vision is only so wide, my brain only so big. I’d be a fool not to supplement. But there’s a limit to how much advice I solicit, and it’s determined less by the rapid approach of a deadline or the bedlam of too many chefs than by something else, something emotional and maybe even moral, an admixture of vanity and integrity. Past a certain point of collaboration, I lose the belief that a piece of work is truly and fully mine. I lose the satisfaction of that. I can’t shake the notion that my role in the process was incidental, verging on irrelevant. I share all of this in the context of the intensifying chatter about what artificial intelligence can do — and about what, specifically, the new chatbot ChatGPT, from the company OpenAI, is already doing. It’s a surprisingly competent writer and sometimes even a clever one, to the point where early users regard it as “some mix of software and sorcery,” as Kevin Roose explained in a recent article in The Times. (The article’s headline: “The Brilliance and Weirdness of ChatGPT.”) Under the right circumstances, with the right prompt, this cyber Cyrano produces relatively seamless prose of considerable ingenuity. Educators are spooked, recognizing a specter on the horizon — no, right in front of us — that makes plagiarism look quaint. Last week, The Atlantic published an article, by Stephen Marche, titled “The College Essay Is Dead.” That was followed just three days later by another article, by Daniel Herman, titled “The End of High School English.” I figure “Curtains for the Seventh Grade” will be out next week and, fast on its heels, “Is Literacy Obsolete?” And I can tell you that here in the lofty precincts of elite academia, conversations about whether a significant fraction of students would be turning in papers generated by A.I. segued quickly into conjecture about whether professors would respond by grading those papers with A.I. Let’s take human endeavor out of the equation entirely. It’s such an inefficient, unnecessary thing. But it’s also, well, everything — not by the dictates of productivity, but by measures much more meaningful. It’s the font and province of originality. It’s the cornerstone of identity. We are what we do, and by that I don’t mean the labels affixed to our professions. I mean the stamps of our idiosyncratic contributions, no matter their nature or context. That’s how we bend the universe — our butterfly effect — and how we register that we were here. If we outsource it to A.I., don’t we erase ourselves? Maybe not. Maybe this is the cusp of a new utopia, in which machines not only assemble our appliances and perform our surgeries but also plot our novels, draft our legislation and write our op-eds while we pop our soma or chew our lotus leaves",[],0.04,"['much', 'many', 'certain', 'new', 'surprisingly', 'clever', 'early', 'right', 'right', 'relatively', 'considerable', 'high', 'fast', 'significant', 'quickly', 'much', 'meaningful', 'new']","['other', 'wide', 'less', 'past', 'irrelevant', 'artificial', 'no', 'dead', 'unnecessary', 'mean', 'mean']"
5,What Would Plato Say About ChatGPT?,"Plato mourned the invention of the alphabet, worried that the use of text would threaten traditional memory-based arts of rhetoric. In his “Dialogues,” arguing through the voice of Thamus, the Egyptian king of the gods, Plato claimed the use of this more modern technology would create “forgetfulness in the learners’ souls, because they will not use their memories,” that it would impart “not truth but only the semblance of truth” and that those who adopt it would “appear to be omniscient and will generally know nothing,” with “the show of wisdom without the reality.” If Plato were alive today, would he say similar things about ChatGPT? ChatGPT, a conversational artificial intelligence program released recently by OpenAI, isn’t just another entry in the artificial intelligence hype cycle. It’s a significant advancement that can produce articles in response to open-ended questions that are comparable to good high school essays. It is in high schools and even college where some of ChatGPT’s most interesting and troubling aspects will become clear. Essay writing is most often assigned not because the result has much value — proud parents putting good grades on the fridge aside — but because the process teaches crucial skills: researching a topic, judging claims, synthesizing knowledge and expressing it in a clear, coherent and persuasive manner. Those skills will be even more important because of advances in A.I. When I asked ChatGPT a range of questions — about the ethical challenges faced by journalists who work with hacked materials, the necessity of cryptocurrency regulation, the possibility of democratic backsliding in the United States — the answers were cogent, well reasoned and clear. It’s also interactive: I could ask for more details or request changes. But then, on trickier topics or more complicated concepts, ChatGPT sometimes gave highly plausible answers that were flat-out wrong — something its creators warn about in their disclaimers. Unless you already knew the answer or were an expert in the field, you could be subjected to a high-quality intellectual snow job. You would face, as Plato predicted, “the show of wisdom without the reality.” All this, however, doesn’t mean ChatGPT — or similar tools, because it’s not the only one of its kind — can’t be a useful tool in education. Schools have already been dealing with the internet’s wealth of knowledge, along with its lies, misleading claims and essay mills. One way has been to change how they teach. Rather than listen to a lecture in class and then go home to research and write an essay, students listen to recorded lectures and do research at home, then write essays in class, with supervision, even collaboration with peers and teachers. This approach is called flipping the classroom. In flipped classrooms, students wouldn’t use ChatGPT to conjure up a whole essay. Instead, they’d use it as a tool to generate critically examined building blocks of essays. It would be similar to how students in advanced math classes are allowed to use calculators to solve complex equations without replicating tedious, previously mastered steps. Teachers could assign a complicated topic and",[],0.14,"['more', 'modern', 'generally', 'alive', 'significant', 'good', 'high', 'high', 'most', 'interesting', 'clear', 'most', 'much', 'proud', 'good', 'clear', 'coherent', 'more', 'important', 'ethical', 'clear', 'more', 'more', 'highly', 'intellectual', 'kind', 'useful', 'whole', 'advanced']","['artificial', 'artificial', 'complicated', 'wrong', 'mean', 'complex', 'tedious', 'previously', 'complicated']"
6,Does ChatGPT Mean Robots Are Coming For the Skilled Jobs?,"Will robots take away our jobs? People have been asking that question for an astonishingly long time. The Regency-era British economist David Ricardo added to the third edition of his classic “Principles of Political Economy,” published in 1821, a chapter titled “On Machinery,” in which he tried to show how the technologies of the early Industrial Revolution could, at least initially, hurt workers. Kurt Vonnegut’s 1952 novel “Player Piano” envisaged a near-future America in which automation has eliminated most employment. At the level of the economy as a whole, the verdict is clear: So far, machines haven’t done away with the need for workers. U.S. workers are almost five times as productive as they were in the early postwar years, but there has been no long-term upward trend in unemployment: That said, technology can eliminate particular kinds of jobs. In 1948 half a million Americans were employed mining coal; the great bulk of those jobs had disappeared by the early 21st century not because we stopped mining coal — the big decline in coal production, in favor first of natural gas and then of renewable energy, started only around 15 years ago — but because strip mining and mountaintop removal made it possible to extract an increasing amount of coal with many fewer workers: It’s true that the jobs that disappear in the face of technological progress have generally been replaced by other jobs. But that doesn’t mean that the process has been painless. Individual workers may not find it easy to change jobs, especially if the new jobs are in different places. They may find their skills devalued; in some cases, as with coal, technological change can uproot communities and their way of life. This kind of dislocation has, as I said, been a feature of modern societies for at least two centuries. But something new may be happening now. In the past, the jobs replaced by technology tended to involve manual labor. Machines replaced muscles. On the one hand, industrial robots replaced routine assembly-line work. On the other hand, there has been ever-growing demand for knowledge workers, a term coined by the management consultant Peter Drucker in 1959 for people engaged in nonrepetitive problem solving. Many people, myself included, have said that we’re increasingly becoming a knowledge economy. But what if machines can take over a large chunk of what we have historically thought of as knowledge work? Last week the research company OpenAI released — to enormous buzz from tech circles — a program called ChatGPT, which can carry out what look like natural-language conversations. You can ask questions or make requests and get responses that are startlingly clear and even seem well-informed. You can also do fun things — one colleague recently asked for and received an analysis of secular stagnation in sonnet form — but let’s stick with things that might be economically useful. ChatGPT is only the latest example of technology that seems to be able to carry out tasks that not long ago seemed to require the services not just of human beings but of",[],0.12,"['classic', 'early', 'most', 'whole', 'clear', 'far', 'early', 'particular', 'great', 'early', 'first', 'natural', 'many', 'true', 'generally', 'easy', 'new', 'kind', 'modern', 'new', 'many', 'becoming', 'large', 'startlingly', 'fun', 'economically', 'latest', 'able', 'not']","['astonishingly', 'least', 'half', 'other', 'mean', 'least', 'past', 'other']"
