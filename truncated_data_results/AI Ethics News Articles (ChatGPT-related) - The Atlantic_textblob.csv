,titles,body_contents,tags,sentiment_score,positive_words,negative_words
0,ChatGPT Changed Everything. Now Its Follow-Up Is Here.,"Less than four months after releasing ChatGPT, the text-generating AI that seems to have pushed us into a science-fictional age of technology, OpenAI has unveiled a new product called GPT-4. Rumors and hype about this program have circulated for more than a year: Pundits have said that it would be unfathomably powerful, writing 60,000-word books from single prompts and producing videos out of whole cloth. Today’s announcement suggests that GPT-4’s abilities, while impressive, are more modest: It performs better than the previous model on standardized tests and other benchmarks, works across dozens of languages, and can take images as input—meaning that it’s able, for instance, to describe the contents of a photo or a chart. Unlike ChatGPT, this new model is not currently available for public testing (although you can apply or pay for access), so the obtainable information comes from OpenAI’s blog post, and from a New York Times story based on a demonstration. From what we know, relative to other programs, GPT-4 appears to have added 150 points to its SAT score, now a 1410 out of 1600, and jumped from the bottom to the top 10 percent of performers on a simulated bar exam. Despite pronounced fears of AI’s writing, the program’s AP English scores remain in the bottom quintile. And while ChatGPT can handle only text, in one example, GPT-4 accurately answered questions about photographs of computer cables. Image inputs are not publicly available yet, even to those eventually granted access off the waitlist, so it’s not possible to verify OpenAI’s claims. The new GPT-4 model is the latest in a long genealogy—GPT-1, GPT-2, GPT-3, GPT-3.5, InstructGPT, ChatGPT—of what are now known as “large language models,” or LLMs, which are AI programs that learn to predict what words are most likely to follow each other. These models work under a premise that traces its origins to some of the earliest AI research in the 1950s: that a computer that understands and produces language will necessarily be intelligent. That belief underpinned Alan Turing’s famous imitation game, now known as the Turing Test, which judged computer intelligence by how “human” its textual output read. Those early language AI programs involved computer scientists deriving complex, hand-written rules, rather than the deep statistical inferences used today. Precursors to contemporary LLMs date to the early 2000s, when computer scientists began using a type of program inspired by the human brain called a “neural network,” which consists of many interconnected layers of artificial nodes that process huge amounts of training data, to analyze and generate text. The technology has advanced rapidly in recent years thanks to some key breakthroughs, notably programs’ increased attention spans—GPT-4 can make predictions based on not just the previous phrase but many words prior, and weigh the importance of each word differently. Today’s LLMs read books, Wikipedia entries, social-media posts, and countless other sources to find these deep statistical patterns; OpenAI has also started using human researchers to fine-tune its models’ outputs. As a result, GPT-4 and similar programs have a remarkable facility with language, writing short stories and essays",[],0.13,"['new', 'more', 'powerful', 'whole', 'impressive', 'more', 'modest', 'better', 'able', 'new', 'new', 'top', 'accurately', 'new', 'latest', 'large', 'most', 'necessarily', 'famous', 'early', 'contemporary', 'early', 'many', 'huge', 'advanced', 'thanks', 'notably', 'many', 'remarkable']","['less', 'single', 'previous', 'other', 'not', 'other', 'not', 'long', 'other', 'imitation', 'game', 'complex', 'artificial', 'previous', 'other']"
1,We Programmed ChatGPT Into This Article. It’s Weird.,"ChatGPT, the internet-famous AI text generator, has taken on a new form. Once a website you could visit, it is now a service that you can integrate into software of all kinds, from spreadsheet programs to delivery apps to magazine websites such as this one. Snapchat added ChatGPT to its chat service (it suggested that users might type “Can you write me a haiku about my cheese-obsessed friend Lukas?”), and Instacart plans to add a recipe robot. Many more will follow. They will be weirder than you might think. Instead of one big AI chat app that delivers knowledge or cheese poetry, the ChatGPT service (and others like it) will become an AI confetti bomb that sticks to everything. AI text in your grocery app. AI text in your workplace-compliance courseware. AI text in your HVAC how-to guide. AI text everywhere—even later in this article—thanks to an API. API is one of those three-letter acronyms that computer people throw around. It stands for “application programming interface”: It allows software applications to talk to one another. That’s useful because software often needs to make use of the functionality from other software. An API is like a delivery service that ferries messages between one computer and another. Despite its name, ChatGPT isn’t really a chat service—that’s just the experience that has become most familiar, thanks to the chatbot’s pop-cultural success. “It’s got chat in the name, but it’s really a much more controllable model,” Greg Brockman, OpenAI’s co-founder and president, told me. He said the chat interface offered the company and its users a way to ease into the habit of asking computers to solve problems, and a way to develop a sense of how to solicit better answers to those problems through iteration. But chat is laborious to use and eerie to engage with. “You don’t want to spend your time talking to a robot,” Brockman said. He sees it as “the tip of an iceberg” of possible future uses: a “general-purpose language system.” That means ChatGPT as a service (rather than a website) may mature into a system of plumbing for creating and inserting text into things that have text in them. As a writer for a magazine that’s definitely in the business of creating and inserting text, I wanted to explore how The Atlantic might use the ChatGPT API, and to demonstrate how it might look in context. The first and most obvious idea was to create some kind of chat interface for accessing magazine stories. Talk to The Atlantic, get content. So I started testing some ideas on ChatGPT (the website) to explore how we might integrate ChatGPT (the API). One idea: a simple search engine that would surface Atlantic stories about a requested topic. But when I started testing out that idea, things quickly went awry. I asked ChatGPT to “find me a story in The Atlantic about tacos,” and it obliged, offering a story by my colleague Amanda Mull, “The Enduring Appeal of Tacos,” along with a link and a summary (it began: “In this article, writer Amanda",[],0.2,"['new', 'many', 'more', 'useful', 'really', 'most', 'familiar', 'thanks', 'success', 'really', 'better', 'mature', 'first', 'most', 'kind', 'quickly']","['other', 'eerie']"
2,A Chatbot Is Secretly Doing My Job,"I have a part-time job that is quite good, except for one task I must do—not even very often, just every other week—that I actively loathe. The task isn’t difficult, and it doesn’t take more than 30 minutes: I scan a long list of short paragraphs about different people and papers from my organization that have been quoted or cited in various publications and broadcasts, pick three or four of these items, and turn them into a new, stand-alone paragraph, which I am told is distributed to a small handful of people (mostly board members) to highlight the most “important” press coverage from that week. Four weeks ago, I began using AI to write this paragraph. The first week, it took about 40 minutes, but now I’ve got it down to about five. Only one colleague knows I’ve been doing this; we used to switch off writing this blurb, but since it’s become so quick and easy and, frankly, interesting, I’ve taken over doing it every week. The process itself takes place within OpenAI’s “Playground” feature, which offers similar functionality as the company’s ChatGPT product. The Playground presents as a blank page, not a chat, and is therefore better at shaping existing words into something new. I write my prompt at the top, which always begins with something like “Write a newspaper-style paragraph out of the following.” Then, I paste below my prompt the three or four paragraphs I selected from the list and—this is crucial, I have learned—edit those a touch, to ensure that the machine “reads” them properly. Sometimes that means placing a proper noun closer to a quote, or doing away with an existing headline. Perhaps you’re thinking, This sounds like work too, and it is—but it’s quite a lot of fun to refine my process and see what the machine spits out at the other end. I like to think that I’ve turned myself from the meat grinder into the meat grinder’s minder—or manager. I keep waiting to be found out, and I keep thinking that somehow the copy will reveal itself for what it is. But I haven’t, and it hasn’t, and at this point I don’t think I or it ever will (at least, not until this essay is published). Which has led me to a more interesting question: Does it matter that I, a professional writer and editor, now secretly have a robot doing part of my job? I’ve surprised myself by deciding that, no, I don’t think it matters at all. This in turn has helped clarify precisely what it was about the writing of this paragraph that I hated so much in the first place. I realized that what I was doing wasn’t writing at all, really—it was just generating copy. Copy is everywhere. There’s a very good chance that even you, dear reader, are encountering copy as you read this: in the margins, between the paragraph breaks, beyond this screen, or in another window, always hovering, in ads or emails—the wordy white noise of our existence. ChatGPT and the Playground are quite",[],0.13,"['good', 'very', 'more', 'new', 'mostly', 'most', 'important', 'first', 'quick', 'easy', 'interesting', 'offers', 'better', 'new', 'top', 'fun', 'more', 'interesting', 'professional', 'surprised', 'precisely', 'much', 'first', 'very']","['other', 'actively', 'difficult', 'long', 'small', 'down', 'other', 'least', 'secretly', 'hated']"
3,What Poets Know That ChatGPT Doesn’t,"One of the least discussed aspects of the AI language generator ChatGPT might be its ability to produce pretty awful poetry. Given how difficult it is to teach a computer how to recognize a syllable, I’m not disparaging the technical prowess of the chatbot’s creators and testers. But very few of the AI-produced poems I’ve read actually follow the prompt that’s been provided. “Write a poem in the style of Seamus Heaney”? This is not that poem: In a garden green and fair, A flower blooms, a sight so rare. But is it meant for me, I fear? Will I, like it, bloom this year? Odds are good that this poem, titled “Is It for Me?,” will not win the National Poetry Series. The final phrase seems plucked from T. S. Eliot’s “The Waste Land,” which gives the last line an unintended comic air, because Eliot is referring to a corpse. Poetry, with its heightened states of emotion, intimate address, ecstatic proclamation, and enchanting song, would seem to be one of the limit cases that prove the point: ChatGPT can write anything we can write. It can indeed compose poems from prompts such as “write a poem about the estate tax.” Asked to write a sonnet about socks, it will produce a poem with the opening line “Oh socks, my trusty companions on my feet.” Such goofy attempts could be said to emulate praise poetry, that venerable form of ode-making. They could just as well have been spoken by Brick Tamland, Steve Carell’s character in Anchorman, who is prone to spouting cryptic one-liners—including, famously, “I love lamp.” (As a teacher of poetry, I can’t help but imagine an overly eager chatbot in one of my creative-writing workshops in the year 2030. “Do you really love the lamp,” I picture myself asking it, “or are you just saying that because you saw it?”) Heaney wrote a poem about the death of his mother called “Clearances” that—like the AI-generated “Is It for Me?”—also uses rhyme, meter, and nature imagery: I thought of walking round and round a space Utterly empty, utterly a source Where the decked chestnut tree had lost its place In our front hedge above the wallflowers. The difference between ChatGPT’s Heaney-esque poem and Heaney’s actual poem is not simply that one is bad and one is good, or that one is sentimental and one is elegiacally beautiful. The difference is that Heaney lost his mother, and the poem expresses the emotional urgency of this fact during a reflective moment sometime after the event. Heaney’s poem carries the ineffable sense that the poet has not only pillaged from the horde of words that already exist but has also worked on them himself, claiming them partly as his and partly as a treasure loaned to him from centuries of poetry written in English. I could point to other aspects of the language: the pause in the second line, the similarity between the sounds of decked and chest-, the lingering syllables of wallflowers. Above all, there’s the mystery of the mourning poet’s meditation—that missing",[],0.02,"['pretty', 'fair', 'rare', 'good', 'comic', 'intimate', 'goofy', 'famously', 'really', 'good', 'beautiful']","['least', 'awful', 'difficult', 'very', 'green', 'not', 'waste', 'round', 'round', 'utterly', 'bad', 'sentimental', 'other', 'missing']"
4,What ChatGPT Can’t Teach My Writing Students,"As the first student papers of the academic semester come rolling in, college and high-school teachers are expressing concern about ChatGPT, the artificial-intelligence interface that responds to queries with competent, if boring, paragraphs. It seems to open up whole new vistas of academic dishonesty, and it calls into question how and why we teach writing at all. A professor at the University of Pennsylvania's Wharton School has said that ChatGPT’s answers to his operations-management class would have earned a B or B–. That seems about right; if a student in my first-year writing class had turned in a ChatGPT-generated essay last semester (and for all I know, someone did), they would have easily passed. The fact is, boring competence is better than what some high-school or college graduates attain, and it’s all most people, in their daily lives, need their writing to be. If, in a few years, AI can do a passable job at most adult writing tasks—sharing information, telling quick stories, apologizing for the delay, and expressing a hope that all is well—then why spend so much time in school learning the maddening complexities of English prose? Surely there are more important things to study than subject-verb agreement, comma splices, and transition sentences. But learning to write is about more than learning to write. For one thing, it’s about learning to turn a loose assemblage of thoughts into a clear line of reasoning—a skill that is useful for everyone, not just those who enjoy writing or need to do a lot of it for work. Just as important, learning to write trains your imagination to construct the person who will read your words. Writing, then, is an ethical act. It puts you in relation to someone you may not know, someone who may, in fact, not yet exist. When you learn to write, you learn to exercise your responsibility to that person, to meet their needs in a context you cannot fully know. That might sound like a lofty goal for a paper about, for instance, the major causes of the American Revolution. But even that bog-standard assignment can get students to anticipate what another person knows and expects. You wouldn’t write the same essay to a veterans’ group as you would to new immigrants. Writing is never simply self-expression. It’s expression to a specific audience for a specific purpose. In some cases, like a love letter, a writer knows their audience intimately. In others, the audience is every bit a work of the imagination as a novel’s characters are. Great writers have known this truth for centuries. Nathaniel Hawthorne writes in the introduction to The Scarlet Letter that “when he casts his leaves forth upon the wind, the author addresses, not the many who will fling aside his volume, or never take it up, but the few who will understand him, better than most of his schoolmates and lifemates.” Writers, then, should give up trying to address the public at large, but should “imagine that a friend, a kind and apprehensive, though not the closest friend, is listening to",[],0.19,"['first', 'competent', 'whole', 'new', 'right', 'easily', 'better', 'most', 'most', 'adult', 'quick', 'much', 'surely', 'more', 'important', 'more', 'clear', 'useful', 'enjoy', 'important', 'ethical', 'sound', 'major', 'new', 'love', 'intimately', 'great', 'many', 'better', 'most', 'large', 'kind']","['boring', 'boring', 'few', 'loose', 'few']"
5,ChatGPT Is About to Dump More Work on Everyone,"Have you been worried that ChatGPT, the AI language generator, could be used maliciously—to cheat on schoolwork or broadcast disinformation? You’re in luck, sort of: OpenAI, the company that made ChatGPT, has introduced a new tool that tries to determine the likelihood that a chunk of text you provide was AI-generated. I say “sort of” because the new software faces the same limitations as ChatGPT itself: It might spread disinformation about the potential for disinformation. As OpenAI explains, the tool will likely yield a lot of false positives and negatives, sometimes with great confidence. In one example, given the first lines of the Book of Genesis, the software concluded that it was likely to be AI-generated. God, the first AI. On the one hand, OpenAI appears to be adopting a classic mode of technological solutionism: creating a problem, and then selling the solution to the problem it created. But on the other hand, it might not even matter if either ChatGPT or its antidote actually “works,” whatever that means (in addition to its limited accuracy, the program is effective only on English text and needs at least 1,000 characters to work with). The machine-learning technology and others like it are creating a new burden for everyone. Now, in addition to everything else we have to do, we also have to make time for the labor of distinguishing between human and AI, and the bureaucracy that will be built around it. If you are a student, parent, educator, or individual with internet access, you may have caught wind of the absolute panic that has erupted around ChatGPT. There are fears—It’s the end of education as we know it! It passed a Wharton MBA exam!—and retorts to those fears: We must defend against rampant cheating. If your class can be gamed by an AI, then it was badly designed in the first place! An assumption underlies all these harangues, that education needs to “respond” to ChatGPT, to make room for and address it. At the start of this semester at Washington University in St. Louis, where I teach, our provost sent all faculty an email encouraging us to be aware of the technology and consider how to react to it. Like many institutions, ours also hosted a roundtable to discuss ChatGPT. In a matter of months, generative AI has sent secondary and postsecondary institutions scrambling to find a response—any response—to its threats or opportunities. That work heaps atop an already overflowing pile of duties. Budgets cut, schoolteachers often crowdsource funds and materials for their classrooms. The coronavirus pandemic changed assumptions about attendance and engagement, making everyone renegotiate, sometimes weekly, where and when class will take place. Managing student anxiety and troubleshooting broken classroom technology is now a part of most teachers’ everyday work. That’s not to mention all the emails, and the training modules, and the self-service accounting tasks. And now comes ChatGPT, and ChatGPT’s flawed remedy. The situation extends well beyond education. Almost a decade ago, I diagnosed a condition I named hyperemployment. Thanks to computer technology, most professionals now work a lot",[],0.06,"['new', 'new', 'great', 'first', 'first', 'classic', 'effective', 'new', 'absolute', 'first', 'aware', 'many', 'most', 'thanks', 'most']","['tries', 'false', 'other', 'limited', 'least', 'badly', 'secondary', 'broken', 'everyday', 'flawed']"
6,How ChatGPT Will Destabilize White-Collar Work,"In the next five years, it is likely that AI will begin to reduce employment for college-educated workers. As the technology continues to advance, it will be able to perform tasks that were previously thought to require a high level of education and skill. This could lead to a displacement of workers in certain industries, as companies look to cut costs by automating processes. While it is difficult to predict the exact extent of this trend, it is clear that AI will have a significant impact on the job market for college-educated workers. It will be important for individuals to stay up to date on the latest developments in AI and to consider how their skills and expertise can be leveraged in a world where machines are increasingly able to perform many tasks. There you have it, I guess: ChatGPT is coming for my job and yours, according to ChatGPT itself. The artificially intelligent content creator, whose name is short for “Chat Generative Pre-trained Transformer,” was released two months ago by OpenAI, one of the country’s most influential artificial-intelligence research laboratories. The technology is, put simply, amazing. It generated that first paragraph instantly, working with this prompt: “Write a five-sentence paragraph in the style of The Atlantic about whether AI will begin to reduce employment for college-educated workers in the next five years.” ChatGPT is just one of many mind-blowing generative AI tools released recently, including the image generators Midjourney and DALL-E and the video generator Synthesia. The upside of these AI tools is easy to see: They’re going to produce a tremendous amount of digital content, quickly and cheaply. Students are already using ChatGPT to help them write essays. Businesses are using ChatGPT to create copy for their websites and promotional materials, and to respond to customer-service inquiries. Lawyers are using it to produce legal briefs (ChatGPT passes the torts and evidence sections of the Multistate Bar Examination, by the way) and academics to produce footnotes. Yet an extraordinary downside is also easy to see: What happens when services like ChatGPT start putting copywriters, journalists, customer-service agents, paralegals, coders, and digital marketers out of a job? For years, tech thinkers have been warning that flexible, creative AI will be a threat to white-collar employment, as robots replace skilled office workers whose jobs were once considered immune to automation. In the most extreme iteration, analysts imagine AI altering the employment landscape permanently. One Oxford study estimates that 47 percent of U.S. jobs might be at risk. No single technology in modern memory has caused mass job loss among highly educated workers. Will generative AI really be an exception? No one can answer this question, given how new the technology is and given how slowly employment can adjust in response to technological change. But AI really is different, technology experts told me—a range of tasks that up until now were impossible to automate are becoming automatable. “Before, progress was linear and predictable. You figured out the steps and the computer followed them. It followed the procedure; it didn’t learn and it didn’t improvise,”",[],0.2,"['able', 'high', 'certain', 'exact', 'clear', 'significant', 'important', 'latest', 'able', 'many', 'artificially', 'most', 'simply', 'first', 'many', 'easy', 'tremendous', 'quickly', 'cheaply', 'legal', 'extraordinary', 'easy', 'creative', 'skilled', 'most', 'no', 'modern', 'highly', 'really', 'new', 'becoming']","['previously', 'difficult', 'extreme', 'slowly', 'impossible', 'predictable']"
7,A Chatbot’s Predictions for the Future of AI,"Question of the Week To complete this week’s question I had a conversation with OpenAI’s chatbot, GPT-3 (which anyone can try). “Every week I ask readers of my newsletter a different question,” I wrote. “Would you compose this week’s question on the subject of AI, choosing one that is likely to elicit the highest number of interesting responses?” GPT-3 responded, in part, with this suggestion: Sure! Here is a question that might elicit a high number of interesting responses: How do you think AI will change the way we live and work in the next decade? This question seems like asking, circa 1995, how the internet would change the way we live and work. When you respond, know that people of the future will look back with interest on your predictions! Conversations of Note In addition to prompting GPT-3 to generate this week’s question, I interviewed it about the other OpenAI tool that I’ve been testing out, DALL-E, an artificial-intelligence program capable of generating original images from text descriptions. “It has the potential to significantly improve the efficiency of image creation,” GPT-3 told me, with applications in advertising, design, entertainment, art work, and other creative enterprises. As an example, I asked DALL-E to generate images of four Looney Tunes characters as if they were starring in a Wes Anderson movie. Here is the star-studded cast: Yosemite Sam: Bugs Bunny: Wile E. Coyote: And the Roadrunner: I also asked DALL-E to generate Michael Jordan posters in different styles. Here’s one in the style of Jackson Pollock: Just as interesting were the results when I deployed a trick I picked up at a recent Atlantic event in Los Angeles: asking the text-based ChatGPT to help write better prompts for an image-generating AI. For example, say I was trying to come up with ideas to decorate my living room. If I ask DALL-E to generate “a living room that would be good for reading in” I get this: Whereas if I ask GPT-3 to help me to write a better prompt for DALL-E, I get this: “Show me a living room with comfortable seating, good lighting, and plenty of shelving for books, that would be the perfect place to relax and get lost in a good book. Include a fireplace, a view of the outdoors, and a quiet and peaceful atmosphere.” Pasting that into DALL-E generates this: You can play with DALL-E on your own, too, and if you do you’ll quickly discover how expansive its potential use cases are. I’ll be eager to hear your various thoughts by email. My prediction is that, for a long stretch of time to come, the use of text and image content generated by AI platforms plus human prompts will outstrip that by AI alone, or by humans alone, across many applications. Is Writing Still an Important Skill to Learn? Daniel Herman, who teaches various high-school humanities classes, reflects in The Atlantic on advances in artificial intelligence that can “generate sophisticated text in response to any prompt you can imagine.” The technology “may signal the end of writing",[],0.24,"['complete', 'interesting', 'sure', 'high', 'interesting', 'live', 'live', 'capable', 'original', 'significantly', 'creative', 'interesting', 'better', 'good', 'better', 'comfortable', 'good', 'perfect', 'good', 'peaceful', 'own', 'quickly', 'many', 'important', 'sophisticated']","['subject', 'other', 'other', 'long', 'artificial']"
8,Money Will Kill ChatGPT’s Magic,"Arthur C. Clarke once remarked, “Any sufficiently advanced technology is indistinguishable from magic.” That ambient sense of magic has been missing from the past decade of internet history. The advances have slowed. Each new tablet and smartphone is only a modest improvement over its predecessor. The expected revolutions—the metaverse, blockchain, self-driving cars—have plodded along, always with promises that the real transformation is just a few years away. The one exception this year has been in the field of generative AI. After years of seemingly false promises, AI got startlingly good in 2022. It began with the AI image generators DALL-E 2, Midjourney, and Stable Diffusion. Overnight, people started sharing AI artwork they had generated for free by simply typing a prompt into a text box. Some of it was weird, some was trite, and some was shockingly good. All of it was unmistakably new terrain. That sense of wonderment accelerated last month with the release of OpenAI’s ChatGPT. It’s not the first AI chatbot, and it certainly won’t be the last, but its intuitive user interface and overall effectiveness leave the collective impression that the future is arriving. Professors are warning that this will be the end of the college essay. Twitter users (in a brief respite from talking about Elon Musk) are sharing delightful examples of genuinely clever writing. A common refrain: “It was like magic.” ChatGPT is free, for now. But OpenAI’s CEO Sam Altman has warned that the gravy train will eventually come to a screeching halt: “We will have to monetize it somehow at some point; the compute costs are eye-watering,” he tweeted. The company, which expects to make $200 million in 2023, is not a charity. Although OpenAI launched as a nonprofit in 2015, it jettisoned that status slightly more than three years later, instead setting up a “capped profit” research lab that is overseen by a nonprofit board. (OpenAI’s backers have agreed to make no more than 100 times what they put into the company—a mere pittance if you expect its products to one day take over the entire global economy.) Microsoft has already poured $1 billion into the company. You can just imagine a high-octane Clippy powered by ChatGPT. Making the first taste free, so to speak, has been a brilliant marketing strategy. In the weeks since its release, more than a million users have reportedly given ChatGPT a whirl, with OpenAI footing the bill. And between the spring 2022 release of DALL-E 2, the current attention on ChatGPT, and the astonished whispers about GPT-4, an even more advanced text-based AI program supposedly arriving next year, OpenAI is well on its way to becoming the company most associated with shocking advances in consumer-facing AI. What Netflix is to streaming video and Google is to search, OpenAI might become for deep learning. How will the use of these tools change as they become profit generators instead of loss leaders? Will they become paid-subscription products? Will they run advertisements? Will they power new companies that undercut existing industries at lower costs? We can draw some lessons from",[],0.15,"['advanced', 'magic', 'magic', 'new', 'modest', 'real', 'startlingly', 'free', 'shockingly', 'new', 'first', 'certainly', 'delightful', 'genuinely', 'magic', 'free', 'slightly', 'first', 'free', 'brilliant', 'more', 'more', 'advanced', 'becoming', 'most', 'new']","['missing', 'past', 'expected', 'few', 'false', 'weird', 'common', 'no', 'mere', 'shocking']"
9,Five Remarkable Chats That Will Help You Understand ChatGPT,"Move over Siri and Alexa, there’s a new AI in town and it’s ready to steal the show—or at least make you laugh with its clever quips and witty responses. That is how ChatGPT, the powerful chatbot released last week by the AI company OpenAI, suggested that I begin this story about ChatGPT. The chatbot isn’t exactly new; it’s an updated version of GPT-3, which has been around since 2020, released to solicit feedback to improve the chatbot’s safety and functionality. But it is the most powerful to date to be made widely available to the public. It’s also very easy to use. Just write a message, and ChatGPT will write back. Because it was trained on massive amounts of conversational text, it will do so in a relatively natural, conversational tone. True to its claim, ChatGPT has stolen the show this week. Within five days of its launch, its user count had broken 1 million. Social media has been flooded with screenshots of people’s coolest or weirdest or dumbest or most troubling conversations with the AI, which reliably serves up a mix of astoundingly humanlike prose and frequently hilarious nonsense. Limericks about otters. Recipes written in pirate-speak. Obituaries for co-workers who are alive and well. “At one recent gathering, ChatGPT was the life of the party,” ChatGPT wrote as part of a draft for this article. “As guests mingled and chatted, ChatGPT joined in the conversation, offering up clever jokes and one-liners that had everyone in stitches.” Along with the screenshots has come a frenzy of speculation about what this latest development could augur for the future. Unlike previous iterations, ChatGPT remembers what users have told it in the past: Could it function as a therapist? Could it soon render Google obsolete? Could it render all white-collar work obsolete? Maybe. But for now, in practice, ChatGPT is mainly a meme machine. Some examples posted online show people using the AI to accomplish a task they needed done, but those examples are the exception. So far, most people are using the AI to produce something expressly to share the results, something to scare or amuse or impress others. Here, culled from the deluge, are a handful of the best chats out there. Some are funny. Some are touching. Some are troubling. Each is instructive in some way. Together, I hope, they’ll give you a bit of a feel for this strange new technology. Sandwich VCR I’m sorry, I simply cannot be cynical about a technology that can accomplish this. — Thomas H. Ptacek (@tqbf) December 2, 2022 This one is already a viral classic. “I’m sorry,” the writer of the prompt tweeted. “I simply cannot be cynical about a technology that can accomplish this.” But what exactly did it accomplish? Many have cited the VCR-sandwich story as evidence of ChatGPT’s capacity for creativity, but the truth is that the real creativity here is in the prompt. A sandwich in a VCR? In the style of the King James Bible? Brilliant. ChatGPT nails this parody and does so orders of magnitude faster than",[],0.16,"['new', 'ready', 'laugh', 'clever', 'witty', 'powerful', 'exactly', 'most', 'powerful', 'widely', 'very', 'relatively', 'true', 'social', 'most', 'astoundingly', 'frequently', 'alive', 'clever', 'latest', 'mainly', 'far', 'most', 'best', 'funny', 'touching', 'new', 'classic', 'exactly', 'many', 'real', 'brilliant']","['least', 'broken', 'previous', 'past', 'strange', 'sorry', 'cynical', 'sorry', 'cynical']"
10,ChatGPT Is Dumber Than You Think,"As a critic of technology, I must say that the enthusiasm for ChatGPT, a large-language model trained by OpenAI, is misplaced. Although it may be impressive from a technical standpoint, the idea of relying on a machine to have conversations and generate responses raises serious concerns. First and foremost, ChatGPT lacks the ability to truly understand the complexity of human language and conversation. It is simply trained to generate words based on a given input, but it does not have the ability to truly comprehend the meaning behind those words. This means that any responses it generates are likely to be shallow and lacking in depth and insight. Furthermore, the reliance on ChatGPT for conversation raises ethical concerns. If people begin to rely on a machine to have conversations for them, it could lead to a loss of genuine human connection. The ability to connect with others through conversation is a fundamental aspect of being human, and outsourcing that to a machine could have detrimental side effects on our society. Hold up, though. I, Ian Bogost, did not actually write the previous three paragraphs. A friend sent them to me as screenshots from his session with ChatGPT, a program released last week by OpenAI that one interacts with by typing into a chat window. It is, indeed, a large language model (or LLM), a type of deep-learning software that can generate new text once trained on massive amounts of existing written material. My friend’s prompt was this: “Create a critique of enthusiasm for ChatGPT in the style of Ian Bogost.” ChatGPT wrote more, but I spared you the rest because it was so boring. The AI wrote another paragraph about accountability (“If ChatGPT says or does something inappropriate, who is to blame?”), and then a concluding paragraph that restated the rest (it even began, “In conclusion, …”). In short, it wrote a basic, high-school-style five-paragraph essay. That fact might comfort or frighten you, depending on your predilections. When OpenAI released ChatGPT to the public last week, the first and most common reaction I saw was fear that it would upend education. “You can no longer give take-home exams,” Kevin Bryan, a University of Toronto professor, posted on Twitter. “I think chat.openai.com may actually spell the end of writing assignments,” wrote Samuel Bagg, a University of South Carolina political scientist. That’s the fear. But you may find comfort in knowing that the bot’s output, while fluent and persuasive as text, is consistently uninteresting as prose. It’s formulaic in structure, style, and content. John Warner, the author of the book Why They Can’t Write, has been railing against the five-paragraph essay for years and wrote a Twitter thread about how ChatGPT reflects this rules-based, standardized form of writing: “Students were essentially trained to produce imitations of writing,” he tweeted. The AI can generate credible writing, but only because writing, and our expectations for it, has become so unaspiring. Even pretending to fool the reader by passing off an AI copy as one’s own, like I did above, has become a tired trope, an expected",[],0.04,"['impressive', 'first', 'ethical', 'genuine', 'large', 'new', 'more', 'first', 'most', 'consistently', 'credible', 'own']","['misplaced', 'serious', 'behind', 'shallow', 'previous', 'boring', 'common', 'tired', 'expected']"
