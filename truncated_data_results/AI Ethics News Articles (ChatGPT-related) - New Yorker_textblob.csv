,titles,body_contents,tags,sentiment_score,positive_words,negative_words
0,I Have Questions for ChatGPT,"ChatGPT enables users to ask questions or tell a story, and the bot will respond with relevant, natural-sounding answers and topics. —Quoted in Forbes. Hi, Chat, A friend gifted me a fancy designer bucket hat that she swore she didn’t want anymore. Then we had a misunderstanding, and she ghosted my birthday party. Then I blocked her. And put a potato in her tailpipe. And slept with her ex. Can our friendship be saved? If not, do I have to give back the hat? why are there suddenly so many different kinds of Oreos? What are Birthday Cake Flavor Creme Oreos really like? Occasionally sampling a blueberry in the produce section is one thing—and, before you say a word, have you seen the price of blueberries lately? If I’m plunking down eight dollars on a container of jumbo organic blueberries, I’m making sure they’re worth it. But I can’t have a full package of Birthday Cake Flavor Creme Oreos hanging around the house because the manager made me buy the whole bag again. So, are they like Golden Oreos? Because—pro tip for you, Chat—Golden Oreos are just O.K. why didn’t I go to Oberlin? should I paint the small bathroom Benjamin Moore’s Antique Pearl or Venetian Marble? The swatches have been taped up for months, but you know how color changes with the light—of course you do!—so it’s been hard to decide. One shade is a little cooler, one a little warmer. My family refuses to discuss it any further, and they’ve begun to (unfairly) characterize my gentle queries every time they come out of the small bathroom as “gotcha” questions. They’ve actually stopped using the small bathroom altogether, which is fine, because none of them remember to jiggle the handle just so (even though I posted a detailed schematic on the wall and have shown them how to do it numerous times). So the color choice is up to me, but I could use a second opinion. What do you think? once, when I was sixteen and was walking along a tree-lined street in the Village with my mom, we saw Matthew Broderick on the sidewalk, and she told me to go up to him and say hi, and I was mortified because . . . who does that? He probably would have been really nice about it. He wasn’t even with what’s-her-face yet. Why didn’t I just do it? Maybe I would have said something clever, and he would have laughed, and now I’d be living with him and our adorable children in our adorable brownstone on that adorable tree-lined street. Not that I care anymore, but my mom wants to know: Why didn’t I listen to her? why did I read both “A Gentleman in Moscow” and “The Lincoln Highway” when I didn’t really like “Rules of Civility”? why didn’t I get those expensive boots from that shop on Fifty-fifth Street all those years ago? I really wanted them, and I bet I’d still have them, and they’d be perfectly broken in by now and be the kind of",[],0.13,"['relevant', 'gifted', 'suddenly', 'really', 'sure', 'worth', 'full', 'whole', 'golden', 'gentle', 'fine', 'detailed', 'really', 'clever', 'laughed', 'adorable', 'adorable', 'adorable', 'wants', 'really', 'really', 'kind']","['lately', 'down', 'small', 'hard', 'little', 'little', 'unfairly', 'small', 'small', 'expensive', 'perfectly']"
1,How ChatGPT Will Strain a Political System in Peril,"In November, OpenAI introduced ChatGPT, a large language model that can generate text that gives the impression of human intelligence, spontaneity, and surprise. Users of ChatGPT have described it as a revolutionary technology that will change every aspect of how we interact with text and with one another. Joshua Rothman, the ideas editor of newyorker.com, joins Tyler Foggatt to talk about the many ways that ChatGPT may be deployed in the realm of politics—from campaigning and lobbying to governance. American political life has already been profoundly altered by the Internet, and the effects of ChatGPT, Rothman says, could be even more profound.",[],0.17,"['large', 'many', 'profoundly', 'more', 'profound']",[]
2,“It’s Not Possible for Me to Feel or Be Creepy”: An Interview with ChatGPT,"Between Christmas and New Year’s, my family took a six-hour drive to Vermont. I drove; my wife and two children sat in the back seat. Our children are five and two—too old to be hypnotized by a rattle or a fidget spinner, too young to entertain themselves—so a six-hour drive amounted to an hour of napping, an hour of free association and sing-alongs, and four hours of desperation. We offered the kids an episode of their favorite storytelling podcast, but they weren’t in the mood for something prerecorded. They wanted us to invent a new story, on the spot, tailored to their interests. And their interests turned out to be pretty narrow. “Tell one about the Ninja Turtles fighting Smasher Venom, a villain I just made up who is the size of a skyscraper,” the five-year-old said. “With lots of details about how the Turtles use their weapons and work together to defeat the bad guy, and how he gets hurt but doesn’t die.” My wife tried improvising a version of this story; then I tried one. The children had notes. Our hearts weren’t in it. It was obvious that our supply of patience for this exercise would never match their demand. Three and a half hours to go. My wife took out her phone and opened ChatGPT, a chatbot that “interacts in a conversational way.” She typed in the prompt, basically word for word, and, within seconds, ChatGPT spat out a story. We didn’t need to tell it the names of the Teenage Mutant Ninja Turtles, or which weapons they used, or how they felt about anchovies on their pizza. More impressive, we didn’t need to tell it what a story was, or what kind of conflict a child might find narratively satisfying. We repeated the experiment many times, adding and tweaking details. (The bot remembers your chat history and understands context, so you don’t have to repeat the whole prompt each time; you can just tell it to repeat the same story but make Raphael surlier, or have Smasher Venom poison the water supply, or set the story in Renaissance Florence, or do it as a film noir.) My wife, trying to assert a vestige of parental influence, ended some of the prompts with “And, in the end, they all learned a valuable lesson about kindness.” We ran the results through a text-to-speech app, to avoid car sickness, and the time pleasantly melted away. My wife took a nap. I put in an earbud and listened to a podcast about the A.I. revolution that was on its way, or that was arguably already here. ChatGPT is a free public demo that the artificial-intelligence company OpenAI put out in late November. (The company also has several other projects in development, including dall-e.) We’ve known for a while that this sort of A.I. chatbot was coming, but this is the first time that anything this powerful has been released into the wild. It’s a large language model trained on a huge corpus of text that apparently included terabytes of books and Reddit",[],0.18,"['new', 'old', 'young', 'free', 'favorite', 'new', 'pretty', 'more', 'impressive', 'kind', 'satisfying', 'many', 'whole', 'pleasantly', 'free', 'first', 'powerful', 'wild', 'large', 'huge', 'apparently']","['narrow', 'bad', 'half', 'late', 'other']"
3,ChatGPT Is a Blurry JPEG of the Web,"In 2013, workers at a German construction company noticed something odd about their Xerox photocopier: when they made a copy of the floor plan of a house, the copy differed from the original in a subtle but significant way. In the original floor plan, each of the house’s three rooms was accompanied by a rectangle specifying its area: the rooms were 14.13, 21.11, and 17.42 square metres, respectively. However, in the photocopy, all three rooms were labelled as being 14.13 square metres in size. The company contacted the computer scientist David Kriesel to investigate this seemingly inconceivable result. They needed a computer scientist because a modern Xerox photocopier doesn’t use the physical xerographic process popularized in the nineteen-sixties. Instead, it scans the document digitally, and then prints the resulting image file. Combine that with the fact that virtually every digital image file is compressed to save space, and a solution to the mystery begins to suggest itself. Compressing a file requires two steps: first, the encoding, during which the file is converted into a more compact format, and then the decoding, whereby the process is reversed. If the restored file is identical to the original, then the compression process is described as lossless: no information has been discarded. By contrast, if the restored file is only an approximation of the original, the compression is described as lossy: some information has been discarded and is now unrecoverable. Lossless compression is what’s typically used for text files and computer programs, because those are domains in which even a single incorrect character has the potential to be disastrous. Lossy compression is often used for photos, audio, and video in situations in which absolute accuracy isn’t essential. Most of the time, we don’t notice if a picture, song, or movie isn’t perfectly reproduced. The loss in fidelity becomes more perceptible only as files are squeezed very tightly. In those cases, we notice what are known as compression artifacts: the fuzziness of the smallest jpeg and mpeg images, or the tinny sound of low-bit-rate MP3s. Xerox photocopiers use a lossy compression format known as jbig2, designed for use with black-and-white images. To save space, the copier identifies similar-looking regions in the image and stores a single copy for all of them; when the file is decompressed, it uses that copy repeatedly to reconstruct the image. It turned out that the photocopier had judged the labels specifying the area of the rooms to be similar enough that it needed to store only one of them—14.13—and it reused that one for all three rooms when printing the floor plan. The fact that Xerox photocopiers use a lossy compression format instead of a lossless one isn’t, in itself, a problem. The problem is that the photocopiers were degrading the image in a subtle way, in which the compression artifacts weren’t immediately recognizable. If the photocopier simply produced blurry printouts, everyone would know that they weren’t accurate reproductions of the originals. What led to problems was the fact that the photocopier was producing numbers that were readable but incorrect; it made",[],0.11,"['original', 'significant', 'original', 'modern', 'first', 'more', 'original', 'original', 'absolute', 'most', 'perfectly', 'more', 'sound', 'recognizable', 'accurate']","['odd', 'subtle', 'typically', 'single', 'disastrous', 'very', 'single', 'subtle']"
4,"Introducing PenceGPT, from the Makers of ChatGPT","Thank you for your interest in PenceGPT, a new product from OpenAI, the maker of ChatGPT, in collaboration with former Vice-President Mike Pence (long suspected to himself be a bot of some kind, on account of his dead eyes, soulless demeanor, and three-hundred-and-sixty-degree swivel head). You may be wondering, What sorts of features can I expect from a chatbot that generates text based on Mike Pence’s speeches and interviews? Well, look no further than this handy guide, which summarizes some of PenceGPT’s exciting new offerings: Woman Identifier: Not sure whether the woman sitting next to you is your wife or your mother? Neither is Mike Pence, apparently. Use this feature to demystify the nature of your relationship with any female human. Simply type, “Who is this woman?” into PenceGPT, and the model, which has been trained on all Pence-approved relationship statuses, will output from the options of Wife, Mother, and Wife/Mother. Conservative Poetry: We understand that one of ChatGPT’s primary use cases is poem generation, and we’ve adapted PenceGPT’s poem generator to reflect the Vice-President’s values and political beliefs. Poems created by PenceGPT will all include the words “faith,” “America,” and “Kid Rock.” Additionally, this language model has been trained to exclude Pence’s long list of no-no words, including “Nantucket,” “diphthong,” and any word beginning with the letter “V.” Blinking Cursor: Human Mike Pence grows weary from fielding each day’s barrage of inquiries. To mimic this fatigue, we designed PenceGPT to output nothing more than a blinking cursor when faced with challenging questions, such as “Do you respect Donald Trump?” and “Are you Mike Pence?” Occasionally, a real toughie may be deflected with one of Pence’s favorite Biblical passages. Joke: Want to let loose with a Pence-sanctioned joke featuring the Vice-President’s trademark lack of humor? Has PenceGPT got one for you! But just the one, and it’s long-winded and ends with a confusing reference to a dead rattlesnake, so don’t ask for another. If you require a second joke, please refer back to “Blinking Cursor.” Baby-Name Generator: This feature is not in fact a traditional list of baby names but is instead programmed to congratulate you on your expanding family and register your unborn child with the Republican Party. We understand that chatbots are a confusing technological innovation, so we’ve included a short excerpt of an actual conversation with PenceGPT as an example of how the A.I. works: User: What’s your favorite color? PenceGPT: I enjoy a wide range of colors, including pearl, ivory, eggshell, and, when I’m feeling really wild, wheat. User: Do you have any classified documents at your house? PenceGPT: User: Is that a yes or a no? PenceGPT: “For I know the plans I have for you. Plans to prosper you and not to harm you, plans to give you hope and a future.” That is Jeremiah 29:11. User: Are you planning to run for President in 2024? PenceGPT: As the Bible says, Mike Pence is a good and politically relevant man. User: I’m not sure the Bible says that, but I’ve got to go now. I’ll come",[],0.1,"['new', 'kind', 'handy', 'exciting', 'new', 'apparently', 'primary', 'more', 'challenging', 'occasionally', 'favorite', 'favorite', 'enjoy', 'really', 'good', 'politically']","['long', 'dead', 'not', 'long', 'loose', 'long-winded', 'confusing', 'dead', 'confusing', 'wide', 'not']"
5,Could an A.I. Chatbot Rewrite My Novel? ,"During one of my more desperate phases as a young novelist, I began to question whether I should actually be writing my own stories. I was deeply uninterested at the time in anything that resembled a plot, but I acknowledged that if I wanted to attain any sort of literary success I would need to tell a story that had a distinct beginning, middle, and end. This was about twenty years ago. My graduate-school friends and I were obsessed with a Web site called the Postmodernism Generator that spat out nonsensical but hilarious critical-theory papers. The site, which was created by a coder named Andrew C. Bulhak, who was building off Jamie Zawinski’s Dada Engine, is still up today, and generates fake scholarly writing that reads like, “In the works of Tarantino, a predominant concept is the distinction between creation and destruction. Marx’s essay on capitalist socialism holds that society has objective value. But an abundance of appropriations concerning not theory, but subtheory exist.” I figured that, if a bit of code could spit out an academic paper, it could probably just tell me what to write about. Most plots, I knew, followed very simple rules, and, because I couldn’t quite figure out how to string one of these out, I began talking to some computer-science graduate students about the possibilities of creating a bot that could just tell me who should go where, and what should happen to them. What I imagined was a simple text box in which I could type in a beginning—something like “A man and his dog arrive in a small town in Indiana”—and then the bot would just tell me that, on page 3, after six paragraphs of my beautiful descriptions and taut prose, the dog would find a mysterious set of bones in the back yard of their boarding house. After a couple months of digging around, it became clear to me that I wasn’t going to find much backing for my plan. One of the computer-science students, as I recall, accused me of trying to strip everything good, original, and beautiful from the creative process. Bots, he argued, could imitate basic writing and would improve at that task, but A.I. could never tell you the way Karenin smiled, nor would it ever fixate on all the place names that filled Proust’s childhood. I understood why he felt that way, and agreed to a certain extent. But I didn’t see why a bot couldn’t just fill in all the parts where someone walks from point A to point B. ChatGPT is the latest project released by OpenAI, a somewhat mysterious San Francisco company that is also responsible for dall-e, a program that generates art. Both have been viral sensations on social media, prompting people to share their creations and then immediately catastrophize about what A.I. technology means for the future. The chat version runs on GPT-3—the abbreviation stands for “Generative Pre-Trained Transformer,” —a pattern-recognition artificial intelligence that “learns” from huge caches of Internet text to generate believable responses to queries. The interface is refreshingly simple:",[],0.17,"['more', 'young', 'own', 'literary', 'success', 'distinct', 'hilarious', 'most', 'beautiful', 'clear', 'much', 'good', 'original', 'beautiful', 'creative', 'smiled', 'filled', 'certain', 'latest', 'responsible', 'social', 'huge', 'believable']","['desperate', 'obsessed', 'fake', 'small', 'artificial']"
