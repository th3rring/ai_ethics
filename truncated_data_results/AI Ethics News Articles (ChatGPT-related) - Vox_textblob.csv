,titles,body_contents,tags,sentiment_score,positive_words,negative_words
0,"The makers of ChatGPT just released a new AI that can build websites, among other things","When ChatGPT came out in November, it took the world by storm. Within a month of its release, some 100 million people had used the viral AI chatbot for everything from writing high school essays to planning travel itineraries to generating computer code. Built by the San Francisco-based startup OpenAI, the app was flawed in many ways, but it also sparked a wave of excitement (and fear) about the transformative power of generative AI to change the way we work and create. ChatGPT, which runs on a technology called GPT-3.5, has been so impressive, in part, because it represents a quantum leap from the capabilities of its predecessor from just a few years ago, GPT-2. On Tuesday, OpenAI released an even more advanced version of its technology: GPT-4. The company says this update is another milestone in the advancement of AI. The new technology has the potential to improve how people learn new languages, how blind people process images, and even how we do our taxes. OpenAI also claims that the new model supports a chatbot that’s more factual, creative, concise, and can understand images, instead of just text. Sam Altman, the CEO of OpenAI, called GPT-4 “our most capable and aligned model yet.” He also cautioned that “it is still flawed, still limited, and it still seems more impressive on first use than it does after you spend more time with it” In a livestream demo of GPT-4 on Tuesday afternoon, OpenAI co-founder and president Greg Brockman showed some new use cases for the technology, including the ability to be given a hand-drawn mockup of a website and, from that, generate code for a functional site in a matter of seconds. Brockman also showcased GPT-4’s visual capabilities by feeding it a cartoon image of a squirrel holding a camera and asking it to explain why the image is funny. “The image is funny because it shows a squirrel holding a camera and taking a photo of a nut as if it were a professional photographer. It’s a humorous situation because squirrels typically eat nuts, and we don’t expect them to use a camera or act like humans,” GPT-4 responded. This is the sort of capability that could be incredibly useful to people who are blind or visually impaired. Not only can GPT-4 describe images, but it can also communicate the meaning and context behind them. Still, as Altman and GPT-4’s creators have been quick to admit, the tool is nowhere near fully replacing human intelligence. Like its predecessors, it has known problems around accuracy, bias, and context. That poses a growing risk as more people start using GPT-4 for more than just novelty. Companies like Microsoft, which invests heavily in OpenAI, are already starting to bake GPT-4 into core products that millions of people use. Here are a few things you need to know about the latest version of the buzziest new technology in the market. It can pass complicated exams One tangible way people are measuring the capabilities of new artificial intelligence tools is by seeing how well they can",[],0.13,"['high', 'many', 'impressive', 'more', 'advanced', 'new', 'new', 'new', 'more', 'creative', 'concise', 'most', 'capable', 'more', 'impressive', 'first', 'more', 'new', 'funny', 'funny', 'professional', 'humorous', 'incredibly', 'quick', 'near', 'more', 'more', 'latest', 'new', 'new']","['flawed', 'few', 'blind', 'flawed', 'limited', 'typically', 'blind', 'behind', 'heavily', 'few', 'complicated', 'artificial']"
1,"If you’re not using ChatGPT for your writing, you’re probably making a mistake","About 10 minutes into my interview with Ethan Mollick, a professor at the University of Pennsylvania’s Wharton business school who has become a prominent evangelist for AI tools, it became clear that he was going to use Bing to interview me. He started by asking the Microsoft search engine, newly infused with a generative AI model from OpenAI, “Can you look at the work of Dylan Matthews of Vox and tell me some common themes, as well as any strengths or weaknesses.” In a couple seconds, Bing had an answer: “Dylan Matthews is one of the senior correspondents at Vox. He covers topics such as effective altruism, philanthropy, global health, and social justice.” (So far, so good.) Dylan “often uses charts, graphs, tables, and quotes from experts and sources to support his arguments,” it continued, but “other Vox writers may have different writing styles and tones depending on their topic and audience.” For instance, “Some may aim to entertain readers with interesting facts or stories,” which I guess is not something the machines think I do. Mollick wasn’t done interrogating. He asked for examples of some of the best praise and criticism of my articles, and unearthed some scathing critiques of an old tongue-in-cheek defense of monarchy I once wrote (“This is a terrible article,” noted one poster. “It’s full of cherry-picked data”), and some nice notes on a feature I wrote about effective altruism last summer. Taking that thread and running with it, Mollick asked Bing for ideas of papers on the topic of effective altruism and some names of journals that might take them; he got three suggestions, with links to previous articles the journals had run on the topic (one journal — notably given generative AI’s occasional tendency to hallucinate false facts — was paired with an article it didn’t run, and an author who did not even write that article). Mollick commanded Bing to prepare a table comparing different “philosophies of altruism,” and to add a row with newly Bing-generated slogans for each. This is what it delivered: While “Survive and thrive by helping your kin” was not the way my evolutionary biology professor in college explained kin selection … it’s a lot catchier than anything you’ll find in a textbook. Neither Ethan Mollick nor Lilach, his equally AI-obsessed research collaborator at Wharton and his spouse, are AI experts by background. Ethan researches and teaches entrepreneurship, while Lilach works on developing interactive simulations meant to help students try out scenarios like job interviews, elevator pitches to investors, running an early-stage startup, and more. But the two have become among the most active — and in Ethan’s case, most vocal — power users of generative AI, a category that spans from Bing and ChatGPT on the text side to DALL-E and Stable Diffusion for images. When she started using ChatGPT, Lilach recalls, “My world fell apart. I thought, ‘This is crazy.’ I couldn’t believe the output it was giving me. I couldn’t believe the feedback it was giving me.” Generative AI has, in a couple of months, gone from",[],0.14,"['prominent', 'clear', 'newly', 'effective', 'social', 'far', 'good', 'interesting', 'best', 'old', 'full', 'nice', 'effective', 'effective', 'notably', 'newly', 'more', 'most', 'most']","['common', 'other', 'scathing', 'terrible', 'previous', 'false', 'active', 'crazy']"
2,How the first chatbot predicted the dangers of AI more than 50 years ago,"It didn’t take long for Microsoft’s new AI-infused search engine chatbot — codenamed “Sydney” — to display a growing list of discomforting behaviors after it was introduced early in February, with weird outbursts ranging from unrequited declarations of love to painting some users as “enemies.” As human-like as some of those exchanges appeared, they probably weren’t the early stirrings of a conscious machine rattling its cage. Instead, Sydney’s outbursts reflect its programming, absorbing huge quantities of digitized language and parroting back what its users ask for. Which is to say, it reflects our online selves back to us. And that shouldn’t have been surprising — chatbots’ habit of mirroring us back to ourselves goes back way further than Sydney’s rumination on whether there is a meaning to being a Bing search engine. In fact, it’s been there since the introduction of the first notable chatbot almost 50 years ago. In 1966, MIT computer scientist Joseph Weizenbaum released ELIZA (named after the fictional Eliza Doolittle from George Bernard Shaw’s 1913 play Pygmalion), the first program that allowed some kind of plausible conversation between humans and machines. The process was simple: Modeled after the Rogerian style of psychotherapy, ELIZA would rephrase whatever speech input it was given in the form of a question. If you told it a conversation with your friend left you angry, it might ask, “Why do you feel angry?” Ironically, though Weizenbaum had designed ELIZA to demonstrate how superficial the state of human-to-machine conversation was, it had the opposite effect. People were entranced, engaging in long, deep, and private conversations with a program that was only capable of reflecting users’ words back to them. Weizenbaum was so disturbed by the public response that he spent the rest of his life warning against the perils of letting computers — and, by extension, the field of AI he helped launch — play too large a role in society. ELIZA built its responses around a single keyword from users, making for a pretty small mirror. Today’s chatbots reflect our tendencies drawn from billions of words. Bing might be the largest mirror humankind has ever constructed, and we’re on the cusp of installing such generative AI technology everywhere. But we still haven’t really addressed Weizenbaum’s concerns, which grow more relevant with each new release. If a simple academic program from the ’60s could affect people so strongly, how will our escalating relationship with artificial intelligences operated for profit change us? There’s great money to be made in engineering AI that does more than just respond to our questions, but plays an active role in bending our behaviors toward greater predictability. These are two-way mirrors. The risk, as Weizenbaum saw, is that without wisdom and deliberation, we might lose ourselves in our own distorted reflection. ELIZA showed us just enough of ourselves to be cathartic Weizenbaum did not believe that any machine could ever actually mimic — let alone understand — human conversation. “There are aspects to human life that a computer cannot understand — cannot,” Weizenbaum told the New York Times in 1977. “It’s",[],0.12,"['new', 'early', 'love', 'early', 'conscious', 'absorbing', 'huge', 'surprising', 'first', 'notable', 'first', 'kind', 'plausible', 'engaging', 'capable', 'large', 'pretty', 'really', 'more', 'relevant', 'new', 'strongly', 'great', 'more', 'greater', 'own', 'new']","['long', 'weird', 'angry', 'angry', 'long', 'spent', 'single', 'small', 'artificial', 'active']"
3,"Here comes Bard, Google’s version of ChatGPT","Under intense pressure to compete with ChatGPT — the buzzy AI chatbot that has become a viral sensation — Google announced on Monday that it’s releasing its own “experimental conversational AI” tool, called “Bard.” The company also said it will add new AI–powered features to Google search. Google will first give Bard access to a group of trusted external partners, according to a company blog post on Monday; it said it plans to give the public access “in the coming weeks.” What the public will have access to starting this week are search results that sometimes show AI-generated text, especially for complex queries. While Google has for years used AI to enhance its products behind the scenes, the company has never released a public-facing version of a conversational chat product. It seems that the breakaway success of ChatGPT — the AI conversation tool created by the startup OpenAI that can auto-generate essays, poetry, and even entire movie scripts, and which amassed 100 million users just two months after it launched — has nudged Google to make this move. Google’s announcement comes a day before Microsoft is expected to announce more details on plans to integrate ChatGPT into its search product, Bing (Microsoft recently invested $10 billion in ChatGPT’s creator, OpenAI). Since ChatGPT came out, Google has faced immense pressure to more publicly showcase its AI technology. Like other big tech companies, Google is overdue for a technological breakthrough akin to its earlier inventions like search, maps, or Gmail — and it’s betting that its next big innovation will be powered by AI. But the company has historically been secretive about the full potential of its AI work, particularly with conversational AI tools, and has only allowed Google employees to test its chatbots internally. This release is a signal that the heated competition has encouraged Google to push its work into the spotlight. “AI is the most profound technology we are working on today,” wrote Google CEO Sundar Pichai in the Monday blog post announcing the changes. “That’s why we re-oriented the company around AI six years ago — and why we see it as the most important way we can deliver on our mission: to organize the world’s information and make it universally accessible and useful.” Google’s blog post said its new AI tool, Bard, “seeks to combine the breadth of the world’s knowledge with the power, intelligence and creativity of our large language models.” Tangibly, that means it can explain new discoveries from NASA’s James Webb Space Telescope in a way that’s understandable for a 9-year-old, or “learn more about the best strikers in football right now, and then get drills to build your skills,” according to the company. Other examples the company gave for Bard were that it can help you plan a friend’s baby shower, compare two Oscar-nominated movies, or get recipe ideas based on what’s in your fridge, according to the release. All of those possibilities sound helpful and convenient for users. However, new technology tends to come with potential downsides, too. Google is one of the most",[],0.16,"['intense', 'own', 'experimental', 'new', 'first', 'success', 'more', 'more', 'full', 'particularly', 'most', 'profound', 'most', 'important', 'universally', 'useful', 'new', 'large', 'new', 'more', 'best', 'right', 'sound', 'new', 'most']","['complex', 'behind', 'expected', 'other', 'other']"
4,What Microsoft gets from betting billions on the maker of ChatGPT,"Microsoft revealed last week that it will lay off 10,000 people throughout 2023. But don’t think that means the company is having money problems. On Monday, the company announced that it’s investing billions of dollars into the hot artificial intelligence platform OpenAI. This is Microsoft’s third investment in the company, and cements Microsoft’s partnership with one of the most exciting companies making one the most exciting technologies today: generative AI. It also shows that Microsoft is committed to making the initiative a key part of its business, as it looks to the future of technology and its place in it. And you can likely expect to see OpenAI’s services in your everyday life as companies you use integrate it into their own offerings. Microsoft told Recode it was not disclosing the deal’s specifics, but Semafor reported two weeks ago that the two companies were talking about $10 billion, with Microsoft getting 75 percent of OpenAI’s profits until it recoups its investment, after which it would have a 49 percent stake in the company. The New York Times has since confirmed the $10 billion amount. With the arrangement, OpenAI runs and powers its technology through Microsoft’s Azure cloud computing platform, which allows it to scale and make it available to developers and companies looking to use AI in their own services (rather than have to build their own). Think of it as AIaaS — AI as a service. Microsoft recently made its OpenAI services widely available, allowing more businesses to integrate some of the hottest AI technologies, including word generator ChatGPT and image generator DALL-E 2, into their own companies’ offerings. Meanwhile, OpenAI also gets a needed cash infusion — key for a company with a lot of potential but not much to show in terms of monetization. And Microsoft can offer something to its cloud customers that rivals Google and Amazon can’t yet: one of the most advanced AI technologies out there, as well as one of the buzziest. They do have their own AI initiatives, like Google’s DeepMind, which is reportedly rolling out a ChatGPT rival at some point. But it’s not here yet. ChatGPT is, and it’s gone mainstream. OpenAI was founded in 2015 as a research laboratory, with backing from Silicon Valley heavyweights, including Peter Thiel, Elon Musk, and Reid Hoffman. Sam Altman, former president of startup incubator Y Combinator, is its CEO and co-founder. The company has pushed its commitment to developing “safe” and “responsible” AI technologies since the beginning; there is a longstanding fear, among some, that if artificial intelligence gets too intelligent, it’ll go SkyNet on all of us. Microsoft stepped in at the end of 2019 with a $1 billion investment in and partnership with OpenAI to help the company continue to develop artificial general intelligence (AGI) — that is, AI that can also learn and perform new tasks. “We believe it’s crucial that AGI is deployed safely and securely and that its economic benefits are widely distributed. We are excited about how deeply Microsoft shares this vision,” Altman said at the time. The arrangement",[],0.2,"['hot', 'most', 'exciting', 'most', 'exciting', 'own', 'new', 'confirmed', 'available', 'own', 'own', 'widely', 'more', 'own', 'most', 'advanced', 'own', 'safe', 'responsible', 'intelligent', 'general', 'new', 'safely', 'securely', 'economic', 'excited']","['artificial', 'everyday', 'not', 'artificial', 'artificial', 'widely']"
5,ChatGPT has given everyone a glimpse at AI’s astounding progress,"There’s a new AI chatbot to check out — provided the servers that host it aren’t down from overwhelming traffic. Since ChatGPT launched last week, more than a million people have signed up to use it, according to OpenAI’s president, Greg Brockman. It’s a funny, inventive, engaging, and totally untrustworthy conversation partner, and I highly recommend you check it out when the servers aren’t staggered under the load. Other writers have had a ball getting ChatGPT to, say, write a rap battle between antibodies and small molecule groups, or a Seinfeld script where Jerry learns about the bubble sort algorithm. But there’s no funny AI-generated text here for you today, just some thoughts on ChatGPT and where we’re headed. A few weeks ago, I wrote about the stunning recent advances in AI, and I quoted Google executive Mo Gawdat, who tells the story of how he became concerned about general AI after he saw robotics researchers working on an AI that could pick up a ball: After many failures, the AI grabbed the ball and held it up to the researchers, eerily humanlike. “And I suddenly realized this is really scary,” Gawdat said. “It completely froze me. … The reality is we’re creating God.” Many people working on AI systems have had a moment like that at one point or another over the past few years — a moment of awe mixed with dread when it suddenly became clear to them that humanity is on the verge of something truly enormous. But for the general public, before 2022, there was little chance to come face to face with what AI is capable of. It was possible to play with OpenAI’s GPT-3 model, but on a relatively inaccessible site with lots of confusing user settings. It was possible to talk with chatbots like Meta’s Blenderbot, but Blenderbot was really, really dumb. So ChatGPT is the general public’s first hands-on introduction to how powerful modern AI has gotten, and as a result, many of us are having our version of the Gawdat moment. ChatGPT, by default, sounds like a college student producing an essay for class (and its most immediate implication is that such essays will likely become a thing of the past). But it doesn’t have to sound like that; tell it to clean up its essays in the New Yorker house style, and it writes better. Tell it to write Shakespeare, and it’ll try (the cadence of anything meant to be spoken is generally not very good, so good luck with iambic pentameter). It is particularly good for rephrasing great philosophers or great works of literature in the vernacular of a 1920s mobster or a 1990s rapper; it can be funny, though it’s never clear how intentionally. “This is big,” I have heard from multiple people who were previously AI-skeptical. The First Law: Don’t get canceled It’s still far from perfect. Despite OpenAI’s best efforts, ChatGPT still frequently makes up nonsense and still sometimes can be coaxed into saying racist or hateful things. And as part of a desperate effort to train",[],0.14,"['new', 'overwhelming', 'more', 'funny', 'inventive', 'engaging', 'highly', 'stunning', 'general', 'many', 'completely', 'many', 'clear', 'general', 'capable', 'general', 'first', 'powerful', 'modern', 'many', 'most', 'sound', 'clean', 'new', 'better', 'good', 'particularly', 'great', 'great', 'funny', 'first', 'far', 'perfect', 'best', 'frequently']","['down', 'other', 'small', 'no', 'few', 'really', 'past', 'few', 'little', 'confusing', 'really', 'past', 'generally', 'never', 'previously', 'desperate']"
